// SPDX-License-Identifier: MIT
// Copyright (C) 2018-present iced project and contributors

// ‚ö†Ô∏èThis file was generated by GENERATOR!ü¶π‚Äç‚ôÇÔ∏è

#pragma once
#ifndef ICED_X86_CODE_HPP
#define ICED_X86_CODE_HPP

#include <cstdint>
#include <cstddef>

namespace iced_x86 {

/// @brief x86 instruction code
enum class Code : uint16_t {
	/// @brief It's an invalid instruction, eg. it's a new unknown instruction, garbage or there's not enough bytes to decode the instruction etc.
	INVALID = 0,
	/// @brief A @c db/@c .byte asm directive that can store 1-16 bytes
	DECLARE_BYTE = 1,
	/// @brief A @c dw/@c .word asm directive that can store 1-8 words
	DECLARE_WORD = 2,
	/// @brief A @c dd/@c .int asm directive that can store 1-4 dwords
	DECLARE_DWORD = 3,
	/// @brief A @c dq/@c .quad asm directive that can store 1-2 qwords
	DECLARE_QWORD = 4,
	/// @brief @c ADD r/m8, r8
	/// @par
	/// @c 00 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	ADD_RM8_R8 = 5,
	/// @brief @c ADD r/m16, r16
	/// @par
	/// @c o16 01 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	ADD_RM16_R16 = 6,
	/// @brief @c ADD r/m32, r32
	/// @par
	/// @c o32 01 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	ADD_RM32_R32 = 7,
	/// @brief @c ADD r/m64, r64
	/// @par
	/// @c o64 01 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	ADD_RM64_R64 = 8,
	/// @brief @c ADD r8, r/m8
	/// @par
	/// @c 02 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	ADD_R8_RM8 = 9,
	/// @brief @c ADD r16, r/m16
	/// @par
	/// @c o16 03 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	ADD_R16_RM16 = 10,
	/// @brief @c ADD r32, r/m32
	/// @par
	/// @c o32 03 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	ADD_R32_RM32 = 11,
	/// @brief @c ADD r64, r/m64
	/// @par
	/// @c o64 03 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	ADD_R64_RM64 = 12,
	/// @brief @c ADD AL, imm8
	/// @par
	/// @c 04 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	ADD_AL_IMM8 = 13,
	/// @brief @c ADD AX, imm16
	/// @par
	/// @c o16 05 iw
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	ADD_AX_IMM16 = 14,
	/// @brief @c ADD EAX, imm32
	/// @par
	/// @c o32 05 id
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	ADD_EAX_IMM32 = 15,
	/// @brief @c ADD RAX, imm32
	/// @par
	/// @c o64 05 id
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	ADD_RAX_IMM32 = 16,
	/// @brief @c PUSH ES
	/// @par
	/// @c o16 06
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	PUSHW_ES = 17,
	/// @brief @c PUSH ES
	/// @par
	/// @c o32 06
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	PUSHD_ES = 18,
	/// @brief @c POP ES
	/// @par
	/// @c o16 07
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	POPW_ES = 19,
	/// @brief @c POP ES
	/// @par
	/// @c o32 07
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	POPD_ES = 20,
	/// @brief @c OR r/m8, r8
	/// @par
	/// @c 08 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	OR_RM8_R8 = 21,
	/// @brief @c OR r/m16, r16
	/// @par
	/// @c o16 09 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	OR_RM16_R16 = 22,
	/// @brief @c OR r/m32, r32
	/// @par
	/// @c o32 09 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	OR_RM32_R32 = 23,
	/// @brief @c OR r/m64, r64
	/// @par
	/// @c o64 09 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	OR_RM64_R64 = 24,
	/// @brief @c OR r8, r/m8
	/// @par
	/// @c 0A /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	OR_R8_RM8 = 25,
	/// @brief @c OR r16, r/m16
	/// @par
	/// @c o16 0B /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	OR_R16_RM16 = 26,
	/// @brief @c OR r32, r/m32
	/// @par
	/// @c o32 0B /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	OR_R32_RM32 = 27,
	/// @brief @c OR r64, r/m64
	/// @par
	/// @c o64 0B /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	OR_R64_RM64 = 28,
	/// @brief @c OR AL, imm8
	/// @par
	/// @c 0C ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	OR_AL_IMM8 = 29,
	/// @brief @c OR AX, imm16
	/// @par
	/// @c o16 0D iw
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	OR_AX_IMM16 = 30,
	/// @brief @c OR EAX, imm32
	/// @par
	/// @c o32 0D id
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	OR_EAX_IMM32 = 31,
	/// @brief @c OR RAX, imm32
	/// @par
	/// @c o64 0D id
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	OR_RAX_IMM32 = 32,
	/// @brief @c PUSH CS
	/// @par
	/// @c o16 0E
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	PUSHW_CS = 33,
	/// @brief @c PUSH CS
	/// @par
	/// @c o32 0E
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	PUSHD_CS = 34,
	/// @brief @c POP CS
	/// @par
	/// @c o16 0F
	/// @par
	/// @c 8086
	/// @par
	/// @c 16-bit
	POPW_CS = 35,
	/// @brief @c ADC r/m8, r8
	/// @par
	/// @c 10 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	ADC_RM8_R8 = 36,
	/// @brief @c ADC r/m16, r16
	/// @par
	/// @c o16 11 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	ADC_RM16_R16 = 37,
	/// @brief @c ADC r/m32, r32
	/// @par
	/// @c o32 11 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	ADC_RM32_R32 = 38,
	/// @brief @c ADC r/m64, r64
	/// @par
	/// @c o64 11 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	ADC_RM64_R64 = 39,
	/// @brief @c ADC r8, r/m8
	/// @par
	/// @c 12 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	ADC_R8_RM8 = 40,
	/// @brief @c ADC r16, r/m16
	/// @par
	/// @c o16 13 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	ADC_R16_RM16 = 41,
	/// @brief @c ADC r32, r/m32
	/// @par
	/// @c o32 13 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	ADC_R32_RM32 = 42,
	/// @brief @c ADC r64, r/m64
	/// @par
	/// @c o64 13 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	ADC_R64_RM64 = 43,
	/// @brief @c ADC AL, imm8
	/// @par
	/// @c 14 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	ADC_AL_IMM8 = 44,
	/// @brief @c ADC AX, imm16
	/// @par
	/// @c o16 15 iw
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	ADC_AX_IMM16 = 45,
	/// @brief @c ADC EAX, imm32
	/// @par
	/// @c o32 15 id
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	ADC_EAX_IMM32 = 46,
	/// @brief @c ADC RAX, imm32
	/// @par
	/// @c o64 15 id
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	ADC_RAX_IMM32 = 47,
	/// @brief @c PUSH SS
	/// @par
	/// @c o16 16
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	PUSHW_SS = 48,
	/// @brief @c PUSH SS
	/// @par
	/// @c o32 16
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	PUSHD_SS = 49,
	/// @brief @c POP SS
	/// @par
	/// @c o16 17
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	POPW_SS = 50,
	/// @brief @c POP SS
	/// @par
	/// @c o32 17
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	POPD_SS = 51,
	/// @brief @c SBB r/m8, r8
	/// @par
	/// @c 18 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SBB_RM8_R8 = 52,
	/// @brief @c SBB r/m16, r16
	/// @par
	/// @c o16 19 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SBB_RM16_R16 = 53,
	/// @brief @c SBB r/m32, r32
	/// @par
	/// @c o32 19 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SBB_RM32_R32 = 54,
	/// @brief @c SBB r/m64, r64
	/// @par
	/// @c o64 19 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SBB_RM64_R64 = 55,
	/// @brief @c SBB r8, r/m8
	/// @par
	/// @c 1A /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SBB_R8_RM8 = 56,
	/// @brief @c SBB r16, r/m16
	/// @par
	/// @c o16 1B /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SBB_R16_RM16 = 57,
	/// @brief @c SBB r32, r/m32
	/// @par
	/// @c o32 1B /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SBB_R32_RM32 = 58,
	/// @brief @c SBB r64, r/m64
	/// @par
	/// @c o64 1B /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SBB_R64_RM64 = 59,
	/// @brief @c SBB AL, imm8
	/// @par
	/// @c 1C ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SBB_AL_IMM8 = 60,
	/// @brief @c SBB AX, imm16
	/// @par
	/// @c o16 1D iw
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SBB_AX_IMM16 = 61,
	/// @brief @c SBB EAX, imm32
	/// @par
	/// @c o32 1D id
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SBB_EAX_IMM32 = 62,
	/// @brief @c SBB RAX, imm32
	/// @par
	/// @c o64 1D id
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SBB_RAX_IMM32 = 63,
	/// @brief @c PUSH DS
	/// @par
	/// @c o16 1E
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	PUSHW_DS = 64,
	/// @brief @c PUSH DS
	/// @par
	/// @c o32 1E
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	PUSHD_DS = 65,
	/// @brief @c POP DS
	/// @par
	/// @c o16 1F
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	POPW_DS = 66,
	/// @brief @c POP DS
	/// @par
	/// @c o32 1F
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	POPD_DS = 67,
	/// @brief @c AND r/m8, r8
	/// @par
	/// @c 20 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	AND_RM8_R8 = 68,
	/// @brief @c AND r/m16, r16
	/// @par
	/// @c o16 21 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	AND_RM16_R16 = 69,
	/// @brief @c AND r/m32, r32
	/// @par
	/// @c o32 21 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	AND_RM32_R32 = 70,
	/// @brief @c AND r/m64, r64
	/// @par
	/// @c o64 21 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	AND_RM64_R64 = 71,
	/// @brief @c AND r8, r/m8
	/// @par
	/// @c 22 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	AND_R8_RM8 = 72,
	/// @brief @c AND r16, r/m16
	/// @par
	/// @c o16 23 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	AND_R16_RM16 = 73,
	/// @brief @c AND r32, r/m32
	/// @par
	/// @c o32 23 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	AND_R32_RM32 = 74,
	/// @brief @c AND r64, r/m64
	/// @par
	/// @c o64 23 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	AND_R64_RM64 = 75,
	/// @brief @c AND AL, imm8
	/// @par
	/// @c 24 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	AND_AL_IMM8 = 76,
	/// @brief @c AND AX, imm16
	/// @par
	/// @c o16 25 iw
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	AND_AX_IMM16 = 77,
	/// @brief @c AND EAX, imm32
	/// @par
	/// @c o32 25 id
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	AND_EAX_IMM32 = 78,
	/// @brief @c AND RAX, imm32
	/// @par
	/// @c o64 25 id
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	AND_RAX_IMM32 = 79,
	/// @brief @c DAA
	/// @par
	/// @c 27
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	DAA = 80,
	/// @brief @c SUB r/m8, r8
	/// @par
	/// @c 28 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SUB_RM8_R8 = 81,
	/// @brief @c SUB r/m16, r16
	/// @par
	/// @c o16 29 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SUB_RM16_R16 = 82,
	/// @brief @c SUB r/m32, r32
	/// @par
	/// @c o32 29 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SUB_RM32_R32 = 83,
	/// @brief @c SUB r/m64, r64
	/// @par
	/// @c o64 29 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SUB_RM64_R64 = 84,
	/// @brief @c SUB r8, r/m8
	/// @par
	/// @c 2A /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SUB_R8_RM8 = 85,
	/// @brief @c SUB r16, r/m16
	/// @par
	/// @c o16 2B /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SUB_R16_RM16 = 86,
	/// @brief @c SUB r32, r/m32
	/// @par
	/// @c o32 2B /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SUB_R32_RM32 = 87,
	/// @brief @c SUB r64, r/m64
	/// @par
	/// @c o64 2B /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SUB_R64_RM64 = 88,
	/// @brief @c SUB AL, imm8
	/// @par
	/// @c 2C ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SUB_AL_IMM8 = 89,
	/// @brief @c SUB AX, imm16
	/// @par
	/// @c o16 2D iw
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SUB_AX_IMM16 = 90,
	/// @brief @c SUB EAX, imm32
	/// @par
	/// @c o32 2D id
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SUB_EAX_IMM32 = 91,
	/// @brief @c SUB RAX, imm32
	/// @par
	/// @c o64 2D id
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SUB_RAX_IMM32 = 92,
	/// @brief @c DAS
	/// @par
	/// @c 2F
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	DAS = 93,
	/// @brief @c XOR r/m8, r8
	/// @par
	/// @c 30 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	XOR_RM8_R8 = 94,
	/// @brief @c XOR r/m16, r16
	/// @par
	/// @c o16 31 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	XOR_RM16_R16 = 95,
	/// @brief @c XOR r/m32, r32
	/// @par
	/// @c o32 31 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	XOR_RM32_R32 = 96,
	/// @brief @c XOR r/m64, r64
	/// @par
	/// @c o64 31 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	XOR_RM64_R64 = 97,
	/// @brief @c XOR r8, r/m8
	/// @par
	/// @c 32 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	XOR_R8_RM8 = 98,
	/// @brief @c XOR r16, r/m16
	/// @par
	/// @c o16 33 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	XOR_R16_RM16 = 99,
	/// @brief @c XOR r32, r/m32
	/// @par
	/// @c o32 33 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	XOR_R32_RM32 = 100,
	/// @brief @c XOR r64, r/m64
	/// @par
	/// @c o64 33 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	XOR_R64_RM64 = 101,
	/// @brief @c XOR AL, imm8
	/// @par
	/// @c 34 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	XOR_AL_IMM8 = 102,
	/// @brief @c XOR AX, imm16
	/// @par
	/// @c o16 35 iw
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	XOR_AX_IMM16 = 103,
	/// @brief @c XOR EAX, imm32
	/// @par
	/// @c o32 35 id
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	XOR_EAX_IMM32 = 104,
	/// @brief @c XOR RAX, imm32
	/// @par
	/// @c o64 35 id
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	XOR_RAX_IMM32 = 105,
	/// @brief @c AAA
	/// @par
	/// @c 37
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	AAA = 106,
	/// @brief @c CMP r/m8, r8
	/// @par
	/// @c 38 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	CMP_RM8_R8 = 107,
	/// @brief @c CMP r/m16, r16
	/// @par
	/// @c o16 39 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	CMP_RM16_R16 = 108,
	/// @brief @c CMP r/m32, r32
	/// @par
	/// @c o32 39 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	CMP_RM32_R32 = 109,
	/// @brief @c CMP r/m64, r64
	/// @par
	/// @c o64 39 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	CMP_RM64_R64 = 110,
	/// @brief @c CMP r8, r/m8
	/// @par
	/// @c 3A /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	CMP_R8_RM8 = 111,
	/// @brief @c CMP r16, r/m16
	/// @par
	/// @c o16 3B /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	CMP_R16_RM16 = 112,
	/// @brief @c CMP r32, r/m32
	/// @par
	/// @c o32 3B /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	CMP_R32_RM32 = 113,
	/// @brief @c CMP r64, r/m64
	/// @par
	/// @c o64 3B /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	CMP_R64_RM64 = 114,
	/// @brief @c CMP AL, imm8
	/// @par
	/// @c 3C ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	CMP_AL_IMM8 = 115,
	/// @brief @c CMP AX, imm16
	/// @par
	/// @c o16 3D iw
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	CMP_AX_IMM16 = 116,
	/// @brief @c CMP EAX, imm32
	/// @par
	/// @c o32 3D id
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	CMP_EAX_IMM32 = 117,
	/// @brief @c CMP RAX, imm32
	/// @par
	/// @c o64 3D id
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	CMP_RAX_IMM32 = 118,
	/// @brief @c AAS
	/// @par
	/// @c 3F
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	AAS = 119,
	/// @brief @c INC r16
	/// @par
	/// @c o16 40+rw
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	INC_R16 = 120,
	/// @brief @c INC r32
	/// @par
	/// @c o32 40+rd
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	INC_R32 = 121,
	/// @brief @c DEC r16
	/// @par
	/// @c o16 48+rw
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	DEC_R16 = 122,
	/// @brief @c DEC r32
	/// @par
	/// @c o32 48+rd
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	DEC_R32 = 123,
	/// @brief @c PUSH r16
	/// @par
	/// @c o16 50+rw
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	PUSH_R16 = 124,
	/// @brief @c PUSH r32
	/// @par
	/// @c o32 50+rd
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	PUSH_R32 = 125,
	/// @brief @c PUSH r64
	/// @par
	/// @c o64 50+ro
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	PUSH_R64 = 126,
	/// @brief @c POP r16
	/// @par
	/// @c o16 58+rw
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	POP_R16 = 127,
	/// @brief @c POP r32
	/// @par
	/// @c o32 58+rd
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	POP_R32 = 128,
	/// @brief @c POP r64
	/// @par
	/// @c o64 58+ro
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	POP_R64 = 129,
	/// @brief @c PUSHA
	/// @par
	/// @c o16 60
	/// @par
	/// @c 186+
	/// @par
	/// @c 16/32-bit
	PUSHAW = 130,
	/// @brief @c PUSHAD
	/// @par
	/// @c o32 60
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	PUSHAD = 131,
	/// @brief @c POPA
	/// @par
	/// @c o16 61
	/// @par
	/// @c 186+
	/// @par
	/// @c 16/32-bit
	POPAW = 132,
	/// @brief @c POPAD
	/// @par
	/// @c o32 61
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	POPAD = 133,
	/// @brief @c BOUND r16, m16&16
	/// @par
	/// @c o16 62 /r
	/// @par
	/// @c 186+
	/// @par
	/// @c 16/32-bit
	BOUND_R16_M1616 = 134,
	/// @brief @c BOUND r32, m32&32
	/// @par
	/// @c o32 62 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	BOUND_R32_M3232 = 135,
	/// @brief @c ARPL r/m16, r16
	/// @par
	/// @c o16 63 /r
	/// @par
	/// @c 286+
	/// @par
	/// @c 16/32-bit
	ARPL_RM16_R16 = 136,
	/// @brief @c ARPL r32/m16, r32
	/// @par
	/// @c o32 63 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	ARPL_R32M16_R32 = 137,
	/// @brief @c MOVSXD r16, r/m16
	/// @par
	/// @c o16 63 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	MOVSXD_R16_RM16 = 138,
	/// @brief @c MOVSXD r32, r/m32
	/// @par
	/// @c o32 63 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	MOVSXD_R32_RM32 = 139,
	/// @brief @c MOVSXD r64, r/m32
	/// @par
	/// @c o64 63 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	MOVSXD_R64_RM32 = 140,
	/// @brief @c PUSH imm16
	/// @par
	/// @c o16 68 iw
	/// @par
	/// @c 186+
	/// @par
	/// @c 16/32/64-bit
	PUSH_IMM16 = 141,
	/// @brief @c PUSH imm32
	/// @par
	/// @c o32 68 id
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	PUSHD_IMM32 = 142,
	/// @brief @c PUSH imm32
	/// @par
	/// @c o64 68 id
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	PUSHQ_IMM32 = 143,
	/// @brief @c IMUL r16, r/m16, imm16
	/// @par
	/// @c o16 69 /r iw
	/// @par
	/// @c 186+
	/// @par
	/// @c 16/32/64-bit
	IMUL_R16_RM16_IMM16 = 144,
	/// @brief @c IMUL r32, r/m32, imm32
	/// @par
	/// @c o32 69 /r id
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	IMUL_R32_RM32_IMM32 = 145,
	/// @brief @c IMUL r64, r/m64, imm32
	/// @par
	/// @c o64 69 /r id
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	IMUL_R64_RM64_IMM32 = 146,
	/// @brief @c PUSH imm8
	/// @par
	/// @c o16 6A ib
	/// @par
	/// @c 186+
	/// @par
	/// @c 16/32/64-bit
	PUSHW_IMM8 = 147,
	/// @brief @c PUSH imm8
	/// @par
	/// @c o32 6A ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	PUSHD_IMM8 = 148,
	/// @brief @c PUSH imm8
	/// @par
	/// @c o64 6A ib
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	PUSHQ_IMM8 = 149,
	/// @brief @c IMUL r16, r/m16, imm8
	/// @par
	/// @c o16 6B /r ib
	/// @par
	/// @c 186+
	/// @par
	/// @c 16/32/64-bit
	IMUL_R16_RM16_IMM8 = 150,
	/// @brief @c IMUL r32, r/m32, imm8
	/// @par
	/// @c o32 6B /r ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	IMUL_R32_RM32_IMM8 = 151,
	/// @brief @c IMUL r64, r/m64, imm8
	/// @par
	/// @c o64 6B /r ib
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	IMUL_R64_RM64_IMM8 = 152,
	/// @brief @c INSB
	/// @par
	/// @c 6C
	/// @par
	/// @c 186+
	/// @par
	/// @c 16/32/64-bit
	INSB_M8_DX = 153,
	/// @brief @c INSW
	/// @par
	/// @c o16 6D
	/// @par
	/// @c 186+
	/// @par
	/// @c 16/32/64-bit
	INSW_M16_DX = 154,
	/// @brief @c INSD
	/// @par
	/// @c o32 6D
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	INSD_M32_DX = 155,
	/// @brief @c OUTSB
	/// @par
	/// @c 6E
	/// @par
	/// @c 186+
	/// @par
	/// @c 16/32/64-bit
	OUTSB_DX_M8 = 156,
	/// @brief @c OUTSW
	/// @par
	/// @c o16 6F
	/// @par
	/// @c 186+
	/// @par
	/// @c 16/32/64-bit
	OUTSW_DX_M16 = 157,
	/// @brief @c OUTSD
	/// @par
	/// @c o32 6F
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	OUTSD_DX_M32 = 158,
	/// @brief @c JO rel8
	/// @par
	/// @c o16 70 cb
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	JO_REL8_16 = 159,
	/// @brief @c JO rel8
	/// @par
	/// @c o32 70 cb
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JO_REL8_32 = 160,
	/// @brief @c JO rel8
	/// @par
	/// @c o64 70 cb
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JO_REL8_64 = 161,
	/// @brief @c JNO rel8
	/// @par
	/// @c o16 71 cb
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	JNO_REL8_16 = 162,
	/// @brief @c JNO rel8
	/// @par
	/// @c o32 71 cb
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JNO_REL8_32 = 163,
	/// @brief @c JNO rel8
	/// @par
	/// @c o64 71 cb
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JNO_REL8_64 = 164,
	/// @brief @c JB rel8
	/// @par
	/// @c o16 72 cb
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	JB_REL8_16 = 165,
	/// @brief @c JB rel8
	/// @par
	/// @c o32 72 cb
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JB_REL8_32 = 166,
	/// @brief @c JB rel8
	/// @par
	/// @c o64 72 cb
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JB_REL8_64 = 167,
	/// @brief @c JAE rel8
	/// @par
	/// @c o16 73 cb
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	JAE_REL8_16 = 168,
	/// @brief @c JAE rel8
	/// @par
	/// @c o32 73 cb
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JAE_REL8_32 = 169,
	/// @brief @c JAE rel8
	/// @par
	/// @c o64 73 cb
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JAE_REL8_64 = 170,
	/// @brief @c JE rel8
	/// @par
	/// @c o16 74 cb
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	JE_REL8_16 = 171,
	/// @brief @c JE rel8
	/// @par
	/// @c o32 74 cb
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JE_REL8_32 = 172,
	/// @brief @c JE rel8
	/// @par
	/// @c o64 74 cb
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JE_REL8_64 = 173,
	/// @brief @c JNE rel8
	/// @par
	/// @c o16 75 cb
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	JNE_REL8_16 = 174,
	/// @brief @c JNE rel8
	/// @par
	/// @c o32 75 cb
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JNE_REL8_32 = 175,
	/// @brief @c JNE rel8
	/// @par
	/// @c o64 75 cb
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JNE_REL8_64 = 176,
	/// @brief @c JBE rel8
	/// @par
	/// @c o16 76 cb
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	JBE_REL8_16 = 177,
	/// @brief @c JBE rel8
	/// @par
	/// @c o32 76 cb
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JBE_REL8_32 = 178,
	/// @brief @c JBE rel8
	/// @par
	/// @c o64 76 cb
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JBE_REL8_64 = 179,
	/// @brief @c JA rel8
	/// @par
	/// @c o16 77 cb
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	JA_REL8_16 = 180,
	/// @brief @c JA rel8
	/// @par
	/// @c o32 77 cb
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JA_REL8_32 = 181,
	/// @brief @c JA rel8
	/// @par
	/// @c o64 77 cb
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JA_REL8_64 = 182,
	/// @brief @c JS rel8
	/// @par
	/// @c o16 78 cb
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	JS_REL8_16 = 183,
	/// @brief @c JS rel8
	/// @par
	/// @c o32 78 cb
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JS_REL8_32 = 184,
	/// @brief @c JS rel8
	/// @par
	/// @c o64 78 cb
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JS_REL8_64 = 185,
	/// @brief @c JNS rel8
	/// @par
	/// @c o16 79 cb
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	JNS_REL8_16 = 186,
	/// @brief @c JNS rel8
	/// @par
	/// @c o32 79 cb
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JNS_REL8_32 = 187,
	/// @brief @c JNS rel8
	/// @par
	/// @c o64 79 cb
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JNS_REL8_64 = 188,
	/// @brief @c JP rel8
	/// @par
	/// @c o16 7A cb
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	JP_REL8_16 = 189,
	/// @brief @c JP rel8
	/// @par
	/// @c o32 7A cb
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JP_REL8_32 = 190,
	/// @brief @c JP rel8
	/// @par
	/// @c o64 7A cb
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JP_REL8_64 = 191,
	/// @brief @c JNP rel8
	/// @par
	/// @c o16 7B cb
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	JNP_REL8_16 = 192,
	/// @brief @c JNP rel8
	/// @par
	/// @c o32 7B cb
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JNP_REL8_32 = 193,
	/// @brief @c JNP rel8
	/// @par
	/// @c o64 7B cb
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JNP_REL8_64 = 194,
	/// @brief @c JL rel8
	/// @par
	/// @c o16 7C cb
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	JL_REL8_16 = 195,
	/// @brief @c JL rel8
	/// @par
	/// @c o32 7C cb
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JL_REL8_32 = 196,
	/// @brief @c JL rel8
	/// @par
	/// @c o64 7C cb
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JL_REL8_64 = 197,
	/// @brief @c JGE rel8
	/// @par
	/// @c o16 7D cb
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	JGE_REL8_16 = 198,
	/// @brief @c JGE rel8
	/// @par
	/// @c o32 7D cb
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JGE_REL8_32 = 199,
	/// @brief @c JGE rel8
	/// @par
	/// @c o64 7D cb
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JGE_REL8_64 = 200,
	/// @brief @c JLE rel8
	/// @par
	/// @c o16 7E cb
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	JLE_REL8_16 = 201,
	/// @brief @c JLE rel8
	/// @par
	/// @c o32 7E cb
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JLE_REL8_32 = 202,
	/// @brief @c JLE rel8
	/// @par
	/// @c o64 7E cb
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JLE_REL8_64 = 203,
	/// @brief @c JG rel8
	/// @par
	/// @c o16 7F cb
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	JG_REL8_16 = 204,
	/// @brief @c JG rel8
	/// @par
	/// @c o32 7F cb
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JG_REL8_32 = 205,
	/// @brief @c JG rel8
	/// @par
	/// @c o64 7F cb
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JG_REL8_64 = 206,
	/// @brief @c ADD r/m8, imm8
	/// @par
	/// @c 80 /0 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	ADD_RM8_IMM8 = 207,
	/// @brief @c OR r/m8, imm8
	/// @par
	/// @c 80 /1 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	OR_RM8_IMM8 = 208,
	/// @brief @c ADC r/m8, imm8
	/// @par
	/// @c 80 /2 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	ADC_RM8_IMM8 = 209,
	/// @brief @c SBB r/m8, imm8
	/// @par
	/// @c 80 /3 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SBB_RM8_IMM8 = 210,
	/// @brief @c AND r/m8, imm8
	/// @par
	/// @c 80 /4 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	AND_RM8_IMM8 = 211,
	/// @brief @c SUB r/m8, imm8
	/// @par
	/// @c 80 /5 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SUB_RM8_IMM8 = 212,
	/// @brief @c XOR r/m8, imm8
	/// @par
	/// @c 80 /6 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	XOR_RM8_IMM8 = 213,
	/// @brief @c CMP r/m8, imm8
	/// @par
	/// @c 80 /7 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	CMP_RM8_IMM8 = 214,
	/// @brief @c ADD r/m16, imm16
	/// @par
	/// @c o16 81 /0 iw
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	ADD_RM16_IMM16 = 215,
	/// @brief @c ADD r/m32, imm32
	/// @par
	/// @c o32 81 /0 id
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	ADD_RM32_IMM32 = 216,
	/// @brief @c ADD r/m64, imm32
	/// @par
	/// @c o64 81 /0 id
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	ADD_RM64_IMM32 = 217,
	/// @brief @c OR r/m16, imm16
	/// @par
	/// @c o16 81 /1 iw
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	OR_RM16_IMM16 = 218,
	/// @brief @c OR r/m32, imm32
	/// @par
	/// @c o32 81 /1 id
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	OR_RM32_IMM32 = 219,
	/// @brief @c OR r/m64, imm32
	/// @par
	/// @c o64 81 /1 id
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	OR_RM64_IMM32 = 220,
	/// @brief @c ADC r/m16, imm16
	/// @par
	/// @c o16 81 /2 iw
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	ADC_RM16_IMM16 = 221,
	/// @brief @c ADC r/m32, imm32
	/// @par
	/// @c o32 81 /2 id
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	ADC_RM32_IMM32 = 222,
	/// @brief @c ADC r/m64, imm32
	/// @par
	/// @c o64 81 /2 id
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	ADC_RM64_IMM32 = 223,
	/// @brief @c SBB r/m16, imm16
	/// @par
	/// @c o16 81 /3 iw
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SBB_RM16_IMM16 = 224,
	/// @brief @c SBB r/m32, imm32
	/// @par
	/// @c o32 81 /3 id
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SBB_RM32_IMM32 = 225,
	/// @brief @c SBB r/m64, imm32
	/// @par
	/// @c o64 81 /3 id
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SBB_RM64_IMM32 = 226,
	/// @brief @c AND r/m16, imm16
	/// @par
	/// @c o16 81 /4 iw
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	AND_RM16_IMM16 = 227,
	/// @brief @c AND r/m32, imm32
	/// @par
	/// @c o32 81 /4 id
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	AND_RM32_IMM32 = 228,
	/// @brief @c AND r/m64, imm32
	/// @par
	/// @c o64 81 /4 id
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	AND_RM64_IMM32 = 229,
	/// @brief @c SUB r/m16, imm16
	/// @par
	/// @c o16 81 /5 iw
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SUB_RM16_IMM16 = 230,
	/// @brief @c SUB r/m32, imm32
	/// @par
	/// @c o32 81 /5 id
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SUB_RM32_IMM32 = 231,
	/// @brief @c SUB r/m64, imm32
	/// @par
	/// @c o64 81 /5 id
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SUB_RM64_IMM32 = 232,
	/// @brief @c XOR r/m16, imm16
	/// @par
	/// @c o16 81 /6 iw
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	XOR_RM16_IMM16 = 233,
	/// @brief @c XOR r/m32, imm32
	/// @par
	/// @c o32 81 /6 id
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	XOR_RM32_IMM32 = 234,
	/// @brief @c XOR r/m64, imm32
	/// @par
	/// @c o64 81 /6 id
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	XOR_RM64_IMM32 = 235,
	/// @brief @c CMP r/m16, imm16
	/// @par
	/// @c o16 81 /7 iw
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	CMP_RM16_IMM16 = 236,
	/// @brief @c CMP r/m32, imm32
	/// @par
	/// @c o32 81 /7 id
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	CMP_RM32_IMM32 = 237,
	/// @brief @c CMP r/m64, imm32
	/// @par
	/// @c o64 81 /7 id
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	CMP_RM64_IMM32 = 238,
	/// @brief @c ADD r/m8, imm8
	/// @par
	/// @c 82 /0 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	ADD_RM8_IMM8_82 = 239,
	/// @brief @c OR r/m8, imm8
	/// @par
	/// @c 82 /1 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	OR_RM8_IMM8_82 = 240,
	/// @brief @c ADC r/m8, imm8
	/// @par
	/// @c 82 /2 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	ADC_RM8_IMM8_82 = 241,
	/// @brief @c SBB r/m8, imm8
	/// @par
	/// @c 82 /3 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	SBB_RM8_IMM8_82 = 242,
	/// @brief @c AND r/m8, imm8
	/// @par
	/// @c 82 /4 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	AND_RM8_IMM8_82 = 243,
	/// @brief @c SUB r/m8, imm8
	/// @par
	/// @c 82 /5 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	SUB_RM8_IMM8_82 = 244,
	/// @brief @c XOR r/m8, imm8
	/// @par
	/// @c 82 /6 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	XOR_RM8_IMM8_82 = 245,
	/// @brief @c CMP r/m8, imm8
	/// @par
	/// @c 82 /7 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	CMP_RM8_IMM8_82 = 246,
	/// @brief @c ADD r/m16, imm8
	/// @par
	/// @c o16 83 /0 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	ADD_RM16_IMM8 = 247,
	/// @brief @c ADD r/m32, imm8
	/// @par
	/// @c o32 83 /0 ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	ADD_RM32_IMM8 = 248,
	/// @brief @c ADD r/m64, imm8
	/// @par
	/// @c o64 83 /0 ib
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	ADD_RM64_IMM8 = 249,
	/// @brief @c OR r/m16, imm8
	/// @par
	/// @c o16 83 /1 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	OR_RM16_IMM8 = 250,
	/// @brief @c OR r/m32, imm8
	/// @par
	/// @c o32 83 /1 ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	OR_RM32_IMM8 = 251,
	/// @brief @c OR r/m64, imm8
	/// @par
	/// @c o64 83 /1 ib
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	OR_RM64_IMM8 = 252,
	/// @brief @c ADC r/m16, imm8
	/// @par
	/// @c o16 83 /2 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	ADC_RM16_IMM8 = 253,
	/// @brief @c ADC r/m32, imm8
	/// @par
	/// @c o32 83 /2 ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	ADC_RM32_IMM8 = 254,
	/// @brief @c ADC r/m64, imm8
	/// @par
	/// @c o64 83 /2 ib
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	ADC_RM64_IMM8 = 255,
	/// @brief @c SBB r/m16, imm8
	/// @par
	/// @c o16 83 /3 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SBB_RM16_IMM8 = 256,
	/// @brief @c SBB r/m32, imm8
	/// @par
	/// @c o32 83 /3 ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SBB_RM32_IMM8 = 257,
	/// @brief @c SBB r/m64, imm8
	/// @par
	/// @c o64 83 /3 ib
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SBB_RM64_IMM8 = 258,
	/// @brief @c AND r/m16, imm8
	/// @par
	/// @c o16 83 /4 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	AND_RM16_IMM8 = 259,
	/// @brief @c AND r/m32, imm8
	/// @par
	/// @c o32 83 /4 ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	AND_RM32_IMM8 = 260,
	/// @brief @c AND r/m64, imm8
	/// @par
	/// @c o64 83 /4 ib
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	AND_RM64_IMM8 = 261,
	/// @brief @c SUB r/m16, imm8
	/// @par
	/// @c o16 83 /5 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SUB_RM16_IMM8 = 262,
	/// @brief @c SUB r/m32, imm8
	/// @par
	/// @c o32 83 /5 ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SUB_RM32_IMM8 = 263,
	/// @brief @c SUB r/m64, imm8
	/// @par
	/// @c o64 83 /5 ib
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SUB_RM64_IMM8 = 264,
	/// @brief @c XOR r/m16, imm8
	/// @par
	/// @c o16 83 /6 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	XOR_RM16_IMM8 = 265,
	/// @brief @c XOR r/m32, imm8
	/// @par
	/// @c o32 83 /6 ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	XOR_RM32_IMM8 = 266,
	/// @brief @c XOR r/m64, imm8
	/// @par
	/// @c o64 83 /6 ib
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	XOR_RM64_IMM8 = 267,
	/// @brief @c CMP r/m16, imm8
	/// @par
	/// @c o16 83 /7 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	CMP_RM16_IMM8 = 268,
	/// @brief @c CMP r/m32, imm8
	/// @par
	/// @c o32 83 /7 ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	CMP_RM32_IMM8 = 269,
	/// @brief @c CMP r/m64, imm8
	/// @par
	/// @c o64 83 /7 ib
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	CMP_RM64_IMM8 = 270,
	/// @brief @c TEST r/m8, r8
	/// @par
	/// @c 84 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	TEST_RM8_R8 = 271,
	/// @brief @c TEST r/m16, r16
	/// @par
	/// @c o16 85 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	TEST_RM16_R16 = 272,
	/// @brief @c TEST r/m32, r32
	/// @par
	/// @c o32 85 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	TEST_RM32_R32 = 273,
	/// @brief @c TEST r/m64, r64
	/// @par
	/// @c o64 85 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	TEST_RM64_R64 = 274,
	/// @brief @c XCHG r/m8, r8
	/// @par
	/// @c 86 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	XCHG_RM8_R8 = 275,
	/// @brief @c XCHG r/m16, r16
	/// @par
	/// @c o16 87 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	XCHG_RM16_R16 = 276,
	/// @brief @c XCHG r/m32, r32
	/// @par
	/// @c o32 87 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	XCHG_RM32_R32 = 277,
	/// @brief @c XCHG r/m64, r64
	/// @par
	/// @c o64 87 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	XCHG_RM64_R64 = 278,
	/// @brief @c MOV r/m8, r8
	/// @par
	/// @c 88 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	MOV_RM8_R8 = 279,
	/// @brief @c MOV r/m16, r16
	/// @par
	/// @c o16 89 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	MOV_RM16_R16 = 280,
	/// @brief @c MOV r/m32, r32
	/// @par
	/// @c o32 89 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	MOV_RM32_R32 = 281,
	/// @brief @c MOV r/m64, r64
	/// @par
	/// @c o64 89 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	MOV_RM64_R64 = 282,
	/// @brief @c MOV r8, r/m8
	/// @par
	/// @c 8A /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	MOV_R8_RM8 = 283,
	/// @brief @c MOV r16, r/m16
	/// @par
	/// @c o16 8B /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	MOV_R16_RM16 = 284,
	/// @brief @c MOV r32, r/m32
	/// @par
	/// @c o32 8B /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	MOV_R32_RM32 = 285,
	/// @brief @c MOV r64, r/m64
	/// @par
	/// @c o64 8B /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	MOV_R64_RM64 = 286,
	/// @brief @c MOV r/m16, Sreg
	/// @par
	/// @c o16 8C /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	MOV_RM16_SREG = 287,
	/// @brief @c MOV r32/m16, Sreg
	/// @par
	/// @c o32 8C /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	MOV_R32M16_SREG = 288,
	/// @brief @c MOV r64/m16, Sreg
	/// @par
	/// @c o64 8C /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	MOV_R64M16_SREG = 289,
	/// @brief @c LEA r16, m
	/// @par
	/// @c o16 8D /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	LEA_R16_M = 290,
	/// @brief @c LEA r32, m
	/// @par
	/// @c o32 8D /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	LEA_R32_M = 291,
	/// @brief @c LEA r64, m
	/// @par
	/// @c o64 8D /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	LEA_R64_M = 292,
	/// @brief @c MOV Sreg, r/m16
	/// @par
	/// @c o16 8E /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	MOV_SREG_RM16 = 293,
	/// @brief @c MOV Sreg, r32/m16
	/// @par
	/// @c o32 8E /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	MOV_SREG_R32M16 = 294,
	/// @brief @c MOV Sreg, r64/m16
	/// @par
	/// @c o64 8E /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	MOV_SREG_R64M16 = 295,
	/// @brief @c POP r/m16
	/// @par
	/// @c o16 8F /0
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	POP_RM16 = 296,
	/// @brief @c POP r/m32
	/// @par
	/// @c o32 8F /0
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	POP_RM32 = 297,
	/// @brief @c POP r/m64
	/// @par
	/// @c o64 8F /0
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	POP_RM64 = 298,
	/// @brief @c NOP
	/// @par
	/// @c o16 90
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	NOPW = 299,
	/// @brief @c NOP
	/// @par
	/// @c o32 90
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	NOPD = 300,
	/// @brief @c NOP
	/// @par
	/// @c o64 90
	/// @par
	/// @c 8086+
	/// @par
	/// @c 64-bit
	NOPQ = 301,
	/// @brief @c XCHG r16, AX
	/// @par
	/// @c o16 90+rw
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	XCHG_R16_AX = 302,
	/// @brief @c XCHG r32, EAX
	/// @par
	/// @c o32 90+rd
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	XCHG_R32_EAX = 303,
	/// @brief @c XCHG r64, RAX
	/// @par
	/// @c o64 90+ro
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	XCHG_R64_RAX = 304,
	/// @brief @c PAUSE
	/// @par
	/// @c F3 90
	/// @par
	/// @c Pentium 4 or later
	/// @par
	/// @c 16/32/64-bit
	PAUSE = 305,
	/// @brief @c CBW
	/// @par
	/// @c o16 98
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	CBW = 306,
	/// @brief @c CWDE
	/// @par
	/// @c o32 98
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	CWDE = 307,
	/// @brief @c CDQE
	/// @par
	/// @c o64 98
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	CDQE = 308,
	/// @brief @c CWD
	/// @par
	/// @c o16 99
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	CWD = 309,
	/// @brief @c CDQ
	/// @par
	/// @c o32 99
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	CDQ = 310,
	/// @brief @c CQO
	/// @par
	/// @c o64 99
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	CQO = 311,
	/// @brief @c CALL ptr16:16
	/// @par
	/// @c o16 9A cd
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	CALL_PTR1616 = 312,
	/// @brief @c CALL ptr16:32
	/// @par
	/// @c o32 9A cp
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	CALL_PTR1632 = 313,
	/// @brief @c WAIT
	/// @par
	/// @c 9B
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	WAIT = 314,
	/// @brief @c PUSHF
	/// @par
	/// @c o16 9C
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	PUSHFW = 315,
	/// @brief @c PUSHFD
	/// @par
	/// @c o32 9C
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	PUSHFD = 316,
	/// @brief @c PUSHFQ
	/// @par
	/// @c o64 9C
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	PUSHFQ = 317,
	/// @brief @c POPF
	/// @par
	/// @c o16 9D
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	POPFW = 318,
	/// @brief @c POPFD
	/// @par
	/// @c o32 9D
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	POPFD = 319,
	/// @brief @c POPFQ
	/// @par
	/// @c o64 9D
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	POPFQ = 320,
	/// @brief @c SAHF
	/// @par
	/// @c 9E
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SAHF = 321,
	/// @brief @c LAHF
	/// @par
	/// @c 9F
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	LAHF = 322,
	/// @brief @c MOV AL, moffs8
	/// @par
	/// @c A0 mo
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	MOV_AL_MOFFS8 = 323,
	/// @brief @c MOV AX, moffs16
	/// @par
	/// @c o16 A1 mo
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	MOV_AX_MOFFS16 = 324,
	/// @brief @c MOV EAX, moffs32
	/// @par
	/// @c o32 A1 mo
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	MOV_EAX_MOFFS32 = 325,
	/// @brief @c MOV RAX, moffs64
	/// @par
	/// @c o64 A1 mo
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	MOV_RAX_MOFFS64 = 326,
	/// @brief @c MOV moffs8, AL
	/// @par
	/// @c A2 mo
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	MOV_MOFFS8_AL = 327,
	/// @brief @c MOV moffs16, AX
	/// @par
	/// @c o16 A3 mo
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	MOV_MOFFS16_AX = 328,
	/// @brief @c MOV moffs32, EAX
	/// @par
	/// @c o32 A3 mo
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	MOV_MOFFS32_EAX = 329,
	/// @brief @c MOV moffs64, RAX
	/// @par
	/// @c o64 A3 mo
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	MOV_MOFFS64_RAX = 330,
	/// @brief @c MOVSB
	/// @par
	/// @c A4
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	MOVSB_M8_M8 = 331,
	/// @brief @c MOVSW
	/// @par
	/// @c o16 A5
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	MOVSW_M16_M16 = 332,
	/// @brief @c MOVSD
	/// @par
	/// @c o32 A5
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	MOVSD_M32_M32 = 333,
	/// @brief @c MOVSQ
	/// @par
	/// @c o64 A5
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	MOVSQ_M64_M64 = 334,
	/// @brief @c CMPSB
	/// @par
	/// @c A6
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	CMPSB_M8_M8 = 335,
	/// @brief @c CMPSW
	/// @par
	/// @c o16 A7
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	CMPSW_M16_M16 = 336,
	/// @brief @c CMPSD
	/// @par
	/// @c o32 A7
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	CMPSD_M32_M32 = 337,
	/// @brief @c CMPSQ
	/// @par
	/// @c o64 A7
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	CMPSQ_M64_M64 = 338,
	/// @brief @c TEST AL, imm8
	/// @par
	/// @c A8 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	TEST_AL_IMM8 = 339,
	/// @brief @c TEST AX, imm16
	/// @par
	/// @c o16 A9 iw
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	TEST_AX_IMM16 = 340,
	/// @brief @c TEST EAX, imm32
	/// @par
	/// @c o32 A9 id
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	TEST_EAX_IMM32 = 341,
	/// @brief @c TEST RAX, imm32
	/// @par
	/// @c o64 A9 id
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	TEST_RAX_IMM32 = 342,
	/// @brief @c STOSB
	/// @par
	/// @c AA
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	STOSB_M8_AL = 343,
	/// @brief @c STOSW
	/// @par
	/// @c o16 AB
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	STOSW_M16_AX = 344,
	/// @brief @c STOSD
	/// @par
	/// @c o32 AB
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	STOSD_M32_EAX = 345,
	/// @brief @c STOSQ
	/// @par
	/// @c o64 AB
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	STOSQ_M64_RAX = 346,
	/// @brief @c LODSB
	/// @par
	/// @c AC
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	LODSB_AL_M8 = 347,
	/// @brief @c LODSW
	/// @par
	/// @c o16 AD
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	LODSW_AX_M16 = 348,
	/// @brief @c LODSD
	/// @par
	/// @c o32 AD
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	LODSD_EAX_M32 = 349,
	/// @brief @c LODSQ
	/// @par
	/// @c o64 AD
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	LODSQ_RAX_M64 = 350,
	/// @brief @c SCASB
	/// @par
	/// @c AE
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SCASB_AL_M8 = 351,
	/// @brief @c SCASW
	/// @par
	/// @c o16 AF
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SCASW_AX_M16 = 352,
	/// @brief @c SCASD
	/// @par
	/// @c o32 AF
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SCASD_EAX_M32 = 353,
	/// @brief @c SCASQ
	/// @par
	/// @c o64 AF
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SCASQ_RAX_M64 = 354,
	/// @brief @c MOV r8, imm8
	/// @par
	/// @c B0+rb ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	MOV_R8_IMM8 = 355,
	/// @brief @c MOV r16, imm16
	/// @par
	/// @c o16 B8+rw iw
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	MOV_R16_IMM16 = 356,
	/// @brief @c MOV r32, imm32
	/// @par
	/// @c o32 B8+rd id
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	MOV_R32_IMM32 = 357,
	/// @brief @c MOV r64, imm64
	/// @par
	/// @c o64 B8+ro io
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	MOV_R64_IMM64 = 358,
	/// @brief @c ROL r/m8, imm8
	/// @par
	/// @c C0 /0 ib
	/// @par
	/// @c 186+
	/// @par
	/// @c 16/32/64-bit
	ROL_RM8_IMM8 = 359,
	/// @brief @c ROR r/m8, imm8
	/// @par
	/// @c C0 /1 ib
	/// @par
	/// @c 186+
	/// @par
	/// @c 16/32/64-bit
	ROR_RM8_IMM8 = 360,
	/// @brief @c RCL r/m8, imm8
	/// @par
	/// @c C0 /2 ib
	/// @par
	/// @c 186+
	/// @par
	/// @c 16/32/64-bit
	RCL_RM8_IMM8 = 361,
	/// @brief @c RCR r/m8, imm8
	/// @par
	/// @c C0 /3 ib
	/// @par
	/// @c 186+
	/// @par
	/// @c 16/32/64-bit
	RCR_RM8_IMM8 = 362,
	/// @brief @c SHL r/m8, imm8
	/// @par
	/// @c C0 /4 ib
	/// @par
	/// @c 186+
	/// @par
	/// @c 16/32/64-bit
	SHL_RM8_IMM8 = 363,
	/// @brief @c SHR r/m8, imm8
	/// @par
	/// @c C0 /5 ib
	/// @par
	/// @c 186+
	/// @par
	/// @c 16/32/64-bit
	SHR_RM8_IMM8 = 364,
	/// @brief @c SAL r/m8, imm8
	/// @par
	/// @c C0 /6 ib
	/// @par
	/// @c 186+
	/// @par
	/// @c 16/32/64-bit
	SAL_RM8_IMM8 = 365,
	/// @brief @c SAR r/m8, imm8
	/// @par
	/// @c C0 /7 ib
	/// @par
	/// @c 186+
	/// @par
	/// @c 16/32/64-bit
	SAR_RM8_IMM8 = 366,
	/// @brief @c ROL r/m16, imm8
	/// @par
	/// @c o16 C1 /0 ib
	/// @par
	/// @c 186+
	/// @par
	/// @c 16/32/64-bit
	ROL_RM16_IMM8 = 367,
	/// @brief @c ROL r/m32, imm8
	/// @par
	/// @c o32 C1 /0 ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	ROL_RM32_IMM8 = 368,
	/// @brief @c ROL r/m64, imm8
	/// @par
	/// @c o64 C1 /0 ib
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	ROL_RM64_IMM8 = 369,
	/// @brief @c ROR r/m16, imm8
	/// @par
	/// @c o16 C1 /1 ib
	/// @par
	/// @c 186+
	/// @par
	/// @c 16/32/64-bit
	ROR_RM16_IMM8 = 370,
	/// @brief @c ROR r/m32, imm8
	/// @par
	/// @c o32 C1 /1 ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	ROR_RM32_IMM8 = 371,
	/// @brief @c ROR r/m64, imm8
	/// @par
	/// @c o64 C1 /1 ib
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	ROR_RM64_IMM8 = 372,
	/// @brief @c RCL r/m16, imm8
	/// @par
	/// @c o16 C1 /2 ib
	/// @par
	/// @c 186+
	/// @par
	/// @c 16/32/64-bit
	RCL_RM16_IMM8 = 373,
	/// @brief @c RCL r/m32, imm8
	/// @par
	/// @c o32 C1 /2 ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	RCL_RM32_IMM8 = 374,
	/// @brief @c RCL r/m64, imm8
	/// @par
	/// @c o64 C1 /2 ib
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	RCL_RM64_IMM8 = 375,
	/// @brief @c RCR r/m16, imm8
	/// @par
	/// @c o16 C1 /3 ib
	/// @par
	/// @c 186+
	/// @par
	/// @c 16/32/64-bit
	RCR_RM16_IMM8 = 376,
	/// @brief @c RCR r/m32, imm8
	/// @par
	/// @c o32 C1 /3 ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	RCR_RM32_IMM8 = 377,
	/// @brief @c RCR r/m64, imm8
	/// @par
	/// @c o64 C1 /3 ib
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	RCR_RM64_IMM8 = 378,
	/// @brief @c SHL r/m16, imm8
	/// @par
	/// @c o16 C1 /4 ib
	/// @par
	/// @c 186+
	/// @par
	/// @c 16/32/64-bit
	SHL_RM16_IMM8 = 379,
	/// @brief @c SHL r/m32, imm8
	/// @par
	/// @c o32 C1 /4 ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SHL_RM32_IMM8 = 380,
	/// @brief @c SHL r/m64, imm8
	/// @par
	/// @c o64 C1 /4 ib
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SHL_RM64_IMM8 = 381,
	/// @brief @c SHR r/m16, imm8
	/// @par
	/// @c o16 C1 /5 ib
	/// @par
	/// @c 186+
	/// @par
	/// @c 16/32/64-bit
	SHR_RM16_IMM8 = 382,
	/// @brief @c SHR r/m32, imm8
	/// @par
	/// @c o32 C1 /5 ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SHR_RM32_IMM8 = 383,
	/// @brief @c SHR r/m64, imm8
	/// @par
	/// @c o64 C1 /5 ib
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SHR_RM64_IMM8 = 384,
	/// @brief @c SAL r/m16, imm8
	/// @par
	/// @c o16 C1 /6 ib
	/// @par
	/// @c 186+
	/// @par
	/// @c 16/32/64-bit
	SAL_RM16_IMM8 = 385,
	/// @brief @c SAL r/m32, imm8
	/// @par
	/// @c o32 C1 /6 ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SAL_RM32_IMM8 = 386,
	/// @brief @c SAL r/m64, imm8
	/// @par
	/// @c o64 C1 /6 ib
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SAL_RM64_IMM8 = 387,
	/// @brief @c SAR r/m16, imm8
	/// @par
	/// @c o16 C1 /7 ib
	/// @par
	/// @c 186+
	/// @par
	/// @c 16/32/64-bit
	SAR_RM16_IMM8 = 388,
	/// @brief @c SAR r/m32, imm8
	/// @par
	/// @c o32 C1 /7 ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SAR_RM32_IMM8 = 389,
	/// @brief @c SAR r/m64, imm8
	/// @par
	/// @c o64 C1 /7 ib
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SAR_RM64_IMM8 = 390,
	/// @brief @c RET imm16
	/// @par
	/// @c o16 C2 iw
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	RETNW_IMM16 = 391,
	/// @brief @c RET imm16
	/// @par
	/// @c o32 C2 iw
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	RETND_IMM16 = 392,
	/// @brief @c RET imm16
	/// @par
	/// @c o64 C2 iw
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	RETNQ_IMM16 = 393,
	/// @brief @c RET
	/// @par
	/// @c o16 C3
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	RETNW = 394,
	/// @brief @c RET
	/// @par
	/// @c o32 C3
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	RETND = 395,
	/// @brief @c RET
	/// @par
	/// @c o64 C3
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	RETNQ = 396,
	/// @brief @c LES r16, m16:16
	/// @par
	/// @c o16 C4 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	LES_R16_M1616 = 397,
	/// @brief @c LES r32, m16:32
	/// @par
	/// @c o32 C4 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	LES_R32_M1632 = 398,
	/// @brief @c LDS r16, m16:16
	/// @par
	/// @c o16 C5 /r
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	LDS_R16_M1616 = 399,
	/// @brief @c LDS r32, m16:32
	/// @par
	/// @c o32 C5 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	LDS_R32_M1632 = 400,
	/// @brief @c MOV r/m8, imm8
	/// @par
	/// @c C6 /0 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	MOV_RM8_IMM8 = 401,
	/// @brief @c XABORT imm8
	/// @par
	/// @c C6 F8 ib
	/// @par
	/// @c RTM
	/// @par
	/// @c 16/32/64-bit
	XABORT_IMM8 = 402,
	/// @brief @c MOV r/m16, imm16
	/// @par
	/// @c o16 C7 /0 iw
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	MOV_RM16_IMM16 = 403,
	/// @brief @c MOV r/m32, imm32
	/// @par
	/// @c o32 C7 /0 id
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	MOV_RM32_IMM32 = 404,
	/// @brief @c MOV r/m64, imm32
	/// @par
	/// @c o64 C7 /0 id
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	MOV_RM64_IMM32 = 405,
	/// @brief @c XBEGIN rel16
	/// @par
	/// @c o16 C7 F8 cw
	/// @par
	/// @c RTM
	/// @par
	/// @c 16/32/64-bit
	XBEGIN_REL16 = 406,
	/// @brief @c XBEGIN rel32
	/// @par
	/// @c o32 C7 F8 cd
	/// @par
	/// @c RTM
	/// @par
	/// @c 16/32/64-bit
	XBEGIN_REL32 = 407,
	/// @brief @c ENTER imm16, imm8
	/// @par
	/// @c o16 C8 iw ib
	/// @par
	/// @c 186+
	/// @par
	/// @c 16/32/64-bit
	ENTERW_IMM16_IMM8 = 408,
	/// @brief @c ENTER imm16, imm8
	/// @par
	/// @c o32 C8 iw ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	ENTERD_IMM16_IMM8 = 409,
	/// @brief @c ENTER imm16, imm8
	/// @par
	/// @c o64 C8 iw ib
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	ENTERQ_IMM16_IMM8 = 410,
	/// @brief @c LEAVE
	/// @par
	/// @c o16 C9
	/// @par
	/// @c 186+
	/// @par
	/// @c 16/32/64-bit
	LEAVEW = 411,
	/// @brief @c LEAVE
	/// @par
	/// @c o32 C9
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	LEAVED = 412,
	/// @brief @c LEAVE
	/// @par
	/// @c o64 C9
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	LEAVEQ = 413,
	/// @brief @c RETF imm16
	/// @par
	/// @c o16 CA iw
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	RETFW_IMM16 = 414,
	/// @brief @c RETF imm16
	/// @par
	/// @c o32 CA iw
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	RETFD_IMM16 = 415,
	/// @brief @c RETF imm16
	/// @par
	/// @c o64 CA iw
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	RETFQ_IMM16 = 416,
	/// @brief @c RETF
	/// @par
	/// @c o16 CB
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	RETFW = 417,
	/// @brief @c RETF
	/// @par
	/// @c o32 CB
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	RETFD = 418,
	/// @brief @c RETF
	/// @par
	/// @c o64 CB
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	RETFQ = 419,
	/// @brief @c INT3
	/// @par
	/// @c CC
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	INT3 = 420,
	/// @brief @c INT imm8
	/// @par
	/// @c CD ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	INT_IMM8 = 421,
	/// @brief @c INTO
	/// @par
	/// @c CE
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	INTO = 422,
	/// @brief @c IRET
	/// @par
	/// @c o16 CF
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	IRETW = 423,
	/// @brief @c IRETD
	/// @par
	/// @c o32 CF
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	IRETD = 424,
	/// @brief @c IRETQ
	/// @par
	/// @c o64 CF
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	IRETQ = 425,
	/// @brief @c ROL r/m8, 1
	/// @par
	/// @c D0 /0
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	ROL_RM8_1 = 426,
	/// @brief @c ROR r/m8, 1
	/// @par
	/// @c D0 /1
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	ROR_RM8_1 = 427,
	/// @brief @c RCL r/m8, 1
	/// @par
	/// @c D0 /2
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	RCL_RM8_1 = 428,
	/// @brief @c RCR r/m8, 1
	/// @par
	/// @c D0 /3
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	RCR_RM8_1 = 429,
	/// @brief @c SHL r/m8, 1
	/// @par
	/// @c D0 /4
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SHL_RM8_1 = 430,
	/// @brief @c SHR r/m8, 1
	/// @par
	/// @c D0 /5
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SHR_RM8_1 = 431,
	/// @brief @c SAL r/m8, 1
	/// @par
	/// @c D0 /6
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SAL_RM8_1 = 432,
	/// @brief @c SAR r/m8, 1
	/// @par
	/// @c D0 /7
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SAR_RM8_1 = 433,
	/// @brief @c ROL r/m16, 1
	/// @par
	/// @c o16 D1 /0
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	ROL_RM16_1 = 434,
	/// @brief @c ROL r/m32, 1
	/// @par
	/// @c o32 D1 /0
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	ROL_RM32_1 = 435,
	/// @brief @c ROL r/m64, 1
	/// @par
	/// @c o64 D1 /0
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	ROL_RM64_1 = 436,
	/// @brief @c ROR r/m16, 1
	/// @par
	/// @c o16 D1 /1
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	ROR_RM16_1 = 437,
	/// @brief @c ROR r/m32, 1
	/// @par
	/// @c o32 D1 /1
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	ROR_RM32_1 = 438,
	/// @brief @c ROR r/m64, 1
	/// @par
	/// @c o64 D1 /1
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	ROR_RM64_1 = 439,
	/// @brief @c RCL r/m16, 1
	/// @par
	/// @c o16 D1 /2
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	RCL_RM16_1 = 440,
	/// @brief @c RCL r/m32, 1
	/// @par
	/// @c o32 D1 /2
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	RCL_RM32_1 = 441,
	/// @brief @c RCL r/m64, 1
	/// @par
	/// @c o64 D1 /2
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	RCL_RM64_1 = 442,
	/// @brief @c RCR r/m16, 1
	/// @par
	/// @c o16 D1 /3
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	RCR_RM16_1 = 443,
	/// @brief @c RCR r/m32, 1
	/// @par
	/// @c o32 D1 /3
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	RCR_RM32_1 = 444,
	/// @brief @c RCR r/m64, 1
	/// @par
	/// @c o64 D1 /3
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	RCR_RM64_1 = 445,
	/// @brief @c SHL r/m16, 1
	/// @par
	/// @c o16 D1 /4
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SHL_RM16_1 = 446,
	/// @brief @c SHL r/m32, 1
	/// @par
	/// @c o32 D1 /4
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SHL_RM32_1 = 447,
	/// @brief @c SHL r/m64, 1
	/// @par
	/// @c o64 D1 /4
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SHL_RM64_1 = 448,
	/// @brief @c SHR r/m16, 1
	/// @par
	/// @c o16 D1 /5
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SHR_RM16_1 = 449,
	/// @brief @c SHR r/m32, 1
	/// @par
	/// @c o32 D1 /5
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SHR_RM32_1 = 450,
	/// @brief @c SHR r/m64, 1
	/// @par
	/// @c o64 D1 /5
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SHR_RM64_1 = 451,
	/// @brief @c SAL r/m16, 1
	/// @par
	/// @c o16 D1 /6
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SAL_RM16_1 = 452,
	/// @brief @c SAL r/m32, 1
	/// @par
	/// @c o32 D1 /6
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SAL_RM32_1 = 453,
	/// @brief @c SAL r/m64, 1
	/// @par
	/// @c o64 D1 /6
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SAL_RM64_1 = 454,
	/// @brief @c SAR r/m16, 1
	/// @par
	/// @c o16 D1 /7
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SAR_RM16_1 = 455,
	/// @brief @c SAR r/m32, 1
	/// @par
	/// @c o32 D1 /7
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SAR_RM32_1 = 456,
	/// @brief @c SAR r/m64, 1
	/// @par
	/// @c o64 D1 /7
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SAR_RM64_1 = 457,
	/// @brief @c ROL r/m8, CL
	/// @par
	/// @c D2 /0
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	ROL_RM8_CL = 458,
	/// @brief @c ROR r/m8, CL
	/// @par
	/// @c D2 /1
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	ROR_RM8_CL = 459,
	/// @brief @c RCL r/m8, CL
	/// @par
	/// @c D2 /2
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	RCL_RM8_CL = 460,
	/// @brief @c RCR r/m8, CL
	/// @par
	/// @c D2 /3
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	RCR_RM8_CL = 461,
	/// @brief @c SHL r/m8, CL
	/// @par
	/// @c D2 /4
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SHL_RM8_CL = 462,
	/// @brief @c SHR r/m8, CL
	/// @par
	/// @c D2 /5
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SHR_RM8_CL = 463,
	/// @brief @c SAL r/m8, CL
	/// @par
	/// @c D2 /6
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SAL_RM8_CL = 464,
	/// @brief @c SAR r/m8, CL
	/// @par
	/// @c D2 /7
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SAR_RM8_CL = 465,
	/// @brief @c ROL r/m16, CL
	/// @par
	/// @c o16 D3 /0
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	ROL_RM16_CL = 466,
	/// @brief @c ROL r/m32, CL
	/// @par
	/// @c o32 D3 /0
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	ROL_RM32_CL = 467,
	/// @brief @c ROL r/m64, CL
	/// @par
	/// @c o64 D3 /0
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	ROL_RM64_CL = 468,
	/// @brief @c ROR r/m16, CL
	/// @par
	/// @c o16 D3 /1
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	ROR_RM16_CL = 469,
	/// @brief @c ROR r/m32, CL
	/// @par
	/// @c o32 D3 /1
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	ROR_RM32_CL = 470,
	/// @brief @c ROR r/m64, CL
	/// @par
	/// @c o64 D3 /1
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	ROR_RM64_CL = 471,
	/// @brief @c RCL r/m16, CL
	/// @par
	/// @c o16 D3 /2
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	RCL_RM16_CL = 472,
	/// @brief @c RCL r/m32, CL
	/// @par
	/// @c o32 D3 /2
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	RCL_RM32_CL = 473,
	/// @brief @c RCL r/m64, CL
	/// @par
	/// @c o64 D3 /2
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	RCL_RM64_CL = 474,
	/// @brief @c RCR r/m16, CL
	/// @par
	/// @c o16 D3 /3
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	RCR_RM16_CL = 475,
	/// @brief @c RCR r/m32, CL
	/// @par
	/// @c o32 D3 /3
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	RCR_RM32_CL = 476,
	/// @brief @c RCR r/m64, CL
	/// @par
	/// @c o64 D3 /3
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	RCR_RM64_CL = 477,
	/// @brief @c SHL r/m16, CL
	/// @par
	/// @c o16 D3 /4
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SHL_RM16_CL = 478,
	/// @brief @c SHL r/m32, CL
	/// @par
	/// @c o32 D3 /4
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SHL_RM32_CL = 479,
	/// @brief @c SHL r/m64, CL
	/// @par
	/// @c o64 D3 /4
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SHL_RM64_CL = 480,
	/// @brief @c SHR r/m16, CL
	/// @par
	/// @c o16 D3 /5
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SHR_RM16_CL = 481,
	/// @brief @c SHR r/m32, CL
	/// @par
	/// @c o32 D3 /5
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SHR_RM32_CL = 482,
	/// @brief @c SHR r/m64, CL
	/// @par
	/// @c o64 D3 /5
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SHR_RM64_CL = 483,
	/// @brief @c SAL r/m16, CL
	/// @par
	/// @c o16 D3 /6
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SAL_RM16_CL = 484,
	/// @brief @c SAL r/m32, CL
	/// @par
	/// @c o32 D3 /6
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SAL_RM32_CL = 485,
	/// @brief @c SAL r/m64, CL
	/// @par
	/// @c o64 D3 /6
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SAL_RM64_CL = 486,
	/// @brief @c SAR r/m16, CL
	/// @par
	/// @c o16 D3 /7
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	SAR_RM16_CL = 487,
	/// @brief @c SAR r/m32, CL
	/// @par
	/// @c o32 D3 /7
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SAR_RM32_CL = 488,
	/// @brief @c SAR r/m64, CL
	/// @par
	/// @c o64 D3 /7
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SAR_RM64_CL = 489,
	/// @brief @c AAM imm8
	/// @par
	/// @c D4 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	AAM_IMM8 = 490,
	/// @brief @c AAD imm8
	/// @par
	/// @c D5 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	AAD_IMM8 = 491,
	/// @brief @c SALC
	/// @par
	/// @c D6
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	SALC = 492,
	/// @brief @c XLATB
	/// @par
	/// @c D7
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	XLAT_M8 = 493,
	/// @brief @c FADD m32fp
	/// @par
	/// @c D8 /0
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FADD_M32FP = 494,
	/// @brief @c FMUL m32fp
	/// @par
	/// @c D8 /1
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FMUL_M32FP = 495,
	/// @brief @c FCOM m32fp
	/// @par
	/// @c D8 /2
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FCOM_M32FP = 496,
	/// @brief @c FCOMP m32fp
	/// @par
	/// @c D8 /3
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FCOMP_M32FP = 497,
	/// @brief @c FSUB m32fp
	/// @par
	/// @c D8 /4
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FSUB_M32FP = 498,
	/// @brief @c FSUBR m32fp
	/// @par
	/// @c D8 /5
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FSUBR_M32FP = 499,
	/// @brief @c FDIV m32fp
	/// @par
	/// @c D8 /6
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FDIV_M32FP = 500,
	/// @brief @c FDIVR m32fp
	/// @par
	/// @c D8 /7
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FDIVR_M32FP = 501,
	/// @brief @c FADD ST(0), ST(i)
	/// @par
	/// @c D8 C0+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FADD_ST0_STI = 502,
	/// @brief @c FMUL ST(0), ST(i)
	/// @par
	/// @c D8 C8+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FMUL_ST0_STI = 503,
	/// @brief @c FCOM ST(i)
	/// @par
	/// @c D8 D0+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FCOM_ST0_STI = 504,
	/// @brief @c FCOMP ST(i)
	/// @par
	/// @c D8 D8+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FCOMP_ST0_STI = 505,
	/// @brief @c FSUB ST(0), ST(i)
	/// @par
	/// @c D8 E0+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FSUB_ST0_STI = 506,
	/// @brief @c FSUBR ST(0), ST(i)
	/// @par
	/// @c D8 E8+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FSUBR_ST0_STI = 507,
	/// @brief @c FDIV ST(0), ST(i)
	/// @par
	/// @c D8 F0+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FDIV_ST0_STI = 508,
	/// @brief @c FDIVR ST(0), ST(i)
	/// @par
	/// @c D8 F8+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FDIVR_ST0_STI = 509,
	/// @brief @c FLD m32fp
	/// @par
	/// @c D9 /0
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FLD_M32FP = 510,
	/// @brief @c FST m32fp
	/// @par
	/// @c D9 /2
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FST_M32FP = 511,
	/// @brief @c FSTP m32fp
	/// @par
	/// @c D9 /3
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FSTP_M32FP = 512,
	/// @brief @c FLDENV m14byte
	/// @par
	/// @c o16 D9 /4
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FLDENV_M14BYTE = 513,
	/// @brief @c FLDENV m28byte
	/// @par
	/// @c o32 D9 /4
	/// @par
	/// @c 387+
	/// @par
	/// @c 16/32/64-bit
	FLDENV_M28BYTE = 514,
	/// @brief @c FLDCW m2byte
	/// @par
	/// @c D9 /5
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FLDCW_M2BYTE = 515,
	/// @brief @c FNSTENV m14byte
	/// @par
	/// @c o16 D9 /6
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FNSTENV_M14BYTE = 516,
	/// @brief @c FSTENV m14byte
	/// @par
	/// @c 9B o16 D9 /6
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FSTENV_M14BYTE = 517,
	/// @brief @c FNSTENV m28byte
	/// @par
	/// @c o32 D9 /6
	/// @par
	/// @c 387+
	/// @par
	/// @c 16/32/64-bit
	FNSTENV_M28BYTE = 518,
	/// @brief @c FSTENV m28byte
	/// @par
	/// @c 9B o32 D9 /6
	/// @par
	/// @c 387+
	/// @par
	/// @c 16/32/64-bit
	FSTENV_M28BYTE = 519,
	/// @brief @c FNSTCW m2byte
	/// @par
	/// @c D9 /7
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FNSTCW_M2BYTE = 520,
	/// @brief @c FSTCW m2byte
	/// @par
	/// @c 9B D9 /7
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FSTCW_M2BYTE = 521,
	/// @brief @c FLD ST(i)
	/// @par
	/// @c D9 C0+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FLD_STI = 522,
	/// @brief @c FXCH ST(i)
	/// @par
	/// @c D9 C8+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FXCH_ST0_STI = 523,
	/// @brief @c FNOP
	/// @par
	/// @c D9 D0
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FNOP = 524,
	/// @brief @c FSTPNCE ST(i)
	/// @par
	/// @c D9 D8+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FSTPNCE_STI = 525,
	/// @brief @c FCHS
	/// @par
	/// @c D9 E0
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FCHS = 526,
	/// @brief @c FABS
	/// @par
	/// @c D9 E1
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FABS = 527,
	/// @brief @c FTST
	/// @par
	/// @c D9 E4
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FTST = 528,
	/// @brief @c FXAM
	/// @par
	/// @c D9 E5
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FXAM = 529,
	/// @brief @c FLD1
	/// @par
	/// @c D9 E8
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FLD1 = 530,
	/// @brief @c FLDL2T
	/// @par
	/// @c D9 E9
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FLDL2T = 531,
	/// @brief @c FLDL2E
	/// @par
	/// @c D9 EA
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FLDL2E = 532,
	/// @brief @c FLDPI
	/// @par
	/// @c D9 EB
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FLDPI = 533,
	/// @brief @c FLDLG2
	/// @par
	/// @c D9 EC
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FLDLG2 = 534,
	/// @brief @c FLDLN2
	/// @par
	/// @c D9 ED
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FLDLN2 = 535,
	/// @brief @c FLDZ
	/// @par
	/// @c D9 EE
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FLDZ = 536,
	/// @brief @c F2XM1
	/// @par
	/// @c D9 F0
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	F2XM1 = 537,
	/// @brief @c FYL2X
	/// @par
	/// @c D9 F1
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FYL2X = 538,
	/// @brief @c FPTAN
	/// @par
	/// @c D9 F2
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FPTAN = 539,
	/// @brief @c FPATAN
	/// @par
	/// @c D9 F3
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FPATAN = 540,
	/// @brief @c FXTRACT
	/// @par
	/// @c D9 F4
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FXTRACT = 541,
	/// @brief @c FPREM1
	/// @par
	/// @c D9 F5
	/// @par
	/// @c 387+
	/// @par
	/// @c 16/32/64-bit
	FPREM1 = 542,
	/// @brief @c FDECSTP
	/// @par
	/// @c D9 F6
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FDECSTP = 543,
	/// @brief @c FINCSTP
	/// @par
	/// @c D9 F7
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FINCSTP = 544,
	/// @brief @c FPREM
	/// @par
	/// @c D9 F8
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FPREM = 545,
	/// @brief @c FYL2XP1
	/// @par
	/// @c D9 F9
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FYL2XP1 = 546,
	/// @brief @c FSQRT
	/// @par
	/// @c D9 FA
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FSQRT = 547,
	/// @brief @c FSINCOS
	/// @par
	/// @c D9 FB
	/// @par
	/// @c 387+
	/// @par
	/// @c 16/32/64-bit
	FSINCOS = 548,
	/// @brief @c FRNDINT
	/// @par
	/// @c D9 FC
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FRNDINT = 549,
	/// @brief @c FSCALE
	/// @par
	/// @c D9 FD
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FSCALE = 550,
	/// @brief @c FSIN
	/// @par
	/// @c D9 FE
	/// @par
	/// @c 387+
	/// @par
	/// @c 16/32/64-bit
	FSIN = 551,
	/// @brief @c FCOS
	/// @par
	/// @c D9 FF
	/// @par
	/// @c 387+
	/// @par
	/// @c 16/32/64-bit
	FCOS = 552,
	/// @brief @c FIADD m32int
	/// @par
	/// @c DA /0
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FIADD_M32INT = 553,
	/// @brief @c FIMUL m32int
	/// @par
	/// @c DA /1
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FIMUL_M32INT = 554,
	/// @brief @c FICOM m32int
	/// @par
	/// @c DA /2
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FICOM_M32INT = 555,
	/// @brief @c FICOMP m32int
	/// @par
	/// @c DA /3
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FICOMP_M32INT = 556,
	/// @brief @c FISUB m32int
	/// @par
	/// @c DA /4
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FISUB_M32INT = 557,
	/// @brief @c FISUBR m32int
	/// @par
	/// @c DA /5
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FISUBR_M32INT = 558,
	/// @brief @c FIDIV m32int
	/// @par
	/// @c DA /6
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FIDIV_M32INT = 559,
	/// @brief @c FIDIVR m32int
	/// @par
	/// @c DA /7
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FIDIVR_M32INT = 560,
	/// @brief @c FCMOVB ST(0), ST(i)
	/// @par
	/// @c DA C0+i
	/// @par
	/// @c 8087+ and CMOV
	/// @par
	/// @c 16/32/64-bit
	FCMOVB_ST0_STI = 561,
	/// @brief @c FCMOVE ST(0), ST(i)
	/// @par
	/// @c DA C8+i
	/// @par
	/// @c 8087+ and CMOV
	/// @par
	/// @c 16/32/64-bit
	FCMOVE_ST0_STI = 562,
	/// @brief @c FCMOVBE ST(0), ST(i)
	/// @par
	/// @c DA D0+i
	/// @par
	/// @c 8087+ and CMOV
	/// @par
	/// @c 16/32/64-bit
	FCMOVBE_ST0_STI = 563,
	/// @brief @c FCMOVU ST(0), ST(i)
	/// @par
	/// @c DA D8+i
	/// @par
	/// @c 8087+ and CMOV
	/// @par
	/// @c 16/32/64-bit
	FCMOVU_ST0_STI = 564,
	/// @brief @c FUCOMPP
	/// @par
	/// @c DA E9
	/// @par
	/// @c 387+
	/// @par
	/// @c 16/32/64-bit
	FUCOMPP = 565,
	/// @brief @c FILD m32int
	/// @par
	/// @c DB /0
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FILD_M32INT = 566,
	/// @brief @c FISTTP m32int
	/// @par
	/// @c DB /1
	/// @par
	/// @c 8087+ and SSE3
	/// @par
	/// @c 16/32/64-bit
	FISTTP_M32INT = 567,
	/// @brief @c FIST m32int
	/// @par
	/// @c DB /2
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FIST_M32INT = 568,
	/// @brief @c FISTP m32int
	/// @par
	/// @c DB /3
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FISTP_M32INT = 569,
	/// @brief @c FLD m80fp
	/// @par
	/// @c DB /5
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FLD_M80FP = 570,
	/// @brief @c FSTP m80fp
	/// @par
	/// @c DB /7
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FSTP_M80FP = 571,
	/// @brief @c FCMOVNB ST(0), ST(i)
	/// @par
	/// @c DB C0+i
	/// @par
	/// @c 8087+ and CMOV
	/// @par
	/// @c 16/32/64-bit
	FCMOVNB_ST0_STI = 572,
	/// @brief @c FCMOVNE ST(0), ST(i)
	/// @par
	/// @c DB C8+i
	/// @par
	/// @c 8087+ and CMOV
	/// @par
	/// @c 16/32/64-bit
	FCMOVNE_ST0_STI = 573,
	/// @brief @c FCMOVNBE ST(0), ST(i)
	/// @par
	/// @c DB D0+i
	/// @par
	/// @c 8087+ and CMOV
	/// @par
	/// @c 16/32/64-bit
	FCMOVNBE_ST0_STI = 574,
	/// @brief @c FCMOVNU ST(0), ST(i)
	/// @par
	/// @c DB D8+i
	/// @par
	/// @c 8087+ and CMOV
	/// @par
	/// @c 16/32/64-bit
	FCMOVNU_ST0_STI = 575,
	/// @brief @c FNENI
	/// @par
	/// @c DB E0
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FNENI = 576,
	/// @brief @c FENI
	/// @par
	/// @c 9B DB E0
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FENI = 577,
	/// @brief @c FNDISI
	/// @par
	/// @c DB E1
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FNDISI = 578,
	/// @brief @c FDISI
	/// @par
	/// @c 9B DB E1
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FDISI = 579,
	/// @brief @c FNCLEX
	/// @par
	/// @c DB E2
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FNCLEX = 580,
	/// @brief @c FCLEX
	/// @par
	/// @c 9B DB E2
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FCLEX = 581,
	/// @brief @c FNINIT
	/// @par
	/// @c DB E3
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FNINIT = 582,
	/// @brief @c FINIT
	/// @par
	/// @c 9B DB E3
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FINIT = 583,
	/// @brief @c FNSETPM
	/// @par
	/// @c DB E4
	/// @par
	/// @c 287+
	/// @par
	/// @c 16/32/64-bit
	FNSETPM = 584,
	/// @brief @c FSETPM
	/// @par
	/// @c 9B DB E4
	/// @par
	/// @c 287+
	/// @par
	/// @c 16/32/64-bit
	FSETPM = 585,
	/// @brief @c FRSTPM
	/// @par
	/// @c DB E5
	/// @par
	/// @c 287 XL
	/// @par
	/// @c 16/32-bit
	FRSTPM = 586,
	/// @brief @c FUCOMI ST, ST(i)
	/// @par
	/// @c DB E8+i
	/// @par
	/// @c 8087+ and CMOV
	/// @par
	/// @c 16/32/64-bit
	FUCOMI_ST0_STI = 587,
	/// @brief @c FCOMI ST, ST(i)
	/// @par
	/// @c DB F0+i
	/// @par
	/// @c 8087+ and CMOV
	/// @par
	/// @c 16/32/64-bit
	FCOMI_ST0_STI = 588,
	/// @brief @c FADD m64fp
	/// @par
	/// @c DC /0
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FADD_M64FP = 589,
	/// @brief @c FMUL m64fp
	/// @par
	/// @c DC /1
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FMUL_M64FP = 590,
	/// @brief @c FCOM m64fp
	/// @par
	/// @c DC /2
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FCOM_M64FP = 591,
	/// @brief @c FCOMP m64fp
	/// @par
	/// @c DC /3
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FCOMP_M64FP = 592,
	/// @brief @c FSUB m64fp
	/// @par
	/// @c DC /4
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FSUB_M64FP = 593,
	/// @brief @c FSUBR m64fp
	/// @par
	/// @c DC /5
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FSUBR_M64FP = 594,
	/// @brief @c FDIV m64fp
	/// @par
	/// @c DC /6
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FDIV_M64FP = 595,
	/// @brief @c FDIVR m64fp
	/// @par
	/// @c DC /7
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FDIVR_M64FP = 596,
	/// @brief @c FADD ST(i), ST(0)
	/// @par
	/// @c DC C0+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FADD_STI_ST0 = 597,
	/// @brief @c FMUL ST(i), ST(0)
	/// @par
	/// @c DC C8+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FMUL_STI_ST0 = 598,
	/// @brief @c FCOM ST(i)
	/// @par
	/// @c DC D0+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FCOM_ST0_STI_DCD0 = 599,
	/// @brief @c FCOMP ST(i)
	/// @par
	/// @c DC D8+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FCOMP_ST0_STI_DCD8 = 600,
	/// @brief @c FSUBR ST(i), ST(0)
	/// @par
	/// @c DC E0+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FSUBR_STI_ST0 = 601,
	/// @brief @c FSUB ST(i), ST(0)
	/// @par
	/// @c DC E8+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FSUB_STI_ST0 = 602,
	/// @brief @c FDIVR ST(i), ST(0)
	/// @par
	/// @c DC F0+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FDIVR_STI_ST0 = 603,
	/// @brief @c FDIV ST(i), ST(0)
	/// @par
	/// @c DC F8+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FDIV_STI_ST0 = 604,
	/// @brief @c FLD m64fp
	/// @par
	/// @c DD /0
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FLD_M64FP = 605,
	/// @brief @c FISTTP m64int
	/// @par
	/// @c DD /1
	/// @par
	/// @c 8087+ and SSE3
	/// @par
	/// @c 16/32/64-bit
	FISTTP_M64INT = 606,
	/// @brief @c FST m64fp
	/// @par
	/// @c DD /2
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FST_M64FP = 607,
	/// @brief @c FSTP m64fp
	/// @par
	/// @c DD /3
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FSTP_M64FP = 608,
	/// @brief @c FRSTOR m94byte
	/// @par
	/// @c o16 DD /4
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FRSTOR_M94BYTE = 609,
	/// @brief @c FRSTOR m108byte
	/// @par
	/// @c o32 DD /4
	/// @par
	/// @c 387+
	/// @par
	/// @c 16/32/64-bit
	FRSTOR_M108BYTE = 610,
	/// @brief @c FNSAVE m94byte
	/// @par
	/// @c o16 DD /6
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FNSAVE_M94BYTE = 611,
	/// @brief @c FSAVE m94byte
	/// @par
	/// @c 9B o16 DD /6
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FSAVE_M94BYTE = 612,
	/// @brief @c FNSAVE m108byte
	/// @par
	/// @c o32 DD /6
	/// @par
	/// @c 387+
	/// @par
	/// @c 16/32/64-bit
	FNSAVE_M108BYTE = 613,
	/// @brief @c FSAVE m108byte
	/// @par
	/// @c 9B o32 DD /6
	/// @par
	/// @c 387+
	/// @par
	/// @c 16/32/64-bit
	FSAVE_M108BYTE = 614,
	/// @brief @c FNSTSW m2byte
	/// @par
	/// @c DD /7
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FNSTSW_M2BYTE = 615,
	/// @brief @c FSTSW m2byte
	/// @par
	/// @c 9B DD /7
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FSTSW_M2BYTE = 616,
	/// @brief @c FFREE ST(i)
	/// @par
	/// @c DD C0+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FFREE_STI = 617,
	/// @brief @c FXCH ST(i)
	/// @par
	/// @c DD C8+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FXCH_ST0_STI_DDC8 = 618,
	/// @brief @c FST ST(i)
	/// @par
	/// @c DD D0+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FST_STI = 619,
	/// @brief @c FSTP ST(i)
	/// @par
	/// @c DD D8+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FSTP_STI = 620,
	/// @brief @c FUCOM ST(i)
	/// @par
	/// @c DD E0+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FUCOM_ST0_STI = 621,
	/// @brief @c FUCOMP ST(i)
	/// @par
	/// @c DD E8+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FUCOMP_ST0_STI = 622,
	/// @brief @c FIADD m16int
	/// @par
	/// @c DE /0
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FIADD_M16INT = 623,
	/// @brief @c FIMUL m16int
	/// @par
	/// @c DE /1
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FIMUL_M16INT = 624,
	/// @brief @c FICOM m16int
	/// @par
	/// @c DE /2
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FICOM_M16INT = 625,
	/// @brief @c FICOMP m16int
	/// @par
	/// @c DE /3
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FICOMP_M16INT = 626,
	/// @brief @c FISUB m16int
	/// @par
	/// @c DE /4
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FISUB_M16INT = 627,
	/// @brief @c FISUBR m16int
	/// @par
	/// @c DE /5
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FISUBR_M16INT = 628,
	/// @brief @c FIDIV m16int
	/// @par
	/// @c DE /6
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FIDIV_M16INT = 629,
	/// @brief @c FIDIVR m16int
	/// @par
	/// @c DE /7
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FIDIVR_M16INT = 630,
	/// @brief @c FADDP ST(i), ST(0)
	/// @par
	/// @c DE C0+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FADDP_STI_ST0 = 631,
	/// @brief @c FMULP ST(i), ST(0)
	/// @par
	/// @c DE C8+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FMULP_STI_ST0 = 632,
	/// @brief @c FCOMP ST(i)
	/// @par
	/// @c DE D0+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FCOMP_ST0_STI_DED0 = 633,
	/// @brief @c FCOMPP
	/// @par
	/// @c DE D9
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FCOMPP = 634,
	/// @brief @c FSUBRP ST(i), ST(0)
	/// @par
	/// @c DE E0+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FSUBRP_STI_ST0 = 635,
	/// @brief @c FSUBP ST(i), ST(0)
	/// @par
	/// @c DE E8+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FSUBP_STI_ST0 = 636,
	/// @brief @c FDIVRP ST(i), ST(0)
	/// @par
	/// @c DE F0+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FDIVRP_STI_ST0 = 637,
	/// @brief @c FDIVP ST(i), ST(0)
	/// @par
	/// @c DE F8+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FDIVP_STI_ST0 = 638,
	/// @brief @c FILD m16int
	/// @par
	/// @c DF /0
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FILD_M16INT = 639,
	/// @brief @c FISTTP m16int
	/// @par
	/// @c DF /1
	/// @par
	/// @c 8087+ and SSE3
	/// @par
	/// @c 16/32/64-bit
	FISTTP_M16INT = 640,
	/// @brief @c FIST m16int
	/// @par
	/// @c DF /2
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FIST_M16INT = 641,
	/// @brief @c FISTP m16int
	/// @par
	/// @c DF /3
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FISTP_M16INT = 642,
	/// @brief @c FBLD m80bcd
	/// @par
	/// @c DF /4
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FBLD_M80BCD = 643,
	/// @brief @c FILD m64int
	/// @par
	/// @c DF /5
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FILD_M64INT = 644,
	/// @brief @c FBSTP m80bcd
	/// @par
	/// @c DF /6
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FBSTP_M80BCD = 645,
	/// @brief @c FISTP m64int
	/// @par
	/// @c DF /7
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FISTP_M64INT = 646,
	/// @brief @c FFREEP ST(i)
	/// @par
	/// @c DF C0+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FFREEP_STI = 647,
	/// @brief @c FXCH ST(i)
	/// @par
	/// @c DF C8+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FXCH_ST0_STI_DFC8 = 648,
	/// @brief @c FSTP ST(i)
	/// @par
	/// @c DF D0+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FSTP_STI_DFD0 = 649,
	/// @brief @c FSTP ST(i)
	/// @par
	/// @c DF D8+i
	/// @par
	/// @c 8087+
	/// @par
	/// @c 16/32/64-bit
	FSTP_STI_DFD8 = 650,
	/// @brief @c FNSTSW AX
	/// @par
	/// @c DF E0
	/// @par
	/// @c 287+
	/// @par
	/// @c 16/32/64-bit
	FNSTSW_AX = 651,
	/// @brief @c FSTSW AX
	/// @par
	/// @c 9B DF E0
	/// @par
	/// @c 287+
	/// @par
	/// @c 16/32/64-bit
	FSTSW_AX = 652,
	/// @brief @c FSTDW AX
	/// @par
	/// @c 9B DF E1
	/// @par
	/// @c 387 SL
	/// @par
	/// @c 16/32-bit
	FSTDW_AX = 653,
	/// @brief @c FSTSG AX
	/// @par
	/// @c 9B DF E2
	/// @par
	/// @c 387 SL
	/// @par
	/// @c 16/32-bit
	FSTSG_AX = 654,
	/// @brief @c FUCOMIP ST, ST(i)
	/// @par
	/// @c DF E8+i
	/// @par
	/// @c 8087+ and CMOV
	/// @par
	/// @c 16/32/64-bit
	FUCOMIP_ST0_STI = 655,
	/// @brief @c FCOMIP ST, ST(i)
	/// @par
	/// @c DF F0+i
	/// @par
	/// @c 8087+ and CMOV
	/// @par
	/// @c 16/32/64-bit
	FCOMIP_ST0_STI = 656,
	/// @brief @c LOOPNE rel8
	/// @par
	/// @c a16 o16 E0 cb
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	LOOPNE_REL8_16_CX = 657,
	/// @brief @c LOOPNE rel8
	/// @par
	/// @c a16 o32 E0 cb
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	LOOPNE_REL8_32_CX = 658,
	/// @brief @c LOOPNE rel8
	/// @par
	/// @c a32 o16 E0 cb
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	LOOPNE_REL8_16_ECX = 659,
	/// @brief @c LOOPNE rel8
	/// @par
	/// @c a32 o32 E0 cb
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	LOOPNE_REL8_32_ECX = 660,
	/// @brief @c LOOPNE rel8
	/// @par
	/// @c a32 o64 E0 cb
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	LOOPNE_REL8_64_ECX = 661,
	/// @brief @c LOOPNE rel8
	/// @par
	/// @c a64 o16 E0 cb
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	LOOPNE_REL8_16_RCX = 662,
	/// @brief @c LOOPNE rel8
	/// @par
	/// @c a64 o64 E0 cb
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	LOOPNE_REL8_64_RCX = 663,
	/// @brief @c LOOPE rel8
	/// @par
	/// @c a16 o16 E1 cb
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	LOOPE_REL8_16_CX = 664,
	/// @brief @c LOOPE rel8
	/// @par
	/// @c a16 o32 E1 cb
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	LOOPE_REL8_32_CX = 665,
	/// @brief @c LOOPE rel8
	/// @par
	/// @c a32 o16 E1 cb
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	LOOPE_REL8_16_ECX = 666,
	/// @brief @c LOOPE rel8
	/// @par
	/// @c a32 o32 E1 cb
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	LOOPE_REL8_32_ECX = 667,
	/// @brief @c LOOPE rel8
	/// @par
	/// @c a32 o64 E1 cb
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	LOOPE_REL8_64_ECX = 668,
	/// @brief @c LOOPE rel8
	/// @par
	/// @c a64 o16 E1 cb
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	LOOPE_REL8_16_RCX = 669,
	/// @brief @c LOOPE rel8
	/// @par
	/// @c a64 o64 E1 cb
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	LOOPE_REL8_64_RCX = 670,
	/// @brief @c LOOP rel8
	/// @par
	/// @c a16 o16 E2 cb
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	LOOP_REL8_16_CX = 671,
	/// @brief @c LOOP rel8
	/// @par
	/// @c a16 o32 E2 cb
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	LOOP_REL8_32_CX = 672,
	/// @brief @c LOOP rel8
	/// @par
	/// @c a32 o16 E2 cb
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	LOOP_REL8_16_ECX = 673,
	/// @brief @c LOOP rel8
	/// @par
	/// @c a32 o32 E2 cb
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	LOOP_REL8_32_ECX = 674,
	/// @brief @c LOOP rel8
	/// @par
	/// @c a32 o64 E2 cb
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	LOOP_REL8_64_ECX = 675,
	/// @brief @c LOOP rel8
	/// @par
	/// @c a64 o16 E2 cb
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	LOOP_REL8_16_RCX = 676,
	/// @brief @c LOOP rel8
	/// @par
	/// @c a64 o64 E2 cb
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	LOOP_REL8_64_RCX = 677,
	/// @brief @c JCXZ rel8
	/// @par
	/// @c a16 o16 E3 cb
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	JCXZ_REL8_16 = 678,
	/// @brief @c JCXZ rel8
	/// @par
	/// @c a16 o32 E3 cb
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JCXZ_REL8_32 = 679,
	/// @brief @c JECXZ rel8
	/// @par
	/// @c a32 o16 E3 cb
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	JECXZ_REL8_16 = 680,
	/// @brief @c JECXZ rel8
	/// @par
	/// @c a32 o32 E3 cb
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JECXZ_REL8_32 = 681,
	/// @brief @c JECXZ rel8
	/// @par
	/// @c a32 o64 E3 cb
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JECXZ_REL8_64 = 682,
	/// @brief @c JRCXZ rel8
	/// @par
	/// @c a64 o16 E3 cb
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JRCXZ_REL8_16 = 683,
	/// @brief @c JRCXZ rel8
	/// @par
	/// @c a64 o64 E3 cb
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JRCXZ_REL8_64 = 684,
	/// @brief @c IN AL, imm8
	/// @par
	/// @c E4 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	IN_AL_IMM8 = 685,
	/// @brief @c IN AX, imm8
	/// @par
	/// @c o16 E5 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	IN_AX_IMM8 = 686,
	/// @brief @c IN EAX, imm8
	/// @par
	/// @c o32 E5 ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	IN_EAX_IMM8 = 687,
	/// @brief @c OUT imm8, AL
	/// @par
	/// @c E6 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	OUT_IMM8_AL = 688,
	/// @brief @c OUT imm8, AX
	/// @par
	/// @c o16 E7 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	OUT_IMM8_AX = 689,
	/// @brief @c OUT imm8, EAX
	/// @par
	/// @c o32 E7 ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	OUT_IMM8_EAX = 690,
	/// @brief @c CALL rel16
	/// @par
	/// @c o16 E8 cw
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	CALL_REL16 = 691,
	/// @brief @c CALL rel32
	/// @par
	/// @c o32 E8 cd
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	CALL_REL32_32 = 692,
	/// @brief @c CALL rel32
	/// @par
	/// @c o64 E8 cd
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	CALL_REL32_64 = 693,
	/// @brief @c JMP rel16
	/// @par
	/// @c o16 E9 cw
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	JMP_REL16 = 694,
	/// @brief @c JMP rel32
	/// @par
	/// @c o32 E9 cd
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JMP_REL32_32 = 695,
	/// @brief @c JMP rel32
	/// @par
	/// @c o64 E9 cd
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JMP_REL32_64 = 696,
	/// @brief @c JMP ptr16:16
	/// @par
	/// @c o16 EA cd
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32-bit
	JMP_PTR1616 = 697,
	/// @brief @c JMP ptr16:32
	/// @par
	/// @c o32 EA cp
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JMP_PTR1632 = 698,
	/// @brief @c JMP rel8
	/// @par
	/// @c o16 EB cb
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	JMP_REL8_16 = 699,
	/// @brief @c JMP rel8
	/// @par
	/// @c o32 EB cb
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JMP_REL8_32 = 700,
	/// @brief @c JMP rel8
	/// @par
	/// @c o64 EB cb
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JMP_REL8_64 = 701,
	/// @brief @c IN AL, DX
	/// @par
	/// @c EC
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	IN_AL_DX = 702,
	/// @brief @c IN AX, DX
	/// @par
	/// @c o16 ED
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	IN_AX_DX = 703,
	/// @brief @c IN EAX, DX
	/// @par
	/// @c o32 ED
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	IN_EAX_DX = 704,
	/// @brief @c OUT DX, AL
	/// @par
	/// @c EE
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	OUT_DX_AL = 705,
	/// @brief @c OUT DX, AX
	/// @par
	/// @c o16 EF
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	OUT_DX_AX = 706,
	/// @brief @c OUT DX, EAX
	/// @par
	/// @c o32 EF
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	OUT_DX_EAX = 707,
	/// @brief @c INT1
	/// @par
	/// @c F1
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	INT1 = 708,
	/// @brief @c HLT
	/// @par
	/// @c F4
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	HLT = 709,
	/// @brief @c CMC
	/// @par
	/// @c F5
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	CMC = 710,
	/// @brief @c TEST r/m8, imm8
	/// @par
	/// @c F6 /0 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	TEST_RM8_IMM8 = 711,
	/// @brief @c TEST r/m8, imm8
	/// @par
	/// @c F6 /1 ib
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	TEST_RM8_IMM8_F6R1 = 712,
	/// @brief @c NOT r/m8
	/// @par
	/// @c F6 /2
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	NOT_RM8 = 713,
	/// @brief @c NEG r/m8
	/// @par
	/// @c F6 /3
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	NEG_RM8 = 714,
	/// @brief @c MUL r/m8
	/// @par
	/// @c F6 /4
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	MUL_RM8 = 715,
	/// @brief @c IMUL r/m8
	/// @par
	/// @c F6 /5
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	IMUL_RM8 = 716,
	/// @brief @c DIV r/m8
	/// @par
	/// @c F6 /6
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	DIV_RM8 = 717,
	/// @brief @c IDIV r/m8
	/// @par
	/// @c F6 /7
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	IDIV_RM8 = 718,
	/// @brief @c TEST r/m16, imm16
	/// @par
	/// @c o16 F7 /0 iw
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	TEST_RM16_IMM16 = 719,
	/// @brief @c TEST r/m32, imm32
	/// @par
	/// @c o32 F7 /0 id
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	TEST_RM32_IMM32 = 720,
	/// @brief @c TEST r/m64, imm32
	/// @par
	/// @c o64 F7 /0 id
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	TEST_RM64_IMM32 = 721,
	/// @brief @c TEST r/m16, imm16
	/// @par
	/// @c o16 F7 /1 iw
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	TEST_RM16_IMM16_F7R1 = 722,
	/// @brief @c TEST r/m32, imm32
	/// @par
	/// @c o32 F7 /1 id
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	TEST_RM32_IMM32_F7R1 = 723,
	/// @brief @c TEST r/m64, imm32
	/// @par
	/// @c o64 F7 /1 id
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	TEST_RM64_IMM32_F7R1 = 724,
	/// @brief @c NOT r/m16
	/// @par
	/// @c o16 F7 /2
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	NOT_RM16 = 725,
	/// @brief @c NOT r/m32
	/// @par
	/// @c o32 F7 /2
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	NOT_RM32 = 726,
	/// @brief @c NOT r/m64
	/// @par
	/// @c o64 F7 /2
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	NOT_RM64 = 727,
	/// @brief @c NEG r/m16
	/// @par
	/// @c o16 F7 /3
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	NEG_RM16 = 728,
	/// @brief @c NEG r/m32
	/// @par
	/// @c o32 F7 /3
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	NEG_RM32 = 729,
	/// @brief @c NEG r/m64
	/// @par
	/// @c o64 F7 /3
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	NEG_RM64 = 730,
	/// @brief @c MUL r/m16
	/// @par
	/// @c o16 F7 /4
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	MUL_RM16 = 731,
	/// @brief @c MUL r/m32
	/// @par
	/// @c o32 F7 /4
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	MUL_RM32 = 732,
	/// @brief @c MUL r/m64
	/// @par
	/// @c o64 F7 /4
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	MUL_RM64 = 733,
	/// @brief @c IMUL r/m16
	/// @par
	/// @c o16 F7 /5
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	IMUL_RM16 = 734,
	/// @brief @c IMUL r/m32
	/// @par
	/// @c o32 F7 /5
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	IMUL_RM32 = 735,
	/// @brief @c IMUL r/m64
	/// @par
	/// @c o64 F7 /5
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	IMUL_RM64 = 736,
	/// @brief @c DIV r/m16
	/// @par
	/// @c o16 F7 /6
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	DIV_RM16 = 737,
	/// @brief @c DIV r/m32
	/// @par
	/// @c o32 F7 /6
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	DIV_RM32 = 738,
	/// @brief @c DIV r/m64
	/// @par
	/// @c o64 F7 /6
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	DIV_RM64 = 739,
	/// @brief @c IDIV r/m16
	/// @par
	/// @c o16 F7 /7
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	IDIV_RM16 = 740,
	/// @brief @c IDIV r/m32
	/// @par
	/// @c o32 F7 /7
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	IDIV_RM32 = 741,
	/// @brief @c IDIV r/m64
	/// @par
	/// @c o64 F7 /7
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	IDIV_RM64 = 742,
	/// @brief @c CLC
	/// @par
	/// @c F8
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	CLC = 743,
	/// @brief @c STC
	/// @par
	/// @c F9
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	STC = 744,
	/// @brief @c CLI
	/// @par
	/// @c FA
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	CLI = 745,
	/// @brief @c STI
	/// @par
	/// @c FB
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	STI = 746,
	/// @brief @c CLD
	/// @par
	/// @c FC
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	CLD = 747,
	/// @brief @c STD
	/// @par
	/// @c FD
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	STD = 748,
	/// @brief @c INC r/m8
	/// @par
	/// @c FE /0
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	INC_RM8 = 749,
	/// @brief @c DEC r/m8
	/// @par
	/// @c FE /1
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	DEC_RM8 = 750,
	/// @brief @c INC r/m16
	/// @par
	/// @c o16 FF /0
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	INC_RM16 = 751,
	/// @brief @c INC r/m32
	/// @par
	/// @c o32 FF /0
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	INC_RM32 = 752,
	/// @brief @c INC r/m64
	/// @par
	/// @c o64 FF /0
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	INC_RM64 = 753,
	/// @brief @c DEC r/m16
	/// @par
	/// @c o16 FF /1
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	DEC_RM16 = 754,
	/// @brief @c DEC r/m32
	/// @par
	/// @c o32 FF /1
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	DEC_RM32 = 755,
	/// @brief @c DEC r/m64
	/// @par
	/// @c o64 FF /1
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	DEC_RM64 = 756,
	/// @brief @c CALL r/m16
	/// @par
	/// @c o16 FF /2
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	CALL_RM16 = 757,
	/// @brief @c CALL r/m32
	/// @par
	/// @c o32 FF /2
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	CALL_RM32 = 758,
	/// @brief @c CALL r/m64
	/// @par
	/// @c o64 FF /2
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	CALL_RM64 = 759,
	/// @brief @c CALL m16:16
	/// @par
	/// @c o16 FF /3
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	CALL_M1616 = 760,
	/// @brief @c CALL m16:32
	/// @par
	/// @c o32 FF /3
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	CALL_M1632 = 761,
	/// @brief @c CALL m16:64
	/// @par
	/// @c o64 FF /3
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	CALL_M1664 = 762,
	/// @brief @c JMP r/m16
	/// @par
	/// @c o16 FF /4
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	JMP_RM16 = 763,
	/// @brief @c JMP r/m32
	/// @par
	/// @c o32 FF /4
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JMP_RM32 = 764,
	/// @brief @c JMP r/m64
	/// @par
	/// @c o64 FF /4
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JMP_RM64 = 765,
	/// @brief @c JMP m16:16
	/// @par
	/// @c o16 FF /5
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	JMP_M1616 = 766,
	/// @brief @c JMP m16:32
	/// @par
	/// @c o32 FF /5
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	JMP_M1632 = 767,
	/// @brief @c JMP m16:64
	/// @par
	/// @c o64 FF /5
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JMP_M1664 = 768,
	/// @brief @c PUSH r/m16
	/// @par
	/// @c o16 FF /6
	/// @par
	/// @c 8086+
	/// @par
	/// @c 16/32/64-bit
	PUSH_RM16 = 769,
	/// @brief @c PUSH r/m32
	/// @par
	/// @c o32 FF /6
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	PUSH_RM32 = 770,
	/// @brief @c PUSH r/m64
	/// @par
	/// @c o64 FF /6
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	PUSH_RM64 = 771,
	/// @brief @c SLDT r/m16
	/// @par
	/// @c o16 0F 00 /0
	/// @par
	/// @c 286+
	/// @par
	/// @c 16/32/64-bit
	SLDT_RM16 = 772,
	/// @brief @c SLDT r32/m16
	/// @par
	/// @c o32 0F 00 /0
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SLDT_R32M16 = 773,
	/// @brief @c SLDT r64/m16
	/// @par
	/// @c o64 0F 00 /0
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SLDT_R64M16 = 774,
	/// @brief @c STR r/m16
	/// @par
	/// @c o16 0F 00 /1
	/// @par
	/// @c 286+
	/// @par
	/// @c 16/32/64-bit
	STR_RM16 = 775,
	/// @brief @c STR r32/m16
	/// @par
	/// @c o32 0F 00 /1
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	STR_R32M16 = 776,
	/// @brief @c STR r64/m16
	/// @par
	/// @c o64 0F 00 /1
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	STR_R64M16 = 777,
	/// @brief @c LLDT r/m16
	/// @par
	/// @c o16 0F 00 /2
	/// @par
	/// @c 286+
	/// @par
	/// @c 16/32/64-bit
	LLDT_RM16 = 778,
	/// @brief @c LLDT r32/m16
	/// @par
	/// @c o32 0F 00 /2
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	LLDT_R32M16 = 779,
	/// @brief @c LLDT r64/m16
	/// @par
	/// @c o64 0F 00 /2
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	LLDT_R64M16 = 780,
	/// @brief @c LTR r/m16
	/// @par
	/// @c o16 0F 00 /3
	/// @par
	/// @c 286+
	/// @par
	/// @c 16/32/64-bit
	LTR_RM16 = 781,
	/// @brief @c LTR r32/m16
	/// @par
	/// @c o32 0F 00 /3
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	LTR_R32M16 = 782,
	/// @brief @c LTR r64/m16
	/// @par
	/// @c o64 0F 00 /3
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	LTR_R64M16 = 783,
	/// @brief @c VERR r/m16
	/// @par
	/// @c o16 0F 00 /4
	/// @par
	/// @c 286+
	/// @par
	/// @c 16/32/64-bit
	VERR_RM16 = 784,
	/// @brief @c VERR r32/m16
	/// @par
	/// @c o32 0F 00 /4
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	VERR_R32M16 = 785,
	/// @brief @c VERR r64/m16
	/// @par
	/// @c o64 0F 00 /4
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	VERR_R64M16 = 786,
	/// @brief @c VERW r/m16
	/// @par
	/// @c o16 0F 00 /5
	/// @par
	/// @c 286+
	/// @par
	/// @c 16/32/64-bit
	VERW_RM16 = 787,
	/// @brief @c VERW r32/m16
	/// @par
	/// @c o32 0F 00 /5
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	VERW_R32M16 = 788,
	/// @brief @c VERW r64/m16
	/// @par
	/// @c o64 0F 00 /5
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	VERW_R64M16 = 789,
	/// @brief @c JMPE r/m16
	/// @par
	/// @c o16 0F 00 /6
	/// @par
	/// @c IA-64
	/// @par
	/// @c 16/32-bit
	JMPE_RM16 = 790,
	/// @brief @c JMPE r/m32
	/// @par
	/// @c o32 0F 00 /6
	/// @par
	/// @c IA-64
	/// @par
	/// @c 16/32-bit
	JMPE_RM32 = 791,
	/// @brief @c SGDT m
	/// @par
	/// @c o16 0F 01 /0
	/// @par
	/// @c 286+
	/// @par
	/// @c 16/32-bit
	SGDT_M1632_16 = 792,
	/// @brief @c SGDT m
	/// @par
	/// @c o32 0F 01 /0
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	SGDT_M1632 = 793,
	/// @brief @c SGDT m
	/// @par
	/// @c 0F 01 /0
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SGDT_M1664 = 794,
	/// @brief @c SIDT m
	/// @par
	/// @c o16 0F 01 /1
	/// @par
	/// @c 286+
	/// @par
	/// @c 16/32-bit
	SIDT_M1632_16 = 795,
	/// @brief @c SIDT m
	/// @par
	/// @c o32 0F 01 /1
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	SIDT_M1632 = 796,
	/// @brief @c SIDT m
	/// @par
	/// @c 0F 01 /1
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SIDT_M1664 = 797,
	/// @brief @c LGDT m16&32
	/// @par
	/// @c o16 0F 01 /2
	/// @par
	/// @c 286+
	/// @par
	/// @c 16/32-bit
	LGDT_M1632_16 = 798,
	/// @brief @c LGDT m16&32
	/// @par
	/// @c o32 0F 01 /2
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	LGDT_M1632 = 799,
	/// @brief @c LGDT m16&64
	/// @par
	/// @c 0F 01 /2
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	LGDT_M1664 = 800,
	/// @brief @c LIDT m16&32
	/// @par
	/// @c o16 0F 01 /3
	/// @par
	/// @c 286+
	/// @par
	/// @c 16/32-bit
	LIDT_M1632_16 = 801,
	/// @brief @c LIDT m16&32
	/// @par
	/// @c o32 0F 01 /3
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	LIDT_M1632 = 802,
	/// @brief @c LIDT m16&64
	/// @par
	/// @c 0F 01 /3
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	LIDT_M1664 = 803,
	/// @brief @c SMSW r/m16
	/// @par
	/// @c o16 0F 01 /4
	/// @par
	/// @c 286+
	/// @par
	/// @c 16/32/64-bit
	SMSW_RM16 = 804,
	/// @brief @c SMSW r32/m16
	/// @par
	/// @c o32 0F 01 /4
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SMSW_R32M16 = 805,
	/// @brief @c SMSW r64/m16
	/// @par
	/// @c o64 0F 01 /4
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SMSW_R64M16 = 806,
	/// @brief @c RSTORSSP m64
	/// @par
	/// @c F3 0F 01 /5
	/// @par
	/// @c CET_SS
	/// @par
	/// @c 16/32/64-bit
	RSTORSSP_M64 = 807,
	/// @brief @c LMSW r/m16
	/// @par
	/// @c o16 0F 01 /6
	/// @par
	/// @c 286+
	/// @par
	/// @c 16/32/64-bit
	LMSW_RM16 = 808,
	/// @brief @c LMSW r32/m16
	/// @par
	/// @c o32 0F 01 /6
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	LMSW_R32M16 = 809,
	/// @brief @c LMSW r64/m16
	/// @par
	/// @c o64 0F 01 /6
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	LMSW_R64M16 = 810,
	/// @brief @c INVLPG m
	/// @par
	/// @c 0F 01 /7
	/// @par
	/// @c 486+
	/// @par
	/// @c 16/32/64-bit
	INVLPG_M = 811,
	/// @brief @c ENCLV
	/// @par
	/// @c NP 0F 01 C0
	/// @par
	/// @c OSS
	/// @par
	/// @c 16/32/64-bit
	ENCLV = 812,
	/// @brief @c VMCALL
	/// @par
	/// @c NP 0F 01 C1
	/// @par
	/// @c VMX
	/// @par
	/// @c 16/32/64-bit
	VMCALL = 813,
	/// @brief @c VMLAUNCH
	/// @par
	/// @c NP 0F 01 C2
	/// @par
	/// @c VMX
	/// @par
	/// @c 16/32/64-bit
	VMLAUNCH = 814,
	/// @brief @c VMRESUME
	/// @par
	/// @c NP 0F 01 C3
	/// @par
	/// @c VMX
	/// @par
	/// @c 16/32/64-bit
	VMRESUME = 815,
	/// @brief @c VMXOFF
	/// @par
	/// @c NP 0F 01 C4
	/// @par
	/// @c VMX
	/// @par
	/// @c 16/32/64-bit
	VMXOFF = 816,
	/// @brief @c PCONFIG
	/// @par
	/// @c NP 0F 01 C5
	/// @par
	/// @c PCONFIG
	/// @par
	/// @c 16/32/64-bit
	PCONFIG = 817,
	/// @brief @c MONITOR
	/// @par
	/// @c a16 NP 0F 01 C8
	/// @par
	/// @c MONITOR
	/// @par
	/// @c 16/32-bit
	MONITORW = 818,
	/// @brief @c MONITOR
	/// @par
	/// @c a32 NP 0F 01 C8
	/// @par
	/// @c MONITOR
	/// @par
	/// @c 16/32/64-bit
	MONITORD = 819,
	/// @brief @c MONITOR
	/// @par
	/// @c a64 NP 0F 01 C8
	/// @par
	/// @c MONITOR
	/// @par
	/// @c 64-bit
	MONITORQ = 820,
	/// @brief @c MWAIT
	/// @par
	/// @c NP 0F 01 C9
	/// @par
	/// @c MONITOR
	/// @par
	/// @c 16/32/64-bit
	MWAIT = 821,
	/// @brief @c CLAC
	/// @par
	/// @c NP 0F 01 CA
	/// @par
	/// @c SMAP
	/// @par
	/// @c 16/32/64-bit
	CLAC = 822,
	/// @brief @c STAC
	/// @par
	/// @c NP 0F 01 CB
	/// @par
	/// @c SMAP
	/// @par
	/// @c 16/32/64-bit
	STAC = 823,
	/// @brief @c ENCLS
	/// @par
	/// @c NP 0F 01 CF
	/// @par
	/// @c SGX1
	/// @par
	/// @c 16/32/64-bit
	ENCLS = 824,
	/// @brief @c XGETBV
	/// @par
	/// @c NP 0F 01 D0
	/// @par
	/// @c XSAVE
	/// @par
	/// @c 16/32/64-bit
	XGETBV = 825,
	/// @brief @c XSETBV
	/// @par
	/// @c NP 0F 01 D1
	/// @par
	/// @c XSAVE
	/// @par
	/// @c 16/32/64-bit
	XSETBV = 826,
	/// @brief @c VMFUNC
	/// @par
	/// @c NP 0F 01 D4
	/// @par
	/// @c VMX
	/// @par
	/// @c 16/32/64-bit
	VMFUNC = 827,
	/// @brief @c XEND
	/// @par
	/// @c NP 0F 01 D5
	/// @par
	/// @c RTM
	/// @par
	/// @c 16/32/64-bit
	XEND = 828,
	/// @brief @c XTEST
	/// @par
	/// @c NP 0F 01 D6
	/// @par
	/// @c HLE or RTM
	/// @par
	/// @c 16/32/64-bit
	XTEST = 829,
	/// @brief @c ENCLU
	/// @par
	/// @c NP 0F 01 D7
	/// @par
	/// @c SGX1
	/// @par
	/// @c 16/32/64-bit
	ENCLU = 830,
	/// @brief @c VMRUN
	/// @par
	/// @c a16 0F 01 D8
	/// @par
	/// @c SVM
	/// @par
	/// @c 16/32-bit
	VMRUNW = 831,
	/// @brief @c VMRUN
	/// @par
	/// @c a32 0F 01 D8
	/// @par
	/// @c SVM
	/// @par
	/// @c 16/32/64-bit
	VMRUND = 832,
	/// @brief @c VMRUN
	/// @par
	/// @c a64 0F 01 D8
	/// @par
	/// @c SVM
	/// @par
	/// @c 64-bit
	VMRUNQ = 833,
	/// @brief @c VMMCALL
	/// @par
	/// @c 0F 01 D9
	/// @par
	/// @c SVM
	/// @par
	/// @c 16/32/64-bit
	VMMCALL = 834,
	/// @brief @c VMLOAD
	/// @par
	/// @c a16 0F 01 DA
	/// @par
	/// @c SVM
	/// @par
	/// @c 16/32-bit
	VMLOADW = 835,
	/// @brief @c VMLOAD
	/// @par
	/// @c a32 0F 01 DA
	/// @par
	/// @c SVM
	/// @par
	/// @c 16/32/64-bit
	VMLOADD = 836,
	/// @brief @c VMLOAD
	/// @par
	/// @c a64 0F 01 DA
	/// @par
	/// @c SVM
	/// @par
	/// @c 64-bit
	VMLOADQ = 837,
	/// @brief @c VMSAVE
	/// @par
	/// @c a16 0F 01 DB
	/// @par
	/// @c SVM
	/// @par
	/// @c 16/32-bit
	VMSAVEW = 838,
	/// @brief @c VMSAVE
	/// @par
	/// @c a32 0F 01 DB
	/// @par
	/// @c SVM
	/// @par
	/// @c 16/32/64-bit
	VMSAVED = 839,
	/// @brief @c VMSAVE
	/// @par
	/// @c a64 0F 01 DB
	/// @par
	/// @c SVM
	/// @par
	/// @c 64-bit
	VMSAVEQ = 840,
	/// @brief @c STGI
	/// @par
	/// @c 0F 01 DC
	/// @par
	/// @c SKINIT or SVM
	/// @par
	/// @c 16/32/64-bit
	STGI = 841,
	/// @brief @c CLGI
	/// @par
	/// @c 0F 01 DD
	/// @par
	/// @c SVM
	/// @par
	/// @c 16/32/64-bit
	CLGI = 842,
	/// @brief @c SKINIT
	/// @par
	/// @c 0F 01 DE
	/// @par
	/// @c SKINIT or SVM
	/// @par
	/// @c 16/32/64-bit
	SKINIT = 843,
	/// @brief @c INVLPGA
	/// @par
	/// @c a16 0F 01 DF
	/// @par
	/// @c SVM
	/// @par
	/// @c 16/32-bit
	INVLPGAW = 844,
	/// @brief @c INVLPGA
	/// @par
	/// @c a32 0F 01 DF
	/// @par
	/// @c SVM
	/// @par
	/// @c 16/32/64-bit
	INVLPGAD = 845,
	/// @brief @c INVLPGA
	/// @par
	/// @c a64 0F 01 DF
	/// @par
	/// @c SVM
	/// @par
	/// @c 64-bit
	INVLPGAQ = 846,
	/// @brief @c SETSSBSY
	/// @par
	/// @c F3 0F 01 E8
	/// @par
	/// @c CET_SS
	/// @par
	/// @c 16/32/64-bit
	SETSSBSY = 847,
	/// @brief @c SAVEPREVSSP
	/// @par
	/// @c F3 0F 01 EA
	/// @par
	/// @c CET_SS
	/// @par
	/// @c 16/32/64-bit
	SAVEPREVSSP = 848,
	/// @brief @c RDPKRU
	/// @par
	/// @c NP 0F 01 EE
	/// @par
	/// @c PKU
	/// @par
	/// @c 16/32/64-bit
	RDPKRU = 849,
	/// @brief @c WRPKRU
	/// @par
	/// @c NP 0F 01 EF
	/// @par
	/// @c PKU
	/// @par
	/// @c 16/32/64-bit
	WRPKRU = 850,
	/// @brief @c SWAPGS
	/// @par
	/// @c 0F 01 F8
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SWAPGS = 851,
	/// @brief @c RDTSCP
	/// @par
	/// @c 0F 01 F9
	/// @par
	/// @c RDTSCP
	/// @par
	/// @c 16/32/64-bit
	RDTSCP = 852,
	/// @brief @c MONITORX
	/// @par
	/// @c a16 NP 0F 01 FA
	/// @par
	/// @c MONITORX
	/// @par
	/// @c 16/32-bit
	MONITORXW = 853,
	/// @brief @c MONITORX
	/// @par
	/// @c a32 NP 0F 01 FA
	/// @par
	/// @c MONITORX
	/// @par
	/// @c 16/32/64-bit
	MONITORXD = 854,
	/// @brief @c MONITORX
	/// @par
	/// @c a64 NP 0F 01 FA
	/// @par
	/// @c MONITORX
	/// @par
	/// @c 64-bit
	MONITORXQ = 855,
	/// @brief @c MCOMMIT
	/// @par
	/// @c F3 0F 01 FA
	/// @par
	/// @c MCOMMIT
	/// @par
	/// @c 16/32/64-bit
	MCOMMIT = 856,
	/// @brief @c MWAITX
	/// @par
	/// @c NP 0F 01 FB
	/// @par
	/// @c MONITORX
	/// @par
	/// @c 16/32/64-bit
	MWAITX = 857,
	/// @brief @c CLZERO
	/// @par
	/// @c a16 0F 01 FC
	/// @par
	/// @c CLZERO
	/// @par
	/// @c 16/32-bit
	CLZEROW = 858,
	/// @brief @c CLZERO
	/// @par
	/// @c a32 0F 01 FC
	/// @par
	/// @c CLZERO
	/// @par
	/// @c 16/32/64-bit
	CLZEROD = 859,
	/// @brief @c CLZERO
	/// @par
	/// @c a64 0F 01 FC
	/// @par
	/// @c CLZERO
	/// @par
	/// @c 64-bit
	CLZEROQ = 860,
	/// @brief @c RDPRU
	/// @par
	/// @c NP 0F 01 FD
	/// @par
	/// @c RDPRU
	/// @par
	/// @c 16/32/64-bit
	RDPRU = 861,
	/// @brief @c LAR r16, r/m16
	/// @par
	/// @c o16 0F 02 /r
	/// @par
	/// @c 286+
	/// @par
	/// @c 16/32/64-bit
	LAR_R16_RM16 = 862,
	/// @brief @c LAR r32, r32/m16
	/// @par
	/// @c o32 0F 02 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	LAR_R32_R32M16 = 863,
	/// @brief @c LAR r64, r64/m16
	/// @par
	/// @c o64 0F 02 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	LAR_R64_R64M16 = 864,
	/// @brief @c LSL r16, r/m16
	/// @par
	/// @c o16 0F 03 /r
	/// @par
	/// @c 286+
	/// @par
	/// @c 16/32/64-bit
	LSL_R16_RM16 = 865,
	/// @brief @c LSL r32, r32/m16
	/// @par
	/// @c o32 0F 03 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	LSL_R32_R32M16 = 866,
	/// @brief @c LSL r64, r64/m16
	/// @par
	/// @c o64 0F 03 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	LSL_R64_R64M16 = 867,
	/// @brief @c STOREALL
	/// @par
	/// @c 0F 04
	/// @par
	/// @c 286
	/// @par
	/// @c 16/32-bit
	STOREALL = 868,
	/// @brief @c LOADALL
	/// @par
	/// @c 0F 05
	/// @par
	/// @c 286
	/// @par
	/// @c 16/32-bit
	LOADALL286 = 869,
	/// @brief @c SYSCALL
	/// @par
	/// @c 0F 05
	/// @par
	/// @c SYSCALL
	/// @par
	/// @c 16/32/64-bit
	SYSCALL = 870,
	/// @brief @c CLTS
	/// @par
	/// @c 0F 06
	/// @par
	/// @c 286+
	/// @par
	/// @c 16/32/64-bit
	CLTS = 871,
	/// @brief @c LOADALL
	/// @par
	/// @c 0F 07
	/// @par
	/// @c 386
	/// @par
	/// @c 16/32-bit
	LOADALL386 = 872,
	/// @brief @c SYSRET
	/// @par
	/// @c 0F 07
	/// @par
	/// @c SYSCALL
	/// @par
	/// @c 16/32/64-bit
	SYSRETD = 873,
	/// @brief @c SYSRETQ
	/// @par
	/// @c o64 0F 07
	/// @par
	/// @c SYSCALL
	/// @par
	/// @c 64-bit
	SYSRETQ = 874,
	/// @brief @c INVD
	/// @par
	/// @c 0F 08
	/// @par
	/// @c 486+
	/// @par
	/// @c 16/32/64-bit
	INVD = 875,
	/// @brief @c WBINVD
	/// @par
	/// @c 0F 09
	/// @par
	/// @c 486+
	/// @par
	/// @c 16/32/64-bit
	WBINVD = 876,
	/// @brief @c WBNOINVD
	/// @par
	/// @c F3 0F 09
	/// @par
	/// @c WBNOINVD
	/// @par
	/// @c 16/32/64-bit
	WBNOINVD = 877,
	/// @brief @c CL1INVMB
	/// @par
	/// @c 0F 0A
	/// @par
	/// @c CL1INVMB
	/// @par
	/// @c 16/32-bit
	CL1INVMB = 878,
	/// @brief @c UD2
	/// @par
	/// @c 0F 0B
	/// @par
	/// @c 286+
	/// @par
	/// @c 16/32/64-bit
	UD2 = 879,
	/// @brief @c RESERVEDNOP r/m16, r16
	/// @par
	/// @c o16 0F 0D /r
	/// @par
	/// @c CPUID.01H.EAX[Bits 11:8] = 0110B or 1111B
	/// @par
	/// @c 16/32/64-bit
	RESERVEDNOP_RM16_R16_0_F0_D = 880,
	/// @brief @c RESERVEDNOP r/m32, r32
	/// @par
	/// @c o32 0F 0D /r
	/// @par
	/// @c CPUID.01H.EAX[Bits 11:8] = 0110B or 1111B
	/// @par
	/// @c 16/32/64-bit
	RESERVEDNOP_RM32_R32_0_F0_D = 881,
	/// @brief @c RESERVEDNOP r/m64, r64
	/// @par
	/// @c o64 0F 0D /r
	/// @par
	/// @c CPUID.01H.EAX[Bits 11:8] = 0110B or 1111B
	/// @par
	/// @c 64-bit
	RESERVEDNOP_RM64_R64_0_F0_D = 882,
	/// @brief @c PREFETCH m8
	/// @par
	/// @c 0F 0D /0
	/// @par
	/// @c PREFETCHW
	/// @par
	/// @c 16/32/64-bit
	PREFETCH_M8 = 883,
	/// @brief @c PREFETCHW m8
	/// @par
	/// @c 0F 0D /1
	/// @par
	/// @c PREFETCHW
	/// @par
	/// @c 16/32/64-bit
	PREFETCHW_M8 = 884,
	/// @brief @c PREFETCHWT1 m8
	/// @par
	/// @c 0F 0D /2
	/// @par
	/// @c PREFETCHWT1
	/// @par
	/// @c 16/32/64-bit
	PREFETCHWT1_M8 = 885,
	/// @brief @c FEMMS
	/// @par
	/// @c 0F 0E
	/// @par
	/// @c 3DNOW
	/// @par
	/// @c 16/32/64-bit
	FEMMS = 886,
	/// @brief @c UMOV r/m8, r8
	/// @par
	/// @c 0F 10 /r
	/// @par
	/// @c 386/486
	/// @par
	/// @c 16/32-bit
	UMOV_RM8_R8 = 887,
	/// @brief @c UMOV r/m16, r16
	/// @par
	/// @c o16 0F 11 /r
	/// @par
	/// @c 386/486
	/// @par
	/// @c 16/32-bit
	UMOV_RM16_R16 = 888,
	/// @brief @c UMOV r/m32, r32
	/// @par
	/// @c o32 0F 11 /r
	/// @par
	/// @c 386/486
	/// @par
	/// @c 16/32-bit
	UMOV_RM32_R32 = 889,
	/// @brief @c UMOV r8, r/m8
	/// @par
	/// @c 0F 12 /r
	/// @par
	/// @c 386/486
	/// @par
	/// @c 16/32-bit
	UMOV_R8_RM8 = 890,
	/// @brief @c UMOV r16, r/m16
	/// @par
	/// @c o16 0F 13 /r
	/// @par
	/// @c 386/486
	/// @par
	/// @c 16/32-bit
	UMOV_R16_RM16 = 891,
	/// @brief @c UMOV r32, r/m32
	/// @par
	/// @c o32 0F 13 /r
	/// @par
	/// @c 386/486
	/// @par
	/// @c 16/32-bit
	UMOV_R32_RM32 = 892,
	/// @brief @c MOVUPS xmm1, xmm2/m128
	/// @par
	/// @c NP 0F 10 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	MOVUPS_XMM_XMMM128 = 893,
	/// @brief @c VMOVUPS xmm1, xmm2/m128
	/// @par
	/// @c VEX.128.0F.WIG 10 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVUPS_XMM_XMMM128 = 894,
	/// @brief @c VMOVUPS ymm1, ymm2/m256
	/// @par
	/// @c VEX.256.0F.WIG 10 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVUPS_YMM_YMMM256 = 895,
	/// @brief @c VMOVUPS xmm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.128.0F.W0 10 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVUPS_XMM_K1Z_XMMM128 = 896,
	/// @brief @c VMOVUPS ymm1 {k1}{z}, ymm2/m256
	/// @par
	/// @c EVEX.256.0F.W0 10 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVUPS_YMM_K1Z_YMMM256 = 897,
	/// @brief @c VMOVUPS zmm1 {k1}{z}, zmm2/m512
	/// @par
	/// @c EVEX.512.0F.W0 10 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVUPS_ZMM_K1Z_ZMMM512 = 898,
	/// @brief @c MOVUPD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 10 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MOVUPD_XMM_XMMM128 = 899,
	/// @brief @c VMOVUPD xmm1, xmm2/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 10 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVUPD_XMM_XMMM128 = 900,
	/// @brief @c VMOVUPD ymm1, ymm2/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 10 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVUPD_YMM_YMMM256 = 901,
	/// @brief @c VMOVUPD xmm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.128.66.0F.W1 10 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVUPD_XMM_K1Z_XMMM128 = 902,
	/// @brief @c VMOVUPD ymm1 {k1}{z}, ymm2/m256
	/// @par
	/// @c EVEX.256.66.0F.W1 10 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVUPD_YMM_K1Z_YMMM256 = 903,
	/// @brief @c VMOVUPD zmm1 {k1}{z}, zmm2/m512
	/// @par
	/// @c EVEX.512.66.0F.W1 10 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVUPD_ZMM_K1Z_ZMMM512 = 904,
	/// @brief @c MOVSS xmm1, xmm2/m32
	/// @par
	/// @c F3 0F 10 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	MOVSS_XMM_XMMM32 = 905,
	/// @brief @c VMOVSS xmm1, xmm2, xmm3
	/// @par
	/// @c VEX.LIG.F3.0F.WIG 10 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVSS_XMM_XMM_XMM = 906,
	/// @brief @c VMOVSS xmm1, m32
	/// @par
	/// @c VEX.LIG.F3.0F.WIG 10 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVSS_XMM_M32 = 907,
	/// @brief @c VMOVSS xmm1 {k1}{z}, xmm2, xmm3
	/// @par
	/// @c EVEX.LIG.F3.0F.W0 10 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVSS_XMM_K1Z_XMM_XMM = 908,
	/// @brief @c VMOVSS xmm1 {k1}{z}, m32
	/// @par
	/// @c EVEX.LIG.F3.0F.W0 10 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVSS_XMM_K1Z_M32 = 909,
	/// @brief @c MOVSD xmm1, xmm2/m64
	/// @par
	/// @c F2 0F 10 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MOVSD_XMM_XMMM64 = 910,
	/// @brief @c VMOVSD xmm1, xmm2, xmm3
	/// @par
	/// @c VEX.LIG.F2.0F.WIG 10 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVSD_XMM_XMM_XMM = 911,
	/// @brief @c VMOVSD xmm1, m64
	/// @par
	/// @c VEX.LIG.F2.0F.WIG 10 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVSD_XMM_M64 = 912,
	/// @brief @c VMOVSD xmm1 {k1}{z}, xmm2, xmm3
	/// @par
	/// @c EVEX.LIG.F2.0F.W1 10 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVSD_XMM_K1Z_XMM_XMM = 913,
	/// @brief @c VMOVSD xmm1 {k1}{z}, m64
	/// @par
	/// @c EVEX.LIG.F2.0F.W1 10 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVSD_XMM_K1Z_M64 = 914,
	/// @brief @c MOVUPS xmm2/m128, xmm1
	/// @par
	/// @c NP 0F 11 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	MOVUPS_XMMM128_XMM = 915,
	/// @brief @c VMOVUPS xmm2/m128, xmm1
	/// @par
	/// @c VEX.128.0F.WIG 11 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVUPS_XMMM128_XMM = 916,
	/// @brief @c VMOVUPS ymm2/m256, ymm1
	/// @par
	/// @c VEX.256.0F.WIG 11 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVUPS_YMMM256_YMM = 917,
	/// @brief @c VMOVUPS xmm2/m128 {k1}{z}, xmm1
	/// @par
	/// @c EVEX.128.0F.W0 11 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVUPS_XMMM128_K1Z_XMM = 918,
	/// @brief @c VMOVUPS ymm2/m256 {k1}{z}, ymm1
	/// @par
	/// @c EVEX.256.0F.W0 11 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVUPS_YMMM256_K1Z_YMM = 919,
	/// @brief @c VMOVUPS zmm2/m512 {k1}{z}, zmm1
	/// @par
	/// @c EVEX.512.0F.W0 11 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVUPS_ZMMM512_K1Z_ZMM = 920,
	/// @brief @c MOVUPD xmm2/m128, xmm1
	/// @par
	/// @c 66 0F 11 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MOVUPD_XMMM128_XMM = 921,
	/// @brief @c VMOVUPD xmm2/m128, xmm1
	/// @par
	/// @c VEX.128.66.0F.WIG 11 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVUPD_XMMM128_XMM = 922,
	/// @brief @c VMOVUPD ymm2/m256, ymm1
	/// @par
	/// @c VEX.256.66.0F.WIG 11 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVUPD_YMMM256_YMM = 923,
	/// @brief @c VMOVUPD xmm2/m128 {k1}{z}, xmm1
	/// @par
	/// @c EVEX.128.66.0F.W1 11 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVUPD_XMMM128_K1Z_XMM = 924,
	/// @brief @c VMOVUPD ymm2/m256 {k1}{z}, ymm1
	/// @par
	/// @c EVEX.256.66.0F.W1 11 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVUPD_YMMM256_K1Z_YMM = 925,
	/// @brief @c VMOVUPD zmm2/m512 {k1}{z}, zmm1
	/// @par
	/// @c EVEX.512.66.0F.W1 11 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVUPD_ZMMM512_K1Z_ZMM = 926,
	/// @brief @c MOVSS xmm2/m32, xmm1
	/// @par
	/// @c F3 0F 11 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	MOVSS_XMMM32_XMM = 927,
	/// @brief @c VMOVSS xmm1, xmm2, xmm3
	/// @par
	/// @c VEX.LIG.F3.0F.WIG 11 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVSS_XMM_XMM_XMM_0_F11 = 928,
	/// @brief @c VMOVSS m32, xmm1
	/// @par
	/// @c VEX.LIG.F3.0F.WIG 11 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVSS_M32_XMM = 929,
	/// @brief @c VMOVSS xmm1 {k1}{z}, xmm2, xmm3
	/// @par
	/// @c EVEX.LIG.F3.0F.W0 11 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVSS_XMM_K1Z_XMM_XMM_0_F11 = 930,
	/// @brief @c VMOVSS m32 {k1}, xmm1
	/// @par
	/// @c EVEX.LIG.F3.0F.W0 11 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVSS_M32_K1_XMM = 931,
	/// @brief @c MOVSD xmm1/m64, xmm2
	/// @par
	/// @c F2 0F 11 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MOVSD_XMMM64_XMM = 932,
	/// @brief @c VMOVSD xmm1, xmm2, xmm3
	/// @par
	/// @c VEX.LIG.F2.0F.WIG 11 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVSD_XMM_XMM_XMM_0_F11 = 933,
	/// @brief @c VMOVSD m64, xmm1
	/// @par
	/// @c VEX.LIG.F2.0F.WIG 11 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVSD_M64_XMM = 934,
	/// @brief @c VMOVSD xmm1 {k1}{z}, xmm2, xmm3
	/// @par
	/// @c EVEX.LIG.F2.0F.W1 11 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVSD_XMM_K1Z_XMM_XMM_0_F11 = 935,
	/// @brief @c VMOVSD m64 {k1}, xmm1
	/// @par
	/// @c EVEX.LIG.F2.0F.W1 11 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVSD_M64_K1_XMM = 936,
	/// @brief @c MOVHLPS xmm1, xmm2
	/// @par
	/// @c NP 0F 12 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	MOVHLPS_XMM_XMM = 937,
	/// @brief @c MOVLPS xmm1, m64
	/// @par
	/// @c NP 0F 12 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	MOVLPS_XMM_M64 = 938,
	/// @brief @c VMOVHLPS xmm1, xmm2, xmm3
	/// @par
	/// @c VEX.128.0F.WIG 12 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVHLPS_XMM_XMM_XMM = 939,
	/// @brief @c VMOVLPS xmm2, xmm1, m64
	/// @par
	/// @c VEX.128.0F.WIG 12 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVLPS_XMM_XMM_M64 = 940,
	/// @brief @c VMOVHLPS xmm1, xmm2, xmm3
	/// @par
	/// @c EVEX.128.0F.W0 12 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVHLPS_XMM_XMM_XMM = 941,
	/// @brief @c VMOVLPS xmm2, xmm1, m64
	/// @par
	/// @c EVEX.128.0F.W0 12 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVLPS_XMM_XMM_M64 = 942,
	/// @brief @c MOVLPD xmm1, m64
	/// @par
	/// @c 66 0F 12 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MOVLPD_XMM_M64 = 943,
	/// @brief @c VMOVLPD xmm2, xmm1, m64
	/// @par
	/// @c VEX.128.66.0F.WIG 12 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVLPD_XMM_XMM_M64 = 944,
	/// @brief @c VMOVLPD xmm2, xmm1, m64
	/// @par
	/// @c EVEX.128.66.0F.W1 12 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVLPD_XMM_XMM_M64 = 945,
	/// @brief @c MOVSLDUP xmm1, xmm2/m128
	/// @par
	/// @c F3 0F 12 /r
	/// @par
	/// @c SSE3
	/// @par
	/// @c 16/32/64-bit
	MOVSLDUP_XMM_XMMM128 = 946,
	/// @brief @c VMOVSLDUP xmm1, xmm2/m128
	/// @par
	/// @c VEX.128.F3.0F.WIG 12 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVSLDUP_XMM_XMMM128 = 947,
	/// @brief @c VMOVSLDUP ymm1, ymm2/m256
	/// @par
	/// @c VEX.256.F3.0F.WIG 12 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVSLDUP_YMM_YMMM256 = 948,
	/// @brief @c VMOVSLDUP xmm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.128.F3.0F.W0 12 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVSLDUP_XMM_K1Z_XMMM128 = 949,
	/// @brief @c VMOVSLDUP ymm1 {k1}{z}, ymm2/m256
	/// @par
	/// @c EVEX.256.F3.0F.W0 12 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVSLDUP_YMM_K1Z_YMMM256 = 950,
	/// @brief @c VMOVSLDUP zmm1 {k1}{z}, zmm2/m512
	/// @par
	/// @c EVEX.512.F3.0F.W0 12 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVSLDUP_ZMM_K1Z_ZMMM512 = 951,
	/// @brief @c MOVDDUP xmm1, xmm2/m64
	/// @par
	/// @c F2 0F 12 /r
	/// @par
	/// @c SSE3
	/// @par
	/// @c 16/32/64-bit
	MOVDDUP_XMM_XMMM64 = 952,
	/// @brief @c VMOVDDUP xmm1, xmm2/m64
	/// @par
	/// @c VEX.128.F2.0F.WIG 12 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVDDUP_XMM_XMMM64 = 953,
	/// @brief @c VMOVDDUP ymm1, ymm2/m256
	/// @par
	/// @c VEX.256.F2.0F.WIG 12 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVDDUP_YMM_YMMM256 = 954,
	/// @brief @c VMOVDDUP xmm1 {k1}{z}, xmm2/m64
	/// @par
	/// @c EVEX.128.F2.0F.W1 12 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDDUP_XMM_K1Z_XMMM64 = 955,
	/// @brief @c VMOVDDUP ymm1 {k1}{z}, ymm2/m256
	/// @par
	/// @c EVEX.256.F2.0F.W1 12 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDDUP_YMM_K1Z_YMMM256 = 956,
	/// @brief @c VMOVDDUP zmm1 {k1}{z}, zmm2/m512
	/// @par
	/// @c EVEX.512.F2.0F.W1 12 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDDUP_ZMM_K1Z_ZMMM512 = 957,
	/// @brief @c MOVLPS m64, xmm1
	/// @par
	/// @c NP 0F 13 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	MOVLPS_M64_XMM = 958,
	/// @brief @c VMOVLPS m64, xmm1
	/// @par
	/// @c VEX.128.0F.WIG 13 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVLPS_M64_XMM = 959,
	/// @brief @c VMOVLPS m64, xmm1
	/// @par
	/// @c EVEX.128.0F.W0 13 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVLPS_M64_XMM = 960,
	/// @brief @c MOVLPD m64, xmm1
	/// @par
	/// @c 66 0F 13 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MOVLPD_M64_XMM = 961,
	/// @brief @c VMOVLPD m64, xmm1
	/// @par
	/// @c VEX.128.66.0F.WIG 13 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVLPD_M64_XMM = 962,
	/// @brief @c VMOVLPD m64, xmm1
	/// @par
	/// @c EVEX.128.66.0F.W1 13 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVLPD_M64_XMM = 963,
	/// @brief @c UNPCKLPS xmm1, xmm2/m128
	/// @par
	/// @c NP 0F 14 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	UNPCKLPS_XMM_XMMM128 = 964,
	/// @brief @c VUNPCKLPS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.0F.WIG 14 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VUNPCKLPS_XMM_XMM_XMMM128 = 965,
	/// @brief @c VUNPCKLPS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.0F.WIG 14 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VUNPCKLPS_YMM_YMM_YMMM256 = 966,
	/// @brief @c VUNPCKLPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.0F.W0 14 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VUNPCKLPS_XMM_K1Z_XMM_XMMM128B32 = 967,
	/// @brief @c VUNPCKLPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.0F.W0 14 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VUNPCKLPS_YMM_K1Z_YMM_YMMM256B32 = 968,
	/// @brief @c VUNPCKLPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.0F.W0 14 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VUNPCKLPS_ZMM_K1Z_ZMM_ZMMM512B32 = 969,
	/// @brief @c UNPCKLPD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 14 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	UNPCKLPD_XMM_XMMM128 = 970,
	/// @brief @c VUNPCKLPD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 14 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VUNPCKLPD_XMM_XMM_XMMM128 = 971,
	/// @brief @c VUNPCKLPD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 14 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VUNPCKLPD_YMM_YMM_YMMM256 = 972,
	/// @brief @c VUNPCKLPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F.W1 14 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VUNPCKLPD_XMM_K1Z_XMM_XMMM128B64 = 973,
	/// @brief @c VUNPCKLPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F.W1 14 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VUNPCKLPD_YMM_K1Z_YMM_YMMM256B64 = 974,
	/// @brief @c VUNPCKLPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F.W1 14 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VUNPCKLPD_ZMM_K1Z_ZMM_ZMMM512B64 = 975,
	/// @brief @c UNPCKHPS xmm1, xmm2/m128
	/// @par
	/// @c NP 0F 15 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	UNPCKHPS_XMM_XMMM128 = 976,
	/// @brief @c VUNPCKHPS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.0F.WIG 15 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VUNPCKHPS_XMM_XMM_XMMM128 = 977,
	/// @brief @c VUNPCKHPS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.0F.WIG 15 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VUNPCKHPS_YMM_YMM_YMMM256 = 978,
	/// @brief @c VUNPCKHPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.0F.W0 15 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VUNPCKHPS_XMM_K1Z_XMM_XMMM128B32 = 979,
	/// @brief @c VUNPCKHPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.0F.W0 15 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VUNPCKHPS_YMM_K1Z_YMM_YMMM256B32 = 980,
	/// @brief @c VUNPCKHPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.0F.W0 15 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VUNPCKHPS_ZMM_K1Z_ZMM_ZMMM512B32 = 981,
	/// @brief @c UNPCKHPD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 15 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	UNPCKHPD_XMM_XMMM128 = 982,
	/// @brief @c VUNPCKHPD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 15 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VUNPCKHPD_XMM_XMM_XMMM128 = 983,
	/// @brief @c VUNPCKHPD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 15 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VUNPCKHPD_YMM_YMM_YMMM256 = 984,
	/// @brief @c VUNPCKHPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F.W1 15 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VUNPCKHPD_XMM_K1Z_XMM_XMMM128B64 = 985,
	/// @brief @c VUNPCKHPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F.W1 15 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VUNPCKHPD_YMM_K1Z_YMM_YMMM256B64 = 986,
	/// @brief @c VUNPCKHPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F.W1 15 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VUNPCKHPD_ZMM_K1Z_ZMM_ZMMM512B64 = 987,
	/// @brief @c MOVLHPS xmm1, xmm2
	/// @par
	/// @c NP 0F 16 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	MOVLHPS_XMM_XMM = 988,
	/// @brief @c VMOVLHPS xmm1, xmm2, xmm3
	/// @par
	/// @c VEX.128.0F.WIG 16 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVLHPS_XMM_XMM_XMM = 989,
	/// @brief @c VMOVLHPS xmm1, xmm2, xmm3
	/// @par
	/// @c EVEX.128.0F.W0 16 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVLHPS_XMM_XMM_XMM = 990,
	/// @brief @c MOVHPS xmm1, m64
	/// @par
	/// @c NP 0F 16 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	MOVHPS_XMM_M64 = 991,
	/// @brief @c VMOVHPS xmm2, xmm1, m64
	/// @par
	/// @c VEX.128.0F.WIG 16 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVHPS_XMM_XMM_M64 = 992,
	/// @brief @c VMOVHPS xmm2, xmm1, m64
	/// @par
	/// @c EVEX.128.0F.W0 16 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVHPS_XMM_XMM_M64 = 993,
	/// @brief @c MOVHPD xmm1, m64
	/// @par
	/// @c 66 0F 16 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MOVHPD_XMM_M64 = 994,
	/// @brief @c VMOVHPD xmm2, xmm1, m64
	/// @par
	/// @c VEX.128.66.0F.WIG 16 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVHPD_XMM_XMM_M64 = 995,
	/// @brief @c VMOVHPD xmm2, xmm1, m64
	/// @par
	/// @c EVEX.128.66.0F.W1 16 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVHPD_XMM_XMM_M64 = 996,
	/// @brief @c MOVSHDUP xmm1, xmm2/m128
	/// @par
	/// @c F3 0F 16 /r
	/// @par
	/// @c SSE3
	/// @par
	/// @c 16/32/64-bit
	MOVSHDUP_XMM_XMMM128 = 997,
	/// @brief @c VMOVSHDUP xmm1, xmm2/m128
	/// @par
	/// @c VEX.128.F3.0F.WIG 16 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVSHDUP_XMM_XMMM128 = 998,
	/// @brief @c VMOVSHDUP ymm1, ymm2/m256
	/// @par
	/// @c VEX.256.F3.0F.WIG 16 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVSHDUP_YMM_YMMM256 = 999,
	/// @brief @c VMOVSHDUP xmm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.128.F3.0F.W0 16 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVSHDUP_XMM_K1Z_XMMM128 = 1000,
	/// @brief @c VMOVSHDUP ymm1 {k1}{z}, ymm2/m256
	/// @par
	/// @c EVEX.256.F3.0F.W0 16 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVSHDUP_YMM_K1Z_YMMM256 = 1001,
	/// @brief @c VMOVSHDUP zmm1 {k1}{z}, zmm2/m512
	/// @par
	/// @c EVEX.512.F3.0F.W0 16 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVSHDUP_ZMM_K1Z_ZMMM512 = 1002,
	/// @brief @c MOVHPS m64, xmm1
	/// @par
	/// @c NP 0F 17 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	MOVHPS_M64_XMM = 1003,
	/// @brief @c VMOVHPS m64, xmm1
	/// @par
	/// @c VEX.128.0F.WIG 17 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVHPS_M64_XMM = 1004,
	/// @brief @c VMOVHPS m64, xmm1
	/// @par
	/// @c EVEX.128.0F.W0 17 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVHPS_M64_XMM = 1005,
	/// @brief @c MOVHPD m64, xmm1
	/// @par
	/// @c 66 0F 17 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MOVHPD_M64_XMM = 1006,
	/// @brief @c VMOVHPD m64, xmm1
	/// @par
	/// @c VEX.128.66.0F.WIG 17 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVHPD_M64_XMM = 1007,
	/// @brief @c VMOVHPD m64, xmm1
	/// @par
	/// @c EVEX.128.66.0F.W1 17 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVHPD_M64_XMM = 1008,
	/// @brief @c RESERVEDNOP r/m16, r16
	/// @par
	/// @c o16 0F 18 /r
	/// @par
	/// @c CPUID.01H.EAX[Bits 11:8] = 0110B or 1111B
	/// @par
	/// @c 16/32/64-bit
	RESERVEDNOP_RM16_R16_0_F18 = 1009,
	/// @brief @c RESERVEDNOP r/m32, r32
	/// @par
	/// @c o32 0F 18 /r
	/// @par
	/// @c CPUID.01H.EAX[Bits 11:8] = 0110B or 1111B
	/// @par
	/// @c 16/32/64-bit
	RESERVEDNOP_RM32_R32_0_F18 = 1010,
	/// @brief @c RESERVEDNOP r/m64, r64
	/// @par
	/// @c o64 0F 18 /r
	/// @par
	/// @c CPUID.01H.EAX[Bits 11:8] = 0110B or 1111B
	/// @par
	/// @c 64-bit
	RESERVEDNOP_RM64_R64_0_F18 = 1011,
	/// @brief @c RESERVEDNOP r/m16, r16
	/// @par
	/// @c o16 0F 19 /r
	/// @par
	/// @c CPUID.01H.EAX[Bits 11:8] = 0110B or 1111B
	/// @par
	/// @c 16/32/64-bit
	RESERVEDNOP_RM16_R16_0_F19 = 1012,
	/// @brief @c RESERVEDNOP r/m32, r32
	/// @par
	/// @c o32 0F 19 /r
	/// @par
	/// @c CPUID.01H.EAX[Bits 11:8] = 0110B or 1111B
	/// @par
	/// @c 16/32/64-bit
	RESERVEDNOP_RM32_R32_0_F19 = 1013,
	/// @brief @c RESERVEDNOP r/m64, r64
	/// @par
	/// @c o64 0F 19 /r
	/// @par
	/// @c CPUID.01H.EAX[Bits 11:8] = 0110B or 1111B
	/// @par
	/// @c 64-bit
	RESERVEDNOP_RM64_R64_0_F19 = 1014,
	/// @brief @c RESERVEDNOP r/m16, r16
	/// @par
	/// @c o16 0F 1A /r
	/// @par
	/// @c CPUID.01H.EAX[Bits 11:8] = 0110B or 1111B
	/// @par
	/// @c 16/32/64-bit
	RESERVEDNOP_RM16_R16_0_F1_A = 1015,
	/// @brief @c RESERVEDNOP r/m32, r32
	/// @par
	/// @c o32 0F 1A /r
	/// @par
	/// @c CPUID.01H.EAX[Bits 11:8] = 0110B or 1111B
	/// @par
	/// @c 16/32/64-bit
	RESERVEDNOP_RM32_R32_0_F1_A = 1016,
	/// @brief @c RESERVEDNOP r/m64, r64
	/// @par
	/// @c o64 0F 1A /r
	/// @par
	/// @c CPUID.01H.EAX[Bits 11:8] = 0110B or 1111B
	/// @par
	/// @c 64-bit
	RESERVEDNOP_RM64_R64_0_F1_A = 1017,
	/// @brief @c RESERVEDNOP r/m16, r16
	/// @par
	/// @c o16 0F 1B /r
	/// @par
	/// @c CPUID.01H.EAX[Bits 11:8] = 0110B or 1111B
	/// @par
	/// @c 16/32/64-bit
	RESERVEDNOP_RM16_R16_0_F1_B = 1018,
	/// @brief @c RESERVEDNOP r/m32, r32
	/// @par
	/// @c o32 0F 1B /r
	/// @par
	/// @c CPUID.01H.EAX[Bits 11:8] = 0110B or 1111B
	/// @par
	/// @c 16/32/64-bit
	RESERVEDNOP_RM32_R32_0_F1_B = 1019,
	/// @brief @c RESERVEDNOP r/m64, r64
	/// @par
	/// @c o64 0F 1B /r
	/// @par
	/// @c CPUID.01H.EAX[Bits 11:8] = 0110B or 1111B
	/// @par
	/// @c 64-bit
	RESERVEDNOP_RM64_R64_0_F1_B = 1020,
	/// @brief @c RESERVEDNOP r/m16, r16
	/// @par
	/// @c o16 0F 1C /r
	/// @par
	/// @c CPUID.01H.EAX[Bits 11:8] = 0110B or 1111B
	/// @par
	/// @c 16/32/64-bit
	RESERVEDNOP_RM16_R16_0_F1_C = 1021,
	/// @brief @c RESERVEDNOP r/m32, r32
	/// @par
	/// @c o32 0F 1C /r
	/// @par
	/// @c CPUID.01H.EAX[Bits 11:8] = 0110B or 1111B
	/// @par
	/// @c 16/32/64-bit
	RESERVEDNOP_RM32_R32_0_F1_C = 1022,
	/// @brief @c RESERVEDNOP r/m64, r64
	/// @par
	/// @c o64 0F 1C /r
	/// @par
	/// @c CPUID.01H.EAX[Bits 11:8] = 0110B or 1111B
	/// @par
	/// @c 64-bit
	RESERVEDNOP_RM64_R64_0_F1_C = 1023,
	/// @brief @c RESERVEDNOP r/m16, r16
	/// @par
	/// @c o16 0F 1D /r
	/// @par
	/// @c CPUID.01H.EAX[Bits 11:8] = 0110B or 1111B
	/// @par
	/// @c 16/32/64-bit
	RESERVEDNOP_RM16_R16_0_F1_D = 1024,
	/// @brief @c RESERVEDNOP r/m32, r32
	/// @par
	/// @c o32 0F 1D /r
	/// @par
	/// @c CPUID.01H.EAX[Bits 11:8] = 0110B or 1111B
	/// @par
	/// @c 16/32/64-bit
	RESERVEDNOP_RM32_R32_0_F1_D = 1025,
	/// @brief @c RESERVEDNOP r/m64, r64
	/// @par
	/// @c o64 0F 1D /r
	/// @par
	/// @c CPUID.01H.EAX[Bits 11:8] = 0110B or 1111B
	/// @par
	/// @c 64-bit
	RESERVEDNOP_RM64_R64_0_F1_D = 1026,
	/// @brief @c RESERVEDNOP r/m16, r16
	/// @par
	/// @c o16 0F 1E /r
	/// @par
	/// @c CPUID.01H.EAX[Bits 11:8] = 0110B or 1111B
	/// @par
	/// @c 16/32/64-bit
	RESERVEDNOP_RM16_R16_0_F1_E = 1027,
	/// @brief @c RESERVEDNOP r/m32, r32
	/// @par
	/// @c o32 0F 1E /r
	/// @par
	/// @c CPUID.01H.EAX[Bits 11:8] = 0110B or 1111B
	/// @par
	/// @c 16/32/64-bit
	RESERVEDNOP_RM32_R32_0_F1_E = 1028,
	/// @brief @c RESERVEDNOP r/m64, r64
	/// @par
	/// @c o64 0F 1E /r
	/// @par
	/// @c CPUID.01H.EAX[Bits 11:8] = 0110B or 1111B
	/// @par
	/// @c 64-bit
	RESERVEDNOP_RM64_R64_0_F1_E = 1029,
	/// @brief @c RESERVEDNOP r/m16, r16
	/// @par
	/// @c o16 0F 1F /r
	/// @par
	/// @c CPUID.01H.EAX[Bits 11:8] = 0110B or 1111B
	/// @par
	/// @c 16/32/64-bit
	RESERVEDNOP_RM16_R16_0_F1_F = 1030,
	/// @brief @c RESERVEDNOP r/m32, r32
	/// @par
	/// @c o32 0F 1F /r
	/// @par
	/// @c CPUID.01H.EAX[Bits 11:8] = 0110B or 1111B
	/// @par
	/// @c 16/32/64-bit
	RESERVEDNOP_RM32_R32_0_F1_F = 1031,
	/// @brief @c RESERVEDNOP r/m64, r64
	/// @par
	/// @c o64 0F 1F /r
	/// @par
	/// @c CPUID.01H.EAX[Bits 11:8] = 0110B or 1111B
	/// @par
	/// @c 64-bit
	RESERVEDNOP_RM64_R64_0_F1_F = 1032,
	/// @brief @c PREFETCHNTA m8
	/// @par
	/// @c 0F 18 /0
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	PREFETCHNTA_M8 = 1033,
	/// @brief @c PREFETCHT0 m8
	/// @par
	/// @c 0F 18 /1
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	PREFETCHT0_M8 = 1034,
	/// @brief @c PREFETCHT1 m8
	/// @par
	/// @c 0F 18 /2
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	PREFETCHT1_M8 = 1035,
	/// @brief @c PREFETCHT2 m8
	/// @par
	/// @c 0F 18 /3
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	PREFETCHT2_M8 = 1036,
	/// @brief @c BNDLDX bnd, mib
	/// @par
	/// @c NP 0F 1A /r
	/// @par
	/// @c MPX
	/// @par
	/// @c 16/32/64-bit
	BNDLDX_BND_MIB = 1037,
	/// @brief @c BNDMOV bnd1, bnd2/m64
	/// @par
	/// @c 66 0F 1A /r
	/// @par
	/// @c MPX
	/// @par
	/// @c 16/32-bit
	BNDMOV_BND_BNDM64 = 1038,
	/// @brief @c BNDMOV bnd1, bnd2/m128
	/// @par
	/// @c 66 0F 1A /r
	/// @par
	/// @c MPX
	/// @par
	/// @c 64-bit
	BNDMOV_BND_BNDM128 = 1039,
	/// @brief @c BNDCL bnd, r/m32
	/// @par
	/// @c F3 0F 1A /r
	/// @par
	/// @c MPX
	/// @par
	/// @c 16/32-bit
	BNDCL_BND_RM32 = 1040,
	/// @brief @c BNDCL bnd, r/m64
	/// @par
	/// @c F3 0F 1A /r
	/// @par
	/// @c MPX
	/// @par
	/// @c 64-bit
	BNDCL_BND_RM64 = 1041,
	/// @brief @c BNDCU bnd, r/m32
	/// @par
	/// @c F2 0F 1A /r
	/// @par
	/// @c MPX
	/// @par
	/// @c 16/32-bit
	BNDCU_BND_RM32 = 1042,
	/// @brief @c BNDCU bnd, r/m64
	/// @par
	/// @c F2 0F 1A /r
	/// @par
	/// @c MPX
	/// @par
	/// @c 64-bit
	BNDCU_BND_RM64 = 1043,
	/// @brief @c BNDSTX mib, bnd
	/// @par
	/// @c NP 0F 1B /r
	/// @par
	/// @c MPX
	/// @par
	/// @c 16/32/64-bit
	BNDSTX_MIB_BND = 1044,
	/// @brief @c BNDMOV bnd1/m64, bnd2
	/// @par
	/// @c 66 0F 1B /r
	/// @par
	/// @c MPX
	/// @par
	/// @c 16/32-bit
	BNDMOV_BNDM64_BND = 1045,
	/// @brief @c BNDMOV bnd1/m128, bnd2
	/// @par
	/// @c 66 0F 1B /r
	/// @par
	/// @c MPX
	/// @par
	/// @c 64-bit
	BNDMOV_BNDM128_BND = 1046,
	/// @brief @c BNDMK bnd, m32
	/// @par
	/// @c F3 0F 1B /r
	/// @par
	/// @c MPX
	/// @par
	/// @c 16/32-bit
	BNDMK_BND_M32 = 1047,
	/// @brief @c BNDMK bnd, m64
	/// @par
	/// @c F3 0F 1B /r
	/// @par
	/// @c MPX
	/// @par
	/// @c 64-bit
	BNDMK_BND_M64 = 1048,
	/// @brief @c BNDCN bnd, r/m32
	/// @par
	/// @c F2 0F 1B /r
	/// @par
	/// @c MPX
	/// @par
	/// @c 16/32-bit
	BNDCN_BND_RM32 = 1049,
	/// @brief @c BNDCN bnd, r/m64
	/// @par
	/// @c F2 0F 1B /r
	/// @par
	/// @c MPX
	/// @par
	/// @c 64-bit
	BNDCN_BND_RM64 = 1050,
	/// @brief @c CLDEMOTE m8
	/// @par
	/// @c NP 0F 1C /0
	/// @par
	/// @c CLDEMOTE
	/// @par
	/// @c 16/32/64-bit
	CLDEMOTE_M8 = 1051,
	/// @brief @c RDSSPD r32
	/// @par
	/// @c F3 0F 1E /1
	/// @par
	/// @c CET_SS
	/// @par
	/// @c 16/32/64-bit
	RDSSPD_R32 = 1052,
	/// @brief @c RDSSPQ r64
	/// @par
	/// @c F3 o64 0F 1E /1
	/// @par
	/// @c CET_SS
	/// @par
	/// @c 64-bit
	RDSSPQ_R64 = 1053,
	/// @brief @c ENDBR64
	/// @par
	/// @c F3 0F 1E FA
	/// @par
	/// @c CET_IBT
	/// @par
	/// @c 16/32/64-bit
	ENDBR64 = 1054,
	/// @brief @c ENDBR32
	/// @par
	/// @c F3 0F 1E FB
	/// @par
	/// @c CET_IBT
	/// @par
	/// @c 16/32/64-bit
	ENDBR32 = 1055,
	/// @brief @c NOP r/m16
	/// @par
	/// @c o16 0F 1F /0
	/// @par
	/// @c CPUID.01H.EAX[Bits 11:8] = 0110B or 1111B
	/// @par
	/// @c 16/32/64-bit
	NOP_RM16 = 1056,
	/// @brief @c NOP r/m32
	/// @par
	/// @c o32 0F 1F /0
	/// @par
	/// @c CPUID.01H.EAX[Bits 11:8] = 0110B or 1111B
	/// @par
	/// @c 16/32/64-bit
	NOP_RM32 = 1057,
	/// @brief @c NOP r/m64
	/// @par
	/// @c o64 0F 1F /0
	/// @par
	/// @c CPUID.01H.EAX[Bits 11:8] = 0110B or 1111B
	/// @par
	/// @c 64-bit
	NOP_RM64 = 1058,
	/// @brief @c MOV r32, cr
	/// @par
	/// @c 0F 20 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	MOV_R32_CR = 1059,
	/// @brief @c MOV r64, cr
	/// @par
	/// @c 0F 20 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	MOV_R64_CR = 1060,
	/// @brief @c MOV r32, dr
	/// @par
	/// @c 0F 21 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	MOV_R32_DR = 1061,
	/// @brief @c MOV r64, dr
	/// @par
	/// @c 0F 21 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	MOV_R64_DR = 1062,
	/// @brief @c MOV cr, r32
	/// @par
	/// @c 0F 22 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	MOV_CR_R32 = 1063,
	/// @brief @c MOV cr, r64
	/// @par
	/// @c 0F 22 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	MOV_CR_R64 = 1064,
	/// @brief @c MOV dr, r32
	/// @par
	/// @c 0F 23 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	MOV_DR_R32 = 1065,
	/// @brief @c MOV dr, r64
	/// @par
	/// @c 0F 23 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	MOV_DR_R64 = 1066,
	/// @brief @c MOV r32, tr
	/// @par
	/// @c 0F 24 /r
	/// @par
	/// @c 386/486/Cyrix/Geode
	/// @par
	/// @c 16/32-bit
	MOV_R32_TR = 1067,
	/// @brief @c MOV tr, r32
	/// @par
	/// @c 0F 26 /r
	/// @par
	/// @c 386/486/Cyrix/Geode
	/// @par
	/// @c 16/32-bit
	MOV_TR_R32 = 1068,
	/// @brief @c MOVAPS xmm1, xmm2/m128
	/// @par
	/// @c NP 0F 28 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	MOVAPS_XMM_XMMM128 = 1069,
	/// @brief @c VMOVAPS xmm1, xmm2/m128
	/// @par
	/// @c VEX.128.0F.WIG 28 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVAPS_XMM_XMMM128 = 1070,
	/// @brief @c VMOVAPS ymm1, ymm2/m256
	/// @par
	/// @c VEX.256.0F.WIG 28 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVAPS_YMM_YMMM256 = 1071,
	/// @brief @c VMOVAPS xmm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.128.0F.W0 28 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVAPS_XMM_K1Z_XMMM128 = 1072,
	/// @brief @c VMOVAPS ymm1 {k1}{z}, ymm2/m256
	/// @par
	/// @c EVEX.256.0F.W0 28 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVAPS_YMM_K1Z_YMMM256 = 1073,
	/// @brief @c VMOVAPS zmm1 {k1}{z}, zmm2/m512
	/// @par
	/// @c EVEX.512.0F.W0 28 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVAPS_ZMM_K1Z_ZMMM512 = 1074,
	/// @brief @c MOVAPD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 28 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MOVAPD_XMM_XMMM128 = 1075,
	/// @brief @c VMOVAPD xmm1, xmm2/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 28 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVAPD_XMM_XMMM128 = 1076,
	/// @brief @c VMOVAPD ymm1, ymm2/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 28 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVAPD_YMM_YMMM256 = 1077,
	/// @brief @c VMOVAPD xmm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.128.66.0F.W1 28 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVAPD_XMM_K1Z_XMMM128 = 1078,
	/// @brief @c VMOVAPD ymm1 {k1}{z}, ymm2/m256
	/// @par
	/// @c EVEX.256.66.0F.W1 28 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVAPD_YMM_K1Z_YMMM256 = 1079,
	/// @brief @c VMOVAPD zmm1 {k1}{z}, zmm2/m512
	/// @par
	/// @c EVEX.512.66.0F.W1 28 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVAPD_ZMM_K1Z_ZMMM512 = 1080,
	/// @brief @c MOVAPS xmm2/m128, xmm1
	/// @par
	/// @c NP 0F 29 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	MOVAPS_XMMM128_XMM = 1081,
	/// @brief @c VMOVAPS xmm2/m128, xmm1
	/// @par
	/// @c VEX.128.0F.WIG 29 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVAPS_XMMM128_XMM = 1082,
	/// @brief @c VMOVAPS ymm2/m256, ymm1
	/// @par
	/// @c VEX.256.0F.WIG 29 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVAPS_YMMM256_YMM = 1083,
	/// @brief @c VMOVAPS xmm2/m128 {k1}{z}, xmm1
	/// @par
	/// @c EVEX.128.0F.W0 29 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVAPS_XMMM128_K1Z_XMM = 1084,
	/// @brief @c VMOVAPS ymm2/m256 {k1}{z}, ymm1
	/// @par
	/// @c EVEX.256.0F.W0 29 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVAPS_YMMM256_K1Z_YMM = 1085,
	/// @brief @c VMOVAPS zmm2/m512 {k1}{z}, zmm1
	/// @par
	/// @c EVEX.512.0F.W0 29 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVAPS_ZMMM512_K1Z_ZMM = 1086,
	/// @brief @c MOVAPD xmm2/m128, xmm1
	/// @par
	/// @c 66 0F 29 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MOVAPD_XMMM128_XMM = 1087,
	/// @brief @c VMOVAPD xmm2/m128, xmm1
	/// @par
	/// @c VEX.128.66.0F.WIG 29 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVAPD_XMMM128_XMM = 1088,
	/// @brief @c VMOVAPD ymm2/m256, ymm1
	/// @par
	/// @c VEX.256.66.0F.WIG 29 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVAPD_YMMM256_YMM = 1089,
	/// @brief @c VMOVAPD xmm2/m128 {k1}{z}, xmm1
	/// @par
	/// @c EVEX.128.66.0F.W1 29 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVAPD_XMMM128_K1Z_XMM = 1090,
	/// @brief @c VMOVAPD ymm2/m256 {k1}{z}, ymm1
	/// @par
	/// @c EVEX.256.66.0F.W1 29 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVAPD_YMMM256_K1Z_YMM = 1091,
	/// @brief @c VMOVAPD zmm2/m512 {k1}{z}, zmm1
	/// @par
	/// @c EVEX.512.66.0F.W1 29 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVAPD_ZMMM512_K1Z_ZMM = 1092,
	/// @brief @c CVTPI2PS xmm, mm/m64
	/// @par
	/// @c NP 0F 2A /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	CVTPI2PS_XMM_MMM64 = 1093,
	/// @brief @c CVTPI2PD xmm, mm/m64
	/// @par
	/// @c 66 0F 2A /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	CVTPI2PD_XMM_MMM64 = 1094,
	/// @brief @c CVTSI2SS xmm1, r/m32
	/// @par
	/// @c F3 0F 2A /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	CVTSI2SS_XMM_RM32 = 1095,
	/// @brief @c CVTSI2SS xmm1, r/m64
	/// @par
	/// @c F3 o64 0F 2A /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 64-bit
	CVTSI2SS_XMM_RM64 = 1096,
	/// @brief @c VCVTSI2SS xmm1, xmm2, r/m32
	/// @par
	/// @c VEX.LIG.F3.0F.W0 2A /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTSI2SS_XMM_XMM_RM32 = 1097,
	/// @brief @c VCVTSI2SS xmm1, xmm2, r/m64
	/// @par
	/// @c VEX.LIG.F3.0F.W1 2A /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 64-bit
	VEX_VCVTSI2SS_XMM_XMM_RM64 = 1098,
	/// @brief @c VCVTSI2SS xmm1, xmm2, r/m32{er}
	/// @par
	/// @c EVEX.LIG.F3.0F.W0 2A /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTSI2SS_XMM_XMM_RM32_ER = 1099,
	/// @brief @c VCVTSI2SS xmm1, xmm2, r/m64{er}
	/// @par
	/// @c EVEX.LIG.F3.0F.W1 2A /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 64-bit
	EVEX_VCVTSI2SS_XMM_XMM_RM64_ER = 1100,
	/// @brief @c CVTSI2SD xmm1, r/m32
	/// @par
	/// @c F2 0F 2A /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	CVTSI2SD_XMM_RM32 = 1101,
	/// @brief @c CVTSI2SD xmm1, r/m64
	/// @par
	/// @c F2 o64 0F 2A /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 64-bit
	CVTSI2SD_XMM_RM64 = 1102,
	/// @brief @c VCVTSI2SD xmm1, xmm2, r/m32
	/// @par
	/// @c VEX.LIG.F2.0F.W0 2A /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTSI2SD_XMM_XMM_RM32 = 1103,
	/// @brief @c VCVTSI2SD xmm1, xmm2, r/m64
	/// @par
	/// @c VEX.LIG.F2.0F.W1 2A /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 64-bit
	VEX_VCVTSI2SD_XMM_XMM_RM64 = 1104,
	/// @brief @c VCVTSI2SD xmm1, xmm2, r/m32{er}
	/// @par
	/// @c EVEX.LIG.F2.0F.W0 2A /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTSI2SD_XMM_XMM_RM32_ER = 1105,
	/// @brief @c VCVTSI2SD xmm1, xmm2, r/m64{er}
	/// @par
	/// @c EVEX.LIG.F2.0F.W1 2A /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 64-bit
	EVEX_VCVTSI2SD_XMM_XMM_RM64_ER = 1106,
	/// @brief @c MOVNTPS m128, xmm1
	/// @par
	/// @c NP 0F 2B /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	MOVNTPS_M128_XMM = 1107,
	/// @brief @c VMOVNTPS m128, xmm1
	/// @par
	/// @c VEX.128.0F.WIG 2B /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVNTPS_M128_XMM = 1108,
	/// @brief @c VMOVNTPS m256, ymm1
	/// @par
	/// @c VEX.256.0F.WIG 2B /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVNTPS_M256_YMM = 1109,
	/// @brief @c VMOVNTPS m128, xmm1
	/// @par
	/// @c EVEX.128.0F.W0 2B /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVNTPS_M128_XMM = 1110,
	/// @brief @c VMOVNTPS m256, ymm1
	/// @par
	/// @c EVEX.256.0F.W0 2B /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVNTPS_M256_YMM = 1111,
	/// @brief @c VMOVNTPS m512, zmm1
	/// @par
	/// @c EVEX.512.0F.W0 2B /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVNTPS_M512_ZMM = 1112,
	/// @brief @c MOVNTPD m128, xmm1
	/// @par
	/// @c 66 0F 2B /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MOVNTPD_M128_XMM = 1113,
	/// @brief @c VMOVNTPD m128, xmm1
	/// @par
	/// @c VEX.128.66.0F.WIG 2B /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVNTPD_M128_XMM = 1114,
	/// @brief @c VMOVNTPD m256, ymm1
	/// @par
	/// @c VEX.256.66.0F.WIG 2B /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVNTPD_M256_YMM = 1115,
	/// @brief @c VMOVNTPD m128, xmm1
	/// @par
	/// @c EVEX.128.66.0F.W1 2B /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVNTPD_M128_XMM = 1116,
	/// @brief @c VMOVNTPD m256, ymm1
	/// @par
	/// @c EVEX.256.66.0F.W1 2B /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVNTPD_M256_YMM = 1117,
	/// @brief @c VMOVNTPD m512, zmm1
	/// @par
	/// @c EVEX.512.66.0F.W1 2B /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVNTPD_M512_ZMM = 1118,
	/// @brief @c MOVNTSS m32, xmm1
	/// @par
	/// @c F3 0F 2B /r
	/// @par
	/// @c SSE4A
	/// @par
	/// @c 16/32/64-bit
	MOVNTSS_M32_XMM = 1119,
	/// @brief @c MOVNTSD m64, xmm1
	/// @par
	/// @c F2 0F 2B /r
	/// @par
	/// @c SSE4A
	/// @par
	/// @c 16/32/64-bit
	MOVNTSD_M64_XMM = 1120,
	/// @brief @c CVTTPS2PI mm, xmm/m64
	/// @par
	/// @c NP 0F 2C /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	CVTTPS2PI_MM_XMMM64 = 1121,
	/// @brief @c CVTTPD2PI mm, xmm/m128
	/// @par
	/// @c 66 0F 2C /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	CVTTPD2PI_MM_XMMM128 = 1122,
	/// @brief @c CVTTSS2SI r32, xmm1/m32
	/// @par
	/// @c F3 0F 2C /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	CVTTSS2SI_R32_XMMM32 = 1123,
	/// @brief @c CVTTSS2SI r64, xmm1/m32
	/// @par
	/// @c F3 o64 0F 2C /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 64-bit
	CVTTSS2SI_R64_XMMM32 = 1124,
	/// @brief @c VCVTTSS2SI r32, xmm1/m32
	/// @par
	/// @c VEX.LIG.F3.0F.W0 2C /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTTSS2SI_R32_XMMM32 = 1125,
	/// @brief @c VCVTTSS2SI r64, xmm1/m32
	/// @par
	/// @c VEX.LIG.F3.0F.W1 2C /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 64-bit
	VEX_VCVTTSS2SI_R64_XMMM32 = 1126,
	/// @brief @c VCVTTSS2SI r32, xmm1/m32{sae}
	/// @par
	/// @c EVEX.LIG.F3.0F.W0 2C /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTSS2SI_R32_XMMM32_SAE = 1127,
	/// @brief @c VCVTTSS2SI r64, xmm1/m32{sae}
	/// @par
	/// @c EVEX.LIG.F3.0F.W1 2C /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 64-bit
	EVEX_VCVTTSS2SI_R64_XMMM32_SAE = 1128,
	/// @brief @c CVTTSD2SI r32, xmm1/m64
	/// @par
	/// @c F2 0F 2C /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	CVTTSD2SI_R32_XMMM64 = 1129,
	/// @brief @c CVTTSD2SI r64, xmm1/m64
	/// @par
	/// @c F2 o64 0F 2C /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 64-bit
	CVTTSD2SI_R64_XMMM64 = 1130,
	/// @brief @c VCVTTSD2SI r32, xmm1/m64
	/// @par
	/// @c VEX.LIG.F2.0F.W0 2C /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTTSD2SI_R32_XMMM64 = 1131,
	/// @brief @c VCVTTSD2SI r64, xmm1/m64
	/// @par
	/// @c VEX.LIG.F2.0F.W1 2C /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 64-bit
	VEX_VCVTTSD2SI_R64_XMMM64 = 1132,
	/// @brief @c VCVTTSD2SI r32, xmm1/m64{sae}
	/// @par
	/// @c EVEX.LIG.F2.0F.W0 2C /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTSD2SI_R32_XMMM64_SAE = 1133,
	/// @brief @c VCVTTSD2SI r64, xmm1/m64{sae}
	/// @par
	/// @c EVEX.LIG.F2.0F.W1 2C /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 64-bit
	EVEX_VCVTTSD2SI_R64_XMMM64_SAE = 1134,
	/// @brief @c CVTPS2PI mm, xmm/m64
	/// @par
	/// @c NP 0F 2D /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	CVTPS2PI_MM_XMMM64 = 1135,
	/// @brief @c CVTPD2PI mm, xmm/m128
	/// @par
	/// @c 66 0F 2D /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	CVTPD2PI_MM_XMMM128 = 1136,
	/// @brief @c CVTSS2SI r32, xmm1/m32
	/// @par
	/// @c F3 0F 2D /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	CVTSS2SI_R32_XMMM32 = 1137,
	/// @brief @c CVTSS2SI r64, xmm1/m32
	/// @par
	/// @c F3 o64 0F 2D /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 64-bit
	CVTSS2SI_R64_XMMM32 = 1138,
	/// @brief @c VCVTSS2SI r32, xmm1/m32
	/// @par
	/// @c VEX.LIG.F3.0F.W0 2D /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTSS2SI_R32_XMMM32 = 1139,
	/// @brief @c VCVTSS2SI r64, xmm1/m32
	/// @par
	/// @c VEX.LIG.F3.0F.W1 2D /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 64-bit
	VEX_VCVTSS2SI_R64_XMMM32 = 1140,
	/// @brief @c VCVTSS2SI r32, xmm1/m32{er}
	/// @par
	/// @c EVEX.LIG.F3.0F.W0 2D /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTSS2SI_R32_XMMM32_ER = 1141,
	/// @brief @c VCVTSS2SI r64, xmm1/m32{er}
	/// @par
	/// @c EVEX.LIG.F3.0F.W1 2D /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 64-bit
	EVEX_VCVTSS2SI_R64_XMMM32_ER = 1142,
	/// @brief @c CVTSD2SI r32, xmm1/m64
	/// @par
	/// @c F2 0F 2D /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	CVTSD2SI_R32_XMMM64 = 1143,
	/// @brief @c CVTSD2SI r64, xmm1/m64
	/// @par
	/// @c F2 o64 0F 2D /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 64-bit
	CVTSD2SI_R64_XMMM64 = 1144,
	/// @brief @c VCVTSD2SI r32, xmm1/m64
	/// @par
	/// @c VEX.LIG.F2.0F.W0 2D /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTSD2SI_R32_XMMM64 = 1145,
	/// @brief @c VCVTSD2SI r64, xmm1/m64
	/// @par
	/// @c VEX.LIG.F2.0F.W1 2D /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 64-bit
	VEX_VCVTSD2SI_R64_XMMM64 = 1146,
	/// @brief @c VCVTSD2SI r32, xmm1/m64{er}
	/// @par
	/// @c EVEX.LIG.F2.0F.W0 2D /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTSD2SI_R32_XMMM64_ER = 1147,
	/// @brief @c VCVTSD2SI r64, xmm1/m64{er}
	/// @par
	/// @c EVEX.LIG.F2.0F.W1 2D /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 64-bit
	EVEX_VCVTSD2SI_R64_XMMM64_ER = 1148,
	/// @brief @c UCOMISS xmm1, xmm2/m32
	/// @par
	/// @c NP 0F 2E /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	UCOMISS_XMM_XMMM32 = 1149,
	/// @brief @c VUCOMISS xmm1, xmm2/m32
	/// @par
	/// @c VEX.LIG.0F.WIG 2E /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VUCOMISS_XMM_XMMM32 = 1150,
	/// @brief @c VUCOMISS xmm1, xmm2/m32{sae}
	/// @par
	/// @c EVEX.LIG.0F.W0 2E /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VUCOMISS_XMM_XMMM32_SAE = 1151,
	/// @brief @c UCOMISD xmm1, xmm2/m64
	/// @par
	/// @c 66 0F 2E /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	UCOMISD_XMM_XMMM64 = 1152,
	/// @brief @c VUCOMISD xmm1, xmm2/m64
	/// @par
	/// @c VEX.LIG.66.0F.WIG 2E /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VUCOMISD_XMM_XMMM64 = 1153,
	/// @brief @c VUCOMISD xmm1, xmm2/m64{sae}
	/// @par
	/// @c EVEX.LIG.66.0F.W1 2E /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VUCOMISD_XMM_XMMM64_SAE = 1154,
	/// @brief @c COMISS xmm1, xmm2/m32
	/// @par
	/// @c NP 0F 2F /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	COMISS_XMM_XMMM32 = 1155,
	/// @brief @c COMISD xmm1, xmm2/m64
	/// @par
	/// @c 66 0F 2F /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	COMISD_XMM_XMMM64 = 1156,
	/// @brief @c VCOMISS xmm1, xmm2/m32
	/// @par
	/// @c VEX.LIG.0F.WIG 2F /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCOMISS_XMM_XMMM32 = 1157,
	/// @brief @c VCOMISD xmm1, xmm2/m64
	/// @par
	/// @c VEX.LIG.66.0F.WIG 2F /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCOMISD_XMM_XMMM64 = 1158,
	/// @brief @c VCOMISS xmm1, xmm2/m32{sae}
	/// @par
	/// @c EVEX.LIG.0F.W0 2F /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCOMISS_XMM_XMMM32_SAE = 1159,
	/// @brief @c VCOMISD xmm1, xmm2/m64{sae}
	/// @par
	/// @c EVEX.LIG.66.0F.W1 2F /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCOMISD_XMM_XMMM64_SAE = 1160,
	/// @brief @c WRMSR
	/// @par
	/// @c 0F 30
	/// @par
	/// @c MSR
	/// @par
	/// @c 16/32/64-bit
	WRMSR = 1161,
	/// @brief @c RDTSC
	/// @par
	/// @c 0F 31
	/// @par
	/// @c TSC
	/// @par
	/// @c 16/32/64-bit
	RDTSC = 1162,
	/// @brief @c RDMSR
	/// @par
	/// @c 0F 32
	/// @par
	/// @c MSR
	/// @par
	/// @c 16/32/64-bit
	RDMSR = 1163,
	/// @brief @c RDPMC
	/// @par
	/// @c 0F 33
	/// @par
	/// @c Pentium MMX or later, or Pentium Pro or later
	/// @par
	/// @c 16/32/64-bit
	RDPMC = 1164,
	/// @brief @c SYSENTER
	/// @par
	/// @c 0F 34
	/// @par
	/// @c SEP
	/// @par
	/// @c 16/32/64-bit
	SYSENTER = 1165,
	/// @brief @c SYSEXIT
	/// @par
	/// @c 0F 35
	/// @par
	/// @c SEP
	/// @par
	/// @c 16/32/64-bit
	SYSEXITD = 1166,
	/// @brief @c SYSEXITQ
	/// @par
	/// @c o64 0F 35
	/// @par
	/// @c SEP
	/// @par
	/// @c 64-bit
	SYSEXITQ = 1167,
	/// @brief @c GETSEC
	/// @par
	/// @c NP 0F 37
	/// @par
	/// @c SMX
	/// @par
	/// @c 16/32/64-bit
	GETSECD = 1168,
	/// @brief @c CMOVO r16, r/m16
	/// @par
	/// @c o16 0F 40 /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVO_R16_RM16 = 1169,
	/// @brief @c CMOVO r32, r/m32
	/// @par
	/// @c o32 0F 40 /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVO_R32_RM32 = 1170,
	/// @brief @c CMOVO r64, r/m64
	/// @par
	/// @c o64 0F 40 /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 64-bit
	CMOVO_R64_RM64 = 1171,
	/// @brief @c CMOVNO r16, r/m16
	/// @par
	/// @c o16 0F 41 /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVNO_R16_RM16 = 1172,
	/// @brief @c CMOVNO r32, r/m32
	/// @par
	/// @c o32 0F 41 /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVNO_R32_RM32 = 1173,
	/// @brief @c CMOVNO r64, r/m64
	/// @par
	/// @c o64 0F 41 /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 64-bit
	CMOVNO_R64_RM64 = 1174,
	/// @brief @c CMOVB r16, r/m16
	/// @par
	/// @c o16 0F 42 /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVB_R16_RM16 = 1175,
	/// @brief @c CMOVB r32, r/m32
	/// @par
	/// @c o32 0F 42 /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVB_R32_RM32 = 1176,
	/// @brief @c CMOVB r64, r/m64
	/// @par
	/// @c o64 0F 42 /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 64-bit
	CMOVB_R64_RM64 = 1177,
	/// @brief @c CMOVAE r16, r/m16
	/// @par
	/// @c o16 0F 43 /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVAE_R16_RM16 = 1178,
	/// @brief @c CMOVAE r32, r/m32
	/// @par
	/// @c o32 0F 43 /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVAE_R32_RM32 = 1179,
	/// @brief @c CMOVAE r64, r/m64
	/// @par
	/// @c o64 0F 43 /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 64-bit
	CMOVAE_R64_RM64 = 1180,
	/// @brief @c CMOVE r16, r/m16
	/// @par
	/// @c o16 0F 44 /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVE_R16_RM16 = 1181,
	/// @brief @c CMOVE r32, r/m32
	/// @par
	/// @c o32 0F 44 /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVE_R32_RM32 = 1182,
	/// @brief @c CMOVE r64, r/m64
	/// @par
	/// @c o64 0F 44 /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 64-bit
	CMOVE_R64_RM64 = 1183,
	/// @brief @c CMOVNE r16, r/m16
	/// @par
	/// @c o16 0F 45 /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVNE_R16_RM16 = 1184,
	/// @brief @c CMOVNE r32, r/m32
	/// @par
	/// @c o32 0F 45 /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVNE_R32_RM32 = 1185,
	/// @brief @c CMOVNE r64, r/m64
	/// @par
	/// @c o64 0F 45 /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 64-bit
	CMOVNE_R64_RM64 = 1186,
	/// @brief @c CMOVBE r16, r/m16
	/// @par
	/// @c o16 0F 46 /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVBE_R16_RM16 = 1187,
	/// @brief @c CMOVBE r32, r/m32
	/// @par
	/// @c o32 0F 46 /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVBE_R32_RM32 = 1188,
	/// @brief @c CMOVBE r64, r/m64
	/// @par
	/// @c o64 0F 46 /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 64-bit
	CMOVBE_R64_RM64 = 1189,
	/// @brief @c CMOVA r16, r/m16
	/// @par
	/// @c o16 0F 47 /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVA_R16_RM16 = 1190,
	/// @brief @c CMOVA r32, r/m32
	/// @par
	/// @c o32 0F 47 /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVA_R32_RM32 = 1191,
	/// @brief @c CMOVA r64, r/m64
	/// @par
	/// @c o64 0F 47 /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 64-bit
	CMOVA_R64_RM64 = 1192,
	/// @brief @c CMOVS r16, r/m16
	/// @par
	/// @c o16 0F 48 /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVS_R16_RM16 = 1193,
	/// @brief @c CMOVS r32, r/m32
	/// @par
	/// @c o32 0F 48 /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVS_R32_RM32 = 1194,
	/// @brief @c CMOVS r64, r/m64
	/// @par
	/// @c o64 0F 48 /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 64-bit
	CMOVS_R64_RM64 = 1195,
	/// @brief @c CMOVNS r16, r/m16
	/// @par
	/// @c o16 0F 49 /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVNS_R16_RM16 = 1196,
	/// @brief @c CMOVNS r32, r/m32
	/// @par
	/// @c o32 0F 49 /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVNS_R32_RM32 = 1197,
	/// @brief @c CMOVNS r64, r/m64
	/// @par
	/// @c o64 0F 49 /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 64-bit
	CMOVNS_R64_RM64 = 1198,
	/// @brief @c CMOVP r16, r/m16
	/// @par
	/// @c o16 0F 4A /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVP_R16_RM16 = 1199,
	/// @brief @c CMOVP r32, r/m32
	/// @par
	/// @c o32 0F 4A /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVP_R32_RM32 = 1200,
	/// @brief @c CMOVP r64, r/m64
	/// @par
	/// @c o64 0F 4A /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 64-bit
	CMOVP_R64_RM64 = 1201,
	/// @brief @c CMOVNP r16, r/m16
	/// @par
	/// @c o16 0F 4B /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVNP_R16_RM16 = 1202,
	/// @brief @c CMOVNP r32, r/m32
	/// @par
	/// @c o32 0F 4B /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVNP_R32_RM32 = 1203,
	/// @brief @c CMOVNP r64, r/m64
	/// @par
	/// @c o64 0F 4B /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 64-bit
	CMOVNP_R64_RM64 = 1204,
	/// @brief @c CMOVL r16, r/m16
	/// @par
	/// @c o16 0F 4C /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVL_R16_RM16 = 1205,
	/// @brief @c CMOVL r32, r/m32
	/// @par
	/// @c o32 0F 4C /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVL_R32_RM32 = 1206,
	/// @brief @c CMOVL r64, r/m64
	/// @par
	/// @c o64 0F 4C /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 64-bit
	CMOVL_R64_RM64 = 1207,
	/// @brief @c CMOVGE r16, r/m16
	/// @par
	/// @c o16 0F 4D /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVGE_R16_RM16 = 1208,
	/// @brief @c CMOVGE r32, r/m32
	/// @par
	/// @c o32 0F 4D /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVGE_R32_RM32 = 1209,
	/// @brief @c CMOVGE r64, r/m64
	/// @par
	/// @c o64 0F 4D /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 64-bit
	CMOVGE_R64_RM64 = 1210,
	/// @brief @c CMOVLE r16, r/m16
	/// @par
	/// @c o16 0F 4E /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVLE_R16_RM16 = 1211,
	/// @brief @c CMOVLE r32, r/m32
	/// @par
	/// @c o32 0F 4E /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVLE_R32_RM32 = 1212,
	/// @brief @c CMOVLE r64, r/m64
	/// @par
	/// @c o64 0F 4E /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 64-bit
	CMOVLE_R64_RM64 = 1213,
	/// @brief @c CMOVG r16, r/m16
	/// @par
	/// @c o16 0F 4F /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVG_R16_RM16 = 1214,
	/// @brief @c CMOVG r32, r/m32
	/// @par
	/// @c o32 0F 4F /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 16/32/64-bit
	CMOVG_R32_RM32 = 1215,
	/// @brief @c CMOVG r64, r/m64
	/// @par
	/// @c o64 0F 4F /r
	/// @par
	/// @c CMOV
	/// @par
	/// @c 64-bit
	CMOVG_R64_RM64 = 1216,
	/// @brief @c KANDW k1, k2, k3
	/// @par
	/// @c VEX.L1.0F.W0 41 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	VEX_KANDW_KR_KR_KR = 1217,
	/// @brief @c KANDQ k1, k2, k3
	/// @par
	/// @c VEX.L1.0F.W1 41 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	VEX_KANDQ_KR_KR_KR = 1218,
	/// @brief @c KANDB k1, k2, k3
	/// @par
	/// @c VEX.L1.66.0F.W0 41 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	VEX_KANDB_KR_KR_KR = 1219,
	/// @brief @c KANDD k1, k2, k3
	/// @par
	/// @c VEX.L1.66.0F.W1 41 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	VEX_KANDD_KR_KR_KR = 1220,
	/// @brief @c KANDNW k1, k2, k3
	/// @par
	/// @c VEX.L1.0F.W0 42 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	VEX_KANDNW_KR_KR_KR = 1221,
	/// @brief @c KANDNQ k1, k2, k3
	/// @par
	/// @c VEX.L1.0F.W1 42 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	VEX_KANDNQ_KR_KR_KR = 1222,
	/// @brief @c KANDNB k1, k2, k3
	/// @par
	/// @c VEX.L1.66.0F.W0 42 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	VEX_KANDNB_KR_KR_KR = 1223,
	/// @brief @c KANDND k1, k2, k3
	/// @par
	/// @c VEX.L1.66.0F.W1 42 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	VEX_KANDND_KR_KR_KR = 1224,
	/// @brief @c KNOTW k1, k2
	/// @par
	/// @c VEX.L0.0F.W0 44 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	VEX_KNOTW_KR_KR = 1225,
	/// @brief @c KNOTQ k1, k2
	/// @par
	/// @c VEX.L0.0F.W1 44 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	VEX_KNOTQ_KR_KR = 1226,
	/// @brief @c KNOTB k1, k2
	/// @par
	/// @c VEX.L0.66.0F.W0 44 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	VEX_KNOTB_KR_KR = 1227,
	/// @brief @c KNOTD k1, k2
	/// @par
	/// @c VEX.L0.66.0F.W1 44 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	VEX_KNOTD_KR_KR = 1228,
	/// @brief @c KORW k1, k2, k3
	/// @par
	/// @c VEX.L1.0F.W0 45 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	VEX_KORW_KR_KR_KR = 1229,
	/// @brief @c KORQ k1, k2, k3
	/// @par
	/// @c VEX.L1.0F.W1 45 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	VEX_KORQ_KR_KR_KR = 1230,
	/// @brief @c KORB k1, k2, k3
	/// @par
	/// @c VEX.L1.66.0F.W0 45 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	VEX_KORB_KR_KR_KR = 1231,
	/// @brief @c KORD k1, k2, k3
	/// @par
	/// @c VEX.L1.66.0F.W1 45 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	VEX_KORD_KR_KR_KR = 1232,
	/// @brief @c KXNORW k1, k2, k3
	/// @par
	/// @c VEX.L1.0F.W0 46 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	VEX_KXNORW_KR_KR_KR = 1233,
	/// @brief @c KXNORQ k1, k2, k3
	/// @par
	/// @c VEX.L1.0F.W1 46 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	VEX_KXNORQ_KR_KR_KR = 1234,
	/// @brief @c KXNORB k1, k2, k3
	/// @par
	/// @c VEX.L1.66.0F.W0 46 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	VEX_KXNORB_KR_KR_KR = 1235,
	/// @brief @c KXNORD k1, k2, k3
	/// @par
	/// @c VEX.L1.66.0F.W1 46 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	VEX_KXNORD_KR_KR_KR = 1236,
	/// @brief @c KXORW k1, k2, k3
	/// @par
	/// @c VEX.L1.0F.W0 47 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	VEX_KXORW_KR_KR_KR = 1237,
	/// @brief @c KXORQ k1, k2, k3
	/// @par
	/// @c VEX.L1.0F.W1 47 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	VEX_KXORQ_KR_KR_KR = 1238,
	/// @brief @c KXORB k1, k2, k3
	/// @par
	/// @c VEX.L1.66.0F.W0 47 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	VEX_KXORB_KR_KR_KR = 1239,
	/// @brief @c KXORD k1, k2, k3
	/// @par
	/// @c VEX.L1.66.0F.W1 47 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	VEX_KXORD_KR_KR_KR = 1240,
	/// @brief @c KADDW k1, k2, k3
	/// @par
	/// @c VEX.L1.0F.W0 4A /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	VEX_KADDW_KR_KR_KR = 1241,
	/// @brief @c KADDQ k1, k2, k3
	/// @par
	/// @c VEX.L1.0F.W1 4A /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	VEX_KADDQ_KR_KR_KR = 1242,
	/// @brief @c KADDB k1, k2, k3
	/// @par
	/// @c VEX.L1.66.0F.W0 4A /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	VEX_KADDB_KR_KR_KR = 1243,
	/// @brief @c KADDD k1, k2, k3
	/// @par
	/// @c VEX.L1.66.0F.W1 4A /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	VEX_KADDD_KR_KR_KR = 1244,
	/// @brief @c KUNPCKWD k1, k2, k3
	/// @par
	/// @c VEX.L1.0F.W0 4B /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	VEX_KUNPCKWD_KR_KR_KR = 1245,
	/// @brief @c KUNPCKDQ k1, k2, k3
	/// @par
	/// @c VEX.L1.0F.W1 4B /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	VEX_KUNPCKDQ_KR_KR_KR = 1246,
	/// @brief @c KUNPCKBW k1, k2, k3
	/// @par
	/// @c VEX.L1.66.0F.W0 4B /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	VEX_KUNPCKBW_KR_KR_KR = 1247,
	/// @brief @c MOVMSKPS r32, xmm
	/// @par
	/// @c NP 0F 50 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	MOVMSKPS_R32_XMM = 1248,
	/// @brief @c MOVMSKPS r64, xmm
	/// @par
	/// @c NP o64 0F 50 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 64-bit
	MOVMSKPS_R64_XMM = 1249,
	/// @brief @c VMOVMSKPS r32, xmm2
	/// @par
	/// @c VEX.128.0F.W0 50 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVMSKPS_R32_XMM = 1250,
	/// @brief @c VMOVMSKPS r64, xmm2
	/// @par
	/// @c VEX.128.0F.W1 50 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 64-bit
	VEX_VMOVMSKPS_R64_XMM = 1251,
	/// @brief @c VMOVMSKPS r32, ymm2
	/// @par
	/// @c VEX.256.0F.W0 50 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVMSKPS_R32_YMM = 1252,
	/// @brief @c VMOVMSKPS r64, ymm2
	/// @par
	/// @c VEX.256.0F.W1 50 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 64-bit
	VEX_VMOVMSKPS_R64_YMM = 1253,
	/// @brief @c MOVMSKPD r32, xmm
	/// @par
	/// @c 66 0F 50 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MOVMSKPD_R32_XMM = 1254,
	/// @brief @c MOVMSKPD r64, xmm
	/// @par
	/// @c 66 o64 0F 50 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 64-bit
	MOVMSKPD_R64_XMM = 1255,
	/// @brief @c VMOVMSKPD r32, xmm2
	/// @par
	/// @c VEX.128.66.0F.W0 50 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVMSKPD_R32_XMM = 1256,
	/// @brief @c VMOVMSKPD r64, xmm2
	/// @par
	/// @c VEX.128.66.0F.W1 50 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 64-bit
	VEX_VMOVMSKPD_R64_XMM = 1257,
	/// @brief @c VMOVMSKPD r32, ymm2
	/// @par
	/// @c VEX.256.66.0F.W0 50 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVMSKPD_R32_YMM = 1258,
	/// @brief @c VMOVMSKPD r64, ymm2
	/// @par
	/// @c VEX.256.66.0F.W1 50 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 64-bit
	VEX_VMOVMSKPD_R64_YMM = 1259,
	/// @brief @c SQRTPS xmm1, xmm2/m128
	/// @par
	/// @c NP 0F 51 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	SQRTPS_XMM_XMMM128 = 1260,
	/// @brief @c VSQRTPS xmm1, xmm2/m128
	/// @par
	/// @c VEX.128.0F.WIG 51 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VSQRTPS_XMM_XMMM128 = 1261,
	/// @brief @c VSQRTPS ymm1, ymm2/m256
	/// @par
	/// @c VEX.256.0F.WIG 51 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VSQRTPS_YMM_YMMM256 = 1262,
	/// @brief @c VSQRTPS xmm1 {k1}{z}, xmm2/m128/m32bcst
	/// @par
	/// @c EVEX.128.0F.W0 51 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSQRTPS_XMM_K1Z_XMMM128B32 = 1263,
	/// @brief @c VSQRTPS ymm1 {k1}{z}, ymm2/m256/m32bcst
	/// @par
	/// @c EVEX.256.0F.W0 51 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSQRTPS_YMM_K1Z_YMMM256B32 = 1264,
	/// @brief @c VSQRTPS zmm1 {k1}{z}, zmm2/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.0F.W0 51 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSQRTPS_ZMM_K1Z_ZMMM512B32_ER = 1265,
	/// @brief @c SQRTPD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 51 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	SQRTPD_XMM_XMMM128 = 1266,
	/// @brief @c VSQRTPD xmm1, xmm2/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 51 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VSQRTPD_XMM_XMMM128 = 1267,
	/// @brief @c VSQRTPD ymm1, ymm2/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 51 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VSQRTPD_YMM_YMMM256 = 1268,
	/// @brief @c VSQRTPD xmm1 {k1}{z}, xmm2/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F.W1 51 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSQRTPD_XMM_K1Z_XMMM128B64 = 1269,
	/// @brief @c VSQRTPD ymm1 {k1}{z}, ymm2/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F.W1 51 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSQRTPD_YMM_K1Z_YMMM256B64 = 1270,
	/// @brief @c VSQRTPD zmm1 {k1}{z}, zmm2/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.66.0F.W1 51 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSQRTPD_ZMM_K1Z_ZMMM512B64_ER = 1271,
	/// @brief @c SQRTSS xmm1, xmm2/m32
	/// @par
	/// @c F3 0F 51 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	SQRTSS_XMM_XMMM32 = 1272,
	/// @brief @c VSQRTSS xmm1, xmm2, xmm3/m32
	/// @par
	/// @c VEX.LIG.F3.0F.WIG 51 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VSQRTSS_XMM_XMM_XMMM32 = 1273,
	/// @brief @c VSQRTSS xmm1 {k1}{z}, xmm2, xmm3/m32{er}
	/// @par
	/// @c EVEX.LIG.F3.0F.W0 51 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSQRTSS_XMM_K1Z_XMM_XMMM32_ER = 1274,
	/// @brief @c SQRTSD xmm1, xmm2/m64
	/// @par
	/// @c F2 0F 51 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	SQRTSD_XMM_XMMM64 = 1275,
	/// @brief @c VSQRTSD xmm1, xmm2, xmm3/m64
	/// @par
	/// @c VEX.LIG.F2.0F.WIG 51 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VSQRTSD_XMM_XMM_XMMM64 = 1276,
	/// @brief @c VSQRTSD xmm1 {k1}{z}, xmm2, xmm3/m64{er}
	/// @par
	/// @c EVEX.LIG.F2.0F.W1 51 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSQRTSD_XMM_K1Z_XMM_XMMM64_ER = 1277,
	/// @brief @c RSQRTPS xmm1, xmm2/m128
	/// @par
	/// @c NP 0F 52 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	RSQRTPS_XMM_XMMM128 = 1278,
	/// @brief @c VRSQRTPS xmm1, xmm2/m128
	/// @par
	/// @c VEX.128.0F.WIG 52 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VRSQRTPS_XMM_XMMM128 = 1279,
	/// @brief @c VRSQRTPS ymm1, ymm2/m256
	/// @par
	/// @c VEX.256.0F.WIG 52 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VRSQRTPS_YMM_YMMM256 = 1280,
	/// @brief @c RSQRTSS xmm1, xmm2/m32
	/// @par
	/// @c F3 0F 52 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	RSQRTSS_XMM_XMMM32 = 1281,
	/// @brief @c VRSQRTSS xmm1, xmm2, xmm3/m32
	/// @par
	/// @c VEX.LIG.F3.0F.WIG 52 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VRSQRTSS_XMM_XMM_XMMM32 = 1282,
	/// @brief @c RCPPS xmm1, xmm2/m128
	/// @par
	/// @c NP 0F 53 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	RCPPS_XMM_XMMM128 = 1283,
	/// @brief @c VRCPPS xmm1, xmm2/m128
	/// @par
	/// @c VEX.128.0F.WIG 53 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VRCPPS_XMM_XMMM128 = 1284,
	/// @brief @c VRCPPS ymm1, ymm2/m256
	/// @par
	/// @c VEX.256.0F.WIG 53 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VRCPPS_YMM_YMMM256 = 1285,
	/// @brief @c RCPSS xmm1, xmm2/m32
	/// @par
	/// @c F3 0F 53 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	RCPSS_XMM_XMMM32 = 1286,
	/// @brief @c VRCPSS xmm1, xmm2, xmm3/m32
	/// @par
	/// @c VEX.LIG.F3.0F.WIG 53 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VRCPSS_XMM_XMM_XMMM32 = 1287,
	/// @brief @c ANDPS xmm1, xmm2/m128
	/// @par
	/// @c NP 0F 54 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	ANDPS_XMM_XMMM128 = 1288,
	/// @brief @c VANDPS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.0F.WIG 54 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VANDPS_XMM_XMM_XMMM128 = 1289,
	/// @brief @c VANDPS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.0F.WIG 54 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VANDPS_YMM_YMM_YMMM256 = 1290,
	/// @brief @c VANDPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.0F.W0 54 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VANDPS_XMM_K1Z_XMM_XMMM128B32 = 1291,
	/// @brief @c VANDPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.0F.W0 54 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VANDPS_YMM_K1Z_YMM_YMMM256B32 = 1292,
	/// @brief @c VANDPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.0F.W0 54 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VANDPS_ZMM_K1Z_ZMM_ZMMM512B32 = 1293,
	/// @brief @c ANDPD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 54 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	ANDPD_XMM_XMMM128 = 1294,
	/// @brief @c VANDPD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 54 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VANDPD_XMM_XMM_XMMM128 = 1295,
	/// @brief @c VANDPD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 54 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VANDPD_YMM_YMM_YMMM256 = 1296,
	/// @brief @c VANDPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F.W1 54 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VANDPD_XMM_K1Z_XMM_XMMM128B64 = 1297,
	/// @brief @c VANDPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F.W1 54 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VANDPD_YMM_K1Z_YMM_YMMM256B64 = 1298,
	/// @brief @c VANDPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F.W1 54 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VANDPD_ZMM_K1Z_ZMM_ZMMM512B64 = 1299,
	/// @brief @c ANDNPS xmm1, xmm2/m128
	/// @par
	/// @c NP 0F 55 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	ANDNPS_XMM_XMMM128 = 1300,
	/// @brief @c VANDNPS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.0F.WIG 55 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VANDNPS_XMM_XMM_XMMM128 = 1301,
	/// @brief @c VANDNPS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.0F.WIG 55 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VANDNPS_YMM_YMM_YMMM256 = 1302,
	/// @brief @c VANDNPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.0F.W0 55 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VANDNPS_XMM_K1Z_XMM_XMMM128B32 = 1303,
	/// @brief @c VANDNPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.0F.W0 55 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VANDNPS_YMM_K1Z_YMM_YMMM256B32 = 1304,
	/// @brief @c VANDNPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.0F.W0 55 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VANDNPS_ZMM_K1Z_ZMM_ZMMM512B32 = 1305,
	/// @brief @c ANDNPD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 55 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	ANDNPD_XMM_XMMM128 = 1306,
	/// @brief @c VANDNPD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 55 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VANDNPD_XMM_XMM_XMMM128 = 1307,
	/// @brief @c VANDNPD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 55 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VANDNPD_YMM_YMM_YMMM256 = 1308,
	/// @brief @c VANDNPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F.W1 55 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VANDNPD_XMM_K1Z_XMM_XMMM128B64 = 1309,
	/// @brief @c VANDNPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F.W1 55 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VANDNPD_YMM_K1Z_YMM_YMMM256B64 = 1310,
	/// @brief @c VANDNPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F.W1 55 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VANDNPD_ZMM_K1Z_ZMM_ZMMM512B64 = 1311,
	/// @brief @c ORPS xmm1, xmm2/m128
	/// @par
	/// @c NP 0F 56 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	ORPS_XMM_XMMM128 = 1312,
	/// @brief @c VORPS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.0F.WIG 56 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VORPS_XMM_XMM_XMMM128 = 1313,
	/// @brief @c VORPS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.0F.WIG 56 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VORPS_YMM_YMM_YMMM256 = 1314,
	/// @brief @c VORPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.0F.W0 56 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VORPS_XMM_K1Z_XMM_XMMM128B32 = 1315,
	/// @brief @c VORPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.0F.W0 56 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VORPS_YMM_K1Z_YMM_YMMM256B32 = 1316,
	/// @brief @c VORPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.0F.W0 56 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VORPS_ZMM_K1Z_ZMM_ZMMM512B32 = 1317,
	/// @brief @c ORPD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 56 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	ORPD_XMM_XMMM128 = 1318,
	/// @brief @c VORPD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 56 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VORPD_XMM_XMM_XMMM128 = 1319,
	/// @brief @c VORPD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 56 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VORPD_YMM_YMM_YMMM256 = 1320,
	/// @brief @c VORPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F.W1 56 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VORPD_XMM_K1Z_XMM_XMMM128B64 = 1321,
	/// @brief @c VORPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F.W1 56 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VORPD_YMM_K1Z_YMM_YMMM256B64 = 1322,
	/// @brief @c VORPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F.W1 56 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VORPD_ZMM_K1Z_ZMM_ZMMM512B64 = 1323,
	/// @brief @c XORPS xmm1, xmm2/m128
	/// @par
	/// @c NP 0F 57 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	XORPS_XMM_XMMM128 = 1324,
	/// @brief @c VXORPS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.0F.WIG 57 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VXORPS_XMM_XMM_XMMM128 = 1325,
	/// @brief @c VXORPS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.0F.WIG 57 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VXORPS_YMM_YMM_YMMM256 = 1326,
	/// @brief @c VXORPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.0F.W0 57 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VXORPS_XMM_K1Z_XMM_XMMM128B32 = 1327,
	/// @brief @c VXORPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.0F.W0 57 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VXORPS_YMM_K1Z_YMM_YMMM256B32 = 1328,
	/// @brief @c VXORPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.0F.W0 57 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VXORPS_ZMM_K1Z_ZMM_ZMMM512B32 = 1329,
	/// @brief @c XORPD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 57 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	XORPD_XMM_XMMM128 = 1330,
	/// @brief @c VXORPD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 57 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VXORPD_XMM_XMM_XMMM128 = 1331,
	/// @brief @c VXORPD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 57 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VXORPD_YMM_YMM_YMMM256 = 1332,
	/// @brief @c VXORPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F.W1 57 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VXORPD_XMM_K1Z_XMM_XMMM128B64 = 1333,
	/// @brief @c VXORPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F.W1 57 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VXORPD_YMM_K1Z_YMM_YMMM256B64 = 1334,
	/// @brief @c VXORPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F.W1 57 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VXORPD_ZMM_K1Z_ZMM_ZMMM512B64 = 1335,
	/// @brief @c ADDPS xmm1, xmm2/m128
	/// @par
	/// @c NP 0F 58 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	ADDPS_XMM_XMMM128 = 1336,
	/// @brief @c VADDPS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.0F.WIG 58 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VADDPS_XMM_XMM_XMMM128 = 1337,
	/// @brief @c VADDPS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.0F.WIG 58 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VADDPS_YMM_YMM_YMMM256 = 1338,
	/// @brief @c VADDPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.0F.W0 58 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VADDPS_XMM_K1Z_XMM_XMMM128B32 = 1339,
	/// @brief @c VADDPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.0F.W0 58 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VADDPS_YMM_K1Z_YMM_YMMM256B32 = 1340,
	/// @brief @c VADDPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.0F.W0 58 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VADDPS_ZMM_K1Z_ZMM_ZMMM512B32_ER = 1341,
	/// @brief @c ADDPD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 58 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	ADDPD_XMM_XMMM128 = 1342,
	/// @brief @c VADDPD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 58 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VADDPD_XMM_XMM_XMMM128 = 1343,
	/// @brief @c VADDPD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 58 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VADDPD_YMM_YMM_YMMM256 = 1344,
	/// @brief @c VADDPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F.W1 58 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VADDPD_XMM_K1Z_XMM_XMMM128B64 = 1345,
	/// @brief @c VADDPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F.W1 58 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VADDPD_YMM_K1Z_YMM_YMMM256B64 = 1346,
	/// @brief @c VADDPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.66.0F.W1 58 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VADDPD_ZMM_K1Z_ZMM_ZMMM512B64_ER = 1347,
	/// @brief @c ADDSS xmm1, xmm2/m32
	/// @par
	/// @c F3 0F 58 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	ADDSS_XMM_XMMM32 = 1348,
	/// @brief @c VADDSS xmm1, xmm2, xmm3/m32
	/// @par
	/// @c VEX.LIG.F3.0F.WIG 58 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VADDSS_XMM_XMM_XMMM32 = 1349,
	/// @brief @c VADDSS xmm1 {k1}{z}, xmm2, xmm3/m32{er}
	/// @par
	/// @c EVEX.LIG.F3.0F.W0 58 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VADDSS_XMM_K1Z_XMM_XMMM32_ER = 1350,
	/// @brief @c ADDSD xmm1, xmm2/m64
	/// @par
	/// @c F2 0F 58 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	ADDSD_XMM_XMMM64 = 1351,
	/// @brief @c VADDSD xmm1, xmm2, xmm3/m64
	/// @par
	/// @c VEX.LIG.F2.0F.WIG 58 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VADDSD_XMM_XMM_XMMM64 = 1352,
	/// @brief @c VADDSD xmm1 {k1}{z}, xmm2, xmm3/m64{er}
	/// @par
	/// @c EVEX.LIG.F2.0F.W1 58 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VADDSD_XMM_K1Z_XMM_XMMM64_ER = 1353,
	/// @brief @c MULPS xmm1, xmm2/m128
	/// @par
	/// @c NP 0F 59 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	MULPS_XMM_XMMM128 = 1354,
	/// @brief @c VMULPS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.0F.WIG 59 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMULPS_XMM_XMM_XMMM128 = 1355,
	/// @brief @c VMULPS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.0F.WIG 59 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMULPS_YMM_YMM_YMMM256 = 1356,
	/// @brief @c VMULPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.0F.W0 59 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMULPS_XMM_K1Z_XMM_XMMM128B32 = 1357,
	/// @brief @c VMULPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.0F.W0 59 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMULPS_YMM_K1Z_YMM_YMMM256B32 = 1358,
	/// @brief @c VMULPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.0F.W0 59 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMULPS_ZMM_K1Z_ZMM_ZMMM512B32_ER = 1359,
	/// @brief @c MULPD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 59 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MULPD_XMM_XMMM128 = 1360,
	/// @brief @c VMULPD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 59 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMULPD_XMM_XMM_XMMM128 = 1361,
	/// @brief @c VMULPD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 59 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMULPD_YMM_YMM_YMMM256 = 1362,
	/// @brief @c VMULPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F.W1 59 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMULPD_XMM_K1Z_XMM_XMMM128B64 = 1363,
	/// @brief @c VMULPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F.W1 59 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMULPD_YMM_K1Z_YMM_YMMM256B64 = 1364,
	/// @brief @c VMULPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.66.0F.W1 59 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMULPD_ZMM_K1Z_ZMM_ZMMM512B64_ER = 1365,
	/// @brief @c MULSS xmm1, xmm2/m32
	/// @par
	/// @c F3 0F 59 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	MULSS_XMM_XMMM32 = 1366,
	/// @brief @c VMULSS xmm1, xmm2, xmm3/m32
	/// @par
	/// @c VEX.LIG.F3.0F.WIG 59 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMULSS_XMM_XMM_XMMM32 = 1367,
	/// @brief @c VMULSS xmm1 {k1}{z}, xmm2, xmm3/m32{er}
	/// @par
	/// @c EVEX.LIG.F3.0F.W0 59 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMULSS_XMM_K1Z_XMM_XMMM32_ER = 1368,
	/// @brief @c MULSD xmm1, xmm2/m64
	/// @par
	/// @c F2 0F 59 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MULSD_XMM_XMMM64 = 1369,
	/// @brief @c VMULSD xmm1, xmm2, xmm3/m64
	/// @par
	/// @c VEX.LIG.F2.0F.WIG 59 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMULSD_XMM_XMM_XMMM64 = 1370,
	/// @brief @c VMULSD xmm1 {k1}{z}, xmm2, xmm3/m64{er}
	/// @par
	/// @c EVEX.LIG.F2.0F.W1 59 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMULSD_XMM_K1Z_XMM_XMMM64_ER = 1371,
	/// @brief @c CVTPS2PD xmm1, xmm2/m64
	/// @par
	/// @c NP 0F 5A /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	CVTPS2PD_XMM_XMMM64 = 1372,
	/// @brief @c VCVTPS2PD xmm1, xmm2/m64
	/// @par
	/// @c VEX.128.0F.WIG 5A /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTPS2PD_XMM_XMMM64 = 1373,
	/// @brief @c VCVTPS2PD ymm1, xmm2/m128
	/// @par
	/// @c VEX.256.0F.WIG 5A /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTPS2PD_YMM_XMMM128 = 1374,
	/// @brief @c VCVTPS2PD xmm1 {k1}{z}, xmm2/m64/m32bcst
	/// @par
	/// @c EVEX.128.0F.W0 5A /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPS2PD_XMM_K1Z_XMMM64B32 = 1375,
	/// @brief @c VCVTPS2PD ymm1 {k1}{z}, xmm2/m128/m32bcst
	/// @par
	/// @c EVEX.256.0F.W0 5A /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPS2PD_YMM_K1Z_XMMM128B32 = 1376,
	/// @brief @c VCVTPS2PD zmm1 {k1}{z}, ymm2/m256/m32bcst{sae}
	/// @par
	/// @c EVEX.512.0F.W0 5A /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPS2PD_ZMM_K1Z_YMMM256B32_SAE = 1377,
	/// @brief @c CVTPD2PS xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 5A /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	CVTPD2PS_XMM_XMMM128 = 1378,
	/// @brief @c VCVTPD2PS xmm1, xmm2/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 5A /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTPD2PS_XMM_XMMM128 = 1379,
	/// @brief @c VCVTPD2PS xmm1, ymm2/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 5A /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTPD2PS_XMM_YMMM256 = 1380,
	/// @brief @c VCVTPD2PS xmm1 {k1}{z}, xmm2/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F.W1 5A /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPD2PS_XMM_K1Z_XMMM128B64 = 1381,
	/// @brief @c VCVTPD2PS xmm1 {k1}{z}, ymm2/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F.W1 5A /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPD2PS_XMM_K1Z_YMMM256B64 = 1382,
	/// @brief @c VCVTPD2PS ymm1 {k1}{z}, zmm2/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.66.0F.W1 5A /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPD2PS_YMM_K1Z_ZMMM512B64_ER = 1383,
	/// @brief @c CVTSS2SD xmm1, xmm2/m32
	/// @par
	/// @c F3 0F 5A /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	CVTSS2SD_XMM_XMMM32 = 1384,
	/// @brief @c VCVTSS2SD xmm1, xmm2, xmm3/m32
	/// @par
	/// @c VEX.LIG.F3.0F.WIG 5A /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTSS2SD_XMM_XMM_XMMM32 = 1385,
	/// @brief @c VCVTSS2SD xmm1 {k1}{z}, xmm2, xmm3/m32{sae}
	/// @par
	/// @c EVEX.LIG.F3.0F.W0 5A /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTSS2SD_XMM_K1Z_XMM_XMMM32_SAE = 1386,
	/// @brief @c CVTSD2SS xmm1, xmm2/m64
	/// @par
	/// @c F2 0F 5A /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	CVTSD2SS_XMM_XMMM64 = 1387,
	/// @brief @c VCVTSD2SS xmm1, xmm2, xmm3/m64
	/// @par
	/// @c VEX.LIG.F2.0F.WIG 5A /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTSD2SS_XMM_XMM_XMMM64 = 1388,
	/// @brief @c VCVTSD2SS xmm1 {k1}{z}, xmm2, xmm3/m64{er}
	/// @par
	/// @c EVEX.LIG.F2.0F.W1 5A /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTSD2SS_XMM_K1Z_XMM_XMMM64_ER = 1389,
	/// @brief @c CVTDQ2PS xmm1, xmm2/m128
	/// @par
	/// @c NP 0F 5B /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	CVTDQ2PS_XMM_XMMM128 = 1390,
	/// @brief @c VCVTDQ2PS xmm1, xmm2/m128
	/// @par
	/// @c VEX.128.0F.WIG 5B /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTDQ2PS_XMM_XMMM128 = 1391,
	/// @brief @c VCVTDQ2PS ymm1, ymm2/m256
	/// @par
	/// @c VEX.256.0F.WIG 5B /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTDQ2PS_YMM_YMMM256 = 1392,
	/// @brief @c VCVTDQ2PS xmm1 {k1}{z}, xmm2/m128/m32bcst
	/// @par
	/// @c EVEX.128.0F.W0 5B /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTDQ2PS_XMM_K1Z_XMMM128B32 = 1393,
	/// @brief @c VCVTDQ2PS ymm1 {k1}{z}, ymm2/m256/m32bcst
	/// @par
	/// @c EVEX.256.0F.W0 5B /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTDQ2PS_YMM_K1Z_YMMM256B32 = 1394,
	/// @brief @c VCVTDQ2PS zmm1 {k1}{z}, zmm2/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.0F.W0 5B /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTDQ2PS_ZMM_K1Z_ZMMM512B32_ER = 1395,
	/// @brief @c VCVTQQ2PS xmm1 {k1}{z}, xmm2/m128/m64bcst
	/// @par
	/// @c EVEX.128.0F.W1 5B /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTQQ2PS_XMM_K1Z_XMMM128B64 = 1396,
	/// @brief @c VCVTQQ2PS xmm1 {k1}{z}, ymm2/m256/m64bcst
	/// @par
	/// @c EVEX.256.0F.W1 5B /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTQQ2PS_XMM_K1Z_YMMM256B64 = 1397,
	/// @brief @c VCVTQQ2PS ymm1 {k1}{z}, zmm2/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.0F.W1 5B /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTQQ2PS_YMM_K1Z_ZMMM512B64_ER = 1398,
	/// @brief @c CVTPS2DQ xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 5B /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	CVTPS2DQ_XMM_XMMM128 = 1399,
	/// @brief @c VCVTPS2DQ xmm1, xmm2/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 5B /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTPS2DQ_XMM_XMMM128 = 1400,
	/// @brief @c VCVTPS2DQ ymm1, ymm2/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 5B /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTPS2DQ_YMM_YMMM256 = 1401,
	/// @brief @c VCVTPS2DQ xmm1 {k1}{z}, xmm2/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F.W0 5B /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPS2DQ_XMM_K1Z_XMMM128B32 = 1402,
	/// @brief @c VCVTPS2DQ ymm1 {k1}{z}, ymm2/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F.W0 5B /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPS2DQ_YMM_K1Z_YMMM256B32 = 1403,
	/// @brief @c VCVTPS2DQ zmm1 {k1}{z}, zmm2/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.66.0F.W0 5B /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPS2DQ_ZMM_K1Z_ZMMM512B32_ER = 1404,
	/// @brief @c CVTTPS2DQ xmm1, xmm2/m128
	/// @par
	/// @c F3 0F 5B /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	CVTTPS2DQ_XMM_XMMM128 = 1405,
	/// @brief @c VCVTTPS2DQ xmm1, xmm2/m128
	/// @par
	/// @c VEX.128.F3.0F.WIG 5B /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTTPS2DQ_XMM_XMMM128 = 1406,
	/// @brief @c VCVTTPS2DQ ymm1, ymm2/m256
	/// @par
	/// @c VEX.256.F3.0F.WIG 5B /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTTPS2DQ_YMM_YMMM256 = 1407,
	/// @brief @c VCVTTPS2DQ xmm1 {k1}{z}, xmm2/m128/m32bcst
	/// @par
	/// @c EVEX.128.F3.0F.W0 5B /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPS2DQ_XMM_K1Z_XMMM128B32 = 1408,
	/// @brief @c VCVTTPS2DQ ymm1 {k1}{z}, ymm2/m256/m32bcst
	/// @par
	/// @c EVEX.256.F3.0F.W0 5B /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPS2DQ_YMM_K1Z_YMMM256B32 = 1409,
	/// @brief @c VCVTTPS2DQ zmm1 {k1}{z}, zmm2/m512/m32bcst{sae}
	/// @par
	/// @c EVEX.512.F3.0F.W0 5B /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPS2DQ_ZMM_K1Z_ZMMM512B32_SAE = 1410,
	/// @brief @c SUBPS xmm1, xmm2/m128
	/// @par
	/// @c NP 0F 5C /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	SUBPS_XMM_XMMM128 = 1411,
	/// @brief @c VSUBPS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.0F.WIG 5C /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VSUBPS_XMM_XMM_XMMM128 = 1412,
	/// @brief @c VSUBPS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.0F.WIG 5C /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VSUBPS_YMM_YMM_YMMM256 = 1413,
	/// @brief @c VSUBPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.0F.W0 5C /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSUBPS_XMM_K1Z_XMM_XMMM128B32 = 1414,
	/// @brief @c VSUBPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.0F.W0 5C /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSUBPS_YMM_K1Z_YMM_YMMM256B32 = 1415,
	/// @brief @c VSUBPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.0F.W0 5C /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSUBPS_ZMM_K1Z_ZMM_ZMMM512B32_ER = 1416,
	/// @brief @c SUBPD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 5C /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	SUBPD_XMM_XMMM128 = 1417,
	/// @brief @c VSUBPD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 5C /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VSUBPD_XMM_XMM_XMMM128 = 1418,
	/// @brief @c VSUBPD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 5C /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VSUBPD_YMM_YMM_YMMM256 = 1419,
	/// @brief @c VSUBPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F.W1 5C /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSUBPD_XMM_K1Z_XMM_XMMM128B64 = 1420,
	/// @brief @c VSUBPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F.W1 5C /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSUBPD_YMM_K1Z_YMM_YMMM256B64 = 1421,
	/// @brief @c VSUBPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.66.0F.W1 5C /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSUBPD_ZMM_K1Z_ZMM_ZMMM512B64_ER = 1422,
	/// @brief @c SUBSS xmm1, xmm2/m32
	/// @par
	/// @c F3 0F 5C /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	SUBSS_XMM_XMMM32 = 1423,
	/// @brief @c VSUBSS xmm1, xmm2, xmm3/m32
	/// @par
	/// @c VEX.LIG.F3.0F.WIG 5C /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VSUBSS_XMM_XMM_XMMM32 = 1424,
	/// @brief @c VSUBSS xmm1 {k1}{z}, xmm2, xmm3/m32{er}
	/// @par
	/// @c EVEX.LIG.F3.0F.W0 5C /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSUBSS_XMM_K1Z_XMM_XMMM32_ER = 1425,
	/// @brief @c SUBSD xmm1, xmm2/m64
	/// @par
	/// @c F2 0F 5C /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	SUBSD_XMM_XMMM64 = 1426,
	/// @brief @c VSUBSD xmm1, xmm2, xmm3/m64
	/// @par
	/// @c VEX.LIG.F2.0F.WIG 5C /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VSUBSD_XMM_XMM_XMMM64 = 1427,
	/// @brief @c VSUBSD xmm1 {k1}{z}, xmm2, xmm3/m64{er}
	/// @par
	/// @c EVEX.LIG.F2.0F.W1 5C /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSUBSD_XMM_K1Z_XMM_XMMM64_ER = 1428,
	/// @brief @c MINPS xmm1, xmm2/m128
	/// @par
	/// @c NP 0F 5D /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	MINPS_XMM_XMMM128 = 1429,
	/// @brief @c VMINPS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.0F.WIG 5D /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMINPS_XMM_XMM_XMMM128 = 1430,
	/// @brief @c VMINPS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.0F.WIG 5D /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMINPS_YMM_YMM_YMMM256 = 1431,
	/// @brief @c VMINPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.0F.W0 5D /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMINPS_XMM_K1Z_XMM_XMMM128B32 = 1432,
	/// @brief @c VMINPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.0F.W0 5D /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMINPS_YMM_K1Z_YMM_YMMM256B32 = 1433,
	/// @brief @c VMINPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{sae}
	/// @par
	/// @c EVEX.512.0F.W0 5D /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMINPS_ZMM_K1Z_ZMM_ZMMM512B32_SAE = 1434,
	/// @brief @c MINPD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 5D /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MINPD_XMM_XMMM128 = 1435,
	/// @brief @c VMINPD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 5D /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMINPD_XMM_XMM_XMMM128 = 1436,
	/// @brief @c VMINPD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 5D /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMINPD_YMM_YMM_YMMM256 = 1437,
	/// @brief @c VMINPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F.W1 5D /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMINPD_XMM_K1Z_XMM_XMMM128B64 = 1438,
	/// @brief @c VMINPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F.W1 5D /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMINPD_YMM_K1Z_YMM_YMMM256B64 = 1439,
	/// @brief @c VMINPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{sae}
	/// @par
	/// @c EVEX.512.66.0F.W1 5D /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMINPD_ZMM_K1Z_ZMM_ZMMM512B64_SAE = 1440,
	/// @brief @c MINSS xmm1, xmm2/m32
	/// @par
	/// @c F3 0F 5D /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	MINSS_XMM_XMMM32 = 1441,
	/// @brief @c VMINSS xmm1, xmm2, xmm3/m32
	/// @par
	/// @c VEX.LIG.F3.0F.WIG 5D /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMINSS_XMM_XMM_XMMM32 = 1442,
	/// @brief @c VMINSS xmm1 {k1}{z}, xmm2, xmm3/m32{sae}
	/// @par
	/// @c EVEX.LIG.F3.0F.W0 5D /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMINSS_XMM_K1Z_XMM_XMMM32_SAE = 1443,
	/// @brief @c MINSD xmm1, xmm2/m64
	/// @par
	/// @c F2 0F 5D /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MINSD_XMM_XMMM64 = 1444,
	/// @brief @c VMINSD xmm1, xmm2, xmm3/m64
	/// @par
	/// @c VEX.LIG.F2.0F.WIG 5D /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMINSD_XMM_XMM_XMMM64 = 1445,
	/// @brief @c VMINSD xmm1 {k1}{z}, xmm2, xmm3/m64{sae}
	/// @par
	/// @c EVEX.LIG.F2.0F.W1 5D /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMINSD_XMM_K1Z_XMM_XMMM64_SAE = 1446,
	/// @brief @c DIVPS xmm1, xmm2/m128
	/// @par
	/// @c NP 0F 5E /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	DIVPS_XMM_XMMM128 = 1447,
	/// @brief @c VDIVPS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.0F.WIG 5E /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VDIVPS_XMM_XMM_XMMM128 = 1448,
	/// @brief @c VDIVPS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.0F.WIG 5E /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VDIVPS_YMM_YMM_YMMM256 = 1449,
	/// @brief @c VDIVPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.0F.W0 5E /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VDIVPS_XMM_K1Z_XMM_XMMM128B32 = 1450,
	/// @brief @c VDIVPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.0F.W0 5E /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VDIVPS_YMM_K1Z_YMM_YMMM256B32 = 1451,
	/// @brief @c VDIVPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.0F.W0 5E /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VDIVPS_ZMM_K1Z_ZMM_ZMMM512B32_ER = 1452,
	/// @brief @c DIVPD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 5E /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	DIVPD_XMM_XMMM128 = 1453,
	/// @brief @c VDIVPD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 5E /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VDIVPD_XMM_XMM_XMMM128 = 1454,
	/// @brief @c VDIVPD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 5E /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VDIVPD_YMM_YMM_YMMM256 = 1455,
	/// @brief @c VDIVPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F.W1 5E /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VDIVPD_XMM_K1Z_XMM_XMMM128B64 = 1456,
	/// @brief @c VDIVPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F.W1 5E /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VDIVPD_YMM_K1Z_YMM_YMMM256B64 = 1457,
	/// @brief @c VDIVPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.66.0F.W1 5E /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VDIVPD_ZMM_K1Z_ZMM_ZMMM512B64_ER = 1458,
	/// @brief @c DIVSS xmm1, xmm2/m32
	/// @par
	/// @c F3 0F 5E /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	DIVSS_XMM_XMMM32 = 1459,
	/// @brief @c VDIVSS xmm1, xmm2, xmm3/m32
	/// @par
	/// @c VEX.LIG.F3.0F.WIG 5E /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VDIVSS_XMM_XMM_XMMM32 = 1460,
	/// @brief @c VDIVSS xmm1 {k1}{z}, xmm2, xmm3/m32{er}
	/// @par
	/// @c EVEX.LIG.F3.0F.W0 5E /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VDIVSS_XMM_K1Z_XMM_XMMM32_ER = 1461,
	/// @brief @c DIVSD xmm1, xmm2/m64
	/// @par
	/// @c F2 0F 5E /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	DIVSD_XMM_XMMM64 = 1462,
	/// @brief @c VDIVSD xmm1, xmm2, xmm3/m64
	/// @par
	/// @c VEX.LIG.F2.0F.WIG 5E /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VDIVSD_XMM_XMM_XMMM64 = 1463,
	/// @brief @c VDIVSD xmm1 {k1}{z}, xmm2, xmm3/m64{er}
	/// @par
	/// @c EVEX.LIG.F2.0F.W1 5E /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VDIVSD_XMM_K1Z_XMM_XMMM64_ER = 1464,
	/// @brief @c MAXPS xmm1, xmm2/m128
	/// @par
	/// @c NP 0F 5F /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	MAXPS_XMM_XMMM128 = 1465,
	/// @brief @c VMAXPS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.0F.WIG 5F /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMAXPS_XMM_XMM_XMMM128 = 1466,
	/// @brief @c VMAXPS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.0F.WIG 5F /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMAXPS_YMM_YMM_YMMM256 = 1467,
	/// @brief @c VMAXPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.0F.W0 5F /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMAXPS_XMM_K1Z_XMM_XMMM128B32 = 1468,
	/// @brief @c VMAXPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.0F.W0 5F /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMAXPS_YMM_K1Z_YMM_YMMM256B32 = 1469,
	/// @brief @c VMAXPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{sae}
	/// @par
	/// @c EVEX.512.0F.W0 5F /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMAXPS_ZMM_K1Z_ZMM_ZMMM512B32_SAE = 1470,
	/// @brief @c MAXPD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 5F /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MAXPD_XMM_XMMM128 = 1471,
	/// @brief @c VMAXPD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 5F /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMAXPD_XMM_XMM_XMMM128 = 1472,
	/// @brief @c VMAXPD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 5F /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMAXPD_YMM_YMM_YMMM256 = 1473,
	/// @brief @c VMAXPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F.W1 5F /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMAXPD_XMM_K1Z_XMM_XMMM128B64 = 1474,
	/// @brief @c VMAXPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F.W1 5F /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMAXPD_YMM_K1Z_YMM_YMMM256B64 = 1475,
	/// @brief @c VMAXPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{sae}
	/// @par
	/// @c EVEX.512.66.0F.W1 5F /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMAXPD_ZMM_K1Z_ZMM_ZMMM512B64_SAE = 1476,
	/// @brief @c MAXSS xmm1, xmm2/m32
	/// @par
	/// @c F3 0F 5F /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	MAXSS_XMM_XMMM32 = 1477,
	/// @brief @c VMAXSS xmm1, xmm2, xmm3/m32
	/// @par
	/// @c VEX.LIG.F3.0F.WIG 5F /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMAXSS_XMM_XMM_XMMM32 = 1478,
	/// @brief @c VMAXSS xmm1 {k1}{z}, xmm2, xmm3/m32{sae}
	/// @par
	/// @c EVEX.LIG.F3.0F.W0 5F /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMAXSS_XMM_K1Z_XMM_XMMM32_SAE = 1479,
	/// @brief @c MAXSD xmm1, xmm2/m64
	/// @par
	/// @c F2 0F 5F /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MAXSD_XMM_XMMM64 = 1480,
	/// @brief @c VMAXSD xmm1, xmm2, xmm3/m64
	/// @par
	/// @c VEX.LIG.F2.0F.WIG 5F /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMAXSD_XMM_XMM_XMMM64 = 1481,
	/// @brief @c VMAXSD xmm1 {k1}{z}, xmm2, xmm3/m64{sae}
	/// @par
	/// @c EVEX.LIG.F2.0F.W1 5F /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMAXSD_XMM_K1Z_XMM_XMMM64_SAE = 1482,
	/// @brief @c PUNPCKLBW mm, mm/m32
	/// @par
	/// @c NP 0F 60 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PUNPCKLBW_MM_MMM32 = 1483,
	/// @brief @c PUNPCKLBW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 60 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PUNPCKLBW_XMM_XMMM128 = 1484,
	/// @brief @c VPUNPCKLBW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 60 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPUNPCKLBW_XMM_XMM_XMMM128 = 1485,
	/// @brief @c VPUNPCKLBW ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 60 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPUNPCKLBW_YMM_YMM_YMMM256 = 1486,
	/// @brief @c VPUNPCKLBW xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG 60 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPUNPCKLBW_XMM_K1Z_XMM_XMMM128 = 1487,
	/// @brief @c VPUNPCKLBW ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG 60 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPUNPCKLBW_YMM_K1Z_YMM_YMMM256 = 1488,
	/// @brief @c VPUNPCKLBW zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG 60 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPUNPCKLBW_ZMM_K1Z_ZMM_ZMMM512 = 1489,
	/// @brief @c PUNPCKLWD mm, mm/m32
	/// @par
	/// @c NP 0F 61 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PUNPCKLWD_MM_MMM32 = 1490,
	/// @brief @c PUNPCKLWD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 61 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PUNPCKLWD_XMM_XMMM128 = 1491,
	/// @brief @c VPUNPCKLWD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 61 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPUNPCKLWD_XMM_XMM_XMMM128 = 1492,
	/// @brief @c VPUNPCKLWD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 61 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPUNPCKLWD_YMM_YMM_YMMM256 = 1493,
	/// @brief @c VPUNPCKLWD xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG 61 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPUNPCKLWD_XMM_K1Z_XMM_XMMM128 = 1494,
	/// @brief @c VPUNPCKLWD ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG 61 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPUNPCKLWD_YMM_K1Z_YMM_YMMM256 = 1495,
	/// @brief @c VPUNPCKLWD zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG 61 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPUNPCKLWD_ZMM_K1Z_ZMM_ZMMM512 = 1496,
	/// @brief @c PUNPCKLDQ mm, mm/m32
	/// @par
	/// @c NP 0F 62 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PUNPCKLDQ_MM_MMM32 = 1497,
	/// @brief @c PUNPCKLDQ xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 62 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PUNPCKLDQ_XMM_XMMM128 = 1498,
	/// @brief @c VPUNPCKLDQ xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 62 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPUNPCKLDQ_XMM_XMM_XMMM128 = 1499,
	/// @brief @c VPUNPCKLDQ ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 62 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPUNPCKLDQ_YMM_YMM_YMMM256 = 1500,
	/// @brief @c VPUNPCKLDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F.W0 62 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPUNPCKLDQ_XMM_K1Z_XMM_XMMM128B32 = 1501,
	/// @brief @c VPUNPCKLDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F.W0 62 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPUNPCKLDQ_YMM_K1Z_YMM_YMMM256B32 = 1502,
	/// @brief @c VPUNPCKLDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F.W0 62 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPUNPCKLDQ_ZMM_K1Z_ZMM_ZMMM512B32 = 1503,
	/// @brief @c PACKSSWB mm1, mm2/m64
	/// @par
	/// @c NP 0F 63 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PACKSSWB_MM_MMM64 = 1504,
	/// @brief @c PACKSSWB xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 63 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PACKSSWB_XMM_XMMM128 = 1505,
	/// @brief @c VPACKSSWB xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 63 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPACKSSWB_XMM_XMM_XMMM128 = 1506,
	/// @brief @c VPACKSSWB ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 63 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPACKSSWB_YMM_YMM_YMMM256 = 1507,
	/// @brief @c VPACKSSWB xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG 63 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPACKSSWB_XMM_K1Z_XMM_XMMM128 = 1508,
	/// @brief @c VPACKSSWB ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG 63 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPACKSSWB_YMM_K1Z_YMM_YMMM256 = 1509,
	/// @brief @c VPACKSSWB zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG 63 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPACKSSWB_ZMM_K1Z_ZMM_ZMMM512 = 1510,
	/// @brief @c PCMPGTB mm, mm/m64
	/// @par
	/// @c NP 0F 64 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PCMPGTB_MM_MMM64 = 1511,
	/// @brief @c PCMPGTB xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 64 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PCMPGTB_XMM_XMMM128 = 1512,
	/// @brief @c VPCMPGTB xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 64 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPCMPGTB_XMM_XMM_XMMM128 = 1513,
	/// @brief @c VPCMPGTB ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 64 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPCMPGTB_YMM_YMM_YMMM256 = 1514,
	/// @brief @c VPCMPGTB k1 {k2}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG 64 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPGTB_KR_K1_XMM_XMMM128 = 1515,
	/// @brief @c VPCMPGTB k1 {k2}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG 64 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPGTB_KR_K1_YMM_YMMM256 = 1516,
	/// @brief @c VPCMPGTB k1 {k2}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG 64 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPGTB_KR_K1_ZMM_ZMMM512 = 1517,
	/// @brief @c PCMPGTW mm, mm/m64
	/// @par
	/// @c NP 0F 65 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PCMPGTW_MM_MMM64 = 1518,
	/// @brief @c PCMPGTW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 65 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PCMPGTW_XMM_XMMM128 = 1519,
	/// @brief @c VPCMPGTW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 65 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPCMPGTW_XMM_XMM_XMMM128 = 1520,
	/// @brief @c VPCMPGTW ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 65 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPCMPGTW_YMM_YMM_YMMM256 = 1521,
	/// @brief @c VPCMPGTW k1 {k2}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG 65 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPGTW_KR_K1_XMM_XMMM128 = 1522,
	/// @brief @c VPCMPGTW k1 {k2}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG 65 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPGTW_KR_K1_YMM_YMMM256 = 1523,
	/// @brief @c VPCMPGTW k1 {k2}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG 65 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPGTW_KR_K1_ZMM_ZMMM512 = 1524,
	/// @brief @c PCMPGTD mm, mm/m64
	/// @par
	/// @c NP 0F 66 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PCMPGTD_MM_MMM64 = 1525,
	/// @brief @c PCMPGTD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 66 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PCMPGTD_XMM_XMMM128 = 1526,
	/// @brief @c VPCMPGTD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 66 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPCMPGTD_XMM_XMM_XMMM128 = 1527,
	/// @brief @c VPCMPGTD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 66 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPCMPGTD_YMM_YMM_YMMM256 = 1528,
	/// @brief @c VPCMPGTD k1 {k2}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F.W0 66 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPGTD_KR_K1_XMM_XMMM128B32 = 1529,
	/// @brief @c VPCMPGTD k1 {k2}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F.W0 66 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPGTD_KR_K1_YMM_YMMM256B32 = 1530,
	/// @brief @c VPCMPGTD k1 {k2}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F.W0 66 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPGTD_KR_K1_ZMM_ZMMM512B32 = 1531,
	/// @brief @c PACKUSWB mm, mm/m64
	/// @par
	/// @c NP 0F 67 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PACKUSWB_MM_MMM64 = 1532,
	/// @brief @c PACKUSWB xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 67 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PACKUSWB_XMM_XMMM128 = 1533,
	/// @brief @c VPACKUSWB xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 67 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPACKUSWB_XMM_XMM_XMMM128 = 1534,
	/// @brief @c VPACKUSWB ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 67 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPACKUSWB_YMM_YMM_YMMM256 = 1535,
	/// @brief @c VPACKUSWB xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG 67 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPACKUSWB_XMM_K1Z_XMM_XMMM128 = 1536,
	/// @brief @c VPACKUSWB ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG 67 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPACKUSWB_YMM_K1Z_YMM_YMMM256 = 1537,
	/// @brief @c VPACKUSWB zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG 67 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPACKUSWB_ZMM_K1Z_ZMM_ZMMM512 = 1538,
	/// @brief @c PUNPCKHBW mm, mm/m64
	/// @par
	/// @c NP 0F 68 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PUNPCKHBW_MM_MMM64 = 1539,
	/// @brief @c PUNPCKHBW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 68 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PUNPCKHBW_XMM_XMMM128 = 1540,
	/// @brief @c VPUNPCKHBW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 68 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPUNPCKHBW_XMM_XMM_XMMM128 = 1541,
	/// @brief @c VPUNPCKHBW ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 68 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPUNPCKHBW_YMM_YMM_YMMM256 = 1542,
	/// @brief @c VPUNPCKHBW xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG 68 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPUNPCKHBW_XMM_K1Z_XMM_XMMM128 = 1543,
	/// @brief @c VPUNPCKHBW ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG 68 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPUNPCKHBW_YMM_K1Z_YMM_YMMM256 = 1544,
	/// @brief @c VPUNPCKHBW zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG 68 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPUNPCKHBW_ZMM_K1Z_ZMM_ZMMM512 = 1545,
	/// @brief @c PUNPCKHWD mm, mm/m64
	/// @par
	/// @c NP 0F 69 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PUNPCKHWD_MM_MMM64 = 1546,
	/// @brief @c PUNPCKHWD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 69 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PUNPCKHWD_XMM_XMMM128 = 1547,
	/// @brief @c VPUNPCKHWD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 69 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPUNPCKHWD_XMM_XMM_XMMM128 = 1548,
	/// @brief @c VPUNPCKHWD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 69 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPUNPCKHWD_YMM_YMM_YMMM256 = 1549,
	/// @brief @c VPUNPCKHWD xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG 69 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPUNPCKHWD_XMM_K1Z_XMM_XMMM128 = 1550,
	/// @brief @c VPUNPCKHWD ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG 69 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPUNPCKHWD_YMM_K1Z_YMM_YMMM256 = 1551,
	/// @brief @c VPUNPCKHWD zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG 69 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPUNPCKHWD_ZMM_K1Z_ZMM_ZMMM512 = 1552,
	/// @brief @c PUNPCKHDQ mm, mm/m64
	/// @par
	/// @c NP 0F 6A /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PUNPCKHDQ_MM_MMM64 = 1553,
	/// @brief @c PUNPCKHDQ xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 6A /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PUNPCKHDQ_XMM_XMMM128 = 1554,
	/// @brief @c VPUNPCKHDQ xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 6A /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPUNPCKHDQ_XMM_XMM_XMMM128 = 1555,
	/// @brief @c VPUNPCKHDQ ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 6A /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPUNPCKHDQ_YMM_YMM_YMMM256 = 1556,
	/// @brief @c VPUNPCKHDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F.W0 6A /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPUNPCKHDQ_XMM_K1Z_XMM_XMMM128B32 = 1557,
	/// @brief @c VPUNPCKHDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F.W0 6A /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPUNPCKHDQ_YMM_K1Z_YMM_YMMM256B32 = 1558,
	/// @brief @c VPUNPCKHDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F.W0 6A /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPUNPCKHDQ_ZMM_K1Z_ZMM_ZMMM512B32 = 1559,
	/// @brief @c PACKSSDW mm1, mm2/m64
	/// @par
	/// @c NP 0F 6B /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PACKSSDW_MM_MMM64 = 1560,
	/// @brief @c PACKSSDW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 6B /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PACKSSDW_XMM_XMMM128 = 1561,
	/// @brief @c VPACKSSDW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 6B /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPACKSSDW_XMM_XMM_XMMM128 = 1562,
	/// @brief @c VPACKSSDW ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 6B /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPACKSSDW_YMM_YMM_YMMM256 = 1563,
	/// @brief @c VPACKSSDW xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F.W0 6B /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPACKSSDW_XMM_K1Z_XMM_XMMM128B32 = 1564,
	/// @brief @c VPACKSSDW ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F.W0 6B /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPACKSSDW_YMM_K1Z_YMM_YMMM256B32 = 1565,
	/// @brief @c VPACKSSDW zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F.W0 6B /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPACKSSDW_ZMM_K1Z_ZMM_ZMMM512B32 = 1566,
	/// @brief @c PUNPCKLQDQ xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 6C /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PUNPCKLQDQ_XMM_XMMM128 = 1567,
	/// @brief @c VPUNPCKLQDQ xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 6C /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPUNPCKLQDQ_XMM_XMM_XMMM128 = 1568,
	/// @brief @c VPUNPCKLQDQ ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 6C /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPUNPCKLQDQ_YMM_YMM_YMMM256 = 1569,
	/// @brief @c VPUNPCKLQDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F.W1 6C /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPUNPCKLQDQ_XMM_K1Z_XMM_XMMM128B64 = 1570,
	/// @brief @c VPUNPCKLQDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F.W1 6C /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPUNPCKLQDQ_YMM_K1Z_YMM_YMMM256B64 = 1571,
	/// @brief @c VPUNPCKLQDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F.W1 6C /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPUNPCKLQDQ_ZMM_K1Z_ZMM_ZMMM512B64 = 1572,
	/// @brief @c PUNPCKHQDQ xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 6D /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PUNPCKHQDQ_XMM_XMMM128 = 1573,
	/// @brief @c VPUNPCKHQDQ xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 6D /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPUNPCKHQDQ_XMM_XMM_XMMM128 = 1574,
	/// @brief @c VPUNPCKHQDQ ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 6D /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPUNPCKHQDQ_YMM_YMM_YMMM256 = 1575,
	/// @brief @c VPUNPCKHQDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F.W1 6D /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPUNPCKHQDQ_XMM_K1Z_XMM_XMMM128B64 = 1576,
	/// @brief @c VPUNPCKHQDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F.W1 6D /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPUNPCKHQDQ_YMM_K1Z_YMM_YMMM256B64 = 1577,
	/// @brief @c VPUNPCKHQDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F.W1 6D /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPUNPCKHQDQ_ZMM_K1Z_ZMM_ZMMM512B64 = 1578,
	/// @brief @c MOVD mm, r/m32
	/// @par
	/// @c NP 0F 6E /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	MOVD_MM_RM32 = 1579,
	/// @brief @c MOVQ mm, r/m64
	/// @par
	/// @c NP o64 0F 6E /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 64-bit
	MOVQ_MM_RM64 = 1580,
	/// @brief @c MOVD xmm, r/m32
	/// @par
	/// @c 66 0F 6E /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MOVD_XMM_RM32 = 1581,
	/// @brief @c MOVQ xmm, r/m64
	/// @par
	/// @c 66 o64 0F 6E /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 64-bit
	MOVQ_XMM_RM64 = 1582,
	/// @brief @c VMOVD xmm1, r/m32
	/// @par
	/// @c VEX.128.66.0F.W0 6E /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVD_XMM_RM32 = 1583,
	/// @brief @c VMOVQ xmm1, r/m64
	/// @par
	/// @c VEX.128.66.0F.W1 6E /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 64-bit
	VEX_VMOVQ_XMM_RM64 = 1584,
	/// @brief @c VMOVD xmm1, r/m32
	/// @par
	/// @c EVEX.128.66.0F.W0 6E /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVD_XMM_RM32 = 1585,
	/// @brief @c VMOVQ xmm1, r/m64
	/// @par
	/// @c EVEX.128.66.0F.W1 6E /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 64-bit
	EVEX_VMOVQ_XMM_RM64 = 1586,
	/// @brief @c MOVQ mm, mm/m64
	/// @par
	/// @c NP 0F 6F /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	MOVQ_MM_MMM64 = 1587,
	/// @brief @c MOVDQA xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 6F /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MOVDQA_XMM_XMMM128 = 1588,
	/// @brief @c VMOVDQA xmm1, xmm2/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 6F /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVDQA_XMM_XMMM128 = 1589,
	/// @brief @c VMOVDQA ymm1, ymm2/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 6F /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVDQA_YMM_YMMM256 = 1590,
	/// @brief @c VMOVDQA32 xmm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.128.66.0F.W0 6F /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQA32_XMM_K1Z_XMMM128 = 1591,
	/// @brief @c VMOVDQA32 ymm1 {k1}{z}, ymm2/m256
	/// @par
	/// @c EVEX.256.66.0F.W0 6F /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQA32_YMM_K1Z_YMMM256 = 1592,
	/// @brief @c VMOVDQA32 zmm1 {k1}{z}, zmm2/m512
	/// @par
	/// @c EVEX.512.66.0F.W0 6F /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQA32_ZMM_K1Z_ZMMM512 = 1593,
	/// @brief @c VMOVDQA64 xmm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.128.66.0F.W1 6F /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQA64_XMM_K1Z_XMMM128 = 1594,
	/// @brief @c VMOVDQA64 ymm1 {k1}{z}, ymm2/m256
	/// @par
	/// @c EVEX.256.66.0F.W1 6F /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQA64_YMM_K1Z_YMMM256 = 1595,
	/// @brief @c VMOVDQA64 zmm1 {k1}{z}, zmm2/m512
	/// @par
	/// @c EVEX.512.66.0F.W1 6F /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQA64_ZMM_K1Z_ZMMM512 = 1596,
	/// @brief @c MOVDQU xmm1, xmm2/m128
	/// @par
	/// @c F3 0F 6F /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MOVDQU_XMM_XMMM128 = 1597,
	/// @brief @c VMOVDQU xmm1, xmm2/m128
	/// @par
	/// @c VEX.128.F3.0F.WIG 6F /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVDQU_XMM_XMMM128 = 1598,
	/// @brief @c VMOVDQU ymm1, ymm2/m256
	/// @par
	/// @c VEX.256.F3.0F.WIG 6F /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVDQU_YMM_YMMM256 = 1599,
	/// @brief @c VMOVDQU32 xmm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.128.F3.0F.W0 6F /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQU32_XMM_K1Z_XMMM128 = 1600,
	/// @brief @c VMOVDQU32 ymm1 {k1}{z}, ymm2/m256
	/// @par
	/// @c EVEX.256.F3.0F.W0 6F /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQU32_YMM_K1Z_YMMM256 = 1601,
	/// @brief @c VMOVDQU32 zmm1 {k1}{z}, zmm2/m512
	/// @par
	/// @c EVEX.512.F3.0F.W0 6F /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQU32_ZMM_K1Z_ZMMM512 = 1602,
	/// @brief @c VMOVDQU64 xmm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.128.F3.0F.W1 6F /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQU64_XMM_K1Z_XMMM128 = 1603,
	/// @brief @c VMOVDQU64 ymm1 {k1}{z}, ymm2/m256
	/// @par
	/// @c EVEX.256.F3.0F.W1 6F /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQU64_YMM_K1Z_YMMM256 = 1604,
	/// @brief @c VMOVDQU64 zmm1 {k1}{z}, zmm2/m512
	/// @par
	/// @c EVEX.512.F3.0F.W1 6F /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQU64_ZMM_K1Z_ZMMM512 = 1605,
	/// @brief @c VMOVDQU8 xmm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.128.F2.0F.W0 6F /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQU8_XMM_K1Z_XMMM128 = 1606,
	/// @brief @c VMOVDQU8 ymm1 {k1}{z}, ymm2/m256
	/// @par
	/// @c EVEX.256.F2.0F.W0 6F /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQU8_YMM_K1Z_YMMM256 = 1607,
	/// @brief @c VMOVDQU8 zmm1 {k1}{z}, zmm2/m512
	/// @par
	/// @c EVEX.512.F2.0F.W0 6F /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQU8_ZMM_K1Z_ZMMM512 = 1608,
	/// @brief @c VMOVDQU16 xmm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.128.F2.0F.W1 6F /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQU16_XMM_K1Z_XMMM128 = 1609,
	/// @brief @c VMOVDQU16 ymm1 {k1}{z}, ymm2/m256
	/// @par
	/// @c EVEX.256.F2.0F.W1 6F /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQU16_YMM_K1Z_YMMM256 = 1610,
	/// @brief @c VMOVDQU16 zmm1 {k1}{z}, zmm2/m512
	/// @par
	/// @c EVEX.512.F2.0F.W1 6F /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQU16_ZMM_K1Z_ZMMM512 = 1611,
	/// @brief @c PSHUFW mm1, mm2/m64, imm8
	/// @par
	/// @c NP 0F 70 /r ib
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	PSHUFW_MM_MMM64_IMM8 = 1612,
	/// @brief @c PSHUFD xmm1, xmm2/m128, imm8
	/// @par
	/// @c 66 0F 70 /r ib
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSHUFD_XMM_XMMM128_IMM8 = 1613,
	/// @brief @c VPSHUFD xmm1, xmm2/m128, imm8
	/// @par
	/// @c VEX.128.66.0F.WIG 70 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSHUFD_XMM_XMMM128_IMM8 = 1614,
	/// @brief @c VPSHUFD ymm1, ymm2/m256, imm8
	/// @par
	/// @c VEX.256.66.0F.WIG 70 /r ib
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSHUFD_YMM_YMMM256_IMM8 = 1615,
	/// @brief @c VPSHUFD xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F.W0 70 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHUFD_XMM_K1Z_XMMM128B32_IMM8 = 1616,
	/// @brief @c VPSHUFD ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F.W0 70 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHUFD_YMM_K1Z_YMMM256B32_IMM8 = 1617,
	/// @brief @c VPSHUFD zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F.W0 70 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHUFD_ZMM_K1Z_ZMMM512B32_IMM8 = 1618,
	/// @brief @c PSHUFHW xmm1, xmm2/m128, imm8
	/// @par
	/// @c F3 0F 70 /r ib
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSHUFHW_XMM_XMMM128_IMM8 = 1619,
	/// @brief @c VPSHUFHW xmm1, xmm2/m128, imm8
	/// @par
	/// @c VEX.128.F3.0F.WIG 70 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSHUFHW_XMM_XMMM128_IMM8 = 1620,
	/// @brief @c VPSHUFHW ymm1, ymm2/m256, imm8
	/// @par
	/// @c VEX.256.F3.0F.WIG 70 /r ib
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSHUFHW_YMM_YMMM256_IMM8 = 1621,
	/// @brief @c VPSHUFHW xmm1 {k1}{z}, xmm2/m128, imm8
	/// @par
	/// @c EVEX.128.F3.0F.WIG 70 /r ib
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHUFHW_XMM_K1Z_XMMM128_IMM8 = 1622,
	/// @brief @c VPSHUFHW ymm1 {k1}{z}, ymm2/m256, imm8
	/// @par
	/// @c EVEX.256.F3.0F.WIG 70 /r ib
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHUFHW_YMM_K1Z_YMMM256_IMM8 = 1623,
	/// @brief @c VPSHUFHW zmm1 {k1}{z}, zmm2/m512, imm8
	/// @par
	/// @c EVEX.512.F3.0F.WIG 70 /r ib
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHUFHW_ZMM_K1Z_ZMMM512_IMM8 = 1624,
	/// @brief @c PSHUFLW xmm1, xmm2/m128, imm8
	/// @par
	/// @c F2 0F 70 /r ib
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSHUFLW_XMM_XMMM128_IMM8 = 1625,
	/// @brief @c VPSHUFLW xmm1, xmm2/m128, imm8
	/// @par
	/// @c VEX.128.F2.0F.WIG 70 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSHUFLW_XMM_XMMM128_IMM8 = 1626,
	/// @brief @c VPSHUFLW ymm1, ymm2/m256, imm8
	/// @par
	/// @c VEX.256.F2.0F.WIG 70 /r ib
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSHUFLW_YMM_YMMM256_IMM8 = 1627,
	/// @brief @c VPSHUFLW xmm1 {k1}{z}, xmm2/m128, imm8
	/// @par
	/// @c EVEX.128.F2.0F.WIG 70 /r ib
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHUFLW_XMM_K1Z_XMMM128_IMM8 = 1628,
	/// @brief @c VPSHUFLW ymm1 {k1}{z}, ymm2/m256, imm8
	/// @par
	/// @c EVEX.256.F2.0F.WIG 70 /r ib
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHUFLW_YMM_K1Z_YMMM256_IMM8 = 1629,
	/// @brief @c VPSHUFLW zmm1 {k1}{z}, zmm2/m512, imm8
	/// @par
	/// @c EVEX.512.F2.0F.WIG 70 /r ib
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHUFLW_ZMM_K1Z_ZMMM512_IMM8 = 1630,
	/// @brief @c PSRLW mm, imm8
	/// @par
	/// @c NP 0F 71 /2 ib
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PSRLW_MM_IMM8 = 1631,
	/// @brief @c PSRLW xmm1, imm8
	/// @par
	/// @c 66 0F 71 /2 ib
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSRLW_XMM_IMM8 = 1632,
	/// @brief @c VPSRLW xmm1, xmm2, imm8
	/// @par
	/// @c VEX.128.66.0F.WIG 71 /2 ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSRLW_XMM_XMM_IMM8 = 1633,
	/// @brief @c VPSRLW ymm1, ymm2, imm8
	/// @par
	/// @c VEX.256.66.0F.WIG 71 /2 ib
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSRLW_YMM_YMM_IMM8 = 1634,
	/// @brief @c VPSRLW xmm1 {k1}{z}, xmm2/m128, imm8
	/// @par
	/// @c EVEX.128.66.0F.WIG 71 /2 ib
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRLW_XMM_K1Z_XMMM128_IMM8 = 1635,
	/// @brief @c VPSRLW ymm1 {k1}{z}, ymm2/m256, imm8
	/// @par
	/// @c EVEX.256.66.0F.WIG 71 /2 ib
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRLW_YMM_K1Z_YMMM256_IMM8 = 1636,
	/// @brief @c VPSRLW zmm1 {k1}{z}, zmm2/m512, imm8
	/// @par
	/// @c EVEX.512.66.0F.WIG 71 /2 ib
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRLW_ZMM_K1Z_ZMMM512_IMM8 = 1637,
	/// @brief @c PSRAW mm, imm8
	/// @par
	/// @c NP 0F 71 /4 ib
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PSRAW_MM_IMM8 = 1638,
	/// @brief @c PSRAW xmm1, imm8
	/// @par
	/// @c 66 0F 71 /4 ib
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSRAW_XMM_IMM8 = 1639,
	/// @brief @c VPSRAW xmm1, xmm2, imm8
	/// @par
	/// @c VEX.128.66.0F.WIG 71 /4 ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSRAW_XMM_XMM_IMM8 = 1640,
	/// @brief @c VPSRAW ymm1, ymm2, imm8
	/// @par
	/// @c VEX.256.66.0F.WIG 71 /4 ib
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSRAW_YMM_YMM_IMM8 = 1641,
	/// @brief @c VPSRAW xmm1 {k1}{z}, xmm2/m128, imm8
	/// @par
	/// @c EVEX.128.66.0F.WIG 71 /4 ib
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRAW_XMM_K1Z_XMMM128_IMM8 = 1642,
	/// @brief @c VPSRAW ymm1 {k1}{z}, ymm2/m256, imm8
	/// @par
	/// @c EVEX.256.66.0F.WIG 71 /4 ib
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRAW_YMM_K1Z_YMMM256_IMM8 = 1643,
	/// @brief @c VPSRAW zmm1 {k1}{z}, zmm2/m512, imm8
	/// @par
	/// @c EVEX.512.66.0F.WIG 71 /4 ib
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRAW_ZMM_K1Z_ZMMM512_IMM8 = 1644,
	/// @brief @c PSLLW mm1, imm8
	/// @par
	/// @c NP 0F 71 /6 ib
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PSLLW_MM_IMM8 = 1645,
	/// @brief @c PSLLW xmm1, imm8
	/// @par
	/// @c 66 0F 71 /6 ib
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSLLW_XMM_IMM8 = 1646,
	/// @brief @c VPSLLW xmm1, xmm2, imm8
	/// @par
	/// @c VEX.128.66.0F.WIG 71 /6 ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSLLW_XMM_XMM_IMM8 = 1647,
	/// @brief @c VPSLLW ymm1, ymm2, imm8
	/// @par
	/// @c VEX.256.66.0F.WIG 71 /6 ib
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSLLW_YMM_YMM_IMM8 = 1648,
	/// @brief @c VPSLLW xmm1 {k1}{z}, xmm2/m128, imm8
	/// @par
	/// @c EVEX.128.66.0F.WIG 71 /6 ib
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSLLW_XMM_K1Z_XMMM128_IMM8 = 1649,
	/// @brief @c VPSLLW ymm1 {k1}{z}, ymm2/m256, imm8
	/// @par
	/// @c EVEX.256.66.0F.WIG 71 /6 ib
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSLLW_YMM_K1Z_YMMM256_IMM8 = 1650,
	/// @brief @c VPSLLW zmm1 {k1}{z}, zmm2/m512, imm8
	/// @par
	/// @c EVEX.512.66.0F.WIG 71 /6 ib
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSLLW_ZMM_K1Z_ZMMM512_IMM8 = 1651,
	/// @brief @c VPRORD xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F.W0 72 /0 ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPRORD_XMM_K1Z_XMMM128B32_IMM8 = 1652,
	/// @brief @c VPRORD ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F.W0 72 /0 ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPRORD_YMM_K1Z_YMMM256B32_IMM8 = 1653,
	/// @brief @c VPRORD zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F.W0 72 /0 ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPRORD_ZMM_K1Z_ZMMM512B32_IMM8 = 1654,
	/// @brief @c VPRORQ xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F.W1 72 /0 ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPRORQ_XMM_K1Z_XMMM128B64_IMM8 = 1655,
	/// @brief @c VPRORQ ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F.W1 72 /0 ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPRORQ_YMM_K1Z_YMMM256B64_IMM8 = 1656,
	/// @brief @c VPRORQ zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F.W1 72 /0 ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPRORQ_ZMM_K1Z_ZMMM512B64_IMM8 = 1657,
	/// @brief @c VPROLD xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F.W0 72 /1 ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPROLD_XMM_K1Z_XMMM128B32_IMM8 = 1658,
	/// @brief @c VPROLD ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F.W0 72 /1 ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPROLD_YMM_K1Z_YMMM256B32_IMM8 = 1659,
	/// @brief @c VPROLD zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F.W0 72 /1 ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPROLD_ZMM_K1Z_ZMMM512B32_IMM8 = 1660,
	/// @brief @c VPROLQ xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F.W1 72 /1 ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPROLQ_XMM_K1Z_XMMM128B64_IMM8 = 1661,
	/// @brief @c VPROLQ ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F.W1 72 /1 ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPROLQ_YMM_K1Z_YMMM256B64_IMM8 = 1662,
	/// @brief @c VPROLQ zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F.W1 72 /1 ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPROLQ_ZMM_K1Z_ZMMM512B64_IMM8 = 1663,
	/// @brief @c PSRLD mm, imm8
	/// @par
	/// @c NP 0F 72 /2 ib
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PSRLD_MM_IMM8 = 1664,
	/// @brief @c PSRLD xmm1, imm8
	/// @par
	/// @c 66 0F 72 /2 ib
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSRLD_XMM_IMM8 = 1665,
	/// @brief @c VPSRLD xmm1, xmm2, imm8
	/// @par
	/// @c VEX.128.66.0F.WIG 72 /2 ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSRLD_XMM_XMM_IMM8 = 1666,
	/// @brief @c VPSRLD ymm1, ymm2, imm8
	/// @par
	/// @c VEX.256.66.0F.WIG 72 /2 ib
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSRLD_YMM_YMM_IMM8 = 1667,
	/// @brief @c VPSRLD xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F.W0 72 /2 ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRLD_XMM_K1Z_XMMM128B32_IMM8 = 1668,
	/// @brief @c VPSRLD ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F.W0 72 /2 ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRLD_YMM_K1Z_YMMM256B32_IMM8 = 1669,
	/// @brief @c VPSRLD zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F.W0 72 /2 ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRLD_ZMM_K1Z_ZMMM512B32_IMM8 = 1670,
	/// @brief @c PSRAD mm, imm8
	/// @par
	/// @c NP 0F 72 /4 ib
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PSRAD_MM_IMM8 = 1671,
	/// @brief @c PSRAD xmm1, imm8
	/// @par
	/// @c 66 0F 72 /4 ib
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSRAD_XMM_IMM8 = 1672,
	/// @brief @c VPSRAD xmm1, xmm2, imm8
	/// @par
	/// @c VEX.128.66.0F.WIG 72 /4 ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSRAD_XMM_XMM_IMM8 = 1673,
	/// @brief @c VPSRAD ymm1, ymm2, imm8
	/// @par
	/// @c VEX.256.66.0F.WIG 72 /4 ib
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSRAD_YMM_YMM_IMM8 = 1674,
	/// @brief @c VPSRAD xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F.W0 72 /4 ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRAD_XMM_K1Z_XMMM128B32_IMM8 = 1675,
	/// @brief @c VPSRAD ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F.W0 72 /4 ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRAD_YMM_K1Z_YMMM256B32_IMM8 = 1676,
	/// @brief @c VPSRAD zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F.W0 72 /4 ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRAD_ZMM_K1Z_ZMMM512B32_IMM8 = 1677,
	/// @brief @c VPSRAQ xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F.W1 72 /4 ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRAQ_XMM_K1Z_XMMM128B64_IMM8 = 1678,
	/// @brief @c VPSRAQ ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F.W1 72 /4 ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRAQ_YMM_K1Z_YMMM256B64_IMM8 = 1679,
	/// @brief @c VPSRAQ zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F.W1 72 /4 ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRAQ_ZMM_K1Z_ZMMM512B64_IMM8 = 1680,
	/// @brief @c PSLLD mm, imm8
	/// @par
	/// @c NP 0F 72 /6 ib
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PSLLD_MM_IMM8 = 1681,
	/// @brief @c PSLLD xmm1, imm8
	/// @par
	/// @c 66 0F 72 /6 ib
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSLLD_XMM_IMM8 = 1682,
	/// @brief @c VPSLLD xmm1, xmm2, imm8
	/// @par
	/// @c VEX.128.66.0F.WIG 72 /6 ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSLLD_XMM_XMM_IMM8 = 1683,
	/// @brief @c VPSLLD ymm1, ymm2, imm8
	/// @par
	/// @c VEX.256.66.0F.WIG 72 /6 ib
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSLLD_YMM_YMM_IMM8 = 1684,
	/// @brief @c VPSLLD xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F.W0 72 /6 ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSLLD_XMM_K1Z_XMMM128B32_IMM8 = 1685,
	/// @brief @c VPSLLD ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F.W0 72 /6 ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSLLD_YMM_K1Z_YMMM256B32_IMM8 = 1686,
	/// @brief @c VPSLLD zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F.W0 72 /6 ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSLLD_ZMM_K1Z_ZMMM512B32_IMM8 = 1687,
	/// @brief @c PSRLQ mm, imm8
	/// @par
	/// @c NP 0F 73 /2 ib
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PSRLQ_MM_IMM8 = 1688,
	/// @brief @c PSRLQ xmm1, imm8
	/// @par
	/// @c 66 0F 73 /2 ib
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSRLQ_XMM_IMM8 = 1689,
	/// @brief @c VPSRLQ xmm1, xmm2, imm8
	/// @par
	/// @c VEX.128.66.0F.WIG 73 /2 ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSRLQ_XMM_XMM_IMM8 = 1690,
	/// @brief @c VPSRLQ ymm1, ymm2, imm8
	/// @par
	/// @c VEX.256.66.0F.WIG 73 /2 ib
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSRLQ_YMM_YMM_IMM8 = 1691,
	/// @brief @c VPSRLQ xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F.W1 73 /2 ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRLQ_XMM_K1Z_XMMM128B64_IMM8 = 1692,
	/// @brief @c VPSRLQ ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F.W1 73 /2 ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRLQ_YMM_K1Z_YMMM256B64_IMM8 = 1693,
	/// @brief @c VPSRLQ zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F.W1 73 /2 ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRLQ_ZMM_K1Z_ZMMM512B64_IMM8 = 1694,
	/// @brief @c PSRLDQ xmm1, imm8
	/// @par
	/// @c 66 0F 73 /3 ib
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSRLDQ_XMM_IMM8 = 1695,
	/// @brief @c VPSRLDQ xmm1, xmm2, imm8
	/// @par
	/// @c VEX.128.66.0F.WIG 73 /3 ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSRLDQ_XMM_XMM_IMM8 = 1696,
	/// @brief @c VPSRLDQ ymm1, ymm2, imm8
	/// @par
	/// @c VEX.256.66.0F.WIG 73 /3 ib
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSRLDQ_YMM_YMM_IMM8 = 1697,
	/// @brief @c VPSRLDQ xmm1, xmm2/m128, imm8
	/// @par
	/// @c EVEX.128.66.0F.WIG 73 /3 ib
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRLDQ_XMM_XMMM128_IMM8 = 1698,
	/// @brief @c VPSRLDQ ymm1, ymm2/m256, imm8
	/// @par
	/// @c EVEX.256.66.0F.WIG 73 /3 ib
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRLDQ_YMM_YMMM256_IMM8 = 1699,
	/// @brief @c VPSRLDQ zmm1, zmm2/m512, imm8
	/// @par
	/// @c EVEX.512.66.0F.WIG 73 /3 ib
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRLDQ_ZMM_ZMMM512_IMM8 = 1700,
	/// @brief @c PSLLQ mm, imm8
	/// @par
	/// @c NP 0F 73 /6 ib
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PSLLQ_MM_IMM8 = 1701,
	/// @brief @c PSLLQ xmm1, imm8
	/// @par
	/// @c 66 0F 73 /6 ib
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSLLQ_XMM_IMM8 = 1702,
	/// @brief @c VPSLLQ xmm1, xmm2, imm8
	/// @par
	/// @c VEX.128.66.0F.WIG 73 /6 ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSLLQ_XMM_XMM_IMM8 = 1703,
	/// @brief @c VPSLLQ ymm1, ymm2, imm8
	/// @par
	/// @c VEX.256.66.0F.WIG 73 /6 ib
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSLLQ_YMM_YMM_IMM8 = 1704,
	/// @brief @c VPSLLQ xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F.W1 73 /6 ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSLLQ_XMM_K1Z_XMMM128B64_IMM8 = 1705,
	/// @brief @c VPSLLQ ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F.W1 73 /6 ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSLLQ_YMM_K1Z_YMMM256B64_IMM8 = 1706,
	/// @brief @c VPSLLQ zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F.W1 73 /6 ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSLLQ_ZMM_K1Z_ZMMM512B64_IMM8 = 1707,
	/// @brief @c PSLLDQ xmm1, imm8
	/// @par
	/// @c 66 0F 73 /7 ib
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSLLDQ_XMM_IMM8 = 1708,
	/// @brief @c VPSLLDQ xmm1, xmm2, imm8
	/// @par
	/// @c VEX.128.66.0F.WIG 73 /7 ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSLLDQ_XMM_XMM_IMM8 = 1709,
	/// @brief @c VPSLLDQ ymm1, ymm2, imm8
	/// @par
	/// @c VEX.256.66.0F.WIG 73 /7 ib
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSLLDQ_YMM_YMM_IMM8 = 1710,
	/// @brief @c VPSLLDQ xmm1, xmm2/m128, imm8
	/// @par
	/// @c EVEX.128.66.0F.WIG 73 /7 ib
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSLLDQ_XMM_XMMM128_IMM8 = 1711,
	/// @brief @c VPSLLDQ ymm1, ymm2/m256, imm8
	/// @par
	/// @c EVEX.256.66.0F.WIG 73 /7 ib
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSLLDQ_YMM_YMMM256_IMM8 = 1712,
	/// @brief @c VPSLLDQ zmm1, zmm2/m512, imm8
	/// @par
	/// @c EVEX.512.66.0F.WIG 73 /7 ib
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSLLDQ_ZMM_ZMMM512_IMM8 = 1713,
	/// @brief @c PCMPEQB mm, mm/m64
	/// @par
	/// @c NP 0F 74 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PCMPEQB_MM_MMM64 = 1714,
	/// @brief @c PCMPEQB xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 74 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PCMPEQB_XMM_XMMM128 = 1715,
	/// @brief @c VPCMPEQB xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 74 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPCMPEQB_XMM_XMM_XMMM128 = 1716,
	/// @brief @c VPCMPEQB ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 74 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPCMPEQB_YMM_YMM_YMMM256 = 1717,
	/// @brief @c VPCMPEQB k1 {k2}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG 74 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPEQB_KR_K1_XMM_XMMM128 = 1718,
	/// @brief @c VPCMPEQB k1 {k2}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG 74 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPEQB_KR_K1_YMM_YMMM256 = 1719,
	/// @brief @c VPCMPEQB k1 {k2}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG 74 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPEQB_KR_K1_ZMM_ZMMM512 = 1720,
	/// @brief @c PCMPEQW mm, mm/m64
	/// @par
	/// @c NP 0F 75 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PCMPEQW_MM_MMM64 = 1721,
	/// @brief @c PCMPEQW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 75 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PCMPEQW_XMM_XMMM128 = 1722,
	/// @brief @c VPCMPEQW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 75 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPCMPEQW_XMM_XMM_XMMM128 = 1723,
	/// @brief @c VPCMPEQW ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 75 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPCMPEQW_YMM_YMM_YMMM256 = 1724,
	/// @brief @c VPCMPEQW k1 {k2}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG 75 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPEQW_KR_K1_XMM_XMMM128 = 1725,
	/// @brief @c VPCMPEQW k1 {k2}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG 75 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPEQW_KR_K1_YMM_YMMM256 = 1726,
	/// @brief @c VPCMPEQW k1 {k2}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG 75 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPEQW_KR_K1_ZMM_ZMMM512 = 1727,
	/// @brief @c PCMPEQD mm, mm/m64
	/// @par
	/// @c NP 0F 76 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PCMPEQD_MM_MMM64 = 1728,
	/// @brief @c PCMPEQD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 76 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PCMPEQD_XMM_XMMM128 = 1729,
	/// @brief @c VPCMPEQD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 76 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPCMPEQD_XMM_XMM_XMMM128 = 1730,
	/// @brief @c VPCMPEQD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 76 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPCMPEQD_YMM_YMM_YMMM256 = 1731,
	/// @brief @c VPCMPEQD k1 {k2}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F.W0 76 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPEQD_KR_K1_XMM_XMMM128B32 = 1732,
	/// @brief @c VPCMPEQD k1 {k2}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F.W0 76 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPEQD_KR_K1_YMM_YMMM256B32 = 1733,
	/// @brief @c VPCMPEQD k1 {k2}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F.W0 76 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPEQD_KR_K1_ZMM_ZMMM512B32 = 1734,
	/// @brief @c EMMS
	/// @par
	/// @c NP 0F 77
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	EMMS = 1735,
	/// @brief @c VZEROUPPER
	/// @par
	/// @c VEX.128.0F.WIG 77
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VZEROUPPER = 1736,
	/// @brief @c VZEROALL
	/// @par
	/// @c VEX.256.0F.WIG 77
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VZEROALL = 1737,
	/// @brief @c VMREAD r/m32, r32
	/// @par
	/// @c NP 0F 78 /r
	/// @par
	/// @c VMX
	/// @par
	/// @c 16/32-bit
	VMREAD_RM32_R32 = 1738,
	/// @brief @c VMREAD r/m64, r64
	/// @par
	/// @c NP 0F 78 /r
	/// @par
	/// @c VMX
	/// @par
	/// @c 64-bit
	VMREAD_RM64_R64 = 1739,
	/// @brief @c VCVTTPS2UDQ xmm1 {k1}{z}, xmm2/m128/m32bcst
	/// @par
	/// @c EVEX.128.0F.W0 78 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPS2UDQ_XMM_K1Z_XMMM128B32 = 1740,
	/// @brief @c VCVTTPS2UDQ ymm1 {k1}{z}, ymm2/m256/m32bcst
	/// @par
	/// @c EVEX.256.0F.W0 78 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPS2UDQ_YMM_K1Z_YMMM256B32 = 1741,
	/// @brief @c VCVTTPS2UDQ zmm1 {k1}{z}, zmm2/m512/m32bcst{sae}
	/// @par
	/// @c EVEX.512.0F.W0 78 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPS2UDQ_ZMM_K1Z_ZMMM512B32_SAE = 1742,
	/// @brief @c VCVTTPD2UDQ xmm1 {k1}{z}, xmm2/m128/m64bcst
	/// @par
	/// @c EVEX.128.0F.W1 78 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPD2UDQ_XMM_K1Z_XMMM128B64 = 1743,
	/// @brief @c VCVTTPD2UDQ xmm1 {k1}{z}, ymm2/m256/m64bcst
	/// @par
	/// @c EVEX.256.0F.W1 78 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPD2UDQ_XMM_K1Z_YMMM256B64 = 1744,
	/// @brief @c VCVTTPD2UDQ ymm1 {k1}{z}, zmm2/m512/m64bcst{sae}
	/// @par
	/// @c EVEX.512.0F.W1 78 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPD2UDQ_YMM_K1Z_ZMMM512B64_SAE = 1745,
	/// @brief @c EXTRQ xmm1, imm8, imm8
	/// @par
	/// @c 66 0F 78 /0 ib ib
	/// @par
	/// @c SSE4A
	/// @par
	/// @c 16/32/64-bit
	EXTRQ_XMM_IMM8_IMM8 = 1746,
	/// @brief @c VCVTTPS2UQQ xmm1 {k1}{z}, xmm2/m64/m32bcst
	/// @par
	/// @c EVEX.128.66.0F.W0 78 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPS2UQQ_XMM_K1Z_XMMM64B32 = 1747,
	/// @brief @c VCVTTPS2UQQ ymm1 {k1}{z}, xmm2/m128/m32bcst
	/// @par
	/// @c EVEX.256.66.0F.W0 78 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPS2UQQ_YMM_K1Z_XMMM128B32 = 1748,
	/// @brief @c VCVTTPS2UQQ zmm1 {k1}{z}, ymm2/m256/m32bcst{sae}
	/// @par
	/// @c EVEX.512.66.0F.W0 78 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPS2UQQ_ZMM_K1Z_YMMM256B32_SAE = 1749,
	/// @brief @c VCVTTPD2UQQ xmm1 {k1}{z}, xmm2/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F.W1 78 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPD2UQQ_XMM_K1Z_XMMM128B64 = 1750,
	/// @brief @c VCVTTPD2UQQ ymm1 {k1}{z}, ymm2/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F.W1 78 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPD2UQQ_YMM_K1Z_YMMM256B64 = 1751,
	/// @brief @c VCVTTPD2UQQ zmm1 {k1}{z}, zmm2/m512/m64bcst{sae}
	/// @par
	/// @c EVEX.512.66.0F.W1 78 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPD2UQQ_ZMM_K1Z_ZMMM512B64_SAE = 1752,
	/// @brief @c VCVTTSS2USI r32, xmm1/m32{sae}
	/// @par
	/// @c EVEX.LIG.F3.0F.W0 78 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTSS2USI_R32_XMMM32_SAE = 1753,
	/// @brief @c VCVTTSS2USI r64, xmm1/m32{sae}
	/// @par
	/// @c EVEX.LIG.F3.0F.W1 78 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 64-bit
	EVEX_VCVTTSS2USI_R64_XMMM32_SAE = 1754,
	/// @brief @c INSERTQ xmm1, xmm2, imm8, imm8
	/// @par
	/// @c F2 0F 78 /r ib ib
	/// @par
	/// @c SSE4A
	/// @par
	/// @c 16/32/64-bit
	INSERTQ_XMM_XMM_IMM8_IMM8 = 1755,
	/// @brief @c VCVTTSD2USI r32, xmm1/m64{sae}
	/// @par
	/// @c EVEX.LIG.F2.0F.W0 78 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTSD2USI_R32_XMMM64_SAE = 1756,
	/// @brief @c VCVTTSD2USI r64, xmm1/m64{sae}
	/// @par
	/// @c EVEX.LIG.F2.0F.W1 78 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 64-bit
	EVEX_VCVTTSD2USI_R64_XMMM64_SAE = 1757,
	/// @brief @c VMWRITE r32, r/m32
	/// @par
	/// @c NP 0F 79 /r
	/// @par
	/// @c VMX
	/// @par
	/// @c 16/32-bit
	VMWRITE_R32_RM32 = 1758,
	/// @brief @c VMWRITE r64, r/m64
	/// @par
	/// @c NP 0F 79 /r
	/// @par
	/// @c VMX
	/// @par
	/// @c 64-bit
	VMWRITE_R64_RM64 = 1759,
	/// @brief @c VCVTPS2UDQ xmm1 {k1}{z}, xmm2/m128/m32bcst
	/// @par
	/// @c EVEX.128.0F.W0 79 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPS2UDQ_XMM_K1Z_XMMM128B32 = 1760,
	/// @brief @c VCVTPS2UDQ ymm1 {k1}{z}, ymm2/m256/m32bcst
	/// @par
	/// @c EVEX.256.0F.W0 79 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPS2UDQ_YMM_K1Z_YMMM256B32 = 1761,
	/// @brief @c VCVTPS2UDQ zmm1 {k1}{z}, zmm2/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.0F.W0 79 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPS2UDQ_ZMM_K1Z_ZMMM512B32_ER = 1762,
	/// @brief @c VCVTPD2UDQ xmm1 {k1}{z}, xmm2/m128/m64bcst
	/// @par
	/// @c EVEX.128.0F.W1 79 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPD2UDQ_XMM_K1Z_XMMM128B64 = 1763,
	/// @brief @c VCVTPD2UDQ xmm1 {k1}{z}, ymm2/m256/m64bcst
	/// @par
	/// @c EVEX.256.0F.W1 79 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPD2UDQ_XMM_K1Z_YMMM256B64 = 1764,
	/// @brief @c VCVTPD2UDQ ymm1 {k1}{z}, zmm2/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.0F.W1 79 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPD2UDQ_YMM_K1Z_ZMMM512B64_ER = 1765,
	/// @brief @c EXTRQ xmm1, xmm2
	/// @par
	/// @c 66 0F 79 /r
	/// @par
	/// @c SSE4A
	/// @par
	/// @c 16/32/64-bit
	EXTRQ_XMM_XMM = 1766,
	/// @brief @c VCVTPS2UQQ xmm1 {k1}{z}, xmm2/m64/m32bcst
	/// @par
	/// @c EVEX.128.66.0F.W0 79 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPS2UQQ_XMM_K1Z_XMMM64B32 = 1767,
	/// @brief @c VCVTPS2UQQ ymm1 {k1}{z}, xmm2/m128/m32bcst
	/// @par
	/// @c EVEX.256.66.0F.W0 79 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPS2UQQ_YMM_K1Z_XMMM128B32 = 1768,
	/// @brief @c VCVTPS2UQQ zmm1 {k1}{z}, ymm2/m256/m32bcst{er}
	/// @par
	/// @c EVEX.512.66.0F.W0 79 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPS2UQQ_ZMM_K1Z_YMMM256B32_ER = 1769,
	/// @brief @c VCVTPD2UQQ xmm1 {k1}{z}, xmm2/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F.W1 79 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPD2UQQ_XMM_K1Z_XMMM128B64 = 1770,
	/// @brief @c VCVTPD2UQQ ymm1 {k1}{z}, ymm2/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F.W1 79 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPD2UQQ_YMM_K1Z_YMMM256B64 = 1771,
	/// @brief @c VCVTPD2UQQ zmm1 {k1}{z}, zmm2/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.66.0F.W1 79 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPD2UQQ_ZMM_K1Z_ZMMM512B64_ER = 1772,
	/// @brief @c VCVTSS2USI r32, xmm1/m32{er}
	/// @par
	/// @c EVEX.LIG.F3.0F.W0 79 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTSS2USI_R32_XMMM32_ER = 1773,
	/// @brief @c VCVTSS2USI r64, xmm1/m32{er}
	/// @par
	/// @c EVEX.LIG.F3.0F.W1 79 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 64-bit
	EVEX_VCVTSS2USI_R64_XMMM32_ER = 1774,
	/// @brief @c INSERTQ xmm1, xmm2
	/// @par
	/// @c F2 0F 79 /r
	/// @par
	/// @c SSE4A
	/// @par
	/// @c 16/32/64-bit
	INSERTQ_XMM_XMM = 1775,
	/// @brief @c VCVTSD2USI r32, xmm1/m64{er}
	/// @par
	/// @c EVEX.LIG.F2.0F.W0 79 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTSD2USI_R32_XMMM64_ER = 1776,
	/// @brief @c VCVTSD2USI r64, xmm1/m64{er}
	/// @par
	/// @c EVEX.LIG.F2.0F.W1 79 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 64-bit
	EVEX_VCVTSD2USI_R64_XMMM64_ER = 1777,
	/// @brief @c VCVTTPS2QQ xmm1 {k1}{z}, xmm2/m64/m32bcst
	/// @par
	/// @c EVEX.128.66.0F.W0 7A /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPS2QQ_XMM_K1Z_XMMM64B32 = 1778,
	/// @brief @c VCVTTPS2QQ ymm1 {k1}{z}, xmm2/m128/m32bcst
	/// @par
	/// @c EVEX.256.66.0F.W0 7A /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPS2QQ_YMM_K1Z_XMMM128B32 = 1779,
	/// @brief @c VCVTTPS2QQ zmm1 {k1}{z}, ymm2/m256/m32bcst{sae}
	/// @par
	/// @c EVEX.512.66.0F.W0 7A /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPS2QQ_ZMM_K1Z_YMMM256B32_SAE = 1780,
	/// @brief @c VCVTTPD2QQ xmm1 {k1}{z}, xmm2/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F.W1 7A /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPD2QQ_XMM_K1Z_XMMM128B64 = 1781,
	/// @brief @c VCVTTPD2QQ ymm1 {k1}{z}, ymm2/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F.W1 7A /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPD2QQ_YMM_K1Z_YMMM256B64 = 1782,
	/// @brief @c VCVTTPD2QQ zmm1 {k1}{z}, zmm2/m512/m64bcst{sae}
	/// @par
	/// @c EVEX.512.66.0F.W1 7A /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPD2QQ_ZMM_K1Z_ZMMM512B64_SAE = 1783,
	/// @brief @c VCVTUDQ2PD xmm1 {k1}{z}, xmm2/m64/m32bcst
	/// @par
	/// @c EVEX.128.F3.0F.W0 7A /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTUDQ2PD_XMM_K1Z_XMMM64B32 = 1784,
	/// @brief @c VCVTUDQ2PD ymm1 {k1}{z}, xmm2/m128/m32bcst
	/// @par
	/// @c EVEX.256.F3.0F.W0 7A /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTUDQ2PD_YMM_K1Z_XMMM128B32 = 1785,
	/// @brief @c VCVTUDQ2PD zmm1 {k1}{z}, ymm2/m256/m32bcst{er}
	/// @par
	/// @c EVEX.512.F3.0F.W0 7A /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTUDQ2PD_ZMM_K1Z_YMMM256B32_ER = 1786,
	/// @brief @c VCVTUQQ2PD xmm1 {k1}{z}, xmm2/m128/m64bcst
	/// @par
	/// @c EVEX.128.F3.0F.W1 7A /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTUQQ2PD_XMM_K1Z_XMMM128B64 = 1787,
	/// @brief @c VCVTUQQ2PD ymm1 {k1}{z}, ymm2/m256/m64bcst
	/// @par
	/// @c EVEX.256.F3.0F.W1 7A /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTUQQ2PD_YMM_K1Z_YMMM256B64 = 1788,
	/// @brief @c VCVTUQQ2PD zmm1 {k1}{z}, zmm2/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.F3.0F.W1 7A /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTUQQ2PD_ZMM_K1Z_ZMMM512B64_ER = 1789,
	/// @brief @c VCVTUDQ2PS xmm1 {k1}{z}, xmm2/m128/m32bcst
	/// @par
	/// @c EVEX.128.F2.0F.W0 7A /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTUDQ2PS_XMM_K1Z_XMMM128B32 = 1790,
	/// @brief @c VCVTUDQ2PS ymm1 {k1}{z}, ymm2/m256/m32bcst
	/// @par
	/// @c EVEX.256.F2.0F.W0 7A /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTUDQ2PS_YMM_K1Z_YMMM256B32 = 1791,
	/// @brief @c VCVTUDQ2PS zmm1 {k1}{z}, zmm2/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.F2.0F.W0 7A /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTUDQ2PS_ZMM_K1Z_ZMMM512B32_ER = 1792,
	/// @brief @c VCVTUQQ2PS xmm1 {k1}{z}, xmm2/m128/m64bcst
	/// @par
	/// @c EVEX.128.F2.0F.W1 7A /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTUQQ2PS_XMM_K1Z_XMMM128B64 = 1793,
	/// @brief @c VCVTUQQ2PS xmm1 {k1}{z}, ymm2/m256/m64bcst
	/// @par
	/// @c EVEX.256.F2.0F.W1 7A /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTUQQ2PS_XMM_K1Z_YMMM256B64 = 1794,
	/// @brief @c VCVTUQQ2PS ymm1 {k1}{z}, zmm2/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.F2.0F.W1 7A /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTUQQ2PS_YMM_K1Z_ZMMM512B64_ER = 1795,
	/// @brief @c VCVTPS2QQ xmm1 {k1}{z}, xmm2/m64/m32bcst
	/// @par
	/// @c EVEX.128.66.0F.W0 7B /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPS2QQ_XMM_K1Z_XMMM64B32 = 1796,
	/// @brief @c VCVTPS2QQ ymm1 {k1}{z}, xmm2/m128/m32bcst
	/// @par
	/// @c EVEX.256.66.0F.W0 7B /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPS2QQ_YMM_K1Z_XMMM128B32 = 1797,
	/// @brief @c VCVTPS2QQ zmm1 {k1}{z}, ymm2/m256/m32bcst{er}
	/// @par
	/// @c EVEX.512.66.0F.W0 7B /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPS2QQ_ZMM_K1Z_YMMM256B32_ER = 1798,
	/// @brief @c VCVTPD2QQ xmm1 {k1}{z}, xmm2/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F.W1 7B /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPD2QQ_XMM_K1Z_XMMM128B64 = 1799,
	/// @brief @c VCVTPD2QQ ymm1 {k1}{z}, ymm2/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F.W1 7B /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPD2QQ_YMM_K1Z_YMMM256B64 = 1800,
	/// @brief @c VCVTPD2QQ zmm1 {k1}{z}, zmm2/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.66.0F.W1 7B /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPD2QQ_ZMM_K1Z_ZMMM512B64_ER = 1801,
	/// @brief @c VCVTUSI2SS xmm1, xmm2, r/m32{er}
	/// @par
	/// @c EVEX.LIG.F3.0F.W0 7B /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTUSI2SS_XMM_XMM_RM32_ER = 1802,
	/// @brief @c VCVTUSI2SS xmm1, xmm2, r/m64{er}
	/// @par
	/// @c EVEX.LIG.F3.0F.W1 7B /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 64-bit
	EVEX_VCVTUSI2SS_XMM_XMM_RM64_ER = 1803,
	/// @brief @c VCVTUSI2SD xmm1, xmm2, r/m32{er}
	/// @par
	/// @c EVEX.LIG.F2.0F.W0 7B /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTUSI2SD_XMM_XMM_RM32_ER = 1804,
	/// @brief @c VCVTUSI2SD xmm1, xmm2, r/m64{er}
	/// @par
	/// @c EVEX.LIG.F2.0F.W1 7B /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 64-bit
	EVEX_VCVTUSI2SD_XMM_XMM_RM64_ER = 1805,
	/// @brief @c HADDPD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 7C /r
	/// @par
	/// @c SSE3
	/// @par
	/// @c 16/32/64-bit
	HADDPD_XMM_XMMM128 = 1806,
	/// @brief @c VHADDPD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 7C /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VHADDPD_XMM_XMM_XMMM128 = 1807,
	/// @brief @c VHADDPD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 7C /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VHADDPD_YMM_YMM_YMMM256 = 1808,
	/// @brief @c HADDPS xmm1, xmm2/m128
	/// @par
	/// @c F2 0F 7C /r
	/// @par
	/// @c SSE3
	/// @par
	/// @c 16/32/64-bit
	HADDPS_XMM_XMMM128 = 1809,
	/// @brief @c VHADDPS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.F2.0F.WIG 7C /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VHADDPS_XMM_XMM_XMMM128 = 1810,
	/// @brief @c VHADDPS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.F2.0F.WIG 7C /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VHADDPS_YMM_YMM_YMMM256 = 1811,
	/// @brief @c HSUBPD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 7D /r
	/// @par
	/// @c SSE3
	/// @par
	/// @c 16/32/64-bit
	HSUBPD_XMM_XMMM128 = 1812,
	/// @brief @c VHSUBPD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG 7D /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VHSUBPD_XMM_XMM_XMMM128 = 1813,
	/// @brief @c VHSUBPD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG 7D /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VHSUBPD_YMM_YMM_YMMM256 = 1814,
	/// @brief @c HSUBPS xmm1, xmm2/m128
	/// @par
	/// @c F2 0F 7D /r
	/// @par
	/// @c SSE3
	/// @par
	/// @c 16/32/64-bit
	HSUBPS_XMM_XMMM128 = 1815,
	/// @brief @c VHSUBPS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.F2.0F.WIG 7D /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VHSUBPS_XMM_XMM_XMMM128 = 1816,
	/// @brief @c VHSUBPS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.F2.0F.WIG 7D /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VHSUBPS_YMM_YMM_YMMM256 = 1817,
	/// @brief @c MOVD r/m32, mm
	/// @par
	/// @c NP 0F 7E /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	MOVD_RM32_MM = 1818,
	/// @brief @c MOVQ r/m64, mm
	/// @par
	/// @c NP o64 0F 7E /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 64-bit
	MOVQ_RM64_MM = 1819,
	/// @brief @c MOVD r/m32, xmm
	/// @par
	/// @c 66 0F 7E /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MOVD_RM32_XMM = 1820,
	/// @brief @c MOVQ r/m64, xmm
	/// @par
	/// @c 66 o64 0F 7E /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 64-bit
	MOVQ_RM64_XMM = 1821,
	/// @brief @c VMOVD r/m32, xmm1
	/// @par
	/// @c VEX.128.66.0F.W0 7E /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVD_RM32_XMM = 1822,
	/// @brief @c VMOVQ r/m64, xmm1
	/// @par
	/// @c VEX.128.66.0F.W1 7E /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 64-bit
	VEX_VMOVQ_RM64_XMM = 1823,
	/// @brief @c VMOVD r/m32, xmm1
	/// @par
	/// @c EVEX.128.66.0F.W0 7E /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVD_RM32_XMM = 1824,
	/// @brief @c VMOVQ r/m64, xmm1
	/// @par
	/// @c EVEX.128.66.0F.W1 7E /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 64-bit
	EVEX_VMOVQ_RM64_XMM = 1825,
	/// @brief @c MOVQ xmm1, xmm2/m64
	/// @par
	/// @c F3 0F 7E /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MOVQ_XMM_XMMM64 = 1826,
	/// @brief @c VMOVQ xmm1, xmm2/m64
	/// @par
	/// @c VEX.128.F3.0F.WIG 7E /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVQ_XMM_XMMM64 = 1827,
	/// @brief @c VMOVQ xmm1, xmm2/m64
	/// @par
	/// @c EVEX.128.F3.0F.W1 7E /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVQ_XMM_XMMM64 = 1828,
	/// @brief @c MOVQ mm/m64, mm
	/// @par
	/// @c NP 0F 7F /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	MOVQ_MMM64_MM = 1829,
	/// @brief @c MOVDQA xmm2/m128, xmm1
	/// @par
	/// @c 66 0F 7F /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MOVDQA_XMMM128_XMM = 1830,
	/// @brief @c VMOVDQA xmm2/m128, xmm1
	/// @par
	/// @c VEX.128.66.0F.WIG 7F /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVDQA_XMMM128_XMM = 1831,
	/// @brief @c VMOVDQA ymm2/m256, ymm1
	/// @par
	/// @c VEX.256.66.0F.WIG 7F /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVDQA_YMMM256_YMM = 1832,
	/// @brief @c VMOVDQA32 xmm2/m128 {k1}{z}, xmm1
	/// @par
	/// @c EVEX.128.66.0F.W0 7F /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQA32_XMMM128_K1Z_XMM = 1833,
	/// @brief @c VMOVDQA32 ymm2/m256 {k1}{z}, ymm1
	/// @par
	/// @c EVEX.256.66.0F.W0 7F /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQA32_YMMM256_K1Z_YMM = 1834,
	/// @brief @c VMOVDQA32 zmm2/m512 {k1}{z}, zmm1
	/// @par
	/// @c EVEX.512.66.0F.W0 7F /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQA32_ZMMM512_K1Z_ZMM = 1835,
	/// @brief @c VMOVDQA64 xmm2/m128 {k1}{z}, xmm1
	/// @par
	/// @c EVEX.128.66.0F.W1 7F /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQA64_XMMM128_K1Z_XMM = 1836,
	/// @brief @c VMOVDQA64 ymm2/m256 {k1}{z}, ymm1
	/// @par
	/// @c EVEX.256.66.0F.W1 7F /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQA64_YMMM256_K1Z_YMM = 1837,
	/// @brief @c VMOVDQA64 zmm2/m512 {k1}{z}, zmm1
	/// @par
	/// @c EVEX.512.66.0F.W1 7F /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQA64_ZMMM512_K1Z_ZMM = 1838,
	/// @brief @c MOVDQU xmm2/m128, xmm1
	/// @par
	/// @c F3 0F 7F /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MOVDQU_XMMM128_XMM = 1839,
	/// @brief @c VMOVDQU xmm2/m128, xmm1
	/// @par
	/// @c VEX.128.F3.0F.WIG 7F /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVDQU_XMMM128_XMM = 1840,
	/// @brief @c VMOVDQU ymm2/m256, ymm1
	/// @par
	/// @c VEX.256.F3.0F.WIG 7F /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVDQU_YMMM256_YMM = 1841,
	/// @brief @c VMOVDQU32 xmm2/m128 {k1}{z}, xmm1
	/// @par
	/// @c EVEX.128.F3.0F.W0 7F /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQU32_XMMM128_K1Z_XMM = 1842,
	/// @brief @c VMOVDQU32 ymm2/m256 {k1}{z}, ymm1
	/// @par
	/// @c EVEX.256.F3.0F.W0 7F /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQU32_YMMM256_K1Z_YMM = 1843,
	/// @brief @c VMOVDQU32 zmm2/m512 {k1}{z}, zmm1
	/// @par
	/// @c EVEX.512.F3.0F.W0 7F /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQU32_ZMMM512_K1Z_ZMM = 1844,
	/// @brief @c VMOVDQU64 xmm2/m128 {k1}{z}, xmm1
	/// @par
	/// @c EVEX.128.F3.0F.W1 7F /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQU64_XMMM128_K1Z_XMM = 1845,
	/// @brief @c VMOVDQU64 ymm2/m256 {k1}{z}, ymm1
	/// @par
	/// @c EVEX.256.F3.0F.W1 7F /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQU64_YMMM256_K1Z_YMM = 1846,
	/// @brief @c VMOVDQU64 zmm2/m512 {k1}{z}, zmm1
	/// @par
	/// @c EVEX.512.F3.0F.W1 7F /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQU64_ZMMM512_K1Z_ZMM = 1847,
	/// @brief @c VMOVDQU8 xmm2/m128 {k1}{z}, xmm1
	/// @par
	/// @c EVEX.128.F2.0F.W0 7F /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQU8_XMMM128_K1Z_XMM = 1848,
	/// @brief @c VMOVDQU8 ymm2/m256 {k1}{z}, ymm1
	/// @par
	/// @c EVEX.256.F2.0F.W0 7F /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQU8_YMMM256_K1Z_YMM = 1849,
	/// @brief @c VMOVDQU8 zmm2/m512 {k1}{z}, zmm1
	/// @par
	/// @c EVEX.512.F2.0F.W0 7F /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQU8_ZMMM512_K1Z_ZMM = 1850,
	/// @brief @c VMOVDQU16 xmm2/m128 {k1}{z}, xmm1
	/// @par
	/// @c EVEX.128.F2.0F.W1 7F /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQU16_XMMM128_K1Z_XMM = 1851,
	/// @brief @c VMOVDQU16 ymm2/m256 {k1}{z}, ymm1
	/// @par
	/// @c EVEX.256.F2.0F.W1 7F /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQU16_YMMM256_K1Z_YMM = 1852,
	/// @brief @c VMOVDQU16 zmm2/m512 {k1}{z}, zmm1
	/// @par
	/// @c EVEX.512.F2.0F.W1 7F /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVDQU16_ZMMM512_K1Z_ZMM = 1853,
	/// @brief @c JO rel16
	/// @par
	/// @c o16 0F 80 cw
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	JO_REL16 = 1854,
	/// @brief @c JO rel32
	/// @par
	/// @c o32 0F 80 cd
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JO_REL32_32 = 1855,
	/// @brief @c JO rel32
	/// @par
	/// @c o64 0F 80 cd
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JO_REL32_64 = 1856,
	/// @brief @c JNO rel16
	/// @par
	/// @c o16 0F 81 cw
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	JNO_REL16 = 1857,
	/// @brief @c JNO rel32
	/// @par
	/// @c o32 0F 81 cd
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JNO_REL32_32 = 1858,
	/// @brief @c JNO rel32
	/// @par
	/// @c o64 0F 81 cd
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JNO_REL32_64 = 1859,
	/// @brief @c JB rel16
	/// @par
	/// @c o16 0F 82 cw
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	JB_REL16 = 1860,
	/// @brief @c JB rel32
	/// @par
	/// @c o32 0F 82 cd
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JB_REL32_32 = 1861,
	/// @brief @c JB rel32
	/// @par
	/// @c o64 0F 82 cd
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JB_REL32_64 = 1862,
	/// @brief @c JAE rel16
	/// @par
	/// @c o16 0F 83 cw
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	JAE_REL16 = 1863,
	/// @brief @c JAE rel32
	/// @par
	/// @c o32 0F 83 cd
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JAE_REL32_32 = 1864,
	/// @brief @c JAE rel32
	/// @par
	/// @c o64 0F 83 cd
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JAE_REL32_64 = 1865,
	/// @brief @c JE rel16
	/// @par
	/// @c o16 0F 84 cw
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	JE_REL16 = 1866,
	/// @brief @c JE rel32
	/// @par
	/// @c o32 0F 84 cd
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JE_REL32_32 = 1867,
	/// @brief @c JE rel32
	/// @par
	/// @c o64 0F 84 cd
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JE_REL32_64 = 1868,
	/// @brief @c JNE rel16
	/// @par
	/// @c o16 0F 85 cw
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	JNE_REL16 = 1869,
	/// @brief @c JNE rel32
	/// @par
	/// @c o32 0F 85 cd
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JNE_REL32_32 = 1870,
	/// @brief @c JNE rel32
	/// @par
	/// @c o64 0F 85 cd
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JNE_REL32_64 = 1871,
	/// @brief @c JBE rel16
	/// @par
	/// @c o16 0F 86 cw
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	JBE_REL16 = 1872,
	/// @brief @c JBE rel32
	/// @par
	/// @c o32 0F 86 cd
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JBE_REL32_32 = 1873,
	/// @brief @c JBE rel32
	/// @par
	/// @c o64 0F 86 cd
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JBE_REL32_64 = 1874,
	/// @brief @c JA rel16
	/// @par
	/// @c o16 0F 87 cw
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	JA_REL16 = 1875,
	/// @brief @c JA rel32
	/// @par
	/// @c o32 0F 87 cd
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JA_REL32_32 = 1876,
	/// @brief @c JA rel32
	/// @par
	/// @c o64 0F 87 cd
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JA_REL32_64 = 1877,
	/// @brief @c JS rel16
	/// @par
	/// @c o16 0F 88 cw
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	JS_REL16 = 1878,
	/// @brief @c JS rel32
	/// @par
	/// @c o32 0F 88 cd
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JS_REL32_32 = 1879,
	/// @brief @c JS rel32
	/// @par
	/// @c o64 0F 88 cd
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JS_REL32_64 = 1880,
	/// @brief @c JNS rel16
	/// @par
	/// @c o16 0F 89 cw
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	JNS_REL16 = 1881,
	/// @brief @c JNS rel32
	/// @par
	/// @c o32 0F 89 cd
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JNS_REL32_32 = 1882,
	/// @brief @c JNS rel32
	/// @par
	/// @c o64 0F 89 cd
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JNS_REL32_64 = 1883,
	/// @brief @c JP rel16
	/// @par
	/// @c o16 0F 8A cw
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	JP_REL16 = 1884,
	/// @brief @c JP rel32
	/// @par
	/// @c o32 0F 8A cd
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JP_REL32_32 = 1885,
	/// @brief @c JP rel32
	/// @par
	/// @c o64 0F 8A cd
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JP_REL32_64 = 1886,
	/// @brief @c JNP rel16
	/// @par
	/// @c o16 0F 8B cw
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	JNP_REL16 = 1887,
	/// @brief @c JNP rel32
	/// @par
	/// @c o32 0F 8B cd
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JNP_REL32_32 = 1888,
	/// @brief @c JNP rel32
	/// @par
	/// @c o64 0F 8B cd
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JNP_REL32_64 = 1889,
	/// @brief @c JL rel16
	/// @par
	/// @c o16 0F 8C cw
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	JL_REL16 = 1890,
	/// @brief @c JL rel32
	/// @par
	/// @c o32 0F 8C cd
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JL_REL32_32 = 1891,
	/// @brief @c JL rel32
	/// @par
	/// @c o64 0F 8C cd
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JL_REL32_64 = 1892,
	/// @brief @c JGE rel16
	/// @par
	/// @c o16 0F 8D cw
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	JGE_REL16 = 1893,
	/// @brief @c JGE rel32
	/// @par
	/// @c o32 0F 8D cd
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JGE_REL32_32 = 1894,
	/// @brief @c JGE rel32
	/// @par
	/// @c o64 0F 8D cd
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JGE_REL32_64 = 1895,
	/// @brief @c JLE rel16
	/// @par
	/// @c o16 0F 8E cw
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	JLE_REL16 = 1896,
	/// @brief @c JLE rel32
	/// @par
	/// @c o32 0F 8E cd
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JLE_REL32_32 = 1897,
	/// @brief @c JLE rel32
	/// @par
	/// @c o64 0F 8E cd
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JLE_REL32_64 = 1898,
	/// @brief @c JG rel16
	/// @par
	/// @c o16 0F 8F cw
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	JG_REL16 = 1899,
	/// @brief @c JG rel32
	/// @par
	/// @c o32 0F 8F cd
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	JG_REL32_32 = 1900,
	/// @brief @c JG rel32
	/// @par
	/// @c o64 0F 8F cd
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	JG_REL32_64 = 1901,
	/// @brief @c SETO r/m8
	/// @par
	/// @c 0F 90 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SETO_RM8 = 1902,
	/// @brief @c SETNO r/m8
	/// @par
	/// @c 0F 91 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SETNO_RM8 = 1903,
	/// @brief @c SETB r/m8
	/// @par
	/// @c 0F 92 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SETB_RM8 = 1904,
	/// @brief @c SETAE r/m8
	/// @par
	/// @c 0F 93 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SETAE_RM8 = 1905,
	/// @brief @c SETE r/m8
	/// @par
	/// @c 0F 94 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SETE_RM8 = 1906,
	/// @brief @c SETNE r/m8
	/// @par
	/// @c 0F 95 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SETNE_RM8 = 1907,
	/// @brief @c SETBE r/m8
	/// @par
	/// @c 0F 96 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SETBE_RM8 = 1908,
	/// @brief @c SETA r/m8
	/// @par
	/// @c 0F 97 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SETA_RM8 = 1909,
	/// @brief @c SETS r/m8
	/// @par
	/// @c 0F 98 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SETS_RM8 = 1910,
	/// @brief @c SETNS r/m8
	/// @par
	/// @c 0F 99 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SETNS_RM8 = 1911,
	/// @brief @c SETP r/m8
	/// @par
	/// @c 0F 9A /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SETP_RM8 = 1912,
	/// @brief @c SETNP r/m8
	/// @par
	/// @c 0F 9B /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SETNP_RM8 = 1913,
	/// @brief @c SETL r/m8
	/// @par
	/// @c 0F 9C /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SETL_RM8 = 1914,
	/// @brief @c SETGE r/m8
	/// @par
	/// @c 0F 9D /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SETGE_RM8 = 1915,
	/// @brief @c SETLE r/m8
	/// @par
	/// @c 0F 9E /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SETLE_RM8 = 1916,
	/// @brief @c SETG r/m8
	/// @par
	/// @c 0F 9F /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SETG_RM8 = 1917,
	/// @brief @c KMOVW k1, k2/m16
	/// @par
	/// @c VEX.L0.0F.W0 90 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	VEX_KMOVW_KR_KM16 = 1918,
	/// @brief @c KMOVQ k1, k2/m64
	/// @par
	/// @c VEX.L0.0F.W1 90 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	VEX_KMOVQ_KR_KM64 = 1919,
	/// @brief @c KMOVB k1, k2/m8
	/// @par
	/// @c VEX.L0.66.0F.W0 90 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	VEX_KMOVB_KR_KM8 = 1920,
	/// @brief @c KMOVD k1, k2/m32
	/// @par
	/// @c VEX.L0.66.0F.W1 90 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	VEX_KMOVD_KR_KM32 = 1921,
	/// @brief @c KMOVW m16, k1
	/// @par
	/// @c VEX.L0.0F.W0 91 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	VEX_KMOVW_M16_KR = 1922,
	/// @brief @c KMOVQ m64, k1
	/// @par
	/// @c VEX.L0.0F.W1 91 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	VEX_KMOVQ_M64_KR = 1923,
	/// @brief @c KMOVB m8, k1
	/// @par
	/// @c VEX.L0.66.0F.W0 91 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	VEX_KMOVB_M8_KR = 1924,
	/// @brief @c KMOVD m32, k1
	/// @par
	/// @c VEX.L0.66.0F.W1 91 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	VEX_KMOVD_M32_KR = 1925,
	/// @brief @c KMOVW k1, r32
	/// @par
	/// @c VEX.L0.0F.W0 92 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	VEX_KMOVW_KR_R32 = 1926,
	/// @brief @c KMOVB k1, r32
	/// @par
	/// @c VEX.L0.66.0F.W0 92 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	VEX_KMOVB_KR_R32 = 1927,
	/// @brief @c KMOVD k1, r32
	/// @par
	/// @c VEX.L0.F2.0F.W0 92 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	VEX_KMOVD_KR_R32 = 1928,
	/// @brief @c KMOVQ k1, r64
	/// @par
	/// @c VEX.L0.F2.0F.W1 92 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 64-bit
	VEX_KMOVQ_KR_R64 = 1929,
	/// @brief @c KMOVW r32, k1
	/// @par
	/// @c VEX.L0.0F.W0 93 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	VEX_KMOVW_R32_KR = 1930,
	/// @brief @c KMOVB r32, k1
	/// @par
	/// @c VEX.L0.66.0F.W0 93 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	VEX_KMOVB_R32_KR = 1931,
	/// @brief @c KMOVD r32, k1
	/// @par
	/// @c VEX.L0.F2.0F.W0 93 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	VEX_KMOVD_R32_KR = 1932,
	/// @brief @c KMOVQ r64, k1
	/// @par
	/// @c VEX.L0.F2.0F.W1 93 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 64-bit
	VEX_KMOVQ_R64_KR = 1933,
	/// @brief @c KORTESTW k1, k2
	/// @par
	/// @c VEX.L0.0F.W0 98 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	VEX_KORTESTW_KR_KR = 1934,
	/// @brief @c KORTESTQ k1, k2
	/// @par
	/// @c VEX.L0.0F.W1 98 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	VEX_KORTESTQ_KR_KR = 1935,
	/// @brief @c KORTESTB k1, k2
	/// @par
	/// @c VEX.L0.66.0F.W0 98 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	VEX_KORTESTB_KR_KR = 1936,
	/// @brief @c KORTESTD k1, k2
	/// @par
	/// @c VEX.L0.66.0F.W1 98 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	VEX_KORTESTD_KR_KR = 1937,
	/// @brief @c KTESTW k1, k2
	/// @par
	/// @c VEX.L0.0F.W0 99 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	VEX_KTESTW_KR_KR = 1938,
	/// @brief @c KTESTQ k1, k2
	/// @par
	/// @c VEX.L0.0F.W1 99 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	VEX_KTESTQ_KR_KR = 1939,
	/// @brief @c KTESTB k1, k2
	/// @par
	/// @c VEX.L0.66.0F.W0 99 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	VEX_KTESTB_KR_KR = 1940,
	/// @brief @c KTESTD k1, k2
	/// @par
	/// @c VEX.L0.66.0F.W1 99 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	VEX_KTESTD_KR_KR = 1941,
	/// @brief @c PUSH FS
	/// @par
	/// @c o16 0F A0
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	PUSHW_FS = 1942,
	/// @brief @c PUSH FS
	/// @par
	/// @c o32 0F A0
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	PUSHD_FS = 1943,
	/// @brief @c PUSH FS
	/// @par
	/// @c o64 0F A0
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	PUSHQ_FS = 1944,
	/// @brief @c POP FS
	/// @par
	/// @c o16 0F A1
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	POPW_FS = 1945,
	/// @brief @c POP FS
	/// @par
	/// @c o32 0F A1
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	POPD_FS = 1946,
	/// @brief @c POP FS
	/// @par
	/// @c o64 0F A1
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	POPQ_FS = 1947,
	/// @brief @c CPUID
	/// @par
	/// @c 0F A2
	/// @par
	/// @c CPUID
	/// @par
	/// @c 16/32/64-bit
	CPUID = 1948,
	/// @brief @c BT r/m16, r16
	/// @par
	/// @c o16 0F A3 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	BT_RM16_R16 = 1949,
	/// @brief @c BT r/m32, r32
	/// @par
	/// @c o32 0F A3 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	BT_RM32_R32 = 1950,
	/// @brief @c BT r/m64, r64
	/// @par
	/// @c o64 0F A3 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	BT_RM64_R64 = 1951,
	/// @brief @c SHLD r/m16, r16, imm8
	/// @par
	/// @c o16 0F A4 /r ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SHLD_RM16_R16_IMM8 = 1952,
	/// @brief @c SHLD r/m32, r32, imm8
	/// @par
	/// @c o32 0F A4 /r ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SHLD_RM32_R32_IMM8 = 1953,
	/// @brief @c SHLD r/m64, r64, imm8
	/// @par
	/// @c o64 0F A4 /r ib
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SHLD_RM64_R64_IMM8 = 1954,
	/// @brief @c SHLD r/m16, r16, CL
	/// @par
	/// @c o16 0F A5 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SHLD_RM16_R16_CL = 1955,
	/// @brief @c SHLD r/m32, r32, CL
	/// @par
	/// @c o32 0F A5 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SHLD_RM32_R32_CL = 1956,
	/// @brief @c SHLD r/m64, r64, CL
	/// @par
	/// @c o64 0F A5 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SHLD_RM64_R64_CL = 1957,
	/// @brief @c MONTMUL
	/// @par
	/// @c a16 F3 0F A6 C0
	/// @par
	/// @c PADLOCK_PMM
	/// @par
	/// @c 16/32-bit
	MONTMUL_16 = 1958,
	/// @brief @c MONTMUL
	/// @par
	/// @c a32 F3 0F A6 C0
	/// @par
	/// @c PADLOCK_PMM
	/// @par
	/// @c 16/32/64-bit
	MONTMUL_32 = 1959,
	/// @brief @c MONTMUL
	/// @par
	/// @c a64 F3 0F A6 C0
	/// @par
	/// @c PADLOCK_PMM
	/// @par
	/// @c 64-bit
	MONTMUL_64 = 1960,
	/// @brief @c XSHA1
	/// @par
	/// @c a16 F3 0F A6 C8
	/// @par
	/// @c PADLOCK_PHE
	/// @par
	/// @c 16/32-bit
	XSHA1_16 = 1961,
	/// @brief @c XSHA1
	/// @par
	/// @c a32 F3 0F A6 C8
	/// @par
	/// @c PADLOCK_PHE
	/// @par
	/// @c 16/32/64-bit
	XSHA1_32 = 1962,
	/// @brief @c XSHA1
	/// @par
	/// @c a64 F3 0F A6 C8
	/// @par
	/// @c PADLOCK_PHE
	/// @par
	/// @c 64-bit
	XSHA1_64 = 1963,
	/// @brief @c XSHA256
	/// @par
	/// @c a16 F3 0F A6 D0
	/// @par
	/// @c PADLOCK_PHE
	/// @par
	/// @c 16/32-bit
	XSHA256_16 = 1964,
	/// @brief @c XSHA256
	/// @par
	/// @c a32 F3 0F A6 D0
	/// @par
	/// @c PADLOCK_PHE
	/// @par
	/// @c 16/32/64-bit
	XSHA256_32 = 1965,
	/// @brief @c XSHA256
	/// @par
	/// @c a64 F3 0F A6 D0
	/// @par
	/// @c PADLOCK_PHE
	/// @par
	/// @c 64-bit
	XSHA256_64 = 1966,
	/// @brief @c XBTS r16, r/m16
	/// @par
	/// @c o16 0F A6 /r
	/// @par
	/// @c 386 A0
	/// @par
	/// @c 16/32-bit
	XBTS_R16_RM16 = 1967,
	/// @brief @c XBTS r32, r/m32
	/// @par
	/// @c o32 0F A6 /r
	/// @par
	/// @c 386 A0
	/// @par
	/// @c 16/32-bit
	XBTS_R32_RM32 = 1968,
	/// @brief @c XSTORE
	/// @par
	/// @c a16 0F A7 C0
	/// @par
	/// @c PADLOCK_RNG
	/// @par
	/// @c 16/32-bit
	XSTORE_16 = 1969,
	/// @brief @c XSTORE
	/// @par
	/// @c a32 0F A7 C0
	/// @par
	/// @c PADLOCK_RNG
	/// @par
	/// @c 16/32/64-bit
	XSTORE_32 = 1970,
	/// @brief @c XSTORE
	/// @par
	/// @c a64 0F A7 C0
	/// @par
	/// @c PADLOCK_RNG
	/// @par
	/// @c 64-bit
	XSTORE_64 = 1971,
	/// @brief @c XCRYPTECB
	/// @par
	/// @c a16 F3 0F A7 C8
	/// @par
	/// @c PADLOCK_ACE
	/// @par
	/// @c 16/32-bit
	XCRYPTECB_16 = 1972,
	/// @brief @c XCRYPTECB
	/// @par
	/// @c a32 F3 0F A7 C8
	/// @par
	/// @c PADLOCK_ACE
	/// @par
	/// @c 16/32/64-bit
	XCRYPTECB_32 = 1973,
	/// @brief @c XCRYPTECB
	/// @par
	/// @c a64 F3 0F A7 C8
	/// @par
	/// @c PADLOCK_ACE
	/// @par
	/// @c 64-bit
	XCRYPTECB_64 = 1974,
	/// @brief @c XCRYPTCBC
	/// @par
	/// @c a16 F3 0F A7 D0
	/// @par
	/// @c PADLOCK_ACE
	/// @par
	/// @c 16/32-bit
	XCRYPTCBC_16 = 1975,
	/// @brief @c XCRYPTCBC
	/// @par
	/// @c a32 F3 0F A7 D0
	/// @par
	/// @c PADLOCK_ACE
	/// @par
	/// @c 16/32/64-bit
	XCRYPTCBC_32 = 1976,
	/// @brief @c XCRYPTCBC
	/// @par
	/// @c a64 F3 0F A7 D0
	/// @par
	/// @c PADLOCK_ACE
	/// @par
	/// @c 64-bit
	XCRYPTCBC_64 = 1977,
	/// @brief @c XCRYPTCTR
	/// @par
	/// @c a16 F3 0F A7 D8
	/// @par
	/// @c PADLOCK_ACE
	/// @par
	/// @c 16/32-bit
	XCRYPTCTR_16 = 1978,
	/// @brief @c XCRYPTCTR
	/// @par
	/// @c a32 F3 0F A7 D8
	/// @par
	/// @c PADLOCK_ACE
	/// @par
	/// @c 16/32/64-bit
	XCRYPTCTR_32 = 1979,
	/// @brief @c XCRYPTCTR
	/// @par
	/// @c a64 F3 0F A7 D8
	/// @par
	/// @c PADLOCK_ACE
	/// @par
	/// @c 64-bit
	XCRYPTCTR_64 = 1980,
	/// @brief @c XCRYPTCFB
	/// @par
	/// @c a16 F3 0F A7 E0
	/// @par
	/// @c PADLOCK_ACE
	/// @par
	/// @c 16/32-bit
	XCRYPTCFB_16 = 1981,
	/// @brief @c XCRYPTCFB
	/// @par
	/// @c a32 F3 0F A7 E0
	/// @par
	/// @c PADLOCK_ACE
	/// @par
	/// @c 16/32/64-bit
	XCRYPTCFB_32 = 1982,
	/// @brief @c XCRYPTCFB
	/// @par
	/// @c a64 F3 0F A7 E0
	/// @par
	/// @c PADLOCK_ACE
	/// @par
	/// @c 64-bit
	XCRYPTCFB_64 = 1983,
	/// @brief @c XCRYPTOFB
	/// @par
	/// @c a16 F3 0F A7 E8
	/// @par
	/// @c PADLOCK_ACE
	/// @par
	/// @c 16/32-bit
	XCRYPTOFB_16 = 1984,
	/// @brief @c XCRYPTOFB
	/// @par
	/// @c a32 F3 0F A7 E8
	/// @par
	/// @c PADLOCK_ACE
	/// @par
	/// @c 16/32/64-bit
	XCRYPTOFB_32 = 1985,
	/// @brief @c XCRYPTOFB
	/// @par
	/// @c a64 F3 0F A7 E8
	/// @par
	/// @c PADLOCK_ACE
	/// @par
	/// @c 64-bit
	XCRYPTOFB_64 = 1986,
	/// @brief @c IBTS r/m16, r16
	/// @par
	/// @c o16 0F A7 /r
	/// @par
	/// @c 386 A0
	/// @par
	/// @c 16/32-bit
	IBTS_RM16_R16 = 1987,
	/// @brief @c IBTS r/m32, r32
	/// @par
	/// @c o32 0F A7 /r
	/// @par
	/// @c 386 A0
	/// @par
	/// @c 16/32-bit
	IBTS_RM32_R32 = 1988,
	/// @brief @c CMPXCHG r/m8, r8
	/// @par
	/// @c 0F A6 /r
	/// @par
	/// @c 486 A
	/// @par
	/// @c 16/32-bit
	CMPXCHG486_RM8_R8 = 1989,
	/// @brief @c CMPXCHG r/m16, r16
	/// @par
	/// @c o16 0F A7 /r
	/// @par
	/// @c 486 A
	/// @par
	/// @c 16/32-bit
	CMPXCHG486_RM16_R16 = 1990,
	/// @brief @c CMPXCHG r/m32, r32
	/// @par
	/// @c o32 0F A7 /r
	/// @par
	/// @c 486 A
	/// @par
	/// @c 16/32-bit
	CMPXCHG486_RM32_R32 = 1991,
	/// @brief @c PUSH GS
	/// @par
	/// @c o16 0F A8
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	PUSHW_GS = 1992,
	/// @brief @c PUSH GS
	/// @par
	/// @c o32 0F A8
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	PUSHD_GS = 1993,
	/// @brief @c PUSH GS
	/// @par
	/// @c o64 0F A8
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	PUSHQ_GS = 1994,
	/// @brief @c POP GS
	/// @par
	/// @c o16 0F A9
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	POPW_GS = 1995,
	/// @brief @c POP GS
	/// @par
	/// @c o32 0F A9
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32-bit
	POPD_GS = 1996,
	/// @brief @c POP GS
	/// @par
	/// @c o64 0F A9
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	POPQ_GS = 1997,
	/// @brief @c RSM
	/// @par
	/// @c 0F AA
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	RSM = 1998,
	/// @brief @c BTS r/m16, r16
	/// @par
	/// @c o16 0F AB /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	BTS_RM16_R16 = 1999,
	/// @brief @c BTS r/m32, r32
	/// @par
	/// @c o32 0F AB /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	BTS_RM32_R32 = 2000,
	/// @brief @c BTS r/m64, r64
	/// @par
	/// @c o64 0F AB /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	BTS_RM64_R64 = 2001,
	/// @brief @c SHRD r/m16, r16, imm8
	/// @par
	/// @c o16 0F AC /r ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SHRD_RM16_R16_IMM8 = 2002,
	/// @brief @c SHRD r/m32, r32, imm8
	/// @par
	/// @c o32 0F AC /r ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SHRD_RM32_R32_IMM8 = 2003,
	/// @brief @c SHRD r/m64, r64, imm8
	/// @par
	/// @c o64 0F AC /r ib
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SHRD_RM64_R64_IMM8 = 2004,
	/// @brief @c SHRD r/m16, r16, CL
	/// @par
	/// @c o16 0F AD /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SHRD_RM16_R16_CL = 2005,
	/// @brief @c SHRD r/m32, r32, CL
	/// @par
	/// @c o32 0F AD /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	SHRD_RM32_R32_CL = 2006,
	/// @brief @c SHRD r/m64, r64, CL
	/// @par
	/// @c o64 0F AD /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	SHRD_RM64_R64_CL = 2007,
	/// @brief @c FXSAVE m512byte
	/// @par
	/// @c NP 0F AE /0
	/// @par
	/// @c FXSR
	/// @par
	/// @c 16/32/64-bit
	FXSAVE_M512BYTE = 2008,
	/// @brief @c FXSAVE64 m512byte
	/// @par
	/// @c NP o64 0F AE /0
	/// @par
	/// @c FXSR
	/// @par
	/// @c 64-bit
	FXSAVE64_M512BYTE = 2009,
	/// @brief @c RDFSBASE r32
	/// @par
	/// @c F3 0F AE /0
	/// @par
	/// @c FSGSBASE
	/// @par
	/// @c 64-bit
	RDFSBASE_R32 = 2010,
	/// @brief @c RDFSBASE r64
	/// @par
	/// @c F3 o64 0F AE /0
	/// @par
	/// @c FSGSBASE
	/// @par
	/// @c 64-bit
	RDFSBASE_R64 = 2011,
	/// @brief @c FXRSTOR m512byte
	/// @par
	/// @c NP 0F AE /1
	/// @par
	/// @c FXSR
	/// @par
	/// @c 16/32/64-bit
	FXRSTOR_M512BYTE = 2012,
	/// @brief @c FXRSTOR64 m512byte
	/// @par
	/// @c NP o64 0F AE /1
	/// @par
	/// @c FXSR
	/// @par
	/// @c 64-bit
	FXRSTOR64_M512BYTE = 2013,
	/// @brief @c RDGSBASE r32
	/// @par
	/// @c F3 0F AE /1
	/// @par
	/// @c FSGSBASE
	/// @par
	/// @c 64-bit
	RDGSBASE_R32 = 2014,
	/// @brief @c RDGSBASE r64
	/// @par
	/// @c F3 o64 0F AE /1
	/// @par
	/// @c FSGSBASE
	/// @par
	/// @c 64-bit
	RDGSBASE_R64 = 2015,
	/// @brief @c LDMXCSR m32
	/// @par
	/// @c NP 0F AE /2
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	LDMXCSR_M32 = 2016,
	/// @brief @c WRFSBASE r32
	/// @par
	/// @c F3 0F AE /2
	/// @par
	/// @c FSGSBASE
	/// @par
	/// @c 64-bit
	WRFSBASE_R32 = 2017,
	/// @brief @c WRFSBASE r64
	/// @par
	/// @c F3 o64 0F AE /2
	/// @par
	/// @c FSGSBASE
	/// @par
	/// @c 64-bit
	WRFSBASE_R64 = 2018,
	/// @brief @c VLDMXCSR m32
	/// @par
	/// @c VEX.LZ.0F.WIG AE /2
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VLDMXCSR_M32 = 2019,
	/// @brief @c STMXCSR m32
	/// @par
	/// @c NP 0F AE /3
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	STMXCSR_M32 = 2020,
	/// @brief @c WRGSBASE r32
	/// @par
	/// @c F3 0F AE /3
	/// @par
	/// @c FSGSBASE
	/// @par
	/// @c 64-bit
	WRGSBASE_R32 = 2021,
	/// @brief @c WRGSBASE r64
	/// @par
	/// @c F3 o64 0F AE /3
	/// @par
	/// @c FSGSBASE
	/// @par
	/// @c 64-bit
	WRGSBASE_R64 = 2022,
	/// @brief @c VSTMXCSR m32
	/// @par
	/// @c VEX.LZ.0F.WIG AE /3
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VSTMXCSR_M32 = 2023,
	/// @brief @c XSAVE mem
	/// @par
	/// @c NP 0F AE /4
	/// @par
	/// @c XSAVE
	/// @par
	/// @c 16/32/64-bit
	XSAVE_MEM = 2024,
	/// @brief @c XSAVE64 mem
	/// @par
	/// @c NP o64 0F AE /4
	/// @par
	/// @c XSAVE
	/// @par
	/// @c 64-bit
	XSAVE64_MEM = 2025,
	/// @brief @c PTWRITE r/m32
	/// @par
	/// @c F3 0F AE /4
	/// @par
	/// @c PTWRITE
	/// @par
	/// @c 16/32/64-bit
	PTWRITE_RM32 = 2026,
	/// @brief @c PTWRITE r/m64
	/// @par
	/// @c F3 o64 0F AE /4
	/// @par
	/// @c PTWRITE
	/// @par
	/// @c 64-bit
	PTWRITE_RM64 = 2027,
	/// @brief @c XRSTOR mem
	/// @par
	/// @c NP 0F AE /5
	/// @par
	/// @c XSAVE
	/// @par
	/// @c 16/32/64-bit
	XRSTOR_MEM = 2028,
	/// @brief @c XRSTOR64 mem
	/// @par
	/// @c NP o64 0F AE /5
	/// @par
	/// @c XSAVE
	/// @par
	/// @c 64-bit
	XRSTOR64_MEM = 2029,
	/// @brief @c INCSSPD r32
	/// @par
	/// @c F3 0F AE /5
	/// @par
	/// @c CET_SS
	/// @par
	/// @c 16/32/64-bit
	INCSSPD_R32 = 2030,
	/// @brief @c INCSSPQ r64
	/// @par
	/// @c F3 o64 0F AE /5
	/// @par
	/// @c CET_SS
	/// @par
	/// @c 64-bit
	INCSSPQ_R64 = 2031,
	/// @brief @c XSAVEOPT mem
	/// @par
	/// @c NP 0F AE /6
	/// @par
	/// @c XSAVEOPT
	/// @par
	/// @c 16/32/64-bit
	XSAVEOPT_MEM = 2032,
	/// @brief @c XSAVEOPT64 mem
	/// @par
	/// @c NP o64 0F AE /6
	/// @par
	/// @c XSAVEOPT
	/// @par
	/// @c 64-bit
	XSAVEOPT64_MEM = 2033,
	/// @brief @c CLWB m8
	/// @par
	/// @c 66 0F AE /6
	/// @par
	/// @c CLWB
	/// @par
	/// @c 16/32/64-bit
	CLWB_M8 = 2034,
	/// @brief @c TPAUSE r32, \<edx\>, \<eax\>
	/// @par
	/// @c 66 0F AE /6
	/// @par
	/// @c WAITPKG
	/// @par
	/// @c 16/32/64-bit
	TPAUSE_R32 = 2035,
	/// @brief @c TPAUSE r64, \<edx\>, \<eax\>
	/// @par
	/// @c 66 o64 0F AE /6
	/// @par
	/// @c WAITPKG
	/// @par
	/// @c 64-bit
	TPAUSE_R64 = 2036,
	/// @brief @c CLRSSBSY m64
	/// @par
	/// @c F3 0F AE /6
	/// @par
	/// @c CET_SS
	/// @par
	/// @c 16/32/64-bit
	CLRSSBSY_M64 = 2037,
	/// @brief @c UMONITOR r16
	/// @par
	/// @c a16 F3 0F AE /6
	/// @par
	/// @c WAITPKG
	/// @par
	/// @c 16/32-bit
	UMONITOR_R16 = 2038,
	/// @brief @c UMONITOR r32
	/// @par
	/// @c a32 F3 0F AE /6
	/// @par
	/// @c WAITPKG
	/// @par
	/// @c 16/32/64-bit
	UMONITOR_R32 = 2039,
	/// @brief @c UMONITOR r64
	/// @par
	/// @c a64 F3 0F AE /6
	/// @par
	/// @c WAITPKG
	/// @par
	/// @c 64-bit
	UMONITOR_R64 = 2040,
	/// @brief @c UMWAIT r32, \<edx\>, \<eax\>
	/// @par
	/// @c F2 0F AE /6
	/// @par
	/// @c WAITPKG
	/// @par
	/// @c 16/32/64-bit
	UMWAIT_R32 = 2041,
	/// @brief @c UMWAIT r64, \<edx\>, \<eax\>
	/// @par
	/// @c F2 o64 0F AE /6
	/// @par
	/// @c WAITPKG
	/// @par
	/// @c 64-bit
	UMWAIT_R64 = 2042,
	/// @brief @c CLFLUSH m8
	/// @par
	/// @c NP 0F AE /7
	/// @par
	/// @c CLFSH
	/// @par
	/// @c 16/32/64-bit
	CLFLUSH_M8 = 2043,
	/// @brief @c CLFLUSHOPT m8
	/// @par
	/// @c 66 0F AE /7
	/// @par
	/// @c CLFLUSHOPT
	/// @par
	/// @c 16/32/64-bit
	CLFLUSHOPT_M8 = 2044,
	/// @brief @c LFENCE
	/// @par
	/// @c NP 0F AE E8
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	LFENCE = 2045,
	/// @brief @c LFENCE
	/// @par
	/// @c NP 0F AE E9
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	LFENCE_E9 = 2046,
	/// @brief @c LFENCE
	/// @par
	/// @c NP 0F AE EA
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	LFENCE_EA = 2047,
	/// @brief @c LFENCE
	/// @par
	/// @c NP 0F AE EB
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	LFENCE_EB = 2048,
	/// @brief @c LFENCE
	/// @par
	/// @c NP 0F AE EC
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	LFENCE_EC = 2049,
	/// @brief @c LFENCE
	/// @par
	/// @c NP 0F AE ED
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	LFENCE_ED = 2050,
	/// @brief @c LFENCE
	/// @par
	/// @c NP 0F AE EE
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	LFENCE_EE = 2051,
	/// @brief @c LFENCE
	/// @par
	/// @c NP 0F AE EF
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	LFENCE_EF = 2052,
	/// @brief @c MFENCE
	/// @par
	/// @c NP 0F AE F0
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MFENCE = 2053,
	/// @brief @c MFENCE
	/// @par
	/// @c NP 0F AE F1
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MFENCE_F1 = 2054,
	/// @brief @c MFENCE
	/// @par
	/// @c NP 0F AE F2
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MFENCE_F2 = 2055,
	/// @brief @c MFENCE
	/// @par
	/// @c NP 0F AE F3
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MFENCE_F3 = 2056,
	/// @brief @c MFENCE
	/// @par
	/// @c NP 0F AE F4
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MFENCE_F4 = 2057,
	/// @brief @c MFENCE
	/// @par
	/// @c NP 0F AE F5
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MFENCE_F5 = 2058,
	/// @brief @c MFENCE
	/// @par
	/// @c NP 0F AE F6
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MFENCE_F6 = 2059,
	/// @brief @c MFENCE
	/// @par
	/// @c NP 0F AE F7
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MFENCE_F7 = 2060,
	/// @brief @c SFENCE
	/// @par
	/// @c NP 0F AE F8
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	SFENCE = 2061,
	/// @brief @c SFENCE
	/// @par
	/// @c NP 0F AE F9
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	SFENCE_F9 = 2062,
	/// @brief @c SFENCE
	/// @par
	/// @c NP 0F AE FA
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	SFENCE_FA = 2063,
	/// @brief @c SFENCE
	/// @par
	/// @c NP 0F AE FB
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	SFENCE_FB = 2064,
	/// @brief @c SFENCE
	/// @par
	/// @c NP 0F AE FC
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	SFENCE_FC = 2065,
	/// @brief @c SFENCE
	/// @par
	/// @c NP 0F AE FD
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	SFENCE_FD = 2066,
	/// @brief @c SFENCE
	/// @par
	/// @c NP 0F AE FE
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	SFENCE_FE = 2067,
	/// @brief @c SFENCE
	/// @par
	/// @c NP 0F AE FF
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	SFENCE_FF = 2068,
	/// @brief @c PCOMMIT
	/// @par
	/// @c 66 0F AE F8
	/// @par
	/// @c PCOMMIT
	/// @par
	/// @c 16/32/64-bit
	PCOMMIT = 2069,
	/// @brief @c IMUL r16, r/m16
	/// @par
	/// @c o16 0F AF /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	IMUL_R16_RM16 = 2070,
	/// @brief @c IMUL r32, r/m32
	/// @par
	/// @c o32 0F AF /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	IMUL_R32_RM32 = 2071,
	/// @brief @c IMUL r64, r/m64
	/// @par
	/// @c o64 0F AF /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	IMUL_R64_RM64 = 2072,
	/// @brief @c CMPXCHG r/m8, r8
	/// @par
	/// @c 0F B0 /r
	/// @par
	/// @c 486+
	/// @par
	/// @c 16/32/64-bit
	CMPXCHG_RM8_R8 = 2073,
	/// @brief @c CMPXCHG r/m16, r16
	/// @par
	/// @c o16 0F B1 /r
	/// @par
	/// @c 486+
	/// @par
	/// @c 16/32/64-bit
	CMPXCHG_RM16_R16 = 2074,
	/// @brief @c CMPXCHG r/m32, r32
	/// @par
	/// @c o32 0F B1 /r
	/// @par
	/// @c 486+
	/// @par
	/// @c 16/32/64-bit
	CMPXCHG_RM32_R32 = 2075,
	/// @brief @c CMPXCHG r/m64, r64
	/// @par
	/// @c o64 0F B1 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	CMPXCHG_RM64_R64 = 2076,
	/// @brief @c LSS r16, m16:16
	/// @par
	/// @c o16 0F B2 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	LSS_R16_M1616 = 2077,
	/// @brief @c LSS r32, m16:32
	/// @par
	/// @c o32 0F B2 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	LSS_R32_M1632 = 2078,
	/// @brief @c LSS r64, m16:64
	/// @par
	/// @c o64 0F B2 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	LSS_R64_M1664 = 2079,
	/// @brief @c BTR r/m16, r16
	/// @par
	/// @c o16 0F B3 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	BTR_RM16_R16 = 2080,
	/// @brief @c BTR r/m32, r32
	/// @par
	/// @c o32 0F B3 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	BTR_RM32_R32 = 2081,
	/// @brief @c BTR r/m64, r64
	/// @par
	/// @c o64 0F B3 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	BTR_RM64_R64 = 2082,
	/// @brief @c LFS r16, m16:16
	/// @par
	/// @c o16 0F B4 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	LFS_R16_M1616 = 2083,
	/// @brief @c LFS r32, m16:32
	/// @par
	/// @c o32 0F B4 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	LFS_R32_M1632 = 2084,
	/// @brief @c LFS r64, m16:64
	/// @par
	/// @c o64 0F B4 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	LFS_R64_M1664 = 2085,
	/// @brief @c LGS r16, m16:16
	/// @par
	/// @c o16 0F B5 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	LGS_R16_M1616 = 2086,
	/// @brief @c LGS r32, m16:32
	/// @par
	/// @c o32 0F B5 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	LGS_R32_M1632 = 2087,
	/// @brief @c LGS r64, m16:64
	/// @par
	/// @c o64 0F B5 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	LGS_R64_M1664 = 2088,
	/// @brief @c MOVZX r16, r/m8
	/// @par
	/// @c o16 0F B6 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	MOVZX_R16_RM8 = 2089,
	/// @brief @c MOVZX r32, r/m8
	/// @par
	/// @c o32 0F B6 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	MOVZX_R32_RM8 = 2090,
	/// @brief @c MOVZX r64, r/m8
	/// @par
	/// @c o64 0F B6 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	MOVZX_R64_RM8 = 2091,
	/// @brief @c MOVZX r16, r/m16
	/// @par
	/// @c o16 0F B7 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	MOVZX_R16_RM16 = 2092,
	/// @brief @c MOVZX r32, r/m16
	/// @par
	/// @c o32 0F B7 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	MOVZX_R32_RM16 = 2093,
	/// @brief @c MOVZX r64, r/m16
	/// @par
	/// @c o64 0F B7 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	MOVZX_R64_RM16 = 2094,
	/// @brief @c JMPE disp16
	/// @par
	/// @c o16 0F B8 cw
	/// @par
	/// @c IA-64
	/// @par
	/// @c 16/32-bit
	JMPE_DISP16 = 2095,
	/// @brief @c JMPE disp32
	/// @par
	/// @c o32 0F B8 cd
	/// @par
	/// @c IA-64
	/// @par
	/// @c 16/32-bit
	JMPE_DISP32 = 2096,
	/// @brief @c POPCNT r16, r/m16
	/// @par
	/// @c o16 F3 0F B8 /r
	/// @par
	/// @c POPCNT
	/// @par
	/// @c 16/32/64-bit
	POPCNT_R16_RM16 = 2097,
	/// @brief @c POPCNT r32, r/m32
	/// @par
	/// @c o32 F3 0F B8 /r
	/// @par
	/// @c POPCNT
	/// @par
	/// @c 16/32/64-bit
	POPCNT_R32_RM32 = 2098,
	/// @brief @c POPCNT r64, r/m64
	/// @par
	/// @c F3 o64 0F B8 /r
	/// @par
	/// @c POPCNT
	/// @par
	/// @c 64-bit
	POPCNT_R64_RM64 = 2099,
	/// @brief @c UD1 r16, r/m16
	/// @par
	/// @c o16 0F B9 /r
	/// @par
	/// @c 286+
	/// @par
	/// @c 16/32/64-bit
	UD1_R16_RM16 = 2100,
	/// @brief @c UD1 r32, r/m32
	/// @par
	/// @c o32 0F B9 /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	UD1_R32_RM32 = 2101,
	/// @brief @c UD1 r64, r/m64
	/// @par
	/// @c o64 0F B9 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	UD1_R64_RM64 = 2102,
	/// @brief @c BT r/m16, imm8
	/// @par
	/// @c o16 0F BA /4 ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	BT_RM16_IMM8 = 2103,
	/// @brief @c BT r/m32, imm8
	/// @par
	/// @c o32 0F BA /4 ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	BT_RM32_IMM8 = 2104,
	/// @brief @c BT r/m64, imm8
	/// @par
	/// @c o64 0F BA /4 ib
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	BT_RM64_IMM8 = 2105,
	/// @brief @c BTS r/m16, imm8
	/// @par
	/// @c o16 0F BA /5 ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	BTS_RM16_IMM8 = 2106,
	/// @brief @c BTS r/m32, imm8
	/// @par
	/// @c o32 0F BA /5 ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	BTS_RM32_IMM8 = 2107,
	/// @brief @c BTS r/m64, imm8
	/// @par
	/// @c o64 0F BA /5 ib
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	BTS_RM64_IMM8 = 2108,
	/// @brief @c BTR r/m16, imm8
	/// @par
	/// @c o16 0F BA /6 ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	BTR_RM16_IMM8 = 2109,
	/// @brief @c BTR r/m32, imm8
	/// @par
	/// @c o32 0F BA /6 ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	BTR_RM32_IMM8 = 2110,
	/// @brief @c BTR r/m64, imm8
	/// @par
	/// @c o64 0F BA /6 ib
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	BTR_RM64_IMM8 = 2111,
	/// @brief @c BTC r/m16, imm8
	/// @par
	/// @c o16 0F BA /7 ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	BTC_RM16_IMM8 = 2112,
	/// @brief @c BTC r/m32, imm8
	/// @par
	/// @c o32 0F BA /7 ib
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	BTC_RM32_IMM8 = 2113,
	/// @brief @c BTC r/m64, imm8
	/// @par
	/// @c o64 0F BA /7 ib
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	BTC_RM64_IMM8 = 2114,
	/// @brief @c BTC r/m16, r16
	/// @par
	/// @c o16 0F BB /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	BTC_RM16_R16 = 2115,
	/// @brief @c BTC r/m32, r32
	/// @par
	/// @c o32 0F BB /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	BTC_RM32_R32 = 2116,
	/// @brief @c BTC r/m64, r64
	/// @par
	/// @c o64 0F BB /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	BTC_RM64_R64 = 2117,
	/// @brief @c BSF r16, r/m16
	/// @par
	/// @c o16 0F BC /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	BSF_R16_RM16 = 2118,
	/// @brief @c BSF r32, r/m32
	/// @par
	/// @c o32 0F BC /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	BSF_R32_RM32 = 2119,
	/// @brief @c BSF r64, r/m64
	/// @par
	/// @c o64 0F BC /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	BSF_R64_RM64 = 2120,
	/// @brief @c TZCNT r16, r/m16
	/// @par
	/// @c o16 F3 0F BC /r
	/// @par
	/// @c BMI1
	/// @par
	/// @c 16/32/64-bit
	TZCNT_R16_RM16 = 2121,
	/// @brief @c TZCNT r32, r/m32
	/// @par
	/// @c o32 F3 0F BC /r
	/// @par
	/// @c BMI1
	/// @par
	/// @c 16/32/64-bit
	TZCNT_R32_RM32 = 2122,
	/// @brief @c TZCNT r64, r/m64
	/// @par
	/// @c F3 o64 0F BC /r
	/// @par
	/// @c BMI1
	/// @par
	/// @c 64-bit
	TZCNT_R64_RM64 = 2123,
	/// @brief @c BSR r16, r/m16
	/// @par
	/// @c o16 0F BD /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	BSR_R16_RM16 = 2124,
	/// @brief @c BSR r32, r/m32
	/// @par
	/// @c o32 0F BD /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	BSR_R32_RM32 = 2125,
	/// @brief @c BSR r64, r/m64
	/// @par
	/// @c o64 0F BD /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	BSR_R64_RM64 = 2126,
	/// @brief @c LZCNT r16, r/m16
	/// @par
	/// @c o16 F3 0F BD /r
	/// @par
	/// @c LZCNT
	/// @par
	/// @c 16/32/64-bit
	LZCNT_R16_RM16 = 2127,
	/// @brief @c LZCNT r32, r/m32
	/// @par
	/// @c o32 F3 0F BD /r
	/// @par
	/// @c LZCNT
	/// @par
	/// @c 16/32/64-bit
	LZCNT_R32_RM32 = 2128,
	/// @brief @c LZCNT r64, r/m64
	/// @par
	/// @c F3 o64 0F BD /r
	/// @par
	/// @c LZCNT
	/// @par
	/// @c 64-bit
	LZCNT_R64_RM64 = 2129,
	/// @brief @c MOVSX r16, r/m8
	/// @par
	/// @c o16 0F BE /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	MOVSX_R16_RM8 = 2130,
	/// @brief @c MOVSX r32, r/m8
	/// @par
	/// @c o32 0F BE /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	MOVSX_R32_RM8 = 2131,
	/// @brief @c MOVSX r64, r/m8
	/// @par
	/// @c o64 0F BE /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	MOVSX_R64_RM8 = 2132,
	/// @brief @c MOVSX r16, r/m16
	/// @par
	/// @c o16 0F BF /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	MOVSX_R16_RM16 = 2133,
	/// @brief @c MOVSX r32, r/m16
	/// @par
	/// @c o32 0F BF /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	MOVSX_R32_RM16 = 2134,
	/// @brief @c MOVSX r64, r/m16
	/// @par
	/// @c o64 0F BF /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	MOVSX_R64_RM16 = 2135,
	/// @brief @c XADD r/m8, r8
	/// @par
	/// @c 0F C0 /r
	/// @par
	/// @c 486+
	/// @par
	/// @c 16/32/64-bit
	XADD_RM8_R8 = 2136,
	/// @brief @c XADD r/m16, r16
	/// @par
	/// @c o16 0F C1 /r
	/// @par
	/// @c 486+
	/// @par
	/// @c 16/32/64-bit
	XADD_RM16_R16 = 2137,
	/// @brief @c XADD r/m32, r32
	/// @par
	/// @c o32 0F C1 /r
	/// @par
	/// @c 486+
	/// @par
	/// @c 16/32/64-bit
	XADD_RM32_R32 = 2138,
	/// @brief @c XADD r/m64, r64
	/// @par
	/// @c o64 0F C1 /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	XADD_RM64_R64 = 2139,
	/// @brief @c CMPPS xmm1, xmm2/m128, imm8
	/// @par
	/// @c NP 0F C2 /r ib
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	CMPPS_XMM_XMMM128_IMM8 = 2140,
	/// @brief @c VCMPPS xmm1, xmm2, xmm3/m128, imm8
	/// @par
	/// @c VEX.128.0F.WIG C2 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCMPPS_XMM_XMM_XMMM128_IMM8 = 2141,
	/// @brief @c VCMPPS ymm1, ymm2, ymm3/m256, imm8
	/// @par
	/// @c VEX.256.0F.WIG C2 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCMPPS_YMM_YMM_YMMM256_IMM8 = 2142,
	/// @brief @c VCMPPS k1 {k2}, xmm2, xmm3/m128/m32bcst, imm8
	/// @par
	/// @c EVEX.128.0F.W0 C2 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCMPPS_KR_K1_XMM_XMMM128B32_IMM8 = 2143,
	/// @brief @c VCMPPS k1 {k2}, ymm2, ymm3/m256/m32bcst, imm8
	/// @par
	/// @c EVEX.256.0F.W0 C2 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCMPPS_KR_K1_YMM_YMMM256B32_IMM8 = 2144,
	/// @brief @c VCMPPS k1 {k2}, zmm2, zmm3/m512/m32bcst{sae}, imm8
	/// @par
	/// @c EVEX.512.0F.W0 C2 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCMPPS_KR_K1_ZMM_ZMMM512B32_IMM8_SAE = 2145,
	/// @brief @c CMPPD xmm1, xmm2/m128, imm8
	/// @par
	/// @c 66 0F C2 /r ib
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	CMPPD_XMM_XMMM128_IMM8 = 2146,
	/// @brief @c VCMPPD xmm1, xmm2, xmm3/m128, imm8
	/// @par
	/// @c VEX.128.66.0F.WIG C2 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCMPPD_XMM_XMM_XMMM128_IMM8 = 2147,
	/// @brief @c VCMPPD ymm1, ymm2, ymm3/m256, imm8
	/// @par
	/// @c VEX.256.66.0F.WIG C2 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCMPPD_YMM_YMM_YMMM256_IMM8 = 2148,
	/// @brief @c VCMPPD k1 {k2}, xmm2, xmm3/m128/m64bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F.W1 C2 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCMPPD_KR_K1_XMM_XMMM128B64_IMM8 = 2149,
	/// @brief @c VCMPPD k1 {k2}, ymm2, ymm3/m256/m64bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F.W1 C2 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCMPPD_KR_K1_YMM_YMMM256B64_IMM8 = 2150,
	/// @brief @c VCMPPD k1 {k2}, zmm2, zmm3/m512/m64bcst{sae}, imm8
	/// @par
	/// @c EVEX.512.66.0F.W1 C2 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCMPPD_KR_K1_ZMM_ZMMM512B64_IMM8_SAE = 2151,
	/// @brief @c CMPSS xmm1, xmm2/m32, imm8
	/// @par
	/// @c F3 0F C2 /r ib
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	CMPSS_XMM_XMMM32_IMM8 = 2152,
	/// @brief @c VCMPSS xmm1, xmm2, xmm3/m32, imm8
	/// @par
	/// @c VEX.LIG.F3.0F.WIG C2 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCMPSS_XMM_XMM_XMMM32_IMM8 = 2153,
	/// @brief @c VCMPSS k1 {k2}, xmm2, xmm3/m32{sae}, imm8
	/// @par
	/// @c EVEX.LIG.F3.0F.W0 C2 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCMPSS_KR_K1_XMM_XMMM32_IMM8_SAE = 2154,
	/// @brief @c CMPSD xmm1, xmm2/m64, imm8
	/// @par
	/// @c F2 0F C2 /r ib
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	CMPSD_XMM_XMMM64_IMM8 = 2155,
	/// @brief @c VCMPSD xmm1, xmm2, xmm3/m64, imm8
	/// @par
	/// @c VEX.LIG.F2.0F.WIG C2 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCMPSD_XMM_XMM_XMMM64_IMM8 = 2156,
	/// @brief @c VCMPSD k1 {k2}, xmm2, xmm3/m64{sae}, imm8
	/// @par
	/// @c EVEX.LIG.F2.0F.W1 C2 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCMPSD_KR_K1_XMM_XMMM64_IMM8_SAE = 2157,
	/// @brief @c MOVNTI m32, r32
	/// @par
	/// @c NP 0F C3 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MOVNTI_M32_R32 = 2158,
	/// @brief @c MOVNTI m64, r64
	/// @par
	/// @c NP o64 0F C3 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 64-bit
	MOVNTI_M64_R64 = 2159,
	/// @brief @c PINSRW mm, r32/m16, imm8
	/// @par
	/// @c NP 0F C4 /r ib
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	PINSRW_MM_R32M16_IMM8 = 2160,
	/// @brief @c PINSRW mm, r64/m16, imm8
	/// @par
	/// @c NP o64 0F C4 /r ib
	/// @par
	/// @c SSE
	/// @par
	/// @c 64-bit
	PINSRW_MM_R64M16_IMM8 = 2161,
	/// @brief @c PINSRW xmm, r32/m16, imm8
	/// @par
	/// @c 66 0F C4 /r ib
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PINSRW_XMM_R32M16_IMM8 = 2162,
	/// @brief @c PINSRW xmm, r64/m16, imm8
	/// @par
	/// @c 66 o64 0F C4 /r ib
	/// @par
	/// @c SSE2
	/// @par
	/// @c 64-bit
	PINSRW_XMM_R64M16_IMM8 = 2163,
	/// @brief @c VPINSRW xmm1, xmm2, r32/m16, imm8
	/// @par
	/// @c VEX.128.66.0F.W0 C4 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPINSRW_XMM_XMM_R32M16_IMM8 = 2164,
	/// @brief @c VPINSRW xmm1, xmm2, r64/m16, imm8
	/// @par
	/// @c VEX.128.66.0F.W1 C4 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 64-bit
	VEX_VPINSRW_XMM_XMM_R64M16_IMM8 = 2165,
	/// @brief @c VPINSRW xmm1, xmm2, r32/m16, imm8
	/// @par
	/// @c EVEX.128.66.0F.W0 C4 /r ib
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPINSRW_XMM_XMM_R32M16_IMM8 = 2166,
	/// @brief @c VPINSRW xmm1, xmm2, r64/m16, imm8
	/// @par
	/// @c EVEX.128.66.0F.W1 C4 /r ib
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 64-bit
	EVEX_VPINSRW_XMM_XMM_R64M16_IMM8 = 2167,
	/// @brief @c PEXTRW r32, mm, imm8
	/// @par
	/// @c NP 0F C5 /r ib
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	PEXTRW_R32_MM_IMM8 = 2168,
	/// @brief @c PEXTRW r64, mm, imm8
	/// @par
	/// @c NP o64 0F C5 /r ib
	/// @par
	/// @c SSE
	/// @par
	/// @c 64-bit
	PEXTRW_R64_MM_IMM8 = 2169,
	/// @brief @c PEXTRW r32, xmm, imm8
	/// @par
	/// @c 66 0F C5 /r ib
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PEXTRW_R32_XMM_IMM8 = 2170,
	/// @brief @c PEXTRW r64, xmm, imm8
	/// @par
	/// @c 66 o64 0F C5 /r ib
	/// @par
	/// @c SSE2
	/// @par
	/// @c 64-bit
	PEXTRW_R64_XMM_IMM8 = 2171,
	/// @brief @c VPEXTRW r32, xmm1, imm8
	/// @par
	/// @c VEX.128.66.0F.W0 C5 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPEXTRW_R32_XMM_IMM8 = 2172,
	/// @brief @c VPEXTRW r64, xmm1, imm8
	/// @par
	/// @c VEX.128.66.0F.W1 C5 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 64-bit
	VEX_VPEXTRW_R64_XMM_IMM8 = 2173,
	/// @brief @c VPEXTRW r32, xmm1, imm8
	/// @par
	/// @c EVEX.128.66.0F.W0 C5 /r ib
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPEXTRW_R32_XMM_IMM8 = 2174,
	/// @brief @c VPEXTRW r64, xmm1, imm8
	/// @par
	/// @c EVEX.128.66.0F.W1 C5 /r ib
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 64-bit
	EVEX_VPEXTRW_R64_XMM_IMM8 = 2175,
	/// @brief @c SHUFPS xmm1, xmm2/m128, imm8
	/// @par
	/// @c NP 0F C6 /r ib
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	SHUFPS_XMM_XMMM128_IMM8 = 2176,
	/// @brief @c VSHUFPS xmm1, xmm2, xmm3/m128, imm8
	/// @par
	/// @c VEX.128.0F.WIG C6 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VSHUFPS_XMM_XMM_XMMM128_IMM8 = 2177,
	/// @brief @c VSHUFPS ymm1, ymm2, ymm3/m256, imm8
	/// @par
	/// @c VEX.256.0F.WIG C6 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VSHUFPS_YMM_YMM_YMMM256_IMM8 = 2178,
	/// @brief @c VSHUFPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst, imm8
	/// @par
	/// @c EVEX.128.0F.W0 C6 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSHUFPS_XMM_K1Z_XMM_XMMM128B32_IMM8 = 2179,
	/// @brief @c VSHUFPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst, imm8
	/// @par
	/// @c EVEX.256.0F.W0 C6 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSHUFPS_YMM_K1Z_YMM_YMMM256B32_IMM8 = 2180,
	/// @brief @c VSHUFPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst, imm8
	/// @par
	/// @c EVEX.512.0F.W0 C6 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSHUFPS_ZMM_K1Z_ZMM_ZMMM512B32_IMM8 = 2181,
	/// @brief @c SHUFPD xmm1, xmm2/m128, imm8
	/// @par
	/// @c 66 0F C6 /r ib
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	SHUFPD_XMM_XMMM128_IMM8 = 2182,
	/// @brief @c VSHUFPD xmm1, xmm2, xmm3/m128, imm8
	/// @par
	/// @c VEX.128.66.0F.WIG C6 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VSHUFPD_XMM_XMM_XMMM128_IMM8 = 2183,
	/// @brief @c VSHUFPD ymm1, ymm2, ymm3/m256, imm8
	/// @par
	/// @c VEX.256.66.0F.WIG C6 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VSHUFPD_YMM_YMM_YMMM256_IMM8 = 2184,
	/// @brief @c VSHUFPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F.W1 C6 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSHUFPD_XMM_K1Z_XMM_XMMM128B64_IMM8 = 2185,
	/// @brief @c VSHUFPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F.W1 C6 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSHUFPD_YMM_K1Z_YMM_YMMM256B64_IMM8 = 2186,
	/// @brief @c VSHUFPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F.W1 C6 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSHUFPD_ZMM_K1Z_ZMM_ZMMM512B64_IMM8 = 2187,
	/// @brief @c CMPXCHG8B m64
	/// @par
	/// @c 0F C7 /1
	/// @par
	/// @c CX8
	/// @par
	/// @c 16/32/64-bit
	CMPXCHG8B_M64 = 2188,
	/// @brief @c CMPXCHG16B m128
	/// @par
	/// @c o64 0F C7 /1
	/// @par
	/// @c CMPXCHG16B
	/// @par
	/// @c 64-bit
	CMPXCHG16B_M128 = 2189,
	/// @brief @c XRSTORS mem
	/// @par
	/// @c NP 0F C7 /3
	/// @par
	/// @c XSAVES
	/// @par
	/// @c 16/32/64-bit
	XRSTORS_MEM = 2190,
	/// @brief @c XRSTORS64 mem
	/// @par
	/// @c NP o64 0F C7 /3
	/// @par
	/// @c XSAVES
	/// @par
	/// @c 64-bit
	XRSTORS64_MEM = 2191,
	/// @brief @c XSAVEC mem
	/// @par
	/// @c NP 0F C7 /4
	/// @par
	/// @c XSAVEC
	/// @par
	/// @c 16/32/64-bit
	XSAVEC_MEM = 2192,
	/// @brief @c XSAVEC64 mem
	/// @par
	/// @c NP o64 0F C7 /4
	/// @par
	/// @c XSAVEC
	/// @par
	/// @c 64-bit
	XSAVEC64_MEM = 2193,
	/// @brief @c XSAVES mem
	/// @par
	/// @c NP 0F C7 /5
	/// @par
	/// @c XSAVES
	/// @par
	/// @c 16/32/64-bit
	XSAVES_MEM = 2194,
	/// @brief @c XSAVES64 mem
	/// @par
	/// @c NP o64 0F C7 /5
	/// @par
	/// @c XSAVES
	/// @par
	/// @c 64-bit
	XSAVES64_MEM = 2195,
	/// @brief @c VMPTRLD m64
	/// @par
	/// @c NP 0F C7 /6
	/// @par
	/// @c VMX
	/// @par
	/// @c 16/32/64-bit
	VMPTRLD_M64 = 2196,
	/// @brief @c VMCLEAR m64
	/// @par
	/// @c 66 0F C7 /6
	/// @par
	/// @c VMX
	/// @par
	/// @c 16/32/64-bit
	VMCLEAR_M64 = 2197,
	/// @brief @c VMXON m64
	/// @par
	/// @c F3 0F C7 /6
	/// @par
	/// @c VMX
	/// @par
	/// @c 16/32/64-bit
	VMXON_M64 = 2198,
	/// @brief @c RDRAND r16
	/// @par
	/// @c o16 0F C7 /6
	/// @par
	/// @c RDRAND
	/// @par
	/// @c 16/32/64-bit
	RDRAND_R16 = 2199,
	/// @brief @c RDRAND r32
	/// @par
	/// @c o32 0F C7 /6
	/// @par
	/// @c RDRAND
	/// @par
	/// @c 16/32/64-bit
	RDRAND_R32 = 2200,
	/// @brief @c RDRAND r64
	/// @par
	/// @c o64 0F C7 /6
	/// @par
	/// @c RDRAND
	/// @par
	/// @c 64-bit
	RDRAND_R64 = 2201,
	/// @brief @c VMPTRST m64
	/// @par
	/// @c NP 0F C7 /7
	/// @par
	/// @c VMX
	/// @par
	/// @c 16/32/64-bit
	VMPTRST_M64 = 2202,
	/// @brief @c RDSEED r16
	/// @par
	/// @c o16 0F C7 /7
	/// @par
	/// @c RDSEED
	/// @par
	/// @c 16/32/64-bit
	RDSEED_R16 = 2203,
	/// @brief @c RDSEED r32
	/// @par
	/// @c o32 0F C7 /7
	/// @par
	/// @c RDSEED
	/// @par
	/// @c 16/32/64-bit
	RDSEED_R32 = 2204,
	/// @brief @c RDSEED r64
	/// @par
	/// @c o64 0F C7 /7
	/// @par
	/// @c RDSEED
	/// @par
	/// @c 64-bit
	RDSEED_R64 = 2205,
	/// @brief @c RDPID r32
	/// @par
	/// @c F3 0F C7 /7
	/// @par
	/// @c RDPID
	/// @par
	/// @c 16/32-bit
	RDPID_R32 = 2206,
	/// @brief @c RDPID r64
	/// @par
	/// @c F3 0F C7 /7
	/// @par
	/// @c RDPID
	/// @par
	/// @c 64-bit
	RDPID_R64 = 2207,
	/// @brief @c BSWAP r16
	/// @par
	/// @c o16 0F C8+rw
	/// @par
	/// @c 486+
	/// @par
	/// @c 16/32/64-bit
	BSWAP_R16 = 2208,
	/// @brief @c BSWAP r32
	/// @par
	/// @c o32 0F C8+rd
	/// @par
	/// @c 486+
	/// @par
	/// @c 16/32/64-bit
	BSWAP_R32 = 2209,
	/// @brief @c BSWAP r64
	/// @par
	/// @c o64 0F C8+ro
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	BSWAP_R64 = 2210,
	/// @brief @c ADDSUBPD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F D0 /r
	/// @par
	/// @c SSE3
	/// @par
	/// @c 16/32/64-bit
	ADDSUBPD_XMM_XMMM128 = 2211,
	/// @brief @c VADDSUBPD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG D0 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VADDSUBPD_XMM_XMM_XMMM128 = 2212,
	/// @brief @c VADDSUBPD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG D0 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VADDSUBPD_YMM_YMM_YMMM256 = 2213,
	/// @brief @c ADDSUBPS xmm1, xmm2/m128
	/// @par
	/// @c F2 0F D0 /r
	/// @par
	/// @c SSE3
	/// @par
	/// @c 16/32/64-bit
	ADDSUBPS_XMM_XMMM128 = 2214,
	/// @brief @c VADDSUBPS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.F2.0F.WIG D0 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VADDSUBPS_XMM_XMM_XMMM128 = 2215,
	/// @brief @c VADDSUBPS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.F2.0F.WIG D0 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VADDSUBPS_YMM_YMM_YMMM256 = 2216,
	/// @brief @c PSRLW mm, mm/m64
	/// @par
	/// @c NP 0F D1 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PSRLW_MM_MMM64 = 2217,
	/// @brief @c PSRLW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F D1 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSRLW_XMM_XMMM128 = 2218,
	/// @brief @c VPSRLW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG D1 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSRLW_XMM_XMM_XMMM128 = 2219,
	/// @brief @c VPSRLW ymm1, ymm2, xmm3/m128
	/// @par
	/// @c VEX.256.66.0F.WIG D1 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSRLW_YMM_YMM_XMMM128 = 2220,
	/// @brief @c VPSRLW xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG D1 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRLW_XMM_K1Z_XMM_XMMM128 = 2221,
	/// @brief @c VPSRLW ymm1 {k1}{z}, ymm2, xmm3/m128
	/// @par
	/// @c EVEX.256.66.0F.WIG D1 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRLW_YMM_K1Z_YMM_XMMM128 = 2222,
	/// @brief @c VPSRLW zmm1 {k1}{z}, zmm2, xmm3/m128
	/// @par
	/// @c EVEX.512.66.0F.WIG D1 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRLW_ZMM_K1Z_ZMM_XMMM128 = 2223,
	/// @brief @c PSRLD mm, mm/m64
	/// @par
	/// @c NP 0F D2 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PSRLD_MM_MMM64 = 2224,
	/// @brief @c PSRLD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F D2 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSRLD_XMM_XMMM128 = 2225,
	/// @brief @c VPSRLD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG D2 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSRLD_XMM_XMM_XMMM128 = 2226,
	/// @brief @c VPSRLD ymm1, ymm2, xmm3/m128
	/// @par
	/// @c VEX.256.66.0F.WIG D2 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSRLD_YMM_YMM_XMMM128 = 2227,
	/// @brief @c VPSRLD xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.W0 D2 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRLD_XMM_K1Z_XMM_XMMM128 = 2228,
	/// @brief @c VPSRLD ymm1 {k1}{z}, ymm2, xmm3/m128
	/// @par
	/// @c EVEX.256.66.0F.W0 D2 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRLD_YMM_K1Z_YMM_XMMM128 = 2229,
	/// @brief @c VPSRLD zmm1 {k1}{z}, zmm2, xmm3/m128
	/// @par
	/// @c EVEX.512.66.0F.W0 D2 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRLD_ZMM_K1Z_ZMM_XMMM128 = 2230,
	/// @brief @c PSRLQ mm, mm/m64
	/// @par
	/// @c NP 0F D3 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PSRLQ_MM_MMM64 = 2231,
	/// @brief @c PSRLQ xmm1, xmm2/m128
	/// @par
	/// @c 66 0F D3 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSRLQ_XMM_XMMM128 = 2232,
	/// @brief @c VPSRLQ xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG D3 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSRLQ_XMM_XMM_XMMM128 = 2233,
	/// @brief @c VPSRLQ ymm1, ymm2, xmm3/m128
	/// @par
	/// @c VEX.256.66.0F.WIG D3 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSRLQ_YMM_YMM_XMMM128 = 2234,
	/// @brief @c VPSRLQ xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.W1 D3 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRLQ_XMM_K1Z_XMM_XMMM128 = 2235,
	/// @brief @c VPSRLQ ymm1 {k1}{z}, ymm2, xmm3/m128
	/// @par
	/// @c EVEX.256.66.0F.W1 D3 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRLQ_YMM_K1Z_YMM_XMMM128 = 2236,
	/// @brief @c VPSRLQ zmm1 {k1}{z}, zmm2, xmm3/m128
	/// @par
	/// @c EVEX.512.66.0F.W1 D3 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRLQ_ZMM_K1Z_ZMM_XMMM128 = 2237,
	/// @brief @c PADDQ mm, mm/m64
	/// @par
	/// @c NP 0F D4 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PADDQ_MM_MMM64 = 2238,
	/// @brief @c PADDQ xmm1, xmm2/m128
	/// @par
	/// @c 66 0F D4 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PADDQ_XMM_XMMM128 = 2239,
	/// @brief @c VPADDQ xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG D4 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPADDQ_XMM_XMM_XMMM128 = 2240,
	/// @brief @c VPADDQ ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG D4 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPADDQ_YMM_YMM_YMMM256 = 2241,
	/// @brief @c VPADDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F.W1 D4 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPADDQ_XMM_K1Z_XMM_XMMM128B64 = 2242,
	/// @brief @c VPADDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F.W1 D4 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPADDQ_YMM_K1Z_YMM_YMMM256B64 = 2243,
	/// @brief @c VPADDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F.W1 D4 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPADDQ_ZMM_K1Z_ZMM_ZMMM512B64 = 2244,
	/// @brief @c PMULLW mm, mm/m64
	/// @par
	/// @c NP 0F D5 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PMULLW_MM_MMM64 = 2245,
	/// @brief @c PMULLW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F D5 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PMULLW_XMM_XMMM128 = 2246,
	/// @brief @c VPMULLW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG D5 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMULLW_XMM_XMM_XMMM128 = 2247,
	/// @brief @c VPMULLW ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG D5 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMULLW_YMM_YMM_YMMM256 = 2248,
	/// @brief @c VPMULLW xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG D5 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMULLW_XMM_K1Z_XMM_XMMM128 = 2249,
	/// @brief @c VPMULLW ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG D5 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMULLW_YMM_K1Z_YMM_YMMM256 = 2250,
	/// @brief @c VPMULLW zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG D5 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMULLW_ZMM_K1Z_ZMM_ZMMM512 = 2251,
	/// @brief @c MOVQ xmm2/m64, xmm1
	/// @par
	/// @c 66 0F D6 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MOVQ_XMMM64_XMM = 2252,
	/// @brief @c VMOVQ xmm1/m64, xmm2
	/// @par
	/// @c VEX.128.66.0F.WIG D6 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVQ_XMMM64_XMM = 2253,
	/// @brief @c VMOVQ xmm1/m64, xmm2
	/// @par
	/// @c EVEX.128.66.0F.W1 D6 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVQ_XMMM64_XMM = 2254,
	/// @brief @c MOVQ2DQ xmm, mm
	/// @par
	/// @c F3 0F D6 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MOVQ2DQ_XMM_MM = 2255,
	/// @brief @c MOVDQ2Q mm, xmm
	/// @par
	/// @c F2 0F D6 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MOVDQ2Q_MM_XMM = 2256,
	/// @brief @c PMOVMSKB r32, mm
	/// @par
	/// @c NP 0F D7 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	PMOVMSKB_R32_MM = 2257,
	/// @brief @c PMOVMSKB r64, mm
	/// @par
	/// @c NP o64 0F D7 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 64-bit
	PMOVMSKB_R64_MM = 2258,
	/// @brief @c PMOVMSKB r32, xmm
	/// @par
	/// @c 66 0F D7 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PMOVMSKB_R32_XMM = 2259,
	/// @brief @c PMOVMSKB r64, xmm
	/// @par
	/// @c 66 o64 0F D7 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 64-bit
	PMOVMSKB_R64_XMM = 2260,
	/// @brief @c VPMOVMSKB r32, xmm1
	/// @par
	/// @c VEX.128.66.0F.W0 D7 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMOVMSKB_R32_XMM = 2261,
	/// @brief @c VPMOVMSKB r64, xmm1
	/// @par
	/// @c VEX.128.66.0F.W1 D7 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 64-bit
	VEX_VPMOVMSKB_R64_XMM = 2262,
	/// @brief @c VPMOVMSKB r32, ymm1
	/// @par
	/// @c VEX.256.66.0F.W0 D7 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMOVMSKB_R32_YMM = 2263,
	/// @brief @c VPMOVMSKB r64, ymm1
	/// @par
	/// @c VEX.256.66.0F.W1 D7 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 64-bit
	VEX_VPMOVMSKB_R64_YMM = 2264,
	/// @brief @c PSUBUSB mm, mm/m64
	/// @par
	/// @c NP 0F D8 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PSUBUSB_MM_MMM64 = 2265,
	/// @brief @c PSUBUSB xmm1, xmm2/m128
	/// @par
	/// @c 66 0F D8 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSUBUSB_XMM_XMMM128 = 2266,
	/// @brief @c VPSUBUSB xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG D8 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSUBUSB_XMM_XMM_XMMM128 = 2267,
	/// @brief @c VPSUBUSB ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG D8 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSUBUSB_YMM_YMM_YMMM256 = 2268,
	/// @brief @c VPSUBUSB xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG D8 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSUBUSB_XMM_K1Z_XMM_XMMM128 = 2269,
	/// @brief @c VPSUBUSB ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG D8 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSUBUSB_YMM_K1Z_YMM_YMMM256 = 2270,
	/// @brief @c VPSUBUSB zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG D8 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSUBUSB_ZMM_K1Z_ZMM_ZMMM512 = 2271,
	/// @brief @c PSUBUSW mm, mm/m64
	/// @par
	/// @c NP 0F D9 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PSUBUSW_MM_MMM64 = 2272,
	/// @brief @c PSUBUSW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F D9 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSUBUSW_XMM_XMMM128 = 2273,
	/// @brief @c VPSUBUSW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG D9 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSUBUSW_XMM_XMM_XMMM128 = 2274,
	/// @brief @c VPSUBUSW ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG D9 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSUBUSW_YMM_YMM_YMMM256 = 2275,
	/// @brief @c VPSUBUSW xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG D9 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSUBUSW_XMM_K1Z_XMM_XMMM128 = 2276,
	/// @brief @c VPSUBUSW ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG D9 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSUBUSW_YMM_K1Z_YMM_YMMM256 = 2277,
	/// @brief @c VPSUBUSW zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG D9 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSUBUSW_ZMM_K1Z_ZMM_ZMMM512 = 2278,
	/// @brief @c PMINUB mm1, mm2/m64
	/// @par
	/// @c NP 0F DA /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	PMINUB_MM_MMM64 = 2279,
	/// @brief @c PMINUB xmm1, xmm2/m128
	/// @par
	/// @c 66 0F DA /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PMINUB_XMM_XMMM128 = 2280,
	/// @brief @c VPMINUB xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG DA /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMINUB_XMM_XMM_XMMM128 = 2281,
	/// @brief @c VPMINUB ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG DA /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMINUB_YMM_YMM_YMMM256 = 2282,
	/// @brief @c VPMINUB xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG DA /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMINUB_XMM_K1Z_XMM_XMMM128 = 2283,
	/// @brief @c VPMINUB ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG DA /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMINUB_YMM_K1Z_YMM_YMMM256 = 2284,
	/// @brief @c VPMINUB zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG DA /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMINUB_ZMM_K1Z_ZMM_ZMMM512 = 2285,
	/// @brief @c PAND mm, mm/m64
	/// @par
	/// @c NP 0F DB /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PAND_MM_MMM64 = 2286,
	/// @brief @c PAND xmm1, xmm2/m128
	/// @par
	/// @c 66 0F DB /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PAND_XMM_XMMM128 = 2287,
	/// @brief @c VPAND xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG DB /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPAND_XMM_XMM_XMMM128 = 2288,
	/// @brief @c VPAND ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG DB /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPAND_YMM_YMM_YMMM256 = 2289,
	/// @brief @c VPANDD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F.W0 DB /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPANDD_XMM_K1Z_XMM_XMMM128B32 = 2290,
	/// @brief @c VPANDD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F.W0 DB /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPANDD_YMM_K1Z_YMM_YMMM256B32 = 2291,
	/// @brief @c VPANDD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F.W0 DB /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPANDD_ZMM_K1Z_ZMM_ZMMM512B32 = 2292,
	/// @brief @c VPANDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F.W1 DB /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPANDQ_XMM_K1Z_XMM_XMMM128B64 = 2293,
	/// @brief @c VPANDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F.W1 DB /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPANDQ_YMM_K1Z_YMM_YMMM256B64 = 2294,
	/// @brief @c VPANDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F.W1 DB /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPANDQ_ZMM_K1Z_ZMM_ZMMM512B64 = 2295,
	/// @brief @c PADDUSB mm, mm/m64
	/// @par
	/// @c NP 0F DC /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PADDUSB_MM_MMM64 = 2296,
	/// @brief @c PADDUSB xmm1, xmm2/m128
	/// @par
	/// @c 66 0F DC /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PADDUSB_XMM_XMMM128 = 2297,
	/// @brief @c VPADDUSB xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG DC /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPADDUSB_XMM_XMM_XMMM128 = 2298,
	/// @brief @c VPADDUSB ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG DC /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPADDUSB_YMM_YMM_YMMM256 = 2299,
	/// @brief @c VPADDUSB xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG DC /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPADDUSB_XMM_K1Z_XMM_XMMM128 = 2300,
	/// @brief @c VPADDUSB ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG DC /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPADDUSB_YMM_K1Z_YMM_YMMM256 = 2301,
	/// @brief @c VPADDUSB zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG DC /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPADDUSB_ZMM_K1Z_ZMM_ZMMM512 = 2302,
	/// @brief @c PADDUSW mm, mm/m64
	/// @par
	/// @c NP 0F DD /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PADDUSW_MM_MMM64 = 2303,
	/// @brief @c PADDUSW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F DD /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PADDUSW_XMM_XMMM128 = 2304,
	/// @brief @c VPADDUSW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG DD /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPADDUSW_XMM_XMM_XMMM128 = 2305,
	/// @brief @c VPADDUSW ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG DD /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPADDUSW_YMM_YMM_YMMM256 = 2306,
	/// @brief @c VPADDUSW xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG DD /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPADDUSW_XMM_K1Z_XMM_XMMM128 = 2307,
	/// @brief @c VPADDUSW ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG DD /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPADDUSW_YMM_K1Z_YMM_YMMM256 = 2308,
	/// @brief @c VPADDUSW zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG DD /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPADDUSW_ZMM_K1Z_ZMM_ZMMM512 = 2309,
	/// @brief @c PMAXUB mm1, mm2/m64
	/// @par
	/// @c NP 0F DE /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	PMAXUB_MM_MMM64 = 2310,
	/// @brief @c PMAXUB xmm1, xmm2/m128
	/// @par
	/// @c 66 0F DE /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PMAXUB_XMM_XMMM128 = 2311,
	/// @brief @c VPMAXUB xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG DE /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMAXUB_XMM_XMM_XMMM128 = 2312,
	/// @brief @c VPMAXUB ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG DE /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMAXUB_YMM_YMM_YMMM256 = 2313,
	/// @brief @c VPMAXUB xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG DE /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMAXUB_XMM_K1Z_XMM_XMMM128 = 2314,
	/// @brief @c VPMAXUB ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG DE /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMAXUB_YMM_K1Z_YMM_YMMM256 = 2315,
	/// @brief @c VPMAXUB zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG DE /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMAXUB_ZMM_K1Z_ZMM_ZMMM512 = 2316,
	/// @brief @c PANDN mm, mm/m64
	/// @par
	/// @c NP 0F DF /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PANDN_MM_MMM64 = 2317,
	/// @brief @c PANDN xmm1, xmm2/m128
	/// @par
	/// @c 66 0F DF /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PANDN_XMM_XMMM128 = 2318,
	/// @brief @c VPANDN xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG DF /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPANDN_XMM_XMM_XMMM128 = 2319,
	/// @brief @c VPANDN ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG DF /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPANDN_YMM_YMM_YMMM256 = 2320,
	/// @brief @c VPANDND xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F.W0 DF /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPANDND_XMM_K1Z_XMM_XMMM128B32 = 2321,
	/// @brief @c VPANDND ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F.W0 DF /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPANDND_YMM_K1Z_YMM_YMMM256B32 = 2322,
	/// @brief @c VPANDND zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F.W0 DF /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPANDND_ZMM_K1Z_ZMM_ZMMM512B32 = 2323,
	/// @brief @c VPANDNQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F.W1 DF /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPANDNQ_XMM_K1Z_XMM_XMMM128B64 = 2324,
	/// @brief @c VPANDNQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F.W1 DF /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPANDNQ_YMM_K1Z_YMM_YMMM256B64 = 2325,
	/// @brief @c VPANDNQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F.W1 DF /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPANDNQ_ZMM_K1Z_ZMM_ZMMM512B64 = 2326,
	/// @brief @c PAVGB mm1, mm2/m64
	/// @par
	/// @c NP 0F E0 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	PAVGB_MM_MMM64 = 2327,
	/// @brief @c PAVGB xmm1, xmm2/m128
	/// @par
	/// @c 66 0F E0 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PAVGB_XMM_XMMM128 = 2328,
	/// @brief @c VPAVGB xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG E0 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPAVGB_XMM_XMM_XMMM128 = 2329,
	/// @brief @c VPAVGB ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG E0 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPAVGB_YMM_YMM_YMMM256 = 2330,
	/// @brief @c VPAVGB xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG E0 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPAVGB_XMM_K1Z_XMM_XMMM128 = 2331,
	/// @brief @c VPAVGB ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG E0 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPAVGB_YMM_K1Z_YMM_YMMM256 = 2332,
	/// @brief @c VPAVGB zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG E0 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPAVGB_ZMM_K1Z_ZMM_ZMMM512 = 2333,
	/// @brief @c PSRAW mm, mm/m64
	/// @par
	/// @c NP 0F E1 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PSRAW_MM_MMM64 = 2334,
	/// @brief @c PSRAW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F E1 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSRAW_XMM_XMMM128 = 2335,
	/// @brief @c VPSRAW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG E1 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSRAW_XMM_XMM_XMMM128 = 2336,
	/// @brief @c VPSRAW ymm1, ymm2, xmm3/m128
	/// @par
	/// @c VEX.256.66.0F.WIG E1 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSRAW_YMM_YMM_XMMM128 = 2337,
	/// @brief @c VPSRAW xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG E1 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRAW_XMM_K1Z_XMM_XMMM128 = 2338,
	/// @brief @c VPSRAW ymm1 {k1}{z}, ymm2, xmm3/m128
	/// @par
	/// @c EVEX.256.66.0F.WIG E1 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRAW_YMM_K1Z_YMM_XMMM128 = 2339,
	/// @brief @c VPSRAW zmm1 {k1}{z}, zmm2, xmm3/m128
	/// @par
	/// @c EVEX.512.66.0F.WIG E1 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRAW_ZMM_K1Z_ZMM_XMMM128 = 2340,
	/// @brief @c PSRAD mm, mm/m64
	/// @par
	/// @c NP 0F E2 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PSRAD_MM_MMM64 = 2341,
	/// @brief @c PSRAD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F E2 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSRAD_XMM_XMMM128 = 2342,
	/// @brief @c VPSRAD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG E2 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSRAD_XMM_XMM_XMMM128 = 2343,
	/// @brief @c VPSRAD ymm1, ymm2, xmm3/m128
	/// @par
	/// @c VEX.256.66.0F.WIG E2 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSRAD_YMM_YMM_XMMM128 = 2344,
	/// @brief @c VPSRAD xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.W0 E2 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRAD_XMM_K1Z_XMM_XMMM128 = 2345,
	/// @brief @c VPSRAD ymm1 {k1}{z}, ymm2, xmm3/m128
	/// @par
	/// @c EVEX.256.66.0F.W0 E2 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRAD_YMM_K1Z_YMM_XMMM128 = 2346,
	/// @brief @c VPSRAD zmm1 {k1}{z}, zmm2, xmm3/m128
	/// @par
	/// @c EVEX.512.66.0F.W0 E2 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRAD_ZMM_K1Z_ZMM_XMMM128 = 2347,
	/// @brief @c VPSRAQ xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.W1 E2 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRAQ_XMM_K1Z_XMM_XMMM128 = 2348,
	/// @brief @c VPSRAQ ymm1 {k1}{z}, ymm2, xmm3/m128
	/// @par
	/// @c EVEX.256.66.0F.W1 E2 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRAQ_YMM_K1Z_YMM_XMMM128 = 2349,
	/// @brief @c VPSRAQ zmm1 {k1}{z}, zmm2, xmm3/m128
	/// @par
	/// @c EVEX.512.66.0F.W1 E2 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRAQ_ZMM_K1Z_ZMM_XMMM128 = 2350,
	/// @brief @c PAVGW mm1, mm2/m64
	/// @par
	/// @c NP 0F E3 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	PAVGW_MM_MMM64 = 2351,
	/// @brief @c PAVGW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F E3 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PAVGW_XMM_XMMM128 = 2352,
	/// @brief @c VPAVGW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG E3 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPAVGW_XMM_XMM_XMMM128 = 2353,
	/// @brief @c VPAVGW ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG E3 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPAVGW_YMM_YMM_YMMM256 = 2354,
	/// @brief @c VPAVGW xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG E3 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPAVGW_XMM_K1Z_XMM_XMMM128 = 2355,
	/// @brief @c VPAVGW ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG E3 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPAVGW_YMM_K1Z_YMM_YMMM256 = 2356,
	/// @brief @c VPAVGW zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG E3 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPAVGW_ZMM_K1Z_ZMM_ZMMM512 = 2357,
	/// @brief @c PMULHUW mm1, mm2/m64
	/// @par
	/// @c NP 0F E4 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	PMULHUW_MM_MMM64 = 2358,
	/// @brief @c PMULHUW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F E4 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PMULHUW_XMM_XMMM128 = 2359,
	/// @brief @c VPMULHUW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG E4 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMULHUW_XMM_XMM_XMMM128 = 2360,
	/// @brief @c VPMULHUW ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG E4 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMULHUW_YMM_YMM_YMMM256 = 2361,
	/// @brief @c VPMULHUW xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG E4 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMULHUW_XMM_K1Z_XMM_XMMM128 = 2362,
	/// @brief @c VPMULHUW ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG E4 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMULHUW_YMM_K1Z_YMM_YMMM256 = 2363,
	/// @brief @c VPMULHUW zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG E4 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMULHUW_ZMM_K1Z_ZMM_ZMMM512 = 2364,
	/// @brief @c PMULHW mm, mm/m64
	/// @par
	/// @c NP 0F E5 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PMULHW_MM_MMM64 = 2365,
	/// @brief @c PMULHW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F E5 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PMULHW_XMM_XMMM128 = 2366,
	/// @brief @c VPMULHW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG E5 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMULHW_XMM_XMM_XMMM128 = 2367,
	/// @brief @c VPMULHW ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG E5 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMULHW_YMM_YMM_YMMM256 = 2368,
	/// @brief @c VPMULHW xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG E5 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMULHW_XMM_K1Z_XMM_XMMM128 = 2369,
	/// @brief @c VPMULHW ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG E5 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMULHW_YMM_K1Z_YMM_YMMM256 = 2370,
	/// @brief @c VPMULHW zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG E5 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMULHW_ZMM_K1Z_ZMM_ZMMM512 = 2371,
	/// @brief @c CVTTPD2DQ xmm1, xmm2/m128
	/// @par
	/// @c 66 0F E6 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	CVTTPD2DQ_XMM_XMMM128 = 2372,
	/// @brief @c VCVTTPD2DQ xmm1, xmm2/m128
	/// @par
	/// @c VEX.128.66.0F.WIG E6 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTTPD2DQ_XMM_XMMM128 = 2373,
	/// @brief @c VCVTTPD2DQ xmm1, ymm2/m256
	/// @par
	/// @c VEX.256.66.0F.WIG E6 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTTPD2DQ_XMM_YMMM256 = 2374,
	/// @brief @c VCVTTPD2DQ xmm1 {k1}{z}, xmm2/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F.W1 E6 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPD2DQ_XMM_K1Z_XMMM128B64 = 2375,
	/// @brief @c VCVTTPD2DQ xmm1 {k1}{z}, ymm2/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F.W1 E6 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPD2DQ_XMM_K1Z_YMMM256B64 = 2376,
	/// @brief @c VCVTTPD2DQ ymm1 {k1}{z}, zmm2/m512/m64bcst{sae}
	/// @par
	/// @c EVEX.512.66.0F.W1 E6 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPD2DQ_YMM_K1Z_ZMMM512B64_SAE = 2377,
	/// @brief @c CVTDQ2PD xmm1, xmm2/m64
	/// @par
	/// @c F3 0F E6 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	CVTDQ2PD_XMM_XMMM64 = 2378,
	/// @brief @c VCVTDQ2PD xmm1, xmm2/m64
	/// @par
	/// @c VEX.128.F3.0F.WIG E6 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTDQ2PD_XMM_XMMM64 = 2379,
	/// @brief @c VCVTDQ2PD ymm1, xmm2/m128
	/// @par
	/// @c VEX.256.F3.0F.WIG E6 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTDQ2PD_YMM_XMMM128 = 2380,
	/// @brief @c VCVTDQ2PD xmm1 {k1}{z}, xmm2/m64/m32bcst
	/// @par
	/// @c EVEX.128.F3.0F.W0 E6 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTDQ2PD_XMM_K1Z_XMMM64B32 = 2381,
	/// @brief @c VCVTDQ2PD ymm1 {k1}{z}, xmm2/m128/m32bcst
	/// @par
	/// @c EVEX.256.F3.0F.W0 E6 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTDQ2PD_YMM_K1Z_XMMM128B32 = 2382,
	/// @brief @c VCVTDQ2PD zmm1 {k1}{z}, ymm2/m256/m32bcst{er}
	/// @par
	/// @c EVEX.512.F3.0F.W0 E6 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTDQ2PD_ZMM_K1Z_YMMM256B32_ER = 2383,
	/// @brief @c VCVTQQ2PD xmm1 {k1}{z}, xmm2/m128/m64bcst
	/// @par
	/// @c EVEX.128.F3.0F.W1 E6 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTQQ2PD_XMM_K1Z_XMMM128B64 = 2384,
	/// @brief @c VCVTQQ2PD ymm1 {k1}{z}, ymm2/m256/m64bcst
	/// @par
	/// @c EVEX.256.F3.0F.W1 E6 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTQQ2PD_YMM_K1Z_YMMM256B64 = 2385,
	/// @brief @c VCVTQQ2PD zmm1 {k1}{z}, zmm2/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.F3.0F.W1 E6 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTQQ2PD_ZMM_K1Z_ZMMM512B64_ER = 2386,
	/// @brief @c CVTPD2DQ xmm1, xmm2/m128
	/// @par
	/// @c F2 0F E6 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	CVTPD2DQ_XMM_XMMM128 = 2387,
	/// @brief @c VCVTPD2DQ xmm1, xmm2/m128
	/// @par
	/// @c VEX.128.F2.0F.WIG E6 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTPD2DQ_XMM_XMMM128 = 2388,
	/// @brief @c VCVTPD2DQ xmm1, ymm2/m256
	/// @par
	/// @c VEX.256.F2.0F.WIG E6 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTPD2DQ_XMM_YMMM256 = 2389,
	/// @brief @c VCVTPD2DQ xmm1 {k1}{z}, xmm2/m128/m64bcst
	/// @par
	/// @c EVEX.128.F2.0F.W1 E6 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPD2DQ_XMM_K1Z_XMMM128B64 = 2390,
	/// @brief @c VCVTPD2DQ xmm1 {k1}{z}, ymm2/m256/m64bcst
	/// @par
	/// @c EVEX.256.F2.0F.W1 E6 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPD2DQ_XMM_K1Z_YMMM256B64 = 2391,
	/// @brief @c VCVTPD2DQ ymm1 {k1}{z}, zmm2/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.F2.0F.W1 E6 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPD2DQ_YMM_K1Z_ZMMM512B64_ER = 2392,
	/// @brief @c MOVNTQ m64, mm
	/// @par
	/// @c NP 0F E7 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	MOVNTQ_M64_MM = 2393,
	/// @brief @c MOVNTDQ m128, xmm1
	/// @par
	/// @c 66 0F E7 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MOVNTDQ_M128_XMM = 2394,
	/// @brief @c VMOVNTDQ m128, xmm1
	/// @par
	/// @c VEX.128.66.0F.WIG E7 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVNTDQ_M128_XMM = 2395,
	/// @brief @c VMOVNTDQ m256, ymm1
	/// @par
	/// @c VEX.256.66.0F.WIG E7 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVNTDQ_M256_YMM = 2396,
	/// @brief @c VMOVNTDQ m128, xmm1
	/// @par
	/// @c EVEX.128.66.0F.W0 E7 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVNTDQ_M128_XMM = 2397,
	/// @brief @c VMOVNTDQ m256, ymm1
	/// @par
	/// @c EVEX.256.66.0F.W0 E7 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVNTDQ_M256_YMM = 2398,
	/// @brief @c VMOVNTDQ m512, zmm1
	/// @par
	/// @c EVEX.512.66.0F.W0 E7 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVNTDQ_M512_ZMM = 2399,
	/// @brief @c PSUBSB mm, mm/m64
	/// @par
	/// @c NP 0F E8 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PSUBSB_MM_MMM64 = 2400,
	/// @brief @c PSUBSB xmm1, xmm2/m128
	/// @par
	/// @c 66 0F E8 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSUBSB_XMM_XMMM128 = 2401,
	/// @brief @c VPSUBSB xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG E8 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSUBSB_XMM_XMM_XMMM128 = 2402,
	/// @brief @c VPSUBSB ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG E8 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSUBSB_YMM_YMM_YMMM256 = 2403,
	/// @brief @c VPSUBSB xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG E8 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSUBSB_XMM_K1Z_XMM_XMMM128 = 2404,
	/// @brief @c VPSUBSB ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG E8 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSUBSB_YMM_K1Z_YMM_YMMM256 = 2405,
	/// @brief @c VPSUBSB zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG E8 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSUBSB_ZMM_K1Z_ZMM_ZMMM512 = 2406,
	/// @brief @c PSUBSW mm, mm/m64
	/// @par
	/// @c NP 0F E9 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PSUBSW_MM_MMM64 = 2407,
	/// @brief @c PSUBSW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F E9 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSUBSW_XMM_XMMM128 = 2408,
	/// @brief @c VPSUBSW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG E9 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSUBSW_XMM_XMM_XMMM128 = 2409,
	/// @brief @c VPSUBSW ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG E9 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSUBSW_YMM_YMM_YMMM256 = 2410,
	/// @brief @c VPSUBSW xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG E9 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSUBSW_XMM_K1Z_XMM_XMMM128 = 2411,
	/// @brief @c VPSUBSW ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG E9 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSUBSW_YMM_K1Z_YMM_YMMM256 = 2412,
	/// @brief @c VPSUBSW zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG E9 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSUBSW_ZMM_K1Z_ZMM_ZMMM512 = 2413,
	/// @brief @c PMINSW mm1, mm2/m64
	/// @par
	/// @c NP 0F EA /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	PMINSW_MM_MMM64 = 2414,
	/// @brief @c PMINSW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F EA /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PMINSW_XMM_XMMM128 = 2415,
	/// @brief @c VPMINSW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG EA /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMINSW_XMM_XMM_XMMM128 = 2416,
	/// @brief @c VPMINSW ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG EA /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMINSW_YMM_YMM_YMMM256 = 2417,
	/// @brief @c VPMINSW xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG EA /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMINSW_XMM_K1Z_XMM_XMMM128 = 2418,
	/// @brief @c VPMINSW ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG EA /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMINSW_YMM_K1Z_YMM_YMMM256 = 2419,
	/// @brief @c VPMINSW zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG EA /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMINSW_ZMM_K1Z_ZMM_ZMMM512 = 2420,
	/// @brief @c POR mm, mm/m64
	/// @par
	/// @c NP 0F EB /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	POR_MM_MMM64 = 2421,
	/// @brief @c POR xmm1, xmm2/m128
	/// @par
	/// @c 66 0F EB /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	POR_XMM_XMMM128 = 2422,
	/// @brief @c VPOR xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG EB /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPOR_XMM_XMM_XMMM128 = 2423,
	/// @brief @c VPOR ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG EB /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPOR_YMM_YMM_YMMM256 = 2424,
	/// @brief @c VPORD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F.W0 EB /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPORD_XMM_K1Z_XMM_XMMM128B32 = 2425,
	/// @brief @c VPORD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F.W0 EB /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPORD_YMM_K1Z_YMM_YMMM256B32 = 2426,
	/// @brief @c VPORD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F.W0 EB /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPORD_ZMM_K1Z_ZMM_ZMMM512B32 = 2427,
	/// @brief @c VPORQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F.W1 EB /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPORQ_XMM_K1Z_XMM_XMMM128B64 = 2428,
	/// @brief @c VPORQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F.W1 EB /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPORQ_YMM_K1Z_YMM_YMMM256B64 = 2429,
	/// @brief @c VPORQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F.W1 EB /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPORQ_ZMM_K1Z_ZMM_ZMMM512B64 = 2430,
	/// @brief @c PADDSB mm, mm/m64
	/// @par
	/// @c NP 0F EC /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PADDSB_MM_MMM64 = 2431,
	/// @brief @c PADDSB xmm1, xmm2/m128
	/// @par
	/// @c 66 0F EC /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PADDSB_XMM_XMMM128 = 2432,
	/// @brief @c VPADDSB xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG EC /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPADDSB_XMM_XMM_XMMM128 = 2433,
	/// @brief @c VPADDSB ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG EC /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPADDSB_YMM_YMM_YMMM256 = 2434,
	/// @brief @c VPADDSB xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG EC /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPADDSB_XMM_K1Z_XMM_XMMM128 = 2435,
	/// @brief @c VPADDSB ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG EC /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPADDSB_YMM_K1Z_YMM_YMMM256 = 2436,
	/// @brief @c VPADDSB zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG EC /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPADDSB_ZMM_K1Z_ZMM_ZMMM512 = 2437,
	/// @brief @c PADDSW mm, mm/m64
	/// @par
	/// @c NP 0F ED /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PADDSW_MM_MMM64 = 2438,
	/// @brief @c PADDSW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F ED /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PADDSW_XMM_XMMM128 = 2439,
	/// @brief @c VPADDSW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG ED /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPADDSW_XMM_XMM_XMMM128 = 2440,
	/// @brief @c VPADDSW ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG ED /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPADDSW_YMM_YMM_YMMM256 = 2441,
	/// @brief @c VPADDSW xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG ED /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPADDSW_XMM_K1Z_XMM_XMMM128 = 2442,
	/// @brief @c VPADDSW ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG ED /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPADDSW_YMM_K1Z_YMM_YMMM256 = 2443,
	/// @brief @c VPADDSW zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG ED /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPADDSW_ZMM_K1Z_ZMM_ZMMM512 = 2444,
	/// @brief @c PMAXSW mm1, mm2/m64
	/// @par
	/// @c NP 0F EE /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	PMAXSW_MM_MMM64 = 2445,
	/// @brief @c PMAXSW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F EE /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PMAXSW_XMM_XMMM128 = 2446,
	/// @brief @c VPMAXSW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG EE /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMAXSW_XMM_XMM_XMMM128 = 2447,
	/// @brief @c VPMAXSW ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG EE /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMAXSW_YMM_YMM_YMMM256 = 2448,
	/// @brief @c VPMAXSW xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG EE /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMAXSW_XMM_K1Z_XMM_XMMM128 = 2449,
	/// @brief @c VPMAXSW ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG EE /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMAXSW_YMM_K1Z_YMM_YMMM256 = 2450,
	/// @brief @c VPMAXSW zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG EE /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMAXSW_ZMM_K1Z_ZMM_ZMMM512 = 2451,
	/// @brief @c PXOR mm, mm/m64
	/// @par
	/// @c NP 0F EF /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PXOR_MM_MMM64 = 2452,
	/// @brief @c PXOR xmm1, xmm2/m128
	/// @par
	/// @c 66 0F EF /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PXOR_XMM_XMMM128 = 2453,
	/// @brief @c VPXOR xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG EF /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPXOR_XMM_XMM_XMMM128 = 2454,
	/// @brief @c VPXOR ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG EF /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPXOR_YMM_YMM_YMMM256 = 2455,
	/// @brief @c VPXORD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F.W0 EF /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPXORD_XMM_K1Z_XMM_XMMM128B32 = 2456,
	/// @brief @c VPXORD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F.W0 EF /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPXORD_YMM_K1Z_YMM_YMMM256B32 = 2457,
	/// @brief @c VPXORD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F.W0 EF /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPXORD_ZMM_K1Z_ZMM_ZMMM512B32 = 2458,
	/// @brief @c VPXORQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F.W1 EF /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPXORQ_XMM_K1Z_XMM_XMMM128B64 = 2459,
	/// @brief @c VPXORQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F.W1 EF /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPXORQ_YMM_K1Z_YMM_YMMM256B64 = 2460,
	/// @brief @c VPXORQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F.W1 EF /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPXORQ_ZMM_K1Z_ZMM_ZMMM512B64 = 2461,
	/// @brief @c LDDQU xmm1, m128
	/// @par
	/// @c F2 0F F0 /r
	/// @par
	/// @c SSE3
	/// @par
	/// @c 16/32/64-bit
	LDDQU_XMM_M128 = 2462,
	/// @brief @c VLDDQU xmm1, m128
	/// @par
	/// @c VEX.128.F2.0F.WIG F0 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VLDDQU_XMM_M128 = 2463,
	/// @brief @c VLDDQU ymm1, m256
	/// @par
	/// @c VEX.256.F2.0F.WIG F0 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VLDDQU_YMM_M256 = 2464,
	/// @brief @c PSLLW mm, mm/m64
	/// @par
	/// @c NP 0F F1 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PSLLW_MM_MMM64 = 2465,
	/// @brief @c PSLLW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F F1 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSLLW_XMM_XMMM128 = 2466,
	/// @brief @c VPSLLW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG F1 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSLLW_XMM_XMM_XMMM128 = 2467,
	/// @brief @c VPSLLW ymm1, ymm2, xmm3/m128
	/// @par
	/// @c VEX.256.66.0F.WIG F1 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSLLW_YMM_YMM_XMMM128 = 2468,
	/// @brief @c VPSLLW xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG F1 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSLLW_XMM_K1Z_XMM_XMMM128 = 2469,
	/// @brief @c VPSLLW ymm1 {k1}{z}, ymm2, xmm3/m128
	/// @par
	/// @c EVEX.256.66.0F.WIG F1 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSLLW_YMM_K1Z_YMM_XMMM128 = 2470,
	/// @brief @c VPSLLW zmm1 {k1}{z}, zmm2, xmm3/m128
	/// @par
	/// @c EVEX.512.66.0F.WIG F1 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSLLW_ZMM_K1Z_ZMM_XMMM128 = 2471,
	/// @brief @c PSLLD mm, mm/m64
	/// @par
	/// @c NP 0F F2 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PSLLD_MM_MMM64 = 2472,
	/// @brief @c PSLLD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F F2 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSLLD_XMM_XMMM128 = 2473,
	/// @brief @c VPSLLD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG F2 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSLLD_XMM_XMM_XMMM128 = 2474,
	/// @brief @c VPSLLD ymm1, ymm2, xmm3/m128
	/// @par
	/// @c VEX.256.66.0F.WIG F2 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSLLD_YMM_YMM_XMMM128 = 2475,
	/// @brief @c VPSLLD xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.W0 F2 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSLLD_XMM_K1Z_XMM_XMMM128 = 2476,
	/// @brief @c VPSLLD ymm1 {k1}{z}, ymm2, xmm3/m128
	/// @par
	/// @c EVEX.256.66.0F.W0 F2 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSLLD_YMM_K1Z_YMM_XMMM128 = 2477,
	/// @brief @c VPSLLD zmm1 {k1}{z}, zmm2, xmm3/m128
	/// @par
	/// @c EVEX.512.66.0F.W0 F2 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSLLD_ZMM_K1Z_ZMM_XMMM128 = 2478,
	/// @brief @c PSLLQ mm, mm/m64
	/// @par
	/// @c NP 0F F3 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PSLLQ_MM_MMM64 = 2479,
	/// @brief @c PSLLQ xmm1, xmm2/m128
	/// @par
	/// @c 66 0F F3 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSLLQ_XMM_XMMM128 = 2480,
	/// @brief @c VPSLLQ xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG F3 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSLLQ_XMM_XMM_XMMM128 = 2481,
	/// @brief @c VPSLLQ ymm1, ymm2, xmm3/m128
	/// @par
	/// @c VEX.256.66.0F.WIG F3 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSLLQ_YMM_YMM_XMMM128 = 2482,
	/// @brief @c VPSLLQ xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.W1 F3 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSLLQ_XMM_K1Z_XMM_XMMM128 = 2483,
	/// @brief @c VPSLLQ ymm1 {k1}{z}, ymm2, xmm3/m128
	/// @par
	/// @c EVEX.256.66.0F.W1 F3 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSLLQ_YMM_K1Z_YMM_XMMM128 = 2484,
	/// @brief @c VPSLLQ zmm1 {k1}{z}, zmm2, xmm3/m128
	/// @par
	/// @c EVEX.512.66.0F.W1 F3 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSLLQ_ZMM_K1Z_ZMM_XMMM128 = 2485,
	/// @brief @c PMULUDQ mm1, mm2/m64
	/// @par
	/// @c NP 0F F4 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PMULUDQ_MM_MMM64 = 2486,
	/// @brief @c PMULUDQ xmm1, xmm2/m128
	/// @par
	/// @c 66 0F F4 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PMULUDQ_XMM_XMMM128 = 2487,
	/// @brief @c VPMULUDQ xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG F4 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMULUDQ_XMM_XMM_XMMM128 = 2488,
	/// @brief @c VPMULUDQ ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG F4 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMULUDQ_YMM_YMM_YMMM256 = 2489,
	/// @brief @c VPMULUDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F.W1 F4 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMULUDQ_XMM_K1Z_XMM_XMMM128B64 = 2490,
	/// @brief @c VPMULUDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F.W1 F4 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMULUDQ_YMM_K1Z_YMM_YMMM256B64 = 2491,
	/// @brief @c VPMULUDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F.W1 F4 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMULUDQ_ZMM_K1Z_ZMM_ZMMM512B64 = 2492,
	/// @brief @c PMADDWD mm, mm/m64
	/// @par
	/// @c NP 0F F5 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PMADDWD_MM_MMM64 = 2493,
	/// @brief @c PMADDWD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F F5 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PMADDWD_XMM_XMMM128 = 2494,
	/// @brief @c VPMADDWD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG F5 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMADDWD_XMM_XMM_XMMM128 = 2495,
	/// @brief @c VPMADDWD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG F5 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMADDWD_YMM_YMM_YMMM256 = 2496,
	/// @brief @c VPMADDWD xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG F5 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMADDWD_XMM_K1Z_XMM_XMMM128 = 2497,
	/// @brief @c VPMADDWD ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG F5 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMADDWD_YMM_K1Z_YMM_YMMM256 = 2498,
	/// @brief @c VPMADDWD zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG F5 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMADDWD_ZMM_K1Z_ZMM_ZMMM512 = 2499,
	/// @brief @c PSADBW mm1, mm2/m64
	/// @par
	/// @c NP 0F F6 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	PSADBW_MM_MMM64 = 2500,
	/// @brief @c PSADBW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F F6 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSADBW_XMM_XMMM128 = 2501,
	/// @brief @c VPSADBW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG F6 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSADBW_XMM_XMM_XMMM128 = 2502,
	/// @brief @c VPSADBW ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG F6 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSADBW_YMM_YMM_YMMM256 = 2503,
	/// @brief @c VPSADBW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG F6 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSADBW_XMM_XMM_XMMM128 = 2504,
	/// @brief @c VPSADBW ymm1, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG F6 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSADBW_YMM_YMM_YMMM256 = 2505,
	/// @brief @c VPSADBW zmm1, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG F6 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSADBW_ZMM_ZMM_ZMMM512 = 2506,
	/// @brief @c MASKMOVQ mm1, mm2
	/// @par
	/// @c NP 0F F7 /r
	/// @par
	/// @c SSE
	/// @par
	/// @c 16/32/64-bit
	MASKMOVQ_R_DI_MM_MM = 2507,
	/// @brief @c MASKMOVDQU xmm1, xmm2
	/// @par
	/// @c 66 0F F7 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	MASKMOVDQU_R_DI_XMM_XMM = 2508,
	/// @brief @c VMASKMOVDQU xmm1, xmm2
	/// @par
	/// @c VEX.128.66.0F.WIG F7 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMASKMOVDQU_R_DI_XMM_XMM = 2509,
	/// @brief @c PSUBB mm, mm/m64
	/// @par
	/// @c NP 0F F8 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PSUBB_MM_MMM64 = 2510,
	/// @brief @c PSUBB xmm1, xmm2/m128
	/// @par
	/// @c 66 0F F8 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSUBB_XMM_XMMM128 = 2511,
	/// @brief @c VPSUBB xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG F8 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSUBB_XMM_XMM_XMMM128 = 2512,
	/// @brief @c VPSUBB ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG F8 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSUBB_YMM_YMM_YMMM256 = 2513,
	/// @brief @c VPSUBB xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG F8 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSUBB_XMM_K1Z_XMM_XMMM128 = 2514,
	/// @brief @c VPSUBB ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG F8 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSUBB_YMM_K1Z_YMM_YMMM256 = 2515,
	/// @brief @c VPSUBB zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG F8 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSUBB_ZMM_K1Z_ZMM_ZMMM512 = 2516,
	/// @brief @c PSUBW mm, mm/m64
	/// @par
	/// @c NP 0F F9 /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PSUBW_MM_MMM64 = 2517,
	/// @brief @c PSUBW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F F9 /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSUBW_XMM_XMMM128 = 2518,
	/// @brief @c VPSUBW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG F9 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSUBW_XMM_XMM_XMMM128 = 2519,
	/// @brief @c VPSUBW ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG F9 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSUBW_YMM_YMM_YMMM256 = 2520,
	/// @brief @c VPSUBW xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG F9 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSUBW_XMM_K1Z_XMM_XMMM128 = 2521,
	/// @brief @c VPSUBW ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG F9 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSUBW_YMM_K1Z_YMM_YMMM256 = 2522,
	/// @brief @c VPSUBW zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG F9 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSUBW_ZMM_K1Z_ZMM_ZMMM512 = 2523,
	/// @brief @c PSUBD mm, mm/m64
	/// @par
	/// @c NP 0F FA /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PSUBD_MM_MMM64 = 2524,
	/// @brief @c PSUBD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F FA /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSUBD_XMM_XMMM128 = 2525,
	/// @brief @c VPSUBD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG FA /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSUBD_XMM_XMM_XMMM128 = 2526,
	/// @brief @c VPSUBD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG FA /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSUBD_YMM_YMM_YMMM256 = 2527,
	/// @brief @c VPSUBD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F.W0 FA /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSUBD_XMM_K1Z_XMM_XMMM128B32 = 2528,
	/// @brief @c VPSUBD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F.W0 FA /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSUBD_YMM_K1Z_YMM_YMMM256B32 = 2529,
	/// @brief @c VPSUBD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F.W0 FA /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSUBD_ZMM_K1Z_ZMM_ZMMM512B32 = 2530,
	/// @brief @c PSUBQ mm1, mm2/m64
	/// @par
	/// @c NP 0F FB /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSUBQ_MM_MMM64 = 2531,
	/// @brief @c PSUBQ xmm1, xmm2/m128
	/// @par
	/// @c 66 0F FB /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PSUBQ_XMM_XMMM128 = 2532,
	/// @brief @c VPSUBQ xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG FB /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSUBQ_XMM_XMM_XMMM128 = 2533,
	/// @brief @c VPSUBQ ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG FB /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSUBQ_YMM_YMM_YMMM256 = 2534,
	/// @brief @c VPSUBQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F.W1 FB /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSUBQ_XMM_K1Z_XMM_XMMM128B64 = 2535,
	/// @brief @c VPSUBQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F.W1 FB /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSUBQ_YMM_K1Z_YMM_YMMM256B64 = 2536,
	/// @brief @c VPSUBQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F.W1 FB /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSUBQ_ZMM_K1Z_ZMM_ZMMM512B64 = 2537,
	/// @brief @c PADDB mm, mm/m64
	/// @par
	/// @c NP 0F FC /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PADDB_MM_MMM64 = 2538,
	/// @brief @c PADDB xmm1, xmm2/m128
	/// @par
	/// @c 66 0F FC /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PADDB_XMM_XMMM128 = 2539,
	/// @brief @c VPADDB xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG FC /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPADDB_XMM_XMM_XMMM128 = 2540,
	/// @brief @c VPADDB ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG FC /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPADDB_YMM_YMM_YMMM256 = 2541,
	/// @brief @c VPADDB xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG FC /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPADDB_XMM_K1Z_XMM_XMMM128 = 2542,
	/// @brief @c VPADDB ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG FC /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPADDB_YMM_K1Z_YMM_YMMM256 = 2543,
	/// @brief @c VPADDB zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG FC /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPADDB_ZMM_K1Z_ZMM_ZMMM512 = 2544,
	/// @brief @c PADDW mm, mm/m64
	/// @par
	/// @c NP 0F FD /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PADDW_MM_MMM64 = 2545,
	/// @brief @c PADDW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F FD /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PADDW_XMM_XMMM128 = 2546,
	/// @brief @c VPADDW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG FD /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPADDW_XMM_XMM_XMMM128 = 2547,
	/// @brief @c VPADDW ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG FD /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPADDW_YMM_YMM_YMMM256 = 2548,
	/// @brief @c VPADDW xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F.WIG FD /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPADDW_XMM_K1Z_XMM_XMMM128 = 2549,
	/// @brief @c VPADDW ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F.WIG FD /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPADDW_YMM_K1Z_YMM_YMMM256 = 2550,
	/// @brief @c VPADDW zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F.WIG FD /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPADDW_ZMM_K1Z_ZMM_ZMMM512 = 2551,
	/// @brief @c PADDD mm, mm/m64
	/// @par
	/// @c NP 0F FE /r
	/// @par
	/// @c MMX
	/// @par
	/// @c 16/32/64-bit
	PADDD_MM_MMM64 = 2552,
	/// @brief @c PADDD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F FE /r
	/// @par
	/// @c SSE2
	/// @par
	/// @c 16/32/64-bit
	PADDD_XMM_XMMM128 = 2553,
	/// @brief @c VPADDD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F.WIG FE /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPADDD_XMM_XMM_XMMM128 = 2554,
	/// @brief @c VPADDD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F.WIG FE /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPADDD_YMM_YMM_YMMM256 = 2555,
	/// @brief @c VPADDD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F.W0 FE /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPADDD_XMM_K1Z_XMM_XMMM128B32 = 2556,
	/// @brief @c VPADDD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F.W0 FE /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPADDD_YMM_K1Z_YMM_YMMM256B32 = 2557,
	/// @brief @c VPADDD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F.W0 FE /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPADDD_ZMM_K1Z_ZMM_ZMMM512B32 = 2558,
	/// @brief @c UD0 r16, r/m16
	/// @par
	/// @c o16 0F FF /r
	/// @par
	/// @c 286+
	/// @par
	/// @c 16/32/64-bit
	UD0_R16_RM16 = 2559,
	/// @brief @c UD0 r32, r/m32
	/// @par
	/// @c o32 0F FF /r
	/// @par
	/// @c 386+
	/// @par
	/// @c 16/32/64-bit
	UD0_R32_RM32 = 2560,
	/// @brief @c UD0 r64, r/m64
	/// @par
	/// @c o64 0F FF /r
	/// @par
	/// @c X64
	/// @par
	/// @c 64-bit
	UD0_R64_RM64 = 2561,
	/// @brief @c PSHUFB mm1, mm2/m64
	/// @par
	/// @c NP 0F 38 00 /r
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PSHUFB_MM_MMM64 = 2562,
	/// @brief @c PSHUFB xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 00 /r
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PSHUFB_XMM_XMMM128 = 2563,
	/// @brief @c VPSHUFB xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 00 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSHUFB_XMM_XMM_XMMM128 = 2564,
	/// @brief @c VPSHUFB ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG 00 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSHUFB_YMM_YMM_YMMM256 = 2565,
	/// @brief @c VPSHUFB xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F38.WIG 00 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHUFB_XMM_K1Z_XMM_XMMM128 = 2566,
	/// @brief @c VPSHUFB ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F38.WIG 00 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHUFB_YMM_K1Z_YMM_YMMM256 = 2567,
	/// @brief @c VPSHUFB zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F38.WIG 00 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHUFB_ZMM_K1Z_ZMM_ZMMM512 = 2568,
	/// @brief @c PHADDW mm1, mm2/m64
	/// @par
	/// @c NP 0F 38 01 /r
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PHADDW_MM_MMM64 = 2569,
	/// @brief @c PHADDW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 01 /r
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PHADDW_XMM_XMMM128 = 2570,
	/// @brief @c VPHADDW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 01 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPHADDW_XMM_XMM_XMMM128 = 2571,
	/// @brief @c VPHADDW ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG 01 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPHADDW_YMM_YMM_YMMM256 = 2572,
	/// @brief @c PHADDD mm1, mm2/m64
	/// @par
	/// @c NP 0F 38 02 /r
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PHADDD_MM_MMM64 = 2573,
	/// @brief @c PHADDD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 02 /r
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PHADDD_XMM_XMMM128 = 2574,
	/// @brief @c VPHADDD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 02 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPHADDD_XMM_XMM_XMMM128 = 2575,
	/// @brief @c VPHADDD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG 02 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPHADDD_YMM_YMM_YMMM256 = 2576,
	/// @brief @c PHADDSW mm1, mm2/m64
	/// @par
	/// @c NP 0F 38 03 /r
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PHADDSW_MM_MMM64 = 2577,
	/// @brief @c PHADDSW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 03 /r
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PHADDSW_XMM_XMMM128 = 2578,
	/// @brief @c VPHADDSW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 03 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPHADDSW_XMM_XMM_XMMM128 = 2579,
	/// @brief @c VPHADDSW ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG 03 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPHADDSW_YMM_YMM_YMMM256 = 2580,
	/// @brief @c PMADDUBSW mm1, mm2/m64
	/// @par
	/// @c NP 0F 38 04 /r
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PMADDUBSW_MM_MMM64 = 2581,
	/// @brief @c PMADDUBSW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 04 /r
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PMADDUBSW_XMM_XMMM128 = 2582,
	/// @brief @c VPMADDUBSW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 04 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMADDUBSW_XMM_XMM_XMMM128 = 2583,
	/// @brief @c VPMADDUBSW ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG 04 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMADDUBSW_YMM_YMM_YMMM256 = 2584,
	/// @brief @c VPMADDUBSW xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F38.WIG 04 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMADDUBSW_XMM_K1Z_XMM_XMMM128 = 2585,
	/// @brief @c VPMADDUBSW ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F38.WIG 04 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMADDUBSW_YMM_K1Z_YMM_YMMM256 = 2586,
	/// @brief @c VPMADDUBSW zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F38.WIG 04 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMADDUBSW_ZMM_K1Z_ZMM_ZMMM512 = 2587,
	/// @brief @c PHSUBW mm1, mm2/m64
	/// @par
	/// @c NP 0F 38 05 /r
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PHSUBW_MM_MMM64 = 2588,
	/// @brief @c PHSUBW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 05 /r
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PHSUBW_XMM_XMMM128 = 2589,
	/// @brief @c VPHSUBW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 05 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPHSUBW_XMM_XMM_XMMM128 = 2590,
	/// @brief @c VPHSUBW ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG 05 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPHSUBW_YMM_YMM_YMMM256 = 2591,
	/// @brief @c PHSUBD mm1, mm2/m64
	/// @par
	/// @c NP 0F 38 06 /r
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PHSUBD_MM_MMM64 = 2592,
	/// @brief @c PHSUBD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 06 /r
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PHSUBD_XMM_XMMM128 = 2593,
	/// @brief @c VPHSUBD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 06 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPHSUBD_XMM_XMM_XMMM128 = 2594,
	/// @brief @c VPHSUBD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG 06 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPHSUBD_YMM_YMM_YMMM256 = 2595,
	/// @brief @c PHSUBSW mm1, mm2/m64
	/// @par
	/// @c NP 0F 38 07 /r
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PHSUBSW_MM_MMM64 = 2596,
	/// @brief @c PHSUBSW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 07 /r
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PHSUBSW_XMM_XMMM128 = 2597,
	/// @brief @c VPHSUBSW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 07 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPHSUBSW_XMM_XMM_XMMM128 = 2598,
	/// @brief @c VPHSUBSW ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG 07 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPHSUBSW_YMM_YMM_YMMM256 = 2599,
	/// @brief @c PSIGNB mm1, mm2/m64
	/// @par
	/// @c NP 0F 38 08 /r
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PSIGNB_MM_MMM64 = 2600,
	/// @brief @c PSIGNB xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 08 /r
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PSIGNB_XMM_XMMM128 = 2601,
	/// @brief @c VPSIGNB xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 08 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSIGNB_XMM_XMM_XMMM128 = 2602,
	/// @brief @c VPSIGNB ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG 08 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSIGNB_YMM_YMM_YMMM256 = 2603,
	/// @brief @c PSIGNW mm1, mm2/m64
	/// @par
	/// @c NP 0F 38 09 /r
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PSIGNW_MM_MMM64 = 2604,
	/// @brief @c PSIGNW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 09 /r
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PSIGNW_XMM_XMMM128 = 2605,
	/// @brief @c VPSIGNW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 09 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSIGNW_XMM_XMM_XMMM128 = 2606,
	/// @brief @c VPSIGNW ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG 09 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSIGNW_YMM_YMM_YMMM256 = 2607,
	/// @brief @c PSIGND mm1, mm2/m64
	/// @par
	/// @c NP 0F 38 0A /r
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PSIGND_MM_MMM64 = 2608,
	/// @brief @c PSIGND xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 0A /r
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PSIGND_XMM_XMMM128 = 2609,
	/// @brief @c VPSIGND xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 0A /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSIGND_XMM_XMM_XMMM128 = 2610,
	/// @brief @c VPSIGND ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG 0A /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSIGND_YMM_YMM_YMMM256 = 2611,
	/// @brief @c PMULHRSW mm1, mm2/m64
	/// @par
	/// @c NP 0F 38 0B /r
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PMULHRSW_MM_MMM64 = 2612,
	/// @brief @c PMULHRSW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 0B /r
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PMULHRSW_XMM_XMMM128 = 2613,
	/// @brief @c VPMULHRSW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 0B /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMULHRSW_XMM_XMM_XMMM128 = 2614,
	/// @brief @c VPMULHRSW ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG 0B /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMULHRSW_YMM_YMM_YMMM256 = 2615,
	/// @brief @c VPMULHRSW xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F38.WIG 0B /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMULHRSW_XMM_K1Z_XMM_XMMM128 = 2616,
	/// @brief @c VPMULHRSW ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F38.WIG 0B /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMULHRSW_YMM_K1Z_YMM_YMMM256 = 2617,
	/// @brief @c VPMULHRSW zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F38.WIG 0B /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMULHRSW_ZMM_K1Z_ZMM_ZMMM512 = 2618,
	/// @brief @c VPERMILPS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 0C /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPERMILPS_XMM_XMM_XMMM128 = 2619,
	/// @brief @c VPERMILPS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 0C /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPERMILPS_YMM_YMM_YMMM256 = 2620,
	/// @brief @c VPERMILPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 0C /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMILPS_XMM_K1Z_XMM_XMMM128B32 = 2621,
	/// @brief @c VPERMILPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 0C /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMILPS_YMM_K1Z_YMM_YMMM256B32 = 2622,
	/// @brief @c VPERMILPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 0C /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMILPS_ZMM_K1Z_ZMM_ZMMM512B32 = 2623,
	/// @brief @c VPERMILPD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 0D /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPERMILPD_XMM_XMM_XMMM128 = 2624,
	/// @brief @c VPERMILPD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 0D /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPERMILPD_YMM_YMM_YMMM256 = 2625,
	/// @brief @c VPERMILPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 0D /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMILPD_XMM_K1Z_XMM_XMMM128B64 = 2626,
	/// @brief @c VPERMILPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 0D /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMILPD_YMM_K1Z_YMM_YMMM256B64 = 2627,
	/// @brief @c VPERMILPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 0D /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMILPD_ZMM_K1Z_ZMM_ZMMM512B64 = 2628,
	/// @brief @c VTESTPS xmm1, xmm2/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 0E /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VTESTPS_XMM_XMMM128 = 2629,
	/// @brief @c VTESTPS ymm1, ymm2/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 0E /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VTESTPS_YMM_YMMM256 = 2630,
	/// @brief @c VTESTPD xmm1, xmm2/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 0F /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VTESTPD_XMM_XMMM128 = 2631,
	/// @brief @c VTESTPD ymm1, ymm2/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 0F /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VTESTPD_YMM_YMMM256 = 2632,
	/// @brief @c PBLENDVB xmm1, xmm2/m128, \<XMM0\>
	/// @par
	/// @c 66 0F 38 10 /r
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PBLENDVB_XMM_XMMM128 = 2633,
	/// @brief @c VPSRLVW xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F38.W1 10 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRLVW_XMM_K1Z_XMM_XMMM128 = 2634,
	/// @brief @c VPSRLVW ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F38.W1 10 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRLVW_YMM_K1Z_YMM_YMMM256 = 2635,
	/// @brief @c VPSRLVW zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F38.W1 10 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRLVW_ZMM_K1Z_ZMM_ZMMM512 = 2636,
	/// @brief @c VPMOVUSWB xmm1/m64 {k1}{z}, xmm2
	/// @par
	/// @c EVEX.128.F3.0F38.W0 10 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVUSWB_XMMM64_K1Z_XMM = 2637,
	/// @brief @c VPMOVUSWB xmm1/m128 {k1}{z}, ymm2
	/// @par
	/// @c EVEX.256.F3.0F38.W0 10 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVUSWB_XMMM128_K1Z_YMM = 2638,
	/// @brief @c VPMOVUSWB ymm1/m256 {k1}{z}, zmm2
	/// @par
	/// @c EVEX.512.F3.0F38.W0 10 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVUSWB_YMMM256_K1Z_ZMM = 2639,
	/// @brief @c VPSRAVW xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F38.W1 11 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRAVW_XMM_K1Z_XMM_XMMM128 = 2640,
	/// @brief @c VPSRAVW ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F38.W1 11 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRAVW_YMM_K1Z_YMM_YMMM256 = 2641,
	/// @brief @c VPSRAVW zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F38.W1 11 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRAVW_ZMM_K1Z_ZMM_ZMMM512 = 2642,
	/// @brief @c VPMOVUSDB xmm1/m32 {k1}{z}, xmm2
	/// @par
	/// @c EVEX.128.F3.0F38.W0 11 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVUSDB_XMMM32_K1Z_XMM = 2643,
	/// @brief @c VPMOVUSDB xmm1/m64 {k1}{z}, ymm2
	/// @par
	/// @c EVEX.256.F3.0F38.W0 11 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVUSDB_XMMM64_K1Z_YMM = 2644,
	/// @brief @c VPMOVUSDB xmm1/m128 {k1}{z}, zmm2
	/// @par
	/// @c EVEX.512.F3.0F38.W0 11 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVUSDB_XMMM128_K1Z_ZMM = 2645,
	/// @brief @c VPSLLVW xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F38.W1 12 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSLLVW_XMM_K1Z_XMM_XMMM128 = 2646,
	/// @brief @c VPSLLVW ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F38.W1 12 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSLLVW_YMM_K1Z_YMM_YMMM256 = 2647,
	/// @brief @c VPSLLVW zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F38.W1 12 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSLLVW_ZMM_K1Z_ZMM_ZMMM512 = 2648,
	/// @brief @c VPMOVUSQB xmm1/m16 {k1}{z}, xmm2
	/// @par
	/// @c EVEX.128.F3.0F38.W0 12 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVUSQB_XMMM16_K1Z_XMM = 2649,
	/// @brief @c VPMOVUSQB xmm1/m32 {k1}{z}, ymm2
	/// @par
	/// @c EVEX.256.F3.0F38.W0 12 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVUSQB_XMMM32_K1Z_YMM = 2650,
	/// @brief @c VPMOVUSQB xmm1/m64 {k1}{z}, zmm2
	/// @par
	/// @c EVEX.512.F3.0F38.W0 12 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVUSQB_XMMM64_K1Z_ZMM = 2651,
	/// @brief @c VCVTPH2PS xmm1, xmm2/m64
	/// @par
	/// @c VEX.128.66.0F38.W0 13 /r
	/// @par
	/// @c F16C
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTPH2PS_XMM_XMMM64 = 2652,
	/// @brief @c VCVTPH2PS ymm1, xmm2/m128
	/// @par
	/// @c VEX.256.66.0F38.W0 13 /r
	/// @par
	/// @c F16C
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTPH2PS_YMM_XMMM128 = 2653,
	/// @brief @c VCVTPH2PS xmm1 {k1}{z}, xmm2/m64
	/// @par
	/// @c EVEX.128.66.0F38.W0 13 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPH2PS_XMM_K1Z_XMMM64 = 2654,
	/// @brief @c VCVTPH2PS ymm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.256.66.0F38.W0 13 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPH2PS_YMM_K1Z_XMMM128 = 2655,
	/// @brief @c VCVTPH2PS zmm1 {k1}{z}, ymm2/m256{sae}
	/// @par
	/// @c EVEX.512.66.0F38.W0 13 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPH2PS_ZMM_K1Z_YMMM256_SAE = 2656,
	/// @brief @c VPMOVUSDW xmm1/m64 {k1}{z}, xmm2
	/// @par
	/// @c EVEX.128.F3.0F38.W0 13 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVUSDW_XMMM64_K1Z_XMM = 2657,
	/// @brief @c VPMOVUSDW xmm1/m128 {k1}{z}, ymm2
	/// @par
	/// @c EVEX.256.F3.0F38.W0 13 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVUSDW_XMMM128_K1Z_YMM = 2658,
	/// @brief @c VPMOVUSDW ymm1/m256 {k1}{z}, zmm2
	/// @par
	/// @c EVEX.512.F3.0F38.W0 13 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVUSDW_YMMM256_K1Z_ZMM = 2659,
	/// @brief @c BLENDVPS xmm1, xmm2/m128, \<XMM0\>
	/// @par
	/// @c 66 0F 38 14 /r
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	BLENDVPS_XMM_XMMM128 = 2660,
	/// @brief @c VPRORVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 14 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPRORVD_XMM_K1Z_XMM_XMMM128B32 = 2661,
	/// @brief @c VPRORVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 14 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPRORVD_YMM_K1Z_YMM_YMMM256B32 = 2662,
	/// @brief @c VPRORVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 14 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPRORVD_ZMM_K1Z_ZMM_ZMMM512B32 = 2663,
	/// @brief @c VPRORVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 14 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPRORVQ_XMM_K1Z_XMM_XMMM128B64 = 2664,
	/// @brief @c VPRORVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 14 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPRORVQ_YMM_K1Z_YMM_YMMM256B64 = 2665,
	/// @brief @c VPRORVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 14 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPRORVQ_ZMM_K1Z_ZMM_ZMMM512B64 = 2666,
	/// @brief @c VPMOVUSQW xmm1/m32 {k1}{z}, xmm2
	/// @par
	/// @c EVEX.128.F3.0F38.W0 14 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVUSQW_XMMM32_K1Z_XMM = 2667,
	/// @brief @c VPMOVUSQW xmm1/m64 {k1}{z}, ymm2
	/// @par
	/// @c EVEX.256.F3.0F38.W0 14 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVUSQW_XMMM64_K1Z_YMM = 2668,
	/// @brief @c VPMOVUSQW xmm1/m128 {k1}{z}, zmm2
	/// @par
	/// @c EVEX.512.F3.0F38.W0 14 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVUSQW_XMMM128_K1Z_ZMM = 2669,
	/// @brief @c BLENDVPD xmm1, xmm2/m128, \<XMM0\>
	/// @par
	/// @c 66 0F 38 15 /r
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	BLENDVPD_XMM_XMMM128 = 2670,
	/// @brief @c VPROLVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 15 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPROLVD_XMM_K1Z_XMM_XMMM128B32 = 2671,
	/// @brief @c VPROLVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 15 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPROLVD_YMM_K1Z_YMM_YMMM256B32 = 2672,
	/// @brief @c VPROLVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 15 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPROLVD_ZMM_K1Z_ZMM_ZMMM512B32 = 2673,
	/// @brief @c VPROLVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 15 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPROLVQ_XMM_K1Z_XMM_XMMM128B64 = 2674,
	/// @brief @c VPROLVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 15 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPROLVQ_YMM_K1Z_YMM_YMMM256B64 = 2675,
	/// @brief @c VPROLVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 15 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPROLVQ_ZMM_K1Z_ZMM_ZMMM512B64 = 2676,
	/// @brief @c VPMOVUSQD xmm1/m64 {k1}{z}, xmm2
	/// @par
	/// @c EVEX.128.F3.0F38.W0 15 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVUSQD_XMMM64_K1Z_XMM = 2677,
	/// @brief @c VPMOVUSQD xmm1/m128 {k1}{z}, ymm2
	/// @par
	/// @c EVEX.256.F3.0F38.W0 15 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVUSQD_XMMM128_K1Z_YMM = 2678,
	/// @brief @c VPMOVUSQD ymm1/m256 {k1}{z}, zmm2
	/// @par
	/// @c EVEX.512.F3.0F38.W0 15 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVUSQD_YMMM256_K1Z_ZMM = 2679,
	/// @brief @c VPERMPS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 16 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPERMPS_YMM_YMM_YMMM256 = 2680,
	/// @brief @c VPERMPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 16 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMPS_YMM_K1Z_YMM_YMMM256B32 = 2681,
	/// @brief @c VPERMPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 16 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMPS_ZMM_K1Z_ZMM_ZMMM512B32 = 2682,
	/// @brief @c VPERMPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 16 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMPD_YMM_K1Z_YMM_YMMM256B64 = 2683,
	/// @brief @c VPERMPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 16 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMPD_ZMM_K1Z_ZMM_ZMMM512B64 = 2684,
	/// @brief @c PTEST xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 17 /r
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PTEST_XMM_XMMM128 = 2685,
	/// @brief @c VPTEST xmm1, xmm2/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 17 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPTEST_XMM_XMMM128 = 2686,
	/// @brief @c VPTEST ymm1, ymm2/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG 17 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPTEST_YMM_YMMM256 = 2687,
	/// @brief @c VBROADCASTSS xmm1, m32
	/// @par
	/// @c VEX.128.66.0F38.W0 18 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VBROADCASTSS_XMM_M32 = 2688,
	/// @brief @c VBROADCASTSS ymm1, m32
	/// @par
	/// @c VEX.256.66.0F38.W0 18 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VBROADCASTSS_YMM_M32 = 2689,
	/// @brief @c VBROADCASTSS xmm1 {k1}{z}, xmm2/m32
	/// @par
	/// @c EVEX.128.66.0F38.W0 18 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VBROADCASTSS_XMM_K1Z_XMMM32 = 2690,
	/// @brief @c VBROADCASTSS ymm1 {k1}{z}, xmm2/m32
	/// @par
	/// @c EVEX.256.66.0F38.W0 18 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VBROADCASTSS_YMM_K1Z_XMMM32 = 2691,
	/// @brief @c VBROADCASTSS zmm1 {k1}{z}, xmm2/m32
	/// @par
	/// @c EVEX.512.66.0F38.W0 18 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VBROADCASTSS_ZMM_K1Z_XMMM32 = 2692,
	/// @brief @c VBROADCASTSD ymm1, m64
	/// @par
	/// @c VEX.256.66.0F38.W0 19 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VBROADCASTSD_YMM_M64 = 2693,
	/// @brief @c VBROADCASTF32X2 ymm1 {k1}{z}, xmm2/m64
	/// @par
	/// @c EVEX.256.66.0F38.W0 19 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VBROADCASTF32X2_YMM_K1Z_XMMM64 = 2694,
	/// @brief @c VBROADCASTF32X2 zmm1 {k1}{z}, xmm2/m64
	/// @par
	/// @c EVEX.512.66.0F38.W0 19 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VBROADCASTF32X2_ZMM_K1Z_XMMM64 = 2695,
	/// @brief @c VBROADCASTSD ymm1 {k1}{z}, xmm2/m64
	/// @par
	/// @c EVEX.256.66.0F38.W1 19 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VBROADCASTSD_YMM_K1Z_XMMM64 = 2696,
	/// @brief @c VBROADCASTSD zmm1 {k1}{z}, xmm2/m64
	/// @par
	/// @c EVEX.512.66.0F38.W1 19 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VBROADCASTSD_ZMM_K1Z_XMMM64 = 2697,
	/// @brief @c VBROADCASTF128 ymm1, m128
	/// @par
	/// @c VEX.256.66.0F38.W0 1A /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VBROADCASTF128_YMM_M128 = 2698,
	/// @brief @c VBROADCASTF32X4 ymm1 {k1}{z}, m128
	/// @par
	/// @c EVEX.256.66.0F38.W0 1A /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VBROADCASTF32X4_YMM_K1Z_M128 = 2699,
	/// @brief @c VBROADCASTF32X4 zmm1 {k1}{z}, m128
	/// @par
	/// @c EVEX.512.66.0F38.W0 1A /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VBROADCASTF32X4_ZMM_K1Z_M128 = 2700,
	/// @brief @c VBROADCASTF64X2 ymm1 {k1}{z}, m128
	/// @par
	/// @c EVEX.256.66.0F38.W1 1A /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VBROADCASTF64X2_YMM_K1Z_M128 = 2701,
	/// @brief @c VBROADCASTF64X2 zmm1 {k1}{z}, m128
	/// @par
	/// @c EVEX.512.66.0F38.W1 1A /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VBROADCASTF64X2_ZMM_K1Z_M128 = 2702,
	/// @brief @c VBROADCASTF32X8 zmm1 {k1}{z}, m256
	/// @par
	/// @c EVEX.512.66.0F38.W0 1B /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VBROADCASTF32X8_ZMM_K1Z_M256 = 2703,
	/// @brief @c VBROADCASTF64X4 zmm1 {k1}{z}, m256
	/// @par
	/// @c EVEX.512.66.0F38.W1 1B /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VBROADCASTF64X4_ZMM_K1Z_M256 = 2704,
	/// @brief @c PABSB mm1, mm2/m64
	/// @par
	/// @c NP 0F 38 1C /r
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PABSB_MM_MMM64 = 2705,
	/// @brief @c PABSB xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 1C /r
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PABSB_XMM_XMMM128 = 2706,
	/// @brief @c VPABSB xmm1, xmm2/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 1C /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPABSB_XMM_XMMM128 = 2707,
	/// @brief @c VPABSB ymm1, ymm2/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG 1C /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPABSB_YMM_YMMM256 = 2708,
	/// @brief @c VPABSB xmm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.128.66.0F38.WIG 1C /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPABSB_XMM_K1Z_XMMM128 = 2709,
	/// @brief @c VPABSB ymm1 {k1}{z}, ymm2/m256
	/// @par
	/// @c EVEX.256.66.0F38.WIG 1C /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPABSB_YMM_K1Z_YMMM256 = 2710,
	/// @brief @c VPABSB zmm1 {k1}{z}, zmm2/m512
	/// @par
	/// @c EVEX.512.66.0F38.WIG 1C /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPABSB_ZMM_K1Z_ZMMM512 = 2711,
	/// @brief @c PABSW mm1, mm2/m64
	/// @par
	/// @c NP 0F 38 1D /r
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PABSW_MM_MMM64 = 2712,
	/// @brief @c PABSW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 1D /r
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PABSW_XMM_XMMM128 = 2713,
	/// @brief @c VPABSW xmm1, xmm2/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 1D /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPABSW_XMM_XMMM128 = 2714,
	/// @brief @c VPABSW ymm1, ymm2/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG 1D /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPABSW_YMM_YMMM256 = 2715,
	/// @brief @c VPABSW xmm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.128.66.0F38.WIG 1D /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPABSW_XMM_K1Z_XMMM128 = 2716,
	/// @brief @c VPABSW ymm1 {k1}{z}, ymm2/m256
	/// @par
	/// @c EVEX.256.66.0F38.WIG 1D /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPABSW_YMM_K1Z_YMMM256 = 2717,
	/// @brief @c VPABSW zmm1 {k1}{z}, zmm2/m512
	/// @par
	/// @c EVEX.512.66.0F38.WIG 1D /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPABSW_ZMM_K1Z_ZMMM512 = 2718,
	/// @brief @c PABSD mm1, mm2/m64
	/// @par
	/// @c NP 0F 38 1E /r
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PABSD_MM_MMM64 = 2719,
	/// @brief @c PABSD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 1E /r
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PABSD_XMM_XMMM128 = 2720,
	/// @brief @c VPABSD xmm1, xmm2/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 1E /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPABSD_XMM_XMMM128 = 2721,
	/// @brief @c VPABSD ymm1, ymm2/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG 1E /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPABSD_YMM_YMMM256 = 2722,
	/// @brief @c VPABSD xmm1 {k1}{z}, xmm2/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 1E /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPABSD_XMM_K1Z_XMMM128B32 = 2723,
	/// @brief @c VPABSD ymm1 {k1}{z}, ymm2/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 1E /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPABSD_YMM_K1Z_YMMM256B32 = 2724,
	/// @brief @c VPABSD zmm1 {k1}{z}, zmm2/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 1E /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPABSD_ZMM_K1Z_ZMMM512B32 = 2725,
	/// @brief @c VPABSQ xmm1 {k1}{z}, xmm2/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 1F /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPABSQ_XMM_K1Z_XMMM128B64 = 2726,
	/// @brief @c VPABSQ ymm1 {k1}{z}, ymm2/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 1F /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPABSQ_YMM_K1Z_YMMM256B64 = 2727,
	/// @brief @c VPABSQ zmm1 {k1}{z}, zmm2/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 1F /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPABSQ_ZMM_K1Z_ZMMM512B64 = 2728,
	/// @brief @c PMOVSXBW xmm1, xmm2/m64
	/// @par
	/// @c 66 0F 38 20 /r
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PMOVSXBW_XMM_XMMM64 = 2729,
	/// @brief @c VPMOVSXBW xmm1, xmm2/m64
	/// @par
	/// @c VEX.128.66.0F38.WIG 20 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMOVSXBW_XMM_XMMM64 = 2730,
	/// @brief @c VPMOVSXBW ymm1, xmm2/m128
	/// @par
	/// @c VEX.256.66.0F38.WIG 20 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMOVSXBW_YMM_XMMM128 = 2731,
	/// @brief @c VPMOVSXBW xmm1 {k1}{z}, xmm2/m64
	/// @par
	/// @c EVEX.128.66.0F38.WIG 20 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSXBW_XMM_K1Z_XMMM64 = 2732,
	/// @brief @c VPMOVSXBW ymm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.256.66.0F38.WIG 20 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSXBW_YMM_K1Z_XMMM128 = 2733,
	/// @brief @c VPMOVSXBW zmm1 {k1}{z}, ymm2/m256
	/// @par
	/// @c EVEX.512.66.0F38.WIG 20 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSXBW_ZMM_K1Z_YMMM256 = 2734,
	/// @brief @c VPMOVSWB xmm1/m64 {k1}{z}, xmm2
	/// @par
	/// @c EVEX.128.F3.0F38.W0 20 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSWB_XMMM64_K1Z_XMM = 2735,
	/// @brief @c VPMOVSWB xmm1/m128 {k1}{z}, ymm2
	/// @par
	/// @c EVEX.256.F3.0F38.W0 20 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSWB_XMMM128_K1Z_YMM = 2736,
	/// @brief @c VPMOVSWB ymm1/m256 {k1}{z}, zmm2
	/// @par
	/// @c EVEX.512.F3.0F38.W0 20 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSWB_YMMM256_K1Z_ZMM = 2737,
	/// @brief @c PMOVSXBD xmm1, xmm2/m32
	/// @par
	/// @c 66 0F 38 21 /r
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PMOVSXBD_XMM_XMMM32 = 2738,
	/// @brief @c VPMOVSXBD xmm1, xmm2/m32
	/// @par
	/// @c VEX.128.66.0F38.WIG 21 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMOVSXBD_XMM_XMMM32 = 2739,
	/// @brief @c VPMOVSXBD ymm1, xmm2/m64
	/// @par
	/// @c VEX.256.66.0F38.WIG 21 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMOVSXBD_YMM_XMMM64 = 2740,
	/// @brief @c VPMOVSXBD xmm1 {k1}{z}, xmm2/m32
	/// @par
	/// @c EVEX.128.66.0F38.WIG 21 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSXBD_XMM_K1Z_XMMM32 = 2741,
	/// @brief @c VPMOVSXBD ymm1 {k1}{z}, xmm2/m64
	/// @par
	/// @c EVEX.256.66.0F38.WIG 21 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSXBD_YMM_K1Z_XMMM64 = 2742,
	/// @brief @c VPMOVSXBD zmm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.512.66.0F38.WIG 21 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSXBD_ZMM_K1Z_XMMM128 = 2743,
	/// @brief @c VPMOVSDB xmm1/m32 {k1}{z}, xmm2
	/// @par
	/// @c EVEX.128.F3.0F38.W0 21 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSDB_XMMM32_K1Z_XMM = 2744,
	/// @brief @c VPMOVSDB xmm1/m64 {k1}{z}, ymm2
	/// @par
	/// @c EVEX.256.F3.0F38.W0 21 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSDB_XMMM64_K1Z_YMM = 2745,
	/// @brief @c VPMOVSDB xmm1/m128 {k1}{z}, zmm2
	/// @par
	/// @c EVEX.512.F3.0F38.W0 21 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSDB_XMMM128_K1Z_ZMM = 2746,
	/// @brief @c PMOVSXBQ xmm1, xmm2/m16
	/// @par
	/// @c 66 0F 38 22 /r
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PMOVSXBQ_XMM_XMMM16 = 2747,
	/// @brief @c VPMOVSXBQ xmm1, xmm2/m16
	/// @par
	/// @c VEX.128.66.0F38.WIG 22 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMOVSXBQ_XMM_XMMM16 = 2748,
	/// @brief @c VPMOVSXBQ ymm1, xmm2/m32
	/// @par
	/// @c VEX.256.66.0F38.WIG 22 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMOVSXBQ_YMM_XMMM32 = 2749,
	/// @brief @c VPMOVSXBQ xmm1 {k1}{z}, xmm2/m16
	/// @par
	/// @c EVEX.128.66.0F38.WIG 22 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSXBQ_XMM_K1Z_XMMM16 = 2750,
	/// @brief @c VPMOVSXBQ ymm1 {k1}{z}, xmm2/m32
	/// @par
	/// @c EVEX.256.66.0F38.WIG 22 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSXBQ_YMM_K1Z_XMMM32 = 2751,
	/// @brief @c VPMOVSXBQ zmm1 {k1}{z}, xmm2/m64
	/// @par
	/// @c EVEX.512.66.0F38.WIG 22 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSXBQ_ZMM_K1Z_XMMM64 = 2752,
	/// @brief @c VPMOVSQB xmm1/m16 {k1}{z}, xmm2
	/// @par
	/// @c EVEX.128.F3.0F38.W0 22 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSQB_XMMM16_K1Z_XMM = 2753,
	/// @brief @c VPMOVSQB xmm1/m32 {k1}{z}, ymm2
	/// @par
	/// @c EVEX.256.F3.0F38.W0 22 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSQB_XMMM32_K1Z_YMM = 2754,
	/// @brief @c VPMOVSQB xmm1/m64 {k1}{z}, zmm2
	/// @par
	/// @c EVEX.512.F3.0F38.W0 22 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSQB_XMMM64_K1Z_ZMM = 2755,
	/// @brief @c PMOVSXWD xmm1, xmm2/m64
	/// @par
	/// @c 66 0F 38 23 /r
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PMOVSXWD_XMM_XMMM64 = 2756,
	/// @brief @c VPMOVSXWD xmm1, xmm2/m64
	/// @par
	/// @c VEX.128.66.0F38.WIG 23 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMOVSXWD_XMM_XMMM64 = 2757,
	/// @brief @c VPMOVSXWD ymm1, xmm2/m128
	/// @par
	/// @c VEX.256.66.0F38.WIG 23 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMOVSXWD_YMM_XMMM128 = 2758,
	/// @brief @c VPMOVSXWD xmm1 {k1}{z}, xmm2/m64
	/// @par
	/// @c EVEX.128.66.0F38.WIG 23 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSXWD_XMM_K1Z_XMMM64 = 2759,
	/// @brief @c VPMOVSXWD ymm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.256.66.0F38.WIG 23 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSXWD_YMM_K1Z_XMMM128 = 2760,
	/// @brief @c VPMOVSXWD zmm1 {k1}{z}, ymm2/m256
	/// @par
	/// @c EVEX.512.66.0F38.WIG 23 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSXWD_ZMM_K1Z_YMMM256 = 2761,
	/// @brief @c VPMOVSDW xmm1/m64 {k1}{z}, xmm2
	/// @par
	/// @c EVEX.128.F3.0F38.W0 23 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSDW_XMMM64_K1Z_XMM = 2762,
	/// @brief @c VPMOVSDW xmm1/m128 {k1}{z}, ymm2
	/// @par
	/// @c EVEX.256.F3.0F38.W0 23 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSDW_XMMM128_K1Z_YMM = 2763,
	/// @brief @c VPMOVSDW ymm1/m256 {k1}{z}, zmm2
	/// @par
	/// @c EVEX.512.F3.0F38.W0 23 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSDW_YMMM256_K1Z_ZMM = 2764,
	/// @brief @c PMOVSXWQ xmm1, xmm2/m32
	/// @par
	/// @c 66 0F 38 24 /r
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PMOVSXWQ_XMM_XMMM32 = 2765,
	/// @brief @c VPMOVSXWQ xmm1, xmm2/m32
	/// @par
	/// @c VEX.128.66.0F38.WIG 24 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMOVSXWQ_XMM_XMMM32 = 2766,
	/// @brief @c VPMOVSXWQ ymm1, xmm2/m64
	/// @par
	/// @c VEX.256.66.0F38.WIG 24 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMOVSXWQ_YMM_XMMM64 = 2767,
	/// @brief @c VPMOVSXWQ xmm1 {k1}{z}, xmm2/m32
	/// @par
	/// @c EVEX.128.66.0F38.WIG 24 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSXWQ_XMM_K1Z_XMMM32 = 2768,
	/// @brief @c VPMOVSXWQ ymm1 {k1}{z}, xmm2/m64
	/// @par
	/// @c EVEX.256.66.0F38.WIG 24 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSXWQ_YMM_K1Z_XMMM64 = 2769,
	/// @brief @c VPMOVSXWQ zmm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.512.66.0F38.WIG 24 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSXWQ_ZMM_K1Z_XMMM128 = 2770,
	/// @brief @c VPMOVSQW xmm1/m32 {k1}{z}, xmm2
	/// @par
	/// @c EVEX.128.F3.0F38.W0 24 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSQW_XMMM32_K1Z_XMM = 2771,
	/// @brief @c VPMOVSQW xmm1/m64 {k1}{z}, ymm2
	/// @par
	/// @c EVEX.256.F3.0F38.W0 24 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSQW_XMMM64_K1Z_YMM = 2772,
	/// @brief @c VPMOVSQW xmm1/m128 {k1}{z}, zmm2
	/// @par
	/// @c EVEX.512.F3.0F38.W0 24 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSQW_XMMM128_K1Z_ZMM = 2773,
	/// @brief @c PMOVSXDQ xmm1, xmm2/m64
	/// @par
	/// @c 66 0F 38 25 /r
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PMOVSXDQ_XMM_XMMM64 = 2774,
	/// @brief @c VPMOVSXDQ xmm1, xmm2/m64
	/// @par
	/// @c VEX.128.66.0F38.WIG 25 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMOVSXDQ_XMM_XMMM64 = 2775,
	/// @brief @c VPMOVSXDQ ymm1, xmm2/m128
	/// @par
	/// @c VEX.256.66.0F38.WIG 25 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMOVSXDQ_YMM_XMMM128 = 2776,
	/// @brief @c VPMOVSXDQ xmm1 {k1}{z}, xmm2/m64
	/// @par
	/// @c EVEX.128.66.0F38.W0 25 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSXDQ_XMM_K1Z_XMMM64 = 2777,
	/// @brief @c VPMOVSXDQ ymm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.256.66.0F38.W0 25 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSXDQ_YMM_K1Z_XMMM128 = 2778,
	/// @brief @c VPMOVSXDQ zmm1 {k1}{z}, ymm2/m256
	/// @par
	/// @c EVEX.512.66.0F38.W0 25 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSXDQ_ZMM_K1Z_YMMM256 = 2779,
	/// @brief @c VPMOVSQD xmm1/m64 {k1}{z}, xmm2
	/// @par
	/// @c EVEX.128.F3.0F38.W0 25 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSQD_XMMM64_K1Z_XMM = 2780,
	/// @brief @c VPMOVSQD xmm1/m128 {k1}{z}, ymm2
	/// @par
	/// @c EVEX.256.F3.0F38.W0 25 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSQD_XMMM128_K1Z_YMM = 2781,
	/// @brief @c VPMOVSQD ymm1/m256 {k1}{z}, zmm2
	/// @par
	/// @c EVEX.512.F3.0F38.W0 25 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVSQD_YMMM256_K1Z_ZMM = 2782,
	/// @brief @c VPTESTMB k2 {k1}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F38.W0 26 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPTESTMB_KR_K1_XMM_XMMM128 = 2783,
	/// @brief @c VPTESTMB k2 {k1}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F38.W0 26 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPTESTMB_KR_K1_YMM_YMMM256 = 2784,
	/// @brief @c VPTESTMB k2 {k1}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F38.W0 26 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPTESTMB_KR_K1_ZMM_ZMMM512 = 2785,
	/// @brief @c VPTESTMW k2 {k1}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F38.W1 26 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPTESTMW_KR_K1_XMM_XMMM128 = 2786,
	/// @brief @c VPTESTMW k2 {k1}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F38.W1 26 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPTESTMW_KR_K1_YMM_YMMM256 = 2787,
	/// @brief @c VPTESTMW k2 {k1}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F38.W1 26 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPTESTMW_KR_K1_ZMM_ZMMM512 = 2788,
	/// @brief @c VPTESTNMB k2 {k1}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.F3.0F38.W0 26 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPTESTNMB_KR_K1_XMM_XMMM128 = 2789,
	/// @brief @c VPTESTNMB k2 {k1}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.F3.0F38.W0 26 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPTESTNMB_KR_K1_YMM_YMMM256 = 2790,
	/// @brief @c VPTESTNMB k2 {k1}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.F3.0F38.W0 26 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPTESTNMB_KR_K1_ZMM_ZMMM512 = 2791,
	/// @brief @c VPTESTNMW k2 {k1}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.F3.0F38.W1 26 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPTESTNMW_KR_K1_XMM_XMMM128 = 2792,
	/// @brief @c VPTESTNMW k2 {k1}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.F3.0F38.W1 26 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPTESTNMW_KR_K1_YMM_YMMM256 = 2793,
	/// @brief @c VPTESTNMW k2 {k1}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.F3.0F38.W1 26 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPTESTNMW_KR_K1_ZMM_ZMMM512 = 2794,
	/// @brief @c VPTESTMD k2 {k1}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 27 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPTESTMD_KR_K1_XMM_XMMM128B32 = 2795,
	/// @brief @c VPTESTMD k2 {k1}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 27 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPTESTMD_KR_K1_YMM_YMMM256B32 = 2796,
	/// @brief @c VPTESTMD k2 {k1}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 27 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPTESTMD_KR_K1_ZMM_ZMMM512B32 = 2797,
	/// @brief @c VPTESTMQ k2 {k1}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 27 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPTESTMQ_KR_K1_XMM_XMMM128B64 = 2798,
	/// @brief @c VPTESTMQ k2 {k1}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 27 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPTESTMQ_KR_K1_YMM_YMMM256B64 = 2799,
	/// @brief @c VPTESTMQ k2 {k1}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 27 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPTESTMQ_KR_K1_ZMM_ZMMM512B64 = 2800,
	/// @brief @c VPTESTNMD k2 {k1}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.F3.0F38.W0 27 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPTESTNMD_KR_K1_XMM_XMMM128B32 = 2801,
	/// @brief @c VPTESTNMD k2 {k1}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.F3.0F38.W0 27 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPTESTNMD_KR_K1_YMM_YMMM256B32 = 2802,
	/// @brief @c VPTESTNMD k2 {k1}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.F3.0F38.W0 27 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPTESTNMD_KR_K1_ZMM_ZMMM512B32 = 2803,
	/// @brief @c VPTESTNMQ k2 {k1}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.F3.0F38.W1 27 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPTESTNMQ_KR_K1_XMM_XMMM128B64 = 2804,
	/// @brief @c VPTESTNMQ k2 {k1}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.F3.0F38.W1 27 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPTESTNMQ_KR_K1_YMM_YMMM256B64 = 2805,
	/// @brief @c VPTESTNMQ k2 {k1}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.F3.0F38.W1 27 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPTESTNMQ_KR_K1_ZMM_ZMMM512B64 = 2806,
	/// @brief @c PMULDQ xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 28 /r
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PMULDQ_XMM_XMMM128 = 2807,
	/// @brief @c VPMULDQ xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 28 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMULDQ_XMM_XMM_XMMM128 = 2808,
	/// @brief @c VPMULDQ ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG 28 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMULDQ_YMM_YMM_YMMM256 = 2809,
	/// @brief @c VPMULDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 28 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMULDQ_XMM_K1Z_XMM_XMMM128B64 = 2810,
	/// @brief @c VPMULDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 28 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMULDQ_YMM_K1Z_YMM_YMMM256B64 = 2811,
	/// @brief @c VPMULDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 28 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMULDQ_ZMM_K1Z_ZMM_ZMMM512B64 = 2812,
	/// @brief @c VPMOVM2B xmm1, k1
	/// @par
	/// @c EVEX.128.F3.0F38.W0 28 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVM2B_XMM_KR = 2813,
	/// @brief @c VPMOVM2B ymm1, k1
	/// @par
	/// @c EVEX.256.F3.0F38.W0 28 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVM2B_YMM_KR = 2814,
	/// @brief @c VPMOVM2B zmm1, k1
	/// @par
	/// @c EVEX.512.F3.0F38.W0 28 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVM2B_ZMM_KR = 2815,
	/// @brief @c VPMOVM2W xmm1, k1
	/// @par
	/// @c EVEX.128.F3.0F38.W1 28 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVM2W_XMM_KR = 2816,
	/// @brief @c VPMOVM2W ymm1, k1
	/// @par
	/// @c EVEX.256.F3.0F38.W1 28 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVM2W_YMM_KR = 2817,
	/// @brief @c VPMOVM2W zmm1, k1
	/// @par
	/// @c EVEX.512.F3.0F38.W1 28 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVM2W_ZMM_KR = 2818,
	/// @brief @c PCMPEQQ xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 29 /r
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PCMPEQQ_XMM_XMMM128 = 2819,
	/// @brief @c VPCMPEQQ xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 29 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPCMPEQQ_XMM_XMM_XMMM128 = 2820,
	/// @brief @c VPCMPEQQ ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG 29 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPCMPEQQ_YMM_YMM_YMMM256 = 2821,
	/// @brief @c VPCMPEQQ k1 {k2}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 29 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPEQQ_KR_K1_XMM_XMMM128B64 = 2822,
	/// @brief @c VPCMPEQQ k1 {k2}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 29 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPEQQ_KR_K1_YMM_YMMM256B64 = 2823,
	/// @brief @c VPCMPEQQ k1 {k2}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 29 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPEQQ_KR_K1_ZMM_ZMMM512B64 = 2824,
	/// @brief @c VPMOVB2M k1, xmm1
	/// @par
	/// @c EVEX.128.F3.0F38.W0 29 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVB2M_KR_XMM = 2825,
	/// @brief @c VPMOVB2M k1, ymm1
	/// @par
	/// @c EVEX.256.F3.0F38.W0 29 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVB2M_KR_YMM = 2826,
	/// @brief @c VPMOVB2M k1, zmm1
	/// @par
	/// @c EVEX.512.F3.0F38.W0 29 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVB2M_KR_ZMM = 2827,
	/// @brief @c VPMOVW2M k1, xmm1
	/// @par
	/// @c EVEX.128.F3.0F38.W1 29 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVW2M_KR_XMM = 2828,
	/// @brief @c VPMOVW2M k1, ymm1
	/// @par
	/// @c EVEX.256.F3.0F38.W1 29 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVW2M_KR_YMM = 2829,
	/// @brief @c VPMOVW2M k1, zmm1
	/// @par
	/// @c EVEX.512.F3.0F38.W1 29 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVW2M_KR_ZMM = 2830,
	/// @brief @c MOVNTDQA xmm1, m128
	/// @par
	/// @c 66 0F 38 2A /r
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	MOVNTDQA_XMM_M128 = 2831,
	/// @brief @c VMOVNTDQA xmm1, m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 2A /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVNTDQA_XMM_M128 = 2832,
	/// @brief @c VMOVNTDQA ymm1, m256
	/// @par
	/// @c VEX.256.66.0F38.WIG 2A /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VMOVNTDQA_YMM_M256 = 2833,
	/// @brief @c VMOVNTDQA xmm1, m128
	/// @par
	/// @c EVEX.128.66.0F38.W0 2A /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVNTDQA_XMM_M128 = 2834,
	/// @brief @c VMOVNTDQA ymm1, m256
	/// @par
	/// @c EVEX.256.66.0F38.W0 2A /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVNTDQA_YMM_M256 = 2835,
	/// @brief @c VMOVNTDQA zmm1, m512
	/// @par
	/// @c EVEX.512.66.0F38.W0 2A /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVNTDQA_ZMM_M512 = 2836,
	/// @brief @c VPBROADCASTMB2Q xmm1, k1
	/// @par
	/// @c EVEX.128.F3.0F38.W1 2A /r
	/// @par
	/// @c AVX512VL and AVX512CD
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBROADCASTMB2Q_XMM_KR = 2837,
	/// @brief @c VPBROADCASTMB2Q ymm1, k1
	/// @par
	/// @c EVEX.256.F3.0F38.W1 2A /r
	/// @par
	/// @c AVX512VL and AVX512CD
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBROADCASTMB2Q_YMM_KR = 2838,
	/// @brief @c VPBROADCASTMB2Q zmm1, k1
	/// @par
	/// @c EVEX.512.F3.0F38.W1 2A /r
	/// @par
	/// @c AVX512CD
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBROADCASTMB2Q_ZMM_KR = 2839,
	/// @brief @c PACKUSDW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 2B /r
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PACKUSDW_XMM_XMMM128 = 2840,
	/// @brief @c VPACKUSDW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 2B /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPACKUSDW_XMM_XMM_XMMM128 = 2841,
	/// @brief @c VPACKUSDW ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG 2B /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPACKUSDW_YMM_YMM_YMMM256 = 2842,
	/// @brief @c VPACKUSDW xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 2B /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPACKUSDW_XMM_K1Z_XMM_XMMM128B32 = 2843,
	/// @brief @c VPACKUSDW ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 2B /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPACKUSDW_YMM_K1Z_YMM_YMMM256B32 = 2844,
	/// @brief @c VPACKUSDW zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 2B /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPACKUSDW_ZMM_K1Z_ZMM_ZMMM512B32 = 2845,
	/// @brief @c VMASKMOVPS xmm1, xmm2, m128
	/// @par
	/// @c VEX.128.66.0F38.W0 2C /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMASKMOVPS_XMM_XMM_M128 = 2846,
	/// @brief @c VMASKMOVPS ymm1, ymm2, m256
	/// @par
	/// @c VEX.256.66.0F38.W0 2C /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMASKMOVPS_YMM_YMM_M256 = 2847,
	/// @brief @c VSCALEFPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 2C /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCALEFPS_XMM_K1Z_XMM_XMMM128B32 = 2848,
	/// @brief @c VSCALEFPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 2C /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCALEFPS_YMM_K1Z_YMM_YMMM256B32 = 2849,
	/// @brief @c VSCALEFPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W0 2C /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCALEFPS_ZMM_K1Z_ZMM_ZMMM512B32_ER = 2850,
	/// @brief @c VSCALEFPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 2C /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCALEFPD_XMM_K1Z_XMM_XMMM128B64 = 2851,
	/// @brief @c VSCALEFPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 2C /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCALEFPD_YMM_K1Z_YMM_YMMM256B64 = 2852,
	/// @brief @c VSCALEFPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W1 2C /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCALEFPD_ZMM_K1Z_ZMM_ZMMM512B64_ER = 2853,
	/// @brief @c VMASKMOVPD xmm1, xmm2, m128
	/// @par
	/// @c VEX.128.66.0F38.W0 2D /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMASKMOVPD_XMM_XMM_M128 = 2854,
	/// @brief @c VMASKMOVPD ymm1, ymm2, m256
	/// @par
	/// @c VEX.256.66.0F38.W0 2D /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMASKMOVPD_YMM_YMM_M256 = 2855,
	/// @brief @c VSCALEFSS xmm1 {k1}{z}, xmm2, xmm3/m32{er}
	/// @par
	/// @c EVEX.LIG.66.0F38.W0 2D /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCALEFSS_XMM_K1Z_XMM_XMMM32_ER = 2856,
	/// @brief @c VSCALEFSD xmm1 {k1}{z}, xmm2, xmm3/m64{er}
	/// @par
	/// @c EVEX.LIG.66.0F38.W1 2D /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCALEFSD_XMM_K1Z_XMM_XMMM64_ER = 2857,
	/// @brief @c VMASKMOVPS m128, xmm1, xmm2
	/// @par
	/// @c VEX.128.66.0F38.W0 2E /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMASKMOVPS_M128_XMM_XMM = 2858,
	/// @brief @c VMASKMOVPS m256, ymm1, ymm2
	/// @par
	/// @c VEX.256.66.0F38.W0 2E /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMASKMOVPS_M256_YMM_YMM = 2859,
	/// @brief @c VMASKMOVPD m128, xmm1, xmm2
	/// @par
	/// @c VEX.128.66.0F38.W0 2F /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMASKMOVPD_M128_XMM_XMM = 2860,
	/// @brief @c VMASKMOVPD m256, ymm1, ymm2
	/// @par
	/// @c VEX.256.66.0F38.W0 2F /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMASKMOVPD_M256_YMM_YMM = 2861,
	/// @brief @c PMOVZXBW xmm1, xmm2/m64
	/// @par
	/// @c 66 0F 38 30 /r
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PMOVZXBW_XMM_XMMM64 = 2862,
	/// @brief @c VPMOVZXBW xmm1, xmm2/m64
	/// @par
	/// @c VEX.128.66.0F38.WIG 30 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMOVZXBW_XMM_XMMM64 = 2863,
	/// @brief @c VPMOVZXBW ymm1, xmm2/m128
	/// @par
	/// @c VEX.256.66.0F38.WIG 30 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMOVZXBW_YMM_XMMM128 = 2864,
	/// @brief @c VPMOVZXBW xmm1 {k1}{z}, xmm2/m64
	/// @par
	/// @c EVEX.128.66.0F38.WIG 30 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVZXBW_XMM_K1Z_XMMM64 = 2865,
	/// @brief @c VPMOVZXBW ymm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.256.66.0F38.WIG 30 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVZXBW_YMM_K1Z_XMMM128 = 2866,
	/// @brief @c VPMOVZXBW zmm1 {k1}{z}, ymm2/m256
	/// @par
	/// @c EVEX.512.66.0F38.WIG 30 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVZXBW_ZMM_K1Z_YMMM256 = 2867,
	/// @brief @c VPMOVWB xmm1/m64 {k1}{z}, xmm2
	/// @par
	/// @c EVEX.128.F3.0F38.W0 30 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVWB_XMMM64_K1Z_XMM = 2868,
	/// @brief @c VPMOVWB xmm1/m128 {k1}{z}, ymm2
	/// @par
	/// @c EVEX.256.F3.0F38.W0 30 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVWB_XMMM128_K1Z_YMM = 2869,
	/// @brief @c VPMOVWB ymm1/m256 {k1}{z}, zmm2
	/// @par
	/// @c EVEX.512.F3.0F38.W0 30 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVWB_YMMM256_K1Z_ZMM = 2870,
	/// @brief @c PMOVZXBD xmm1, xmm2/m32
	/// @par
	/// @c 66 0F 38 31 /r
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PMOVZXBD_XMM_XMMM32 = 2871,
	/// @brief @c VPMOVZXBD xmm1, xmm2/m32
	/// @par
	/// @c VEX.128.66.0F38.WIG 31 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMOVZXBD_XMM_XMMM32 = 2872,
	/// @brief @c VPMOVZXBD ymm1, xmm2/m64
	/// @par
	/// @c VEX.256.66.0F38.WIG 31 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMOVZXBD_YMM_XMMM64 = 2873,
	/// @brief @c VPMOVZXBD xmm1 {k1}{z}, xmm2/m32
	/// @par
	/// @c EVEX.128.66.0F38.WIG 31 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVZXBD_XMM_K1Z_XMMM32 = 2874,
	/// @brief @c VPMOVZXBD ymm1 {k1}{z}, xmm2/m64
	/// @par
	/// @c EVEX.256.66.0F38.WIG 31 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVZXBD_YMM_K1Z_XMMM64 = 2875,
	/// @brief @c VPMOVZXBD zmm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.512.66.0F38.WIG 31 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVZXBD_ZMM_K1Z_XMMM128 = 2876,
	/// @brief @c VPMOVDB xmm1/m32 {k1}{z}, xmm2
	/// @par
	/// @c EVEX.128.F3.0F38.W0 31 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVDB_XMMM32_K1Z_XMM = 2877,
	/// @brief @c VPMOVDB xmm1/m64 {k1}{z}, ymm2
	/// @par
	/// @c EVEX.256.F3.0F38.W0 31 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVDB_XMMM64_K1Z_YMM = 2878,
	/// @brief @c VPMOVDB xmm1/m128 {k1}{z}, zmm2
	/// @par
	/// @c EVEX.512.F3.0F38.W0 31 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVDB_XMMM128_K1Z_ZMM = 2879,
	/// @brief @c PMOVZXBQ xmm1, xmm2/m16
	/// @par
	/// @c 66 0F 38 32 /r
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PMOVZXBQ_XMM_XMMM16 = 2880,
	/// @brief @c VPMOVZXBQ xmm1, xmm2/m16
	/// @par
	/// @c VEX.128.66.0F38.WIG 32 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMOVZXBQ_XMM_XMMM16 = 2881,
	/// @brief @c VPMOVZXBQ ymm1, xmm2/m32
	/// @par
	/// @c VEX.256.66.0F38.WIG 32 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMOVZXBQ_YMM_XMMM32 = 2882,
	/// @brief @c VPMOVZXBQ xmm1 {k1}{z}, xmm2/m16
	/// @par
	/// @c EVEX.128.66.0F38.WIG 32 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVZXBQ_XMM_K1Z_XMMM16 = 2883,
	/// @brief @c VPMOVZXBQ ymm1 {k1}{z}, xmm2/m32
	/// @par
	/// @c EVEX.256.66.0F38.WIG 32 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVZXBQ_YMM_K1Z_XMMM32 = 2884,
	/// @brief @c VPMOVZXBQ zmm1 {k1}{z}, xmm2/m64
	/// @par
	/// @c EVEX.512.66.0F38.WIG 32 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVZXBQ_ZMM_K1Z_XMMM64 = 2885,
	/// @brief @c VPMOVQB xmm1/m16 {k1}{z}, xmm2
	/// @par
	/// @c EVEX.128.F3.0F38.W0 32 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVQB_XMMM16_K1Z_XMM = 2886,
	/// @brief @c VPMOVQB xmm1/m32 {k1}{z}, ymm2
	/// @par
	/// @c EVEX.256.F3.0F38.W0 32 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVQB_XMMM32_K1Z_YMM = 2887,
	/// @brief @c VPMOVQB xmm1/m64 {k1}{z}, zmm2
	/// @par
	/// @c EVEX.512.F3.0F38.W0 32 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVQB_XMMM64_K1Z_ZMM = 2888,
	/// @brief @c PMOVZXWD xmm1, xmm2/m64
	/// @par
	/// @c 66 0F 38 33 /r
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PMOVZXWD_XMM_XMMM64 = 2889,
	/// @brief @c VPMOVZXWD xmm1, xmm2/m64
	/// @par
	/// @c VEX.128.66.0F38.WIG 33 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMOVZXWD_XMM_XMMM64 = 2890,
	/// @brief @c VPMOVZXWD ymm1, xmm2/m128
	/// @par
	/// @c VEX.256.66.0F38.WIG 33 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMOVZXWD_YMM_XMMM128 = 2891,
	/// @brief @c VPMOVZXWD xmm1 {k1}{z}, xmm2/m64
	/// @par
	/// @c EVEX.128.66.0F38.WIG 33 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVZXWD_XMM_K1Z_XMMM64 = 2892,
	/// @brief @c VPMOVZXWD ymm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.256.66.0F38.WIG 33 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVZXWD_YMM_K1Z_XMMM128 = 2893,
	/// @brief @c VPMOVZXWD zmm1 {k1}{z}, ymm2/m256
	/// @par
	/// @c EVEX.512.66.0F38.WIG 33 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVZXWD_ZMM_K1Z_YMMM256 = 2894,
	/// @brief @c VPMOVDW xmm1/m64 {k1}{z}, xmm2
	/// @par
	/// @c EVEX.128.F3.0F38.W0 33 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVDW_XMMM64_K1Z_XMM = 2895,
	/// @brief @c VPMOVDW xmm1/m128 {k1}{z}, ymm2
	/// @par
	/// @c EVEX.256.F3.0F38.W0 33 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVDW_XMMM128_K1Z_YMM = 2896,
	/// @brief @c VPMOVDW ymm1/m256 {k1}{z}, zmm2
	/// @par
	/// @c EVEX.512.F3.0F38.W0 33 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVDW_YMMM256_K1Z_ZMM = 2897,
	/// @brief @c PMOVZXWQ xmm1, xmm2/m32
	/// @par
	/// @c 66 0F 38 34 /r
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PMOVZXWQ_XMM_XMMM32 = 2898,
	/// @brief @c VPMOVZXWQ xmm1, xmm2/m32
	/// @par
	/// @c VEX.128.66.0F38.WIG 34 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMOVZXWQ_XMM_XMMM32 = 2899,
	/// @brief @c VPMOVZXWQ ymm1, xmm2/m64
	/// @par
	/// @c VEX.256.66.0F38.WIG 34 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMOVZXWQ_YMM_XMMM64 = 2900,
	/// @brief @c VPMOVZXWQ xmm1 {k1}{z}, xmm2/m32
	/// @par
	/// @c EVEX.128.66.0F38.WIG 34 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVZXWQ_XMM_K1Z_XMMM32 = 2901,
	/// @brief @c VPMOVZXWQ ymm1 {k1}{z}, xmm2/m64
	/// @par
	/// @c EVEX.256.66.0F38.WIG 34 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVZXWQ_YMM_K1Z_XMMM64 = 2902,
	/// @brief @c VPMOVZXWQ zmm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.512.66.0F38.WIG 34 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVZXWQ_ZMM_K1Z_XMMM128 = 2903,
	/// @brief @c VPMOVQW xmm1/m32 {k1}{z}, xmm2
	/// @par
	/// @c EVEX.128.F3.0F38.W0 34 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVQW_XMMM32_K1Z_XMM = 2904,
	/// @brief @c VPMOVQW xmm1/m64 {k1}{z}, ymm2
	/// @par
	/// @c EVEX.256.F3.0F38.W0 34 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVQW_XMMM64_K1Z_YMM = 2905,
	/// @brief @c VPMOVQW xmm1/m128 {k1}{z}, zmm2
	/// @par
	/// @c EVEX.512.F3.0F38.W0 34 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVQW_XMMM128_K1Z_ZMM = 2906,
	/// @brief @c PMOVZXDQ xmm1, xmm2/m64
	/// @par
	/// @c 66 0F 38 35 /r
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PMOVZXDQ_XMM_XMMM64 = 2907,
	/// @brief @c VPMOVZXDQ xmm1, xmm2/m64
	/// @par
	/// @c VEX.128.66.0F38.WIG 35 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMOVZXDQ_XMM_XMMM64 = 2908,
	/// @brief @c VPMOVZXDQ ymm1, xmm2/m128
	/// @par
	/// @c VEX.256.66.0F38.WIG 35 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMOVZXDQ_YMM_XMMM128 = 2909,
	/// @brief @c VPMOVZXDQ xmm1 {k1}{z}, xmm2/m64
	/// @par
	/// @c EVEX.128.66.0F38.W0 35 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVZXDQ_XMM_K1Z_XMMM64 = 2910,
	/// @brief @c VPMOVZXDQ ymm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.256.66.0F38.W0 35 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVZXDQ_YMM_K1Z_XMMM128 = 2911,
	/// @brief @c VPMOVZXDQ zmm1 {k1}{z}, ymm2/m256
	/// @par
	/// @c EVEX.512.66.0F38.W0 35 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVZXDQ_ZMM_K1Z_YMMM256 = 2912,
	/// @brief @c VPMOVQD xmm1/m64 {k1}{z}, xmm2
	/// @par
	/// @c EVEX.128.F3.0F38.W0 35 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVQD_XMMM64_K1Z_XMM = 2913,
	/// @brief @c VPMOVQD xmm1/m128 {k1}{z}, ymm2
	/// @par
	/// @c EVEX.256.F3.0F38.W0 35 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVQD_XMMM128_K1Z_YMM = 2914,
	/// @brief @c VPMOVQD ymm1/m256 {k1}{z}, zmm2
	/// @par
	/// @c EVEX.512.F3.0F38.W0 35 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVQD_YMMM256_K1Z_ZMM = 2915,
	/// @brief @c VPERMD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 36 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPERMD_YMM_YMM_YMMM256 = 2916,
	/// @brief @c VPERMD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 36 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMD_YMM_K1Z_YMM_YMMM256B32 = 2917,
	/// @brief @c VPERMD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 36 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMD_ZMM_K1Z_ZMM_ZMMM512B32 = 2918,
	/// @brief @c VPERMQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 36 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMQ_YMM_K1Z_YMM_YMMM256B64 = 2919,
	/// @brief @c VPERMQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 36 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMQ_ZMM_K1Z_ZMM_ZMMM512B64 = 2920,
	/// @brief @c PCMPGTQ xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 37 /r
	/// @par
	/// @c SSE4.2
	/// @par
	/// @c 16/32/64-bit
	PCMPGTQ_XMM_XMMM128 = 2921,
	/// @brief @c VPCMPGTQ xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 37 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPCMPGTQ_XMM_XMM_XMMM128 = 2922,
	/// @brief @c VPCMPGTQ ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG 37 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPCMPGTQ_YMM_YMM_YMMM256 = 2923,
	/// @brief @c VPCMPGTQ k1 {k2}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 37 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPGTQ_KR_K1_XMM_XMMM128B64 = 2924,
	/// @brief @c VPCMPGTQ k1 {k2}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 37 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPGTQ_KR_K1_YMM_YMMM256B64 = 2925,
	/// @brief @c VPCMPGTQ k1 {k2}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 37 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPGTQ_KR_K1_ZMM_ZMMM512B64 = 2926,
	/// @brief @c PMINSB xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 38 /r
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PMINSB_XMM_XMMM128 = 2927,
	/// @brief @c VPMINSB xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 38 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMINSB_XMM_XMM_XMMM128 = 2928,
	/// @brief @c VPMINSB ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG 38 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMINSB_YMM_YMM_YMMM256 = 2929,
	/// @brief @c VPMINSB xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F38.WIG 38 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMINSB_XMM_K1Z_XMM_XMMM128 = 2930,
	/// @brief @c VPMINSB ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F38.WIG 38 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMINSB_YMM_K1Z_YMM_YMMM256 = 2931,
	/// @brief @c VPMINSB zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F38.WIG 38 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMINSB_ZMM_K1Z_ZMM_ZMMM512 = 2932,
	/// @brief @c VPMOVM2D xmm1, k1
	/// @par
	/// @c EVEX.128.F3.0F38.W0 38 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVM2D_XMM_KR = 2933,
	/// @brief @c VPMOVM2D ymm1, k1
	/// @par
	/// @c EVEX.256.F3.0F38.W0 38 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVM2D_YMM_KR = 2934,
	/// @brief @c VPMOVM2D zmm1, k1
	/// @par
	/// @c EVEX.512.F3.0F38.W0 38 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVM2D_ZMM_KR = 2935,
	/// @brief @c VPMOVM2Q xmm1, k1
	/// @par
	/// @c EVEX.128.F3.0F38.W1 38 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVM2Q_XMM_KR = 2936,
	/// @brief @c VPMOVM2Q ymm1, k1
	/// @par
	/// @c EVEX.256.F3.0F38.W1 38 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVM2Q_YMM_KR = 2937,
	/// @brief @c VPMOVM2Q zmm1, k1
	/// @par
	/// @c EVEX.512.F3.0F38.W1 38 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVM2Q_ZMM_KR = 2938,
	/// @brief @c PMINSD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 39 /r
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PMINSD_XMM_XMMM128 = 2939,
	/// @brief @c VPMINSD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 39 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMINSD_XMM_XMM_XMMM128 = 2940,
	/// @brief @c VPMINSD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG 39 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMINSD_YMM_YMM_YMMM256 = 2941,
	/// @brief @c VPMINSD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 39 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMINSD_XMM_K1Z_XMM_XMMM128B32 = 2942,
	/// @brief @c VPMINSD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 39 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMINSD_YMM_K1Z_YMM_YMMM256B32 = 2943,
	/// @brief @c VPMINSD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 39 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMINSD_ZMM_K1Z_ZMM_ZMMM512B32 = 2944,
	/// @brief @c VPMINSQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 39 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMINSQ_XMM_K1Z_XMM_XMMM128B64 = 2945,
	/// @brief @c VPMINSQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 39 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMINSQ_YMM_K1Z_YMM_YMMM256B64 = 2946,
	/// @brief @c VPMINSQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 39 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMINSQ_ZMM_K1Z_ZMM_ZMMM512B64 = 2947,
	/// @brief @c VPMOVD2M k1, xmm1
	/// @par
	/// @c EVEX.128.F3.0F38.W0 39 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVD2M_KR_XMM = 2948,
	/// @brief @c VPMOVD2M k1, ymm1
	/// @par
	/// @c EVEX.256.F3.0F38.W0 39 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVD2M_KR_YMM = 2949,
	/// @brief @c VPMOVD2M k1, zmm1
	/// @par
	/// @c EVEX.512.F3.0F38.W0 39 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVD2M_KR_ZMM = 2950,
	/// @brief @c VPMOVQ2M k1, xmm1
	/// @par
	/// @c EVEX.128.F3.0F38.W1 39 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVQ2M_KR_XMM = 2951,
	/// @brief @c VPMOVQ2M k1, ymm1
	/// @par
	/// @c EVEX.256.F3.0F38.W1 39 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVQ2M_KR_YMM = 2952,
	/// @brief @c VPMOVQ2M k1, zmm1
	/// @par
	/// @c EVEX.512.F3.0F38.W1 39 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMOVQ2M_KR_ZMM = 2953,
	/// @brief @c PMINUW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 3A /r
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PMINUW_XMM_XMMM128 = 2954,
	/// @brief @c VPMINUW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 3A /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMINUW_XMM_XMM_XMMM128 = 2955,
	/// @brief @c VPMINUW ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG 3A /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMINUW_YMM_YMM_YMMM256 = 2956,
	/// @brief @c VPMINUW xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F38.WIG 3A /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMINUW_XMM_K1Z_XMM_XMMM128 = 2957,
	/// @brief @c VPMINUW ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F38.WIG 3A /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMINUW_YMM_K1Z_YMM_YMMM256 = 2958,
	/// @brief @c VPMINUW zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F38.WIG 3A /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMINUW_ZMM_K1Z_ZMM_ZMMM512 = 2959,
	/// @brief @c VPBROADCASTMW2D xmm1, k1
	/// @par
	/// @c EVEX.128.F3.0F38.W0 3A /r
	/// @par
	/// @c AVX512VL and AVX512CD
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBROADCASTMW2D_XMM_KR = 2960,
	/// @brief @c VPBROADCASTMW2D ymm1, k1
	/// @par
	/// @c EVEX.256.F3.0F38.W0 3A /r
	/// @par
	/// @c AVX512VL and AVX512CD
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBROADCASTMW2D_YMM_KR = 2961,
	/// @brief @c VPBROADCASTMW2D zmm1, k1
	/// @par
	/// @c EVEX.512.F3.0F38.W0 3A /r
	/// @par
	/// @c AVX512CD
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBROADCASTMW2D_ZMM_KR = 2962,
	/// @brief @c PMINUD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 3B /r
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PMINUD_XMM_XMMM128 = 2963,
	/// @brief @c VPMINUD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 3B /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMINUD_XMM_XMM_XMMM128 = 2964,
	/// @brief @c VPMINUD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG 3B /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMINUD_YMM_YMM_YMMM256 = 2965,
	/// @brief @c VPMINUD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 3B /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMINUD_XMM_K1Z_XMM_XMMM128B32 = 2966,
	/// @brief @c VPMINUD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 3B /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMINUD_YMM_K1Z_YMM_YMMM256B32 = 2967,
	/// @brief @c VPMINUD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 3B /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMINUD_ZMM_K1Z_ZMM_ZMMM512B32 = 2968,
	/// @brief @c VPMINUQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 3B /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMINUQ_XMM_K1Z_XMM_XMMM128B64 = 2969,
	/// @brief @c VPMINUQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 3B /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMINUQ_YMM_K1Z_YMM_YMMM256B64 = 2970,
	/// @brief @c VPMINUQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 3B /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMINUQ_ZMM_K1Z_ZMM_ZMMM512B64 = 2971,
	/// @brief @c PMAXSB xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 3C /r
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PMAXSB_XMM_XMMM128 = 2972,
	/// @brief @c VPMAXSB xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 3C /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMAXSB_XMM_XMM_XMMM128 = 2973,
	/// @brief @c VPMAXSB ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG 3C /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMAXSB_YMM_YMM_YMMM256 = 2974,
	/// @brief @c VPMAXSB xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F38.WIG 3C /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMAXSB_XMM_K1Z_XMM_XMMM128 = 2975,
	/// @brief @c VPMAXSB ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F38.WIG 3C /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMAXSB_YMM_K1Z_YMM_YMMM256 = 2976,
	/// @brief @c VPMAXSB zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F38.WIG 3C /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMAXSB_ZMM_K1Z_ZMM_ZMMM512 = 2977,
	/// @brief @c PMAXSD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 3D /r
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PMAXSD_XMM_XMMM128 = 2978,
	/// @brief @c VPMAXSD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 3D /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMAXSD_XMM_XMM_XMMM128 = 2979,
	/// @brief @c VPMAXSD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG 3D /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMAXSD_YMM_YMM_YMMM256 = 2980,
	/// @brief @c VPMAXSD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 3D /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMAXSD_XMM_K1Z_XMM_XMMM128B32 = 2981,
	/// @brief @c VPMAXSD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 3D /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMAXSD_YMM_K1Z_YMM_YMMM256B32 = 2982,
	/// @brief @c VPMAXSD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 3D /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMAXSD_ZMM_K1Z_ZMM_ZMMM512B32 = 2983,
	/// @brief @c VPMAXSQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 3D /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMAXSQ_XMM_K1Z_XMM_XMMM128B64 = 2984,
	/// @brief @c VPMAXSQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 3D /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMAXSQ_YMM_K1Z_YMM_YMMM256B64 = 2985,
	/// @brief @c VPMAXSQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 3D /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMAXSQ_ZMM_K1Z_ZMM_ZMMM512B64 = 2986,
	/// @brief @c PMAXUW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 3E /r
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PMAXUW_XMM_XMMM128 = 2987,
	/// @brief @c VPMAXUW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 3E /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMAXUW_XMM_XMM_XMMM128 = 2988,
	/// @brief @c VPMAXUW ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG 3E /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMAXUW_YMM_YMM_YMMM256 = 2989,
	/// @brief @c VPMAXUW xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F38.WIG 3E /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMAXUW_XMM_K1Z_XMM_XMMM128 = 2990,
	/// @brief @c VPMAXUW ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F38.WIG 3E /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMAXUW_YMM_K1Z_YMM_YMMM256 = 2991,
	/// @brief @c VPMAXUW zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F38.WIG 3E /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMAXUW_ZMM_K1Z_ZMM_ZMMM512 = 2992,
	/// @brief @c PMAXUD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 3F /r
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PMAXUD_XMM_XMMM128 = 2993,
	/// @brief @c VPMAXUD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 3F /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMAXUD_XMM_XMM_XMMM128 = 2994,
	/// @brief @c VPMAXUD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG 3F /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMAXUD_YMM_YMM_YMMM256 = 2995,
	/// @brief @c VPMAXUD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 3F /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMAXUD_XMM_K1Z_XMM_XMMM128B32 = 2996,
	/// @brief @c VPMAXUD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 3F /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMAXUD_YMM_K1Z_YMM_YMMM256B32 = 2997,
	/// @brief @c VPMAXUD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 3F /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMAXUD_ZMM_K1Z_ZMM_ZMMM512B32 = 2998,
	/// @brief @c VPMAXUQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 3F /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMAXUQ_XMM_K1Z_XMM_XMMM128B64 = 2999,
	/// @brief @c VPMAXUQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 3F /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMAXUQ_YMM_K1Z_YMM_YMMM256B64 = 3000,
	/// @brief @c VPMAXUQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 3F /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMAXUQ_ZMM_K1Z_ZMM_ZMMM512B64 = 3001,
	/// @brief @c PMULLD xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 40 /r
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PMULLD_XMM_XMMM128 = 3002,
	/// @brief @c VPMULLD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 40 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMULLD_XMM_XMM_XMMM128 = 3003,
	/// @brief @c VPMULLD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG 40 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMULLD_YMM_YMM_YMMM256 = 3004,
	/// @brief @c VPMULLD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 40 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMULLD_XMM_K1Z_XMM_XMMM128B32 = 3005,
	/// @brief @c VPMULLD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 40 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMULLD_YMM_K1Z_YMM_YMMM256B32 = 3006,
	/// @brief @c VPMULLD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 40 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMULLD_ZMM_K1Z_ZMM_ZMMM512B32 = 3007,
	/// @brief @c VPMULLQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 40 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMULLQ_XMM_K1Z_XMM_XMMM128B64 = 3008,
	/// @brief @c VPMULLQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 40 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMULLQ_YMM_K1Z_YMM_YMMM256B64 = 3009,
	/// @brief @c VPMULLQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 40 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMULLQ_ZMM_K1Z_ZMM_ZMMM512B64 = 3010,
	/// @brief @c PHMINPOSUW xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 41 /r
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PHMINPOSUW_XMM_XMMM128 = 3011,
	/// @brief @c VPHMINPOSUW xmm1, xmm2/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG 41 /r
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPHMINPOSUW_XMM_XMMM128 = 3012,
	/// @brief @c VGETEXPPS xmm1 {k1}{z}, xmm2/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 42 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGETEXPPS_XMM_K1Z_XMMM128B32 = 3013,
	/// @brief @c VGETEXPPS ymm1 {k1}{z}, ymm2/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 42 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGETEXPPS_YMM_K1Z_YMMM256B32 = 3014,
	/// @brief @c VGETEXPPS zmm1 {k1}{z}, zmm2/m512/m32bcst{sae}
	/// @par
	/// @c EVEX.512.66.0F38.W0 42 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGETEXPPS_ZMM_K1Z_ZMMM512B32_SAE = 3015,
	/// @brief @c VGETEXPPD xmm1 {k1}{z}, xmm2/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 42 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGETEXPPD_XMM_K1Z_XMMM128B64 = 3016,
	/// @brief @c VGETEXPPD ymm1 {k1}{z}, ymm2/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 42 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGETEXPPD_YMM_K1Z_YMMM256B64 = 3017,
	/// @brief @c VGETEXPPD zmm1 {k1}{z}, zmm2/m512/m64bcst{sae}
	/// @par
	/// @c EVEX.512.66.0F38.W1 42 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGETEXPPD_ZMM_K1Z_ZMMM512B64_SAE = 3018,
	/// @brief @c VGETEXPSS xmm1 {k1}{z}, xmm2, xmm3/m32{sae}
	/// @par
	/// @c EVEX.LIG.66.0F38.W0 43 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGETEXPSS_XMM_K1Z_XMM_XMMM32_SAE = 3019,
	/// @brief @c VGETEXPSD xmm1 {k1}{z}, xmm2, xmm3/m64{sae}
	/// @par
	/// @c EVEX.LIG.66.0F38.W1 43 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGETEXPSD_XMM_K1Z_XMM_XMMM64_SAE = 3020,
	/// @brief @c VPLZCNTD xmm1 {k1}{z}, xmm2/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 44 /r
	/// @par
	/// @c AVX512VL and AVX512CD
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPLZCNTD_XMM_K1Z_XMMM128B32 = 3021,
	/// @brief @c VPLZCNTD ymm1 {k1}{z}, ymm2/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 44 /r
	/// @par
	/// @c AVX512VL and AVX512CD
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPLZCNTD_YMM_K1Z_YMMM256B32 = 3022,
	/// @brief @c VPLZCNTD zmm1 {k1}{z}, zmm2/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 44 /r
	/// @par
	/// @c AVX512CD
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPLZCNTD_ZMM_K1Z_ZMMM512B32 = 3023,
	/// @brief @c VPLZCNTQ xmm1 {k1}{z}, xmm2/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 44 /r
	/// @par
	/// @c AVX512VL and AVX512CD
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPLZCNTQ_XMM_K1Z_XMMM128B64 = 3024,
	/// @brief @c VPLZCNTQ ymm1 {k1}{z}, ymm2/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 44 /r
	/// @par
	/// @c AVX512VL and AVX512CD
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPLZCNTQ_YMM_K1Z_YMMM256B64 = 3025,
	/// @brief @c VPLZCNTQ zmm1 {k1}{z}, zmm2/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 44 /r
	/// @par
	/// @c AVX512CD
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPLZCNTQ_ZMM_K1Z_ZMMM512B64 = 3026,
	/// @brief @c VPSRLVD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 45 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSRLVD_XMM_XMM_XMMM128 = 3027,
	/// @brief @c VPSRLVD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 45 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSRLVD_YMM_YMM_YMMM256 = 3028,
	/// @brief @c VPSRLVQ xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W1 45 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSRLVQ_XMM_XMM_XMMM128 = 3029,
	/// @brief @c VPSRLVQ ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W1 45 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSRLVQ_YMM_YMM_YMMM256 = 3030,
	/// @brief @c VPSRLVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 45 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRLVD_XMM_K1Z_XMM_XMMM128B32 = 3031,
	/// @brief @c VPSRLVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 45 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRLVD_YMM_K1Z_YMM_YMMM256B32 = 3032,
	/// @brief @c VPSRLVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 45 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRLVD_ZMM_K1Z_ZMM_ZMMM512B32 = 3033,
	/// @brief @c VPSRLVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 45 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRLVQ_XMM_K1Z_XMM_XMMM128B64 = 3034,
	/// @brief @c VPSRLVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 45 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRLVQ_YMM_K1Z_YMM_YMMM256B64 = 3035,
	/// @brief @c VPSRLVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 45 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRLVQ_ZMM_K1Z_ZMM_ZMMM512B64 = 3036,
	/// @brief @c VPSRAVD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 46 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSRAVD_XMM_XMM_XMMM128 = 3037,
	/// @brief @c VPSRAVD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 46 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSRAVD_YMM_YMM_YMMM256 = 3038,
	/// @brief @c VPSRAVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 46 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRAVD_XMM_K1Z_XMM_XMMM128B32 = 3039,
	/// @brief @c VPSRAVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 46 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRAVD_YMM_K1Z_YMM_YMMM256B32 = 3040,
	/// @brief @c VPSRAVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 46 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRAVD_ZMM_K1Z_ZMM_ZMMM512B32 = 3041,
	/// @brief @c VPSRAVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 46 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRAVQ_XMM_K1Z_XMM_XMMM128B64 = 3042,
	/// @brief @c VPSRAVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 46 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRAVQ_YMM_K1Z_YMM_YMMM256B64 = 3043,
	/// @brief @c VPSRAVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 46 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSRAVQ_ZMM_K1Z_ZMM_ZMMM512B64 = 3044,
	/// @brief @c VPSLLVD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 47 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSLLVD_XMM_XMM_XMMM128 = 3045,
	/// @brief @c VPSLLVD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 47 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSLLVD_YMM_YMM_YMMM256 = 3046,
	/// @brief @c VPSLLVQ xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W1 47 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSLLVQ_XMM_XMM_XMMM128 = 3047,
	/// @brief @c VPSLLVQ ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W1 47 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPSLLVQ_YMM_YMM_YMMM256 = 3048,
	/// @brief @c VPSLLVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 47 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSLLVD_XMM_K1Z_XMM_XMMM128B32 = 3049,
	/// @brief @c VPSLLVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 47 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSLLVD_YMM_K1Z_YMM_YMMM256B32 = 3050,
	/// @brief @c VPSLLVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 47 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSLLVD_ZMM_K1Z_ZMM_ZMMM512B32 = 3051,
	/// @brief @c VPSLLVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 47 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSLLVQ_XMM_K1Z_XMM_XMMM128B64 = 3052,
	/// @brief @c VPSLLVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 47 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSLLVQ_YMM_K1Z_YMM_YMMM256B64 = 3053,
	/// @brief @c VPSLLVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 47 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSLLVQ_ZMM_K1Z_ZMM_ZMMM512B64 = 3054,
	/// @brief @c VRCP14PS xmm1 {k1}{z}, xmm2/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 4C /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRCP14PS_XMM_K1Z_XMMM128B32 = 3055,
	/// @brief @c VRCP14PS ymm1 {k1}{z}, ymm2/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 4C /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRCP14PS_YMM_K1Z_YMMM256B32 = 3056,
	/// @brief @c VRCP14PS zmm1 {k1}{z}, zmm2/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 4C /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRCP14PS_ZMM_K1Z_ZMMM512B32 = 3057,
	/// @brief @c VRCP14PD xmm1 {k1}{z}, xmm2/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 4C /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRCP14PD_XMM_K1Z_XMMM128B64 = 3058,
	/// @brief @c VRCP14PD ymm1 {k1}{z}, ymm2/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 4C /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRCP14PD_YMM_K1Z_YMMM256B64 = 3059,
	/// @brief @c VRCP14PD zmm1 {k1}{z}, zmm2/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 4C /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRCP14PD_ZMM_K1Z_ZMMM512B64 = 3060,
	/// @brief @c VRCP14SS xmm1 {k1}{z}, xmm2, xmm3/m32
	/// @par
	/// @c EVEX.LIG.66.0F38.W0 4D /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRCP14SS_XMM_K1Z_XMM_XMMM32 = 3061,
	/// @brief @c VRCP14SD xmm1 {k1}{z}, xmm2, xmm3/m64
	/// @par
	/// @c EVEX.LIG.66.0F38.W1 4D /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRCP14SD_XMM_K1Z_XMM_XMMM64 = 3062,
	/// @brief @c VRSQRT14PS xmm1 {k1}{z}, xmm2/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 4E /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRSQRT14PS_XMM_K1Z_XMMM128B32 = 3063,
	/// @brief @c VRSQRT14PS ymm1 {k1}{z}, ymm2/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 4E /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRSQRT14PS_YMM_K1Z_YMMM256B32 = 3064,
	/// @brief @c VRSQRT14PS zmm1 {k1}{z}, zmm2/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 4E /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRSQRT14PS_ZMM_K1Z_ZMMM512B32 = 3065,
	/// @brief @c VRSQRT14PD xmm1 {k1}{z}, xmm2/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 4E /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRSQRT14PD_XMM_K1Z_XMMM128B64 = 3066,
	/// @brief @c VRSQRT14PD ymm1 {k1}{z}, ymm2/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 4E /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRSQRT14PD_YMM_K1Z_YMMM256B64 = 3067,
	/// @brief @c VRSQRT14PD zmm1 {k1}{z}, zmm2/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 4E /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRSQRT14PD_ZMM_K1Z_ZMMM512B64 = 3068,
	/// @brief @c VRSQRT14SS xmm1 {k1}{z}, xmm2, xmm3/m32
	/// @par
	/// @c EVEX.LIG.66.0F38.W0 4F /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRSQRT14SS_XMM_K1Z_XMM_XMMM32 = 3069,
	/// @brief @c VRSQRT14SD xmm1 {k1}{z}, xmm2, xmm3/m64
	/// @par
	/// @c EVEX.LIG.66.0F38.W1 4F /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRSQRT14SD_XMM_K1Z_XMM_XMMM64 = 3070,
	/// @brief @c VPDPBUSD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 50 /r
	/// @par
	/// @c AVX512VL and AVX512_VNNI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPDPBUSD_XMM_K1Z_XMM_XMMM128B32 = 3071,
	/// @brief @c VPDPBUSD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 50 /r
	/// @par
	/// @c AVX512VL and AVX512_VNNI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPDPBUSD_YMM_K1Z_YMM_YMMM256B32 = 3072,
	/// @brief @c VPDPBUSD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 50 /r
	/// @par
	/// @c AVX512_VNNI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPDPBUSD_ZMM_K1Z_ZMM_ZMMM512B32 = 3073,
	/// @brief @c VPDPBUSDS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 51 /r
	/// @par
	/// @c AVX512VL and AVX512_VNNI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPDPBUSDS_XMM_K1Z_XMM_XMMM128B32 = 3074,
	/// @brief @c VPDPBUSDS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 51 /r
	/// @par
	/// @c AVX512VL and AVX512_VNNI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPDPBUSDS_YMM_K1Z_YMM_YMMM256B32 = 3075,
	/// @brief @c VPDPBUSDS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 51 /r
	/// @par
	/// @c AVX512_VNNI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPDPBUSDS_ZMM_K1Z_ZMM_ZMMM512B32 = 3076,
	/// @brief @c VPDPWSSD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 52 /r
	/// @par
	/// @c AVX512VL and AVX512_VNNI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPDPWSSD_XMM_K1Z_XMM_XMMM128B32 = 3077,
	/// @brief @c VPDPWSSD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 52 /r
	/// @par
	/// @c AVX512VL and AVX512_VNNI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPDPWSSD_YMM_K1Z_YMM_YMMM256B32 = 3078,
	/// @brief @c VPDPWSSD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 52 /r
	/// @par
	/// @c AVX512_VNNI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPDPWSSD_ZMM_K1Z_ZMM_ZMMM512B32 = 3079,
	/// @brief @c VDPBF16PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.F3.0F38.W0 52 /r
	/// @par
	/// @c AVX512VL and AVX512_BF16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VDPBF16PS_XMM_K1Z_XMM_XMMM128B32 = 3080,
	/// @brief @c VDPBF16PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.F3.0F38.W0 52 /r
	/// @par
	/// @c AVX512VL and AVX512_BF16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VDPBF16PS_YMM_K1Z_YMM_YMMM256B32 = 3081,
	/// @brief @c VDPBF16PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.F3.0F38.W0 52 /r
	/// @par
	/// @c AVX512F and AVX512_BF16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VDPBF16PS_ZMM_K1Z_ZMM_ZMMM512B32 = 3082,
	/// @brief @c VP4DPWSSD zmm1 {k1}{z}, zmm2+3, m128
	/// @par
	/// @c EVEX.512.F2.0F38.W0 52 /r
	/// @par
	/// @c AVX512_4VNNIW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VP4DPWSSD_ZMM_K1Z_ZMMP3_M128 = 3083,
	/// @brief @c VPDPWSSDS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 53 /r
	/// @par
	/// @c AVX512VL and AVX512_VNNI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPDPWSSDS_XMM_K1Z_XMM_XMMM128B32 = 3084,
	/// @brief @c VPDPWSSDS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 53 /r
	/// @par
	/// @c AVX512VL and AVX512_VNNI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPDPWSSDS_YMM_K1Z_YMM_YMMM256B32 = 3085,
	/// @brief @c VPDPWSSDS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 53 /r
	/// @par
	/// @c AVX512_VNNI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPDPWSSDS_ZMM_K1Z_ZMM_ZMMM512B32 = 3086,
	/// @brief @c VP4DPWSSDS zmm1 {k1}{z}, zmm2+3, m128
	/// @par
	/// @c EVEX.512.F2.0F38.W0 53 /r
	/// @par
	/// @c AVX512_4VNNIW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VP4DPWSSDS_ZMM_K1Z_ZMMP3_M128 = 3087,
	/// @brief @c VPOPCNTB xmm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.128.66.0F38.W0 54 /r
	/// @par
	/// @c AVX512VL and AVX512_BITALG
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPOPCNTB_XMM_K1Z_XMMM128 = 3088,
	/// @brief @c VPOPCNTB ymm1 {k1}{z}, ymm2/m256
	/// @par
	/// @c EVEX.256.66.0F38.W0 54 /r
	/// @par
	/// @c AVX512VL and AVX512_BITALG
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPOPCNTB_YMM_K1Z_YMMM256 = 3089,
	/// @brief @c VPOPCNTB zmm1 {k1}{z}, zmm2/m512
	/// @par
	/// @c EVEX.512.66.0F38.W0 54 /r
	/// @par
	/// @c AVX512_BITALG
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPOPCNTB_ZMM_K1Z_ZMMM512 = 3090,
	/// @brief @c VPOPCNTW xmm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.128.66.0F38.W1 54 /r
	/// @par
	/// @c AVX512VL and AVX512_BITALG
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPOPCNTW_XMM_K1Z_XMMM128 = 3091,
	/// @brief @c VPOPCNTW ymm1 {k1}{z}, ymm2/m256
	/// @par
	/// @c EVEX.256.66.0F38.W1 54 /r
	/// @par
	/// @c AVX512VL and AVX512_BITALG
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPOPCNTW_YMM_K1Z_YMMM256 = 3092,
	/// @brief @c VPOPCNTW zmm1 {k1}{z}, zmm2/m512
	/// @par
	/// @c EVEX.512.66.0F38.W1 54 /r
	/// @par
	/// @c AVX512_BITALG
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPOPCNTW_ZMM_K1Z_ZMMM512 = 3093,
	/// @brief @c VPOPCNTD xmm1 {k1}{z}, xmm2/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 55 /r
	/// @par
	/// @c AVX512VL and AVX512_VPOPCNTDQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPOPCNTD_XMM_K1Z_XMMM128B32 = 3094,
	/// @brief @c VPOPCNTD ymm1 {k1}{z}, ymm2/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 55 /r
	/// @par
	/// @c AVX512VL and AVX512_VPOPCNTDQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPOPCNTD_YMM_K1Z_YMMM256B32 = 3095,
	/// @brief @c VPOPCNTD zmm1 {k1}{z}, zmm2/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 55 /r
	/// @par
	/// @c AVX512_VPOPCNTDQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPOPCNTD_ZMM_K1Z_ZMMM512B32 = 3096,
	/// @brief @c VPOPCNTQ xmm1 {k1}{z}, xmm2/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 55 /r
	/// @par
	/// @c AVX512VL and AVX512_VPOPCNTDQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPOPCNTQ_XMM_K1Z_XMMM128B64 = 3097,
	/// @brief @c VPOPCNTQ ymm1 {k1}{z}, ymm2/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 55 /r
	/// @par
	/// @c AVX512VL and AVX512_VPOPCNTDQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPOPCNTQ_YMM_K1Z_YMMM256B64 = 3098,
	/// @brief @c VPOPCNTQ zmm1 {k1}{z}, zmm2/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 55 /r
	/// @par
	/// @c AVX512_VPOPCNTDQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPOPCNTQ_ZMM_K1Z_ZMMM512B64 = 3099,
	/// @brief @c VPBROADCASTD xmm1, xmm2/m32
	/// @par
	/// @c VEX.128.66.0F38.W0 58 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPBROADCASTD_XMM_XMMM32 = 3100,
	/// @brief @c VPBROADCASTD ymm1, xmm2/m32
	/// @par
	/// @c VEX.256.66.0F38.W0 58 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPBROADCASTD_YMM_XMMM32 = 3101,
	/// @brief @c VPBROADCASTD xmm1 {k1}{z}, xmm2/m32
	/// @par
	/// @c EVEX.128.66.0F38.W0 58 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBROADCASTD_XMM_K1Z_XMMM32 = 3102,
	/// @brief @c VPBROADCASTD ymm1 {k1}{z}, xmm2/m32
	/// @par
	/// @c EVEX.256.66.0F38.W0 58 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBROADCASTD_YMM_K1Z_XMMM32 = 3103,
	/// @brief @c VPBROADCASTD zmm1 {k1}{z}, xmm2/m32
	/// @par
	/// @c EVEX.512.66.0F38.W0 58 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBROADCASTD_ZMM_K1Z_XMMM32 = 3104,
	/// @brief @c VPBROADCASTQ xmm1, xmm2/m64
	/// @par
	/// @c VEX.128.66.0F38.W0 59 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPBROADCASTQ_XMM_XMMM64 = 3105,
	/// @brief @c VPBROADCASTQ ymm1, xmm2/m64
	/// @par
	/// @c VEX.256.66.0F38.W0 59 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPBROADCASTQ_YMM_XMMM64 = 3106,
	/// @brief @c VBROADCASTI32X2 xmm1 {k1}{z}, xmm2/m64
	/// @par
	/// @c EVEX.128.66.0F38.W0 59 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VBROADCASTI32X2_XMM_K1Z_XMMM64 = 3107,
	/// @brief @c VBROADCASTI32X2 ymm1 {k1}{z}, xmm2/m64
	/// @par
	/// @c EVEX.256.66.0F38.W0 59 /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VBROADCASTI32X2_YMM_K1Z_XMMM64 = 3108,
	/// @brief @c VBROADCASTI32X2 zmm1 {k1}{z}, xmm2/m64
	/// @par
	/// @c EVEX.512.66.0F38.W0 59 /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VBROADCASTI32X2_ZMM_K1Z_XMMM64 = 3109,
	/// @brief @c VPBROADCASTQ xmm1 {k1}{z}, xmm2/m64
	/// @par
	/// @c EVEX.128.66.0F38.W1 59 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBROADCASTQ_XMM_K1Z_XMMM64 = 3110,
	/// @brief @c VPBROADCASTQ ymm1 {k1}{z}, xmm2/m64
	/// @par
	/// @c EVEX.256.66.0F38.W1 59 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBROADCASTQ_YMM_K1Z_XMMM64 = 3111,
	/// @brief @c VPBROADCASTQ zmm1 {k1}{z}, xmm2/m64
	/// @par
	/// @c EVEX.512.66.0F38.W1 59 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBROADCASTQ_ZMM_K1Z_XMMM64 = 3112,
	/// @brief @c VBROADCASTI128 ymm1, m128
	/// @par
	/// @c VEX.256.66.0F38.W0 5A /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VBROADCASTI128_YMM_M128 = 3113,
	/// @brief @c VBROADCASTI32X4 ymm1 {k1}{z}, m128
	/// @par
	/// @c EVEX.256.66.0F38.W0 5A /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VBROADCASTI32X4_YMM_K1Z_M128 = 3114,
	/// @brief @c VBROADCASTI32X4 zmm1 {k1}{z}, m128
	/// @par
	/// @c EVEX.512.66.0F38.W0 5A /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VBROADCASTI32X4_ZMM_K1Z_M128 = 3115,
	/// @brief @c VBROADCASTI64X2 ymm1 {k1}{z}, m128
	/// @par
	/// @c EVEX.256.66.0F38.W1 5A /r
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VBROADCASTI64X2_YMM_K1Z_M128 = 3116,
	/// @brief @c VBROADCASTI64X2 zmm1 {k1}{z}, m128
	/// @par
	/// @c EVEX.512.66.0F38.W1 5A /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VBROADCASTI64X2_ZMM_K1Z_M128 = 3117,
	/// @brief @c VBROADCASTI32X8 zmm1 {k1}{z}, m256
	/// @par
	/// @c EVEX.512.66.0F38.W0 5B /r
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VBROADCASTI32X8_ZMM_K1Z_M256 = 3118,
	/// @brief @c VBROADCASTI64X4 zmm1 {k1}{z}, m256
	/// @par
	/// @c EVEX.512.66.0F38.W1 5B /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VBROADCASTI64X4_ZMM_K1Z_M256 = 3119,
	/// @brief @c VPEXPANDB xmm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.128.66.0F38.W0 62 /r
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPEXPANDB_XMM_K1Z_XMMM128 = 3120,
	/// @brief @c VPEXPANDB ymm1 {k1}{z}, ymm2/m256
	/// @par
	/// @c EVEX.256.66.0F38.W0 62 /r
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPEXPANDB_YMM_K1Z_YMMM256 = 3121,
	/// @brief @c VPEXPANDB zmm1 {k1}{z}, zmm2/m512
	/// @par
	/// @c EVEX.512.66.0F38.W0 62 /r
	/// @par
	/// @c AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPEXPANDB_ZMM_K1Z_ZMMM512 = 3122,
	/// @brief @c VPEXPANDW xmm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.128.66.0F38.W1 62 /r
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPEXPANDW_XMM_K1Z_XMMM128 = 3123,
	/// @brief @c VPEXPANDW ymm1 {k1}{z}, ymm2/m256
	/// @par
	/// @c EVEX.256.66.0F38.W1 62 /r
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPEXPANDW_YMM_K1Z_YMMM256 = 3124,
	/// @brief @c VPEXPANDW zmm1 {k1}{z}, zmm2/m512
	/// @par
	/// @c EVEX.512.66.0F38.W1 62 /r
	/// @par
	/// @c AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPEXPANDW_ZMM_K1Z_ZMMM512 = 3125,
	/// @brief @c VPCOMPRESSB xmm1/m128 {k1}{z}, xmm2
	/// @par
	/// @c EVEX.128.66.0F38.W0 63 /r
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCOMPRESSB_XMMM128_K1Z_XMM = 3126,
	/// @brief @c VPCOMPRESSB ymm1/m256 {k1}{z}, ymm2
	/// @par
	/// @c EVEX.256.66.0F38.W0 63 /r
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCOMPRESSB_YMMM256_K1Z_YMM = 3127,
	/// @brief @c VPCOMPRESSB zmm1/m512 {k1}{z}, zmm2
	/// @par
	/// @c EVEX.512.66.0F38.W0 63 /r
	/// @par
	/// @c AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCOMPRESSB_ZMMM512_K1Z_ZMM = 3128,
	/// @brief @c VPCOMPRESSW xmm1/m128 {k1}{z}, xmm2
	/// @par
	/// @c EVEX.128.66.0F38.W1 63 /r
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCOMPRESSW_XMMM128_K1Z_XMM = 3129,
	/// @brief @c VPCOMPRESSW ymm1/m256 {k1}{z}, ymm2
	/// @par
	/// @c EVEX.256.66.0F38.W1 63 /r
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCOMPRESSW_YMMM256_K1Z_YMM = 3130,
	/// @brief @c VPCOMPRESSW zmm1/m512 {k1}{z}, zmm2
	/// @par
	/// @c EVEX.512.66.0F38.W1 63 /r
	/// @par
	/// @c AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCOMPRESSW_ZMMM512_K1Z_ZMM = 3131,
	/// @brief @c VPBLENDMD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 64 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBLENDMD_XMM_K1Z_XMM_XMMM128B32 = 3132,
	/// @brief @c VPBLENDMD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 64 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBLENDMD_YMM_K1Z_YMM_YMMM256B32 = 3133,
	/// @brief @c VPBLENDMD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 64 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBLENDMD_ZMM_K1Z_ZMM_ZMMM512B32 = 3134,
	/// @brief @c VPBLENDMQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 64 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBLENDMQ_XMM_K1Z_XMM_XMMM128B64 = 3135,
	/// @brief @c VPBLENDMQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 64 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBLENDMQ_YMM_K1Z_YMM_YMMM256B64 = 3136,
	/// @brief @c VPBLENDMQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 64 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBLENDMQ_ZMM_K1Z_ZMM_ZMMM512B64 = 3137,
	/// @brief @c VBLENDMPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 65 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VBLENDMPS_XMM_K1Z_XMM_XMMM128B32 = 3138,
	/// @brief @c VBLENDMPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 65 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VBLENDMPS_YMM_K1Z_YMM_YMMM256B32 = 3139,
	/// @brief @c VBLENDMPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 65 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VBLENDMPS_ZMM_K1Z_ZMM_ZMMM512B32 = 3140,
	/// @brief @c VBLENDMPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 65 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VBLENDMPD_XMM_K1Z_XMM_XMMM128B64 = 3141,
	/// @brief @c VBLENDMPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 65 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VBLENDMPD_YMM_K1Z_YMM_YMMM256B64 = 3142,
	/// @brief @c VBLENDMPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 65 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VBLENDMPD_ZMM_K1Z_ZMM_ZMMM512B64 = 3143,
	/// @brief @c VPBLENDMB xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F38.W0 66 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBLENDMB_XMM_K1Z_XMM_XMMM128 = 3144,
	/// @brief @c VPBLENDMB ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F38.W0 66 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBLENDMB_YMM_K1Z_YMM_YMMM256 = 3145,
	/// @brief @c VPBLENDMB zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F38.W0 66 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBLENDMB_ZMM_K1Z_ZMM_ZMMM512 = 3146,
	/// @brief @c VPBLENDMW xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F38.W1 66 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBLENDMW_XMM_K1Z_XMM_XMMM128 = 3147,
	/// @brief @c VPBLENDMW ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F38.W1 66 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBLENDMW_YMM_K1Z_YMM_YMMM256 = 3148,
	/// @brief @c VPBLENDMW zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F38.W1 66 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBLENDMW_ZMM_K1Z_ZMM_ZMMM512 = 3149,
	/// @brief @c VP2INTERSECTD k1+1, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.F2.0F38.W0 68 /r
	/// @par
	/// @c AVX512VL and AVX512_VP2INTERSECT
	/// @par
	/// @c 16/32/64-bit
	EVEX_VP2INTERSECTD_KP1_XMM_XMMM128B32 = 3150,
	/// @brief @c VP2INTERSECTD k1+1, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.F2.0F38.W0 68 /r
	/// @par
	/// @c AVX512VL and AVX512_VP2INTERSECT
	/// @par
	/// @c 16/32/64-bit
	EVEX_VP2INTERSECTD_KP1_YMM_YMMM256B32 = 3151,
	/// @brief @c VP2INTERSECTD k1+1, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.F2.0F38.W0 68 /r
	/// @par
	/// @c AVX512F and AVX512_VP2INTERSECT
	/// @par
	/// @c 16/32/64-bit
	EVEX_VP2INTERSECTD_KP1_ZMM_ZMMM512B32 = 3152,
	/// @brief @c VP2INTERSECTQ k1+1, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.F2.0F38.W1 68 /r
	/// @par
	/// @c AVX512VL and AVX512_VP2INTERSECT
	/// @par
	/// @c 16/32/64-bit
	EVEX_VP2INTERSECTQ_KP1_XMM_XMMM128B64 = 3153,
	/// @brief @c VP2INTERSECTQ k1+1, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.F2.0F38.W1 68 /r
	/// @par
	/// @c AVX512VL and AVX512_VP2INTERSECT
	/// @par
	/// @c 16/32/64-bit
	EVEX_VP2INTERSECTQ_KP1_YMM_YMMM256B64 = 3154,
	/// @brief @c VP2INTERSECTQ k1+1, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.F2.0F38.W1 68 /r
	/// @par
	/// @c AVX512F and AVX512_VP2INTERSECT
	/// @par
	/// @c 16/32/64-bit
	EVEX_VP2INTERSECTQ_KP1_ZMM_ZMMM512B64 = 3155,
	/// @brief @c VPSHLDVW xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F38.W1 70 /r
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHLDVW_XMM_K1Z_XMM_XMMM128 = 3156,
	/// @brief @c VPSHLDVW ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F38.W1 70 /r
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHLDVW_YMM_K1Z_YMM_YMMM256 = 3157,
	/// @brief @c VPSHLDVW zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F38.W1 70 /r
	/// @par
	/// @c AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHLDVW_ZMM_K1Z_ZMM_ZMMM512 = 3158,
	/// @brief @c VPSHLDVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 71 /r
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHLDVD_XMM_K1Z_XMM_XMMM128B32 = 3159,
	/// @brief @c VPSHLDVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 71 /r
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHLDVD_YMM_K1Z_YMM_YMMM256B32 = 3160,
	/// @brief @c VPSHLDVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 71 /r
	/// @par
	/// @c AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHLDVD_ZMM_K1Z_ZMM_ZMMM512B32 = 3161,
	/// @brief @c VPSHLDVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 71 /r
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHLDVQ_XMM_K1Z_XMM_XMMM128B64 = 3162,
	/// @brief @c VPSHLDVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 71 /r
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHLDVQ_YMM_K1Z_YMM_YMMM256B64 = 3163,
	/// @brief @c VPSHLDVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 71 /r
	/// @par
	/// @c AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHLDVQ_ZMM_K1Z_ZMM_ZMMM512B64 = 3164,
	/// @brief @c VPSHRDVW xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F38.W1 72 /r
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHRDVW_XMM_K1Z_XMM_XMMM128 = 3165,
	/// @brief @c VPSHRDVW ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F38.W1 72 /r
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHRDVW_YMM_K1Z_YMM_YMMM256 = 3166,
	/// @brief @c VPSHRDVW zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F38.W1 72 /r
	/// @par
	/// @c AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHRDVW_ZMM_K1Z_ZMM_ZMMM512 = 3167,
	/// @brief @c VCVTNEPS2BF16 xmm1 {k1}{z}, xmm2/m128/m32bcst
	/// @par
	/// @c EVEX.128.F3.0F38.W0 72 /r
	/// @par
	/// @c AVX512VL and AVX512_BF16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTNEPS2BF16_XMM_K1Z_XMMM128B32 = 3168,
	/// @brief @c VCVTNEPS2BF16 xmm1 {k1}{z}, ymm2/m256/m32bcst
	/// @par
	/// @c EVEX.256.F3.0F38.W0 72 /r
	/// @par
	/// @c AVX512VL and AVX512_BF16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTNEPS2BF16_XMM_K1Z_YMMM256B32 = 3169,
	/// @brief @c VCVTNEPS2BF16 ymm1 {k1}{z}, zmm2/m512/m32bcst
	/// @par
	/// @c EVEX.512.F3.0F38.W0 72 /r
	/// @par
	/// @c AVX512F and AVX512_BF16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTNEPS2BF16_YMM_K1Z_ZMMM512B32 = 3170,
	/// @brief @c VCVTNE2PS2BF16 xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.F2.0F38.W0 72 /r
	/// @par
	/// @c AVX512VL and AVX512_BF16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTNE2PS2BF16_XMM_K1Z_XMM_XMMM128B32 = 3171,
	/// @brief @c VCVTNE2PS2BF16 ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.F2.0F38.W0 72 /r
	/// @par
	/// @c AVX512VL and AVX512_BF16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTNE2PS2BF16_YMM_K1Z_YMM_YMMM256B32 = 3172,
	/// @brief @c VCVTNE2PS2BF16 zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.F2.0F38.W0 72 /r
	/// @par
	/// @c AVX512F and AVX512_BF16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTNE2PS2BF16_ZMM_K1Z_ZMM_ZMMM512B32 = 3173,
	/// @brief @c VPSHRDVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 73 /r
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHRDVD_XMM_K1Z_XMM_XMMM128B32 = 3174,
	/// @brief @c VPSHRDVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 73 /r
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHRDVD_YMM_K1Z_YMM_YMMM256B32 = 3175,
	/// @brief @c VPSHRDVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 73 /r
	/// @par
	/// @c AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHRDVD_ZMM_K1Z_ZMM_ZMMM512B32 = 3176,
	/// @brief @c VPSHRDVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 73 /r
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHRDVQ_XMM_K1Z_XMM_XMMM128B64 = 3177,
	/// @brief @c VPSHRDVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 73 /r
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHRDVQ_YMM_K1Z_YMM_YMMM256B64 = 3178,
	/// @brief @c VPSHRDVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 73 /r
	/// @par
	/// @c AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHRDVQ_ZMM_K1Z_ZMM_ZMMM512B64 = 3179,
	/// @brief @c VPERMI2B xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F38.W0 75 /r
	/// @par
	/// @c AVX512VL and AVX512_VBMI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMI2B_XMM_K1Z_XMM_XMMM128 = 3180,
	/// @brief @c VPERMI2B ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F38.W0 75 /r
	/// @par
	/// @c AVX512VL and AVX512_VBMI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMI2B_YMM_K1Z_YMM_YMMM256 = 3181,
	/// @brief @c VPERMI2B zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F38.W0 75 /r
	/// @par
	/// @c AVX512_VBMI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMI2B_ZMM_K1Z_ZMM_ZMMM512 = 3182,
	/// @brief @c VPERMI2W xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F38.W1 75 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMI2W_XMM_K1Z_XMM_XMMM128 = 3183,
	/// @brief @c VPERMI2W ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F38.W1 75 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMI2W_YMM_K1Z_YMM_YMMM256 = 3184,
	/// @brief @c VPERMI2W zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F38.W1 75 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMI2W_ZMM_K1Z_ZMM_ZMMM512 = 3185,
	/// @brief @c VPERMI2D xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 76 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMI2D_XMM_K1Z_XMM_XMMM128B32 = 3186,
	/// @brief @c VPERMI2D ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 76 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMI2D_YMM_K1Z_YMM_YMMM256B32 = 3187,
	/// @brief @c VPERMI2D zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 76 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMI2D_ZMM_K1Z_ZMM_ZMMM512B32 = 3188,
	/// @brief @c VPERMI2Q xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 76 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMI2Q_XMM_K1Z_XMM_XMMM128B64 = 3189,
	/// @brief @c VPERMI2Q ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 76 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMI2Q_YMM_K1Z_YMM_YMMM256B64 = 3190,
	/// @brief @c VPERMI2Q zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 76 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMI2Q_ZMM_K1Z_ZMM_ZMMM512B64 = 3191,
	/// @brief @c VPERMI2PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 77 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMI2PS_XMM_K1Z_XMM_XMMM128B32 = 3192,
	/// @brief @c VPERMI2PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 77 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMI2PS_YMM_K1Z_YMM_YMMM256B32 = 3193,
	/// @brief @c VPERMI2PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 77 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMI2PS_ZMM_K1Z_ZMM_ZMMM512B32 = 3194,
	/// @brief @c VPERMI2PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 77 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMI2PD_XMM_K1Z_XMM_XMMM128B64 = 3195,
	/// @brief @c VPERMI2PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 77 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMI2PD_YMM_K1Z_YMM_YMMM256B64 = 3196,
	/// @brief @c VPERMI2PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 77 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMI2PD_ZMM_K1Z_ZMM_ZMMM512B64 = 3197,
	/// @brief @c VPBROADCASTB xmm1, xmm2/m8
	/// @par
	/// @c VEX.128.66.0F38.W0 78 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPBROADCASTB_XMM_XMMM8 = 3198,
	/// @brief @c VPBROADCASTB ymm1, xmm2/m8
	/// @par
	/// @c VEX.256.66.0F38.W0 78 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPBROADCASTB_YMM_XMMM8 = 3199,
	/// @brief @c VPBROADCASTB xmm1 {k1}{z}, xmm2/m8
	/// @par
	/// @c EVEX.128.66.0F38.W0 78 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBROADCASTB_XMM_K1Z_XMMM8 = 3200,
	/// @brief @c VPBROADCASTB ymm1 {k1}{z}, xmm2/m8
	/// @par
	/// @c EVEX.256.66.0F38.W0 78 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBROADCASTB_YMM_K1Z_XMMM8 = 3201,
	/// @brief @c VPBROADCASTB zmm1 {k1}{z}, xmm2/m8
	/// @par
	/// @c EVEX.512.66.0F38.W0 78 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBROADCASTB_ZMM_K1Z_XMMM8 = 3202,
	/// @brief @c VPBROADCASTW xmm1, xmm2/m16
	/// @par
	/// @c VEX.128.66.0F38.W0 79 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPBROADCASTW_XMM_XMMM16 = 3203,
	/// @brief @c VPBROADCASTW ymm1, xmm2/m16
	/// @par
	/// @c VEX.256.66.0F38.W0 79 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPBROADCASTW_YMM_XMMM16 = 3204,
	/// @brief @c VPBROADCASTW xmm1 {k1}{z}, xmm2/m16
	/// @par
	/// @c EVEX.128.66.0F38.W0 79 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBROADCASTW_XMM_K1Z_XMMM16 = 3205,
	/// @brief @c VPBROADCASTW ymm1 {k1}{z}, xmm2/m16
	/// @par
	/// @c EVEX.256.66.0F38.W0 79 /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBROADCASTW_YMM_K1Z_XMMM16 = 3206,
	/// @brief @c VPBROADCASTW zmm1 {k1}{z}, xmm2/m16
	/// @par
	/// @c EVEX.512.66.0F38.W0 79 /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBROADCASTW_ZMM_K1Z_XMMM16 = 3207,
	/// @brief @c VPBROADCASTB xmm1 {k1}{z}, r32
	/// @par
	/// @c EVEX.128.66.0F38.W0 7A /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBROADCASTB_XMM_K1Z_R32 = 3208,
	/// @brief @c VPBROADCASTB ymm1 {k1}{z}, r32
	/// @par
	/// @c EVEX.256.66.0F38.W0 7A /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBROADCASTB_YMM_K1Z_R32 = 3209,
	/// @brief @c VPBROADCASTB zmm1 {k1}{z}, r32
	/// @par
	/// @c EVEX.512.66.0F38.W0 7A /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBROADCASTB_ZMM_K1Z_R32 = 3210,
	/// @brief @c VPBROADCASTW xmm1 {k1}{z}, r32
	/// @par
	/// @c EVEX.128.66.0F38.W0 7B /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBROADCASTW_XMM_K1Z_R32 = 3211,
	/// @brief @c VPBROADCASTW ymm1 {k1}{z}, r32
	/// @par
	/// @c EVEX.256.66.0F38.W0 7B /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBROADCASTW_YMM_K1Z_R32 = 3212,
	/// @brief @c VPBROADCASTW zmm1 {k1}{z}, r32
	/// @par
	/// @c EVEX.512.66.0F38.W0 7B /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBROADCASTW_ZMM_K1Z_R32 = 3213,
	/// @brief @c VPBROADCASTD xmm1 {k1}{z}, r32
	/// @par
	/// @c EVEX.128.66.0F38.W0 7C /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBROADCASTD_XMM_K1Z_R32 = 3214,
	/// @brief @c VPBROADCASTD ymm1 {k1}{z}, r32
	/// @par
	/// @c EVEX.256.66.0F38.W0 7C /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBROADCASTD_YMM_K1Z_R32 = 3215,
	/// @brief @c VPBROADCASTD zmm1 {k1}{z}, r32
	/// @par
	/// @c EVEX.512.66.0F38.W0 7C /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPBROADCASTD_ZMM_K1Z_R32 = 3216,
	/// @brief @c VPBROADCASTQ xmm1 {k1}{z}, r64
	/// @par
	/// @c EVEX.128.66.0F38.W1 7C /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 64-bit
	EVEX_VPBROADCASTQ_XMM_K1Z_R64 = 3217,
	/// @brief @c VPBROADCASTQ ymm1 {k1}{z}, r64
	/// @par
	/// @c EVEX.256.66.0F38.W1 7C /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 64-bit
	EVEX_VPBROADCASTQ_YMM_K1Z_R64 = 3218,
	/// @brief @c VPBROADCASTQ zmm1 {k1}{z}, r64
	/// @par
	/// @c EVEX.512.66.0F38.W1 7C /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 64-bit
	EVEX_VPBROADCASTQ_ZMM_K1Z_R64 = 3219,
	/// @brief @c VPERMT2B xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F38.W0 7D /r
	/// @par
	/// @c AVX512VL and AVX512_VBMI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMT2B_XMM_K1Z_XMM_XMMM128 = 3220,
	/// @brief @c VPERMT2B ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F38.W0 7D /r
	/// @par
	/// @c AVX512VL and AVX512_VBMI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMT2B_YMM_K1Z_YMM_YMMM256 = 3221,
	/// @brief @c VPERMT2B zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F38.W0 7D /r
	/// @par
	/// @c AVX512_VBMI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMT2B_ZMM_K1Z_ZMM_ZMMM512 = 3222,
	/// @brief @c VPERMT2W xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F38.W1 7D /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMT2W_XMM_K1Z_XMM_XMMM128 = 3223,
	/// @brief @c VPERMT2W ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F38.W1 7D /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMT2W_YMM_K1Z_YMM_YMMM256 = 3224,
	/// @brief @c VPERMT2W zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F38.W1 7D /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMT2W_ZMM_K1Z_ZMM_ZMMM512 = 3225,
	/// @brief @c VPERMT2D xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 7E /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMT2D_XMM_K1Z_XMM_XMMM128B32 = 3226,
	/// @brief @c VPERMT2D ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 7E /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMT2D_YMM_K1Z_YMM_YMMM256B32 = 3227,
	/// @brief @c VPERMT2D zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 7E /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMT2D_ZMM_K1Z_ZMM_ZMMM512B32 = 3228,
	/// @brief @c VPERMT2Q xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 7E /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMT2Q_XMM_K1Z_XMM_XMMM128B64 = 3229,
	/// @brief @c VPERMT2Q ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 7E /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMT2Q_YMM_K1Z_YMM_YMMM256B64 = 3230,
	/// @brief @c VPERMT2Q zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 7E /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMT2Q_ZMM_K1Z_ZMM_ZMMM512B64 = 3231,
	/// @brief @c VPERMT2PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 7F /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMT2PS_XMM_K1Z_XMM_XMMM128B32 = 3232,
	/// @brief @c VPERMT2PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 7F /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMT2PS_YMM_K1Z_YMM_YMMM256B32 = 3233,
	/// @brief @c VPERMT2PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 7F /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMT2PS_ZMM_K1Z_ZMM_ZMMM512B32 = 3234,
	/// @brief @c VPERMT2PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 7F /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMT2PD_XMM_K1Z_XMM_XMMM128B64 = 3235,
	/// @brief @c VPERMT2PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 7F /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMT2PD_YMM_K1Z_YMM_YMMM256B64 = 3236,
	/// @brief @c VPERMT2PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 7F /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMT2PD_ZMM_K1Z_ZMM_ZMMM512B64 = 3237,
	/// @brief @c INVEPT r32, m128
	/// @par
	/// @c 66 0F 38 80 /r
	/// @par
	/// @c VMX and IA32_VMX_EPT_VPID_CAP[bit 20]
	/// @par
	/// @c 16/32-bit
	INVEPT_R32_M128 = 3238,
	/// @brief @c INVEPT r64, m128
	/// @par
	/// @c 66 0F 38 80 /r
	/// @par
	/// @c VMX and IA32_VMX_EPT_VPID_CAP[bit 20]
	/// @par
	/// @c 64-bit
	INVEPT_R64_M128 = 3239,
	/// @brief @c INVVPID r32, m128
	/// @par
	/// @c 66 0F 38 81 /r
	/// @par
	/// @c VMX and IA32_VMX_EPT_VPID_CAP[bit 32]
	/// @par
	/// @c 16/32-bit
	INVVPID_R32_M128 = 3240,
	/// @brief @c INVVPID r64, m128
	/// @par
	/// @c 66 0F 38 81 /r
	/// @par
	/// @c VMX and IA32_VMX_EPT_VPID_CAP[bit 32]
	/// @par
	/// @c 64-bit
	INVVPID_R64_M128 = 3241,
	/// @brief @c INVPCID r32, m128
	/// @par
	/// @c 66 0F 38 82 /r
	/// @par
	/// @c INVPCID
	/// @par
	/// @c 16/32-bit
	INVPCID_R32_M128 = 3242,
	/// @brief @c INVPCID r64, m128
	/// @par
	/// @c 66 0F 38 82 /r
	/// @par
	/// @c INVPCID
	/// @par
	/// @c 64-bit
	INVPCID_R64_M128 = 3243,
	/// @brief @c VPMULTISHIFTQB xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 83 /r
	/// @par
	/// @c AVX512VL and AVX512_VBMI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMULTISHIFTQB_XMM_K1Z_XMM_XMMM128B64 = 3244,
	/// @brief @c VPMULTISHIFTQB ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 83 /r
	/// @par
	/// @c AVX512VL and AVX512_VBMI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMULTISHIFTQB_YMM_K1Z_YMM_YMMM256B64 = 3245,
	/// @brief @c VPMULTISHIFTQB zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 83 /r
	/// @par
	/// @c AVX512_VBMI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMULTISHIFTQB_ZMM_K1Z_ZMM_ZMMM512B64 = 3246,
	/// @brief @c VEXPANDPS xmm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.128.66.0F38.W0 88 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VEXPANDPS_XMM_K1Z_XMMM128 = 3247,
	/// @brief @c VEXPANDPS ymm1 {k1}{z}, ymm2/m256
	/// @par
	/// @c EVEX.256.66.0F38.W0 88 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VEXPANDPS_YMM_K1Z_YMMM256 = 3248,
	/// @brief @c VEXPANDPS zmm1 {k1}{z}, zmm2/m512
	/// @par
	/// @c EVEX.512.66.0F38.W0 88 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VEXPANDPS_ZMM_K1Z_ZMMM512 = 3249,
	/// @brief @c VEXPANDPD xmm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.128.66.0F38.W1 88 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VEXPANDPD_XMM_K1Z_XMMM128 = 3250,
	/// @brief @c VEXPANDPD ymm1 {k1}{z}, ymm2/m256
	/// @par
	/// @c EVEX.256.66.0F38.W1 88 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VEXPANDPD_YMM_K1Z_YMMM256 = 3251,
	/// @brief @c VEXPANDPD zmm1 {k1}{z}, zmm2/m512
	/// @par
	/// @c EVEX.512.66.0F38.W1 88 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VEXPANDPD_ZMM_K1Z_ZMMM512 = 3252,
	/// @brief @c VPEXPANDD xmm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.128.66.0F38.W0 89 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPEXPANDD_XMM_K1Z_XMMM128 = 3253,
	/// @brief @c VPEXPANDD ymm1 {k1}{z}, ymm2/m256
	/// @par
	/// @c EVEX.256.66.0F38.W0 89 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPEXPANDD_YMM_K1Z_YMMM256 = 3254,
	/// @brief @c VPEXPANDD zmm1 {k1}{z}, zmm2/m512
	/// @par
	/// @c EVEX.512.66.0F38.W0 89 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPEXPANDD_ZMM_K1Z_ZMMM512 = 3255,
	/// @brief @c VPEXPANDQ xmm1 {k1}{z}, xmm2/m128
	/// @par
	/// @c EVEX.128.66.0F38.W1 89 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPEXPANDQ_XMM_K1Z_XMMM128 = 3256,
	/// @brief @c VPEXPANDQ ymm1 {k1}{z}, ymm2/m256
	/// @par
	/// @c EVEX.256.66.0F38.W1 89 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPEXPANDQ_YMM_K1Z_YMMM256 = 3257,
	/// @brief @c VPEXPANDQ zmm1 {k1}{z}, zmm2/m512
	/// @par
	/// @c EVEX.512.66.0F38.W1 89 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPEXPANDQ_ZMM_K1Z_ZMMM512 = 3258,
	/// @brief @c VCOMPRESSPS xmm1/m128 {k1}{z}, xmm2
	/// @par
	/// @c EVEX.128.66.0F38.W0 8A /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCOMPRESSPS_XMMM128_K1Z_XMM = 3259,
	/// @brief @c VCOMPRESSPS ymm1/m256 {k1}{z}, ymm2
	/// @par
	/// @c EVEX.256.66.0F38.W0 8A /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCOMPRESSPS_YMMM256_K1Z_YMM = 3260,
	/// @brief @c VCOMPRESSPS zmm1/m512 {k1}{z}, zmm2
	/// @par
	/// @c EVEX.512.66.0F38.W0 8A /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCOMPRESSPS_ZMMM512_K1Z_ZMM = 3261,
	/// @brief @c VCOMPRESSPD xmm1/m128 {k1}{z}, xmm2
	/// @par
	/// @c EVEX.128.66.0F38.W1 8A /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCOMPRESSPD_XMMM128_K1Z_XMM = 3262,
	/// @brief @c VCOMPRESSPD ymm1/m256 {k1}{z}, ymm2
	/// @par
	/// @c EVEX.256.66.0F38.W1 8A /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCOMPRESSPD_YMMM256_K1Z_YMM = 3263,
	/// @brief @c VCOMPRESSPD zmm1/m512 {k1}{z}, zmm2
	/// @par
	/// @c EVEX.512.66.0F38.W1 8A /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCOMPRESSPD_ZMMM512_K1Z_ZMM = 3264,
	/// @brief @c VPCOMPRESSD xmm1/m128 {k1}{z}, xmm2
	/// @par
	/// @c EVEX.128.66.0F38.W0 8B /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCOMPRESSD_XMMM128_K1Z_XMM = 3265,
	/// @brief @c VPCOMPRESSD ymm1/m256 {k1}{z}, ymm2
	/// @par
	/// @c EVEX.256.66.0F38.W0 8B /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCOMPRESSD_YMMM256_K1Z_YMM = 3266,
	/// @brief @c VPCOMPRESSD zmm1/m512 {k1}{z}, zmm2
	/// @par
	/// @c EVEX.512.66.0F38.W0 8B /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCOMPRESSD_ZMMM512_K1Z_ZMM = 3267,
	/// @brief @c VPCOMPRESSQ xmm1/m128 {k1}{z}, xmm2
	/// @par
	/// @c EVEX.128.66.0F38.W1 8B /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCOMPRESSQ_XMMM128_K1Z_XMM = 3268,
	/// @brief @c VPCOMPRESSQ ymm1/m256 {k1}{z}, ymm2
	/// @par
	/// @c EVEX.256.66.0F38.W1 8B /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCOMPRESSQ_YMMM256_K1Z_YMM = 3269,
	/// @brief @c VPCOMPRESSQ zmm1/m512 {k1}{z}, zmm2
	/// @par
	/// @c EVEX.512.66.0F38.W1 8B /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCOMPRESSQ_ZMMM512_K1Z_ZMM = 3270,
	/// @brief @c VPMASKMOVD xmm1, xmm2, m128
	/// @par
	/// @c VEX.128.66.0F38.W0 8C /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMASKMOVD_XMM_XMM_M128 = 3271,
	/// @brief @c VPMASKMOVD ymm1, ymm2, m256
	/// @par
	/// @c VEX.256.66.0F38.W0 8C /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMASKMOVD_YMM_YMM_M256 = 3272,
	/// @brief @c VPMASKMOVQ xmm1, xmm2, m128
	/// @par
	/// @c VEX.128.66.0F38.W1 8C /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMASKMOVQ_XMM_XMM_M128 = 3273,
	/// @brief @c VPMASKMOVQ ymm1, ymm2, m256
	/// @par
	/// @c VEX.256.66.0F38.W1 8C /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMASKMOVQ_YMM_YMM_M256 = 3274,
	/// @brief @c VPERMB xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F38.W0 8D /r
	/// @par
	/// @c AVX512VL and AVX512_VBMI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMB_XMM_K1Z_XMM_XMMM128 = 3275,
	/// @brief @c VPERMB ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F38.W0 8D /r
	/// @par
	/// @c AVX512VL and AVX512_VBMI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMB_YMM_K1Z_YMM_YMMM256 = 3276,
	/// @brief @c VPERMB zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F38.W0 8D /r
	/// @par
	/// @c AVX512_VBMI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMB_ZMM_K1Z_ZMM_ZMMM512 = 3277,
	/// @brief @c VPERMW xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F38.W1 8D /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMW_XMM_K1Z_XMM_XMMM128 = 3278,
	/// @brief @c VPERMW ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F38.W1 8D /r
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMW_YMM_K1Z_YMM_YMMM256 = 3279,
	/// @brief @c VPERMW zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F38.W1 8D /r
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMW_ZMM_K1Z_ZMM_ZMMM512 = 3280,
	/// @brief @c VPMASKMOVD m128, xmm1, xmm2
	/// @par
	/// @c VEX.128.66.0F38.W0 8E /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMASKMOVD_M128_XMM_XMM = 3281,
	/// @brief @c VPMASKMOVD m256, ymm1, ymm2
	/// @par
	/// @c VEX.256.66.0F38.W0 8E /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMASKMOVD_M256_YMM_YMM = 3282,
	/// @brief @c VPMASKMOVQ m128, xmm1, xmm2
	/// @par
	/// @c VEX.128.66.0F38.W1 8E /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMASKMOVQ_M128_XMM_XMM = 3283,
	/// @brief @c VPMASKMOVQ m256, ymm1, ymm2
	/// @par
	/// @c VEX.256.66.0F38.W1 8E /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMASKMOVQ_M256_YMM_YMM = 3284,
	/// @brief @c VPSHUFBITQMB k1 {k2}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F38.W0 8F /r
	/// @par
	/// @c AVX512VL and AVX512_BITALG
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHUFBITQMB_KR_K1_XMM_XMMM128 = 3285,
	/// @brief @c VPSHUFBITQMB k1 {k2}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F38.W0 8F /r
	/// @par
	/// @c AVX512VL and AVX512_BITALG
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHUFBITQMB_KR_K1_YMM_YMMM256 = 3286,
	/// @brief @c VPSHUFBITQMB k1 {k2}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F38.W0 8F /r
	/// @par
	/// @c AVX512_BITALG
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHUFBITQMB_KR_K1_ZMM_ZMMM512 = 3287,
	/// @brief @c VPGATHERDD xmm1, vm32x, xmm2
	/// @par
	/// @c VEX.128.66.0F38.W0 90 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPGATHERDD_XMM_VM32X_XMM = 3288,
	/// @brief @c VPGATHERDD ymm1, vm32y, ymm2
	/// @par
	/// @c VEX.256.66.0F38.W0 90 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPGATHERDD_YMM_VM32Y_YMM = 3289,
	/// @brief @c VPGATHERDQ xmm1, vm32x, xmm2
	/// @par
	/// @c VEX.128.66.0F38.W1 90 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPGATHERDQ_XMM_VM32X_XMM = 3290,
	/// @brief @c VPGATHERDQ ymm1, vm32x, ymm2
	/// @par
	/// @c VEX.256.66.0F38.W1 90 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPGATHERDQ_YMM_VM32X_YMM = 3291,
	/// @brief @c VPGATHERDD xmm1 {k1}, vm32x
	/// @par
	/// @c EVEX.128.66.0F38.W0 90 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPGATHERDD_XMM_K1_VM32X = 3292,
	/// @brief @c VPGATHERDD ymm1 {k1}, vm32y
	/// @par
	/// @c EVEX.256.66.0F38.W0 90 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPGATHERDD_YMM_K1_VM32Y = 3293,
	/// @brief @c VPGATHERDD zmm1 {k1}, vm32z
	/// @par
	/// @c EVEX.512.66.0F38.W0 90 /vsib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPGATHERDD_ZMM_K1_VM32Z = 3294,
	/// @brief @c VPGATHERDQ xmm1 {k1}, vm32x
	/// @par
	/// @c EVEX.128.66.0F38.W1 90 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPGATHERDQ_XMM_K1_VM32X = 3295,
	/// @brief @c VPGATHERDQ ymm1 {k1}, vm32x
	/// @par
	/// @c EVEX.256.66.0F38.W1 90 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPGATHERDQ_YMM_K1_VM32X = 3296,
	/// @brief @c VPGATHERDQ zmm1 {k1}, vm32y
	/// @par
	/// @c EVEX.512.66.0F38.W1 90 /vsib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPGATHERDQ_ZMM_K1_VM32Y = 3297,
	/// @brief @c VPGATHERQD xmm1, vm64x, xmm2
	/// @par
	/// @c VEX.128.66.0F38.W0 91 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPGATHERQD_XMM_VM64X_XMM = 3298,
	/// @brief @c VPGATHERQD xmm1, vm64y, xmm2
	/// @par
	/// @c VEX.256.66.0F38.W0 91 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPGATHERQD_XMM_VM64Y_XMM = 3299,
	/// @brief @c VPGATHERQQ xmm1, vm64x, xmm2
	/// @par
	/// @c VEX.128.66.0F38.W1 91 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPGATHERQQ_XMM_VM64X_XMM = 3300,
	/// @brief @c VPGATHERQQ ymm1, vm64y, ymm2
	/// @par
	/// @c VEX.256.66.0F38.W1 91 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPGATHERQQ_YMM_VM64Y_YMM = 3301,
	/// @brief @c VPGATHERQD xmm1 {k1}, vm64x
	/// @par
	/// @c EVEX.128.66.0F38.W0 91 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPGATHERQD_XMM_K1_VM64X = 3302,
	/// @brief @c VPGATHERQD xmm1 {k1}, vm64y
	/// @par
	/// @c EVEX.256.66.0F38.W0 91 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPGATHERQD_XMM_K1_VM64Y = 3303,
	/// @brief @c VPGATHERQD ymm1 {k1}, vm64z
	/// @par
	/// @c EVEX.512.66.0F38.W0 91 /vsib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPGATHERQD_YMM_K1_VM64Z = 3304,
	/// @brief @c VPGATHERQQ xmm1 {k1}, vm64x
	/// @par
	/// @c EVEX.128.66.0F38.W1 91 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPGATHERQQ_XMM_K1_VM64X = 3305,
	/// @brief @c VPGATHERQQ ymm1 {k1}, vm64y
	/// @par
	/// @c EVEX.256.66.0F38.W1 91 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPGATHERQQ_YMM_K1_VM64Y = 3306,
	/// @brief @c VPGATHERQQ zmm1 {k1}, vm64z
	/// @par
	/// @c EVEX.512.66.0F38.W1 91 /vsib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPGATHERQQ_ZMM_K1_VM64Z = 3307,
	/// @brief @c VGATHERDPS xmm1, vm32x, xmm2
	/// @par
	/// @c VEX.128.66.0F38.W0 92 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VGATHERDPS_XMM_VM32X_XMM = 3308,
	/// @brief @c VGATHERDPS ymm1, vm32y, ymm2
	/// @par
	/// @c VEX.256.66.0F38.W0 92 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VGATHERDPS_YMM_VM32Y_YMM = 3309,
	/// @brief @c VGATHERDPD xmm1, vm32x, xmm2
	/// @par
	/// @c VEX.128.66.0F38.W1 92 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VGATHERDPD_XMM_VM32X_XMM = 3310,
	/// @brief @c VGATHERDPD ymm1, vm32x, ymm2
	/// @par
	/// @c VEX.256.66.0F38.W1 92 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VGATHERDPD_YMM_VM32X_YMM = 3311,
	/// @brief @c VGATHERDPS xmm1 {k1}, vm32x
	/// @par
	/// @c EVEX.128.66.0F38.W0 92 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGATHERDPS_XMM_K1_VM32X = 3312,
	/// @brief @c VGATHERDPS ymm1 {k1}, vm32y
	/// @par
	/// @c EVEX.256.66.0F38.W0 92 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGATHERDPS_YMM_K1_VM32Y = 3313,
	/// @brief @c VGATHERDPS zmm1 {k1}, vm32z
	/// @par
	/// @c EVEX.512.66.0F38.W0 92 /vsib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGATHERDPS_ZMM_K1_VM32Z = 3314,
	/// @brief @c VGATHERDPD xmm1 {k1}, vm32x
	/// @par
	/// @c EVEX.128.66.0F38.W1 92 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGATHERDPD_XMM_K1_VM32X = 3315,
	/// @brief @c VGATHERDPD ymm1 {k1}, vm32x
	/// @par
	/// @c EVEX.256.66.0F38.W1 92 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGATHERDPD_YMM_K1_VM32X = 3316,
	/// @brief @c VGATHERDPD zmm1 {k1}, vm32y
	/// @par
	/// @c EVEX.512.66.0F38.W1 92 /vsib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGATHERDPD_ZMM_K1_VM32Y = 3317,
	/// @brief @c VGATHERQPS xmm1, vm64x, xmm2
	/// @par
	/// @c VEX.128.66.0F38.W0 93 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VGATHERQPS_XMM_VM64X_XMM = 3318,
	/// @brief @c VGATHERQPS xmm1, vm64y, xmm2
	/// @par
	/// @c VEX.256.66.0F38.W0 93 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VGATHERQPS_XMM_VM64Y_XMM = 3319,
	/// @brief @c VGATHERQPD xmm1, vm64x, xmm2
	/// @par
	/// @c VEX.128.66.0F38.W1 93 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VGATHERQPD_XMM_VM64X_XMM = 3320,
	/// @brief @c VGATHERQPD ymm1, vm64y, ymm2
	/// @par
	/// @c VEX.256.66.0F38.W1 93 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VGATHERQPD_YMM_VM64Y_YMM = 3321,
	/// @brief @c VGATHERQPS xmm1 {k1}, vm64x
	/// @par
	/// @c EVEX.128.66.0F38.W0 93 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGATHERQPS_XMM_K1_VM64X = 3322,
	/// @brief @c VGATHERQPS xmm1 {k1}, vm64y
	/// @par
	/// @c EVEX.256.66.0F38.W0 93 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGATHERQPS_XMM_K1_VM64Y = 3323,
	/// @brief @c VGATHERQPS ymm1 {k1}, vm64z
	/// @par
	/// @c EVEX.512.66.0F38.W0 93 /vsib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGATHERQPS_YMM_K1_VM64Z = 3324,
	/// @brief @c VGATHERQPD xmm1 {k1}, vm64x
	/// @par
	/// @c EVEX.128.66.0F38.W1 93 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGATHERQPD_XMM_K1_VM64X = 3325,
	/// @brief @c VGATHERQPD ymm1 {k1}, vm64y
	/// @par
	/// @c EVEX.256.66.0F38.W1 93 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGATHERQPD_YMM_K1_VM64Y = 3326,
	/// @brief @c VGATHERQPD zmm1 {k1}, vm64z
	/// @par
	/// @c EVEX.512.66.0F38.W1 93 /vsib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGATHERQPD_ZMM_K1_VM64Z = 3327,
	/// @brief @c VFMADDSUB132PS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 96 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDSUB132PS_XMM_XMM_XMMM128 = 3328,
	/// @brief @c VFMADDSUB132PS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 96 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDSUB132PS_YMM_YMM_YMMM256 = 3329,
	/// @brief @c VFMADDSUB132PD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W1 96 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDSUB132PD_XMM_XMM_XMMM128 = 3330,
	/// @brief @c VFMADDSUB132PD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W1 96 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDSUB132PD_YMM_YMM_YMMM256 = 3331,
	/// @brief @c VFMADDSUB132PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 96 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDSUB132PS_XMM_K1Z_XMM_XMMM128B32 = 3332,
	/// @brief @c VFMADDSUB132PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 96 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDSUB132PS_YMM_K1Z_YMM_YMMM256B32 = 3333,
	/// @brief @c VFMADDSUB132PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W0 96 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDSUB132PS_ZMM_K1Z_ZMM_ZMMM512B32_ER = 3334,
	/// @brief @c VFMADDSUB132PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 96 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDSUB132PD_XMM_K1Z_XMM_XMMM128B64 = 3335,
	/// @brief @c VFMADDSUB132PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 96 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDSUB132PD_YMM_K1Z_YMM_YMMM256B64 = 3336,
	/// @brief @c VFMADDSUB132PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W1 96 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDSUB132PD_ZMM_K1Z_ZMM_ZMMM512B64_ER = 3337,
	/// @brief @c VFMSUBADD132PS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 97 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBADD132PS_XMM_XMM_XMMM128 = 3338,
	/// @brief @c VFMSUBADD132PS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 97 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBADD132PS_YMM_YMM_YMMM256 = 3339,
	/// @brief @c VFMSUBADD132PD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W1 97 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBADD132PD_XMM_XMM_XMMM128 = 3340,
	/// @brief @c VFMSUBADD132PD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W1 97 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBADD132PD_YMM_YMM_YMMM256 = 3341,
	/// @brief @c VFMSUBADD132PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 97 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUBADD132PS_XMM_K1Z_XMM_XMMM128B32 = 3342,
	/// @brief @c VFMSUBADD132PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 97 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUBADD132PS_YMM_K1Z_YMM_YMMM256B32 = 3343,
	/// @brief @c VFMSUBADD132PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W0 97 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUBADD132PS_ZMM_K1Z_ZMM_ZMMM512B32_ER = 3344,
	/// @brief @c VFMSUBADD132PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 97 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUBADD132PD_XMM_K1Z_XMM_XMMM128B64 = 3345,
	/// @brief @c VFMSUBADD132PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 97 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUBADD132PD_YMM_K1Z_YMM_YMMM256B64 = 3346,
	/// @brief @c VFMSUBADD132PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W1 97 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUBADD132PD_ZMM_K1Z_ZMM_ZMMM512B64_ER = 3347,
	/// @brief @c VFMADD132PS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 98 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADD132PS_XMM_XMM_XMMM128 = 3348,
	/// @brief @c VFMADD132PS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 98 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADD132PS_YMM_YMM_YMMM256 = 3349,
	/// @brief @c VFMADD132PD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W1 98 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADD132PD_XMM_XMM_XMMM128 = 3350,
	/// @brief @c VFMADD132PD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W1 98 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADD132PD_YMM_YMM_YMMM256 = 3351,
	/// @brief @c VFMADD132PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 98 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD132PS_XMM_K1Z_XMM_XMMM128B32 = 3352,
	/// @brief @c VFMADD132PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 98 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD132PS_YMM_K1Z_YMM_YMMM256B32 = 3353,
	/// @brief @c VFMADD132PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W0 98 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD132PS_ZMM_K1Z_ZMM_ZMMM512B32_ER = 3354,
	/// @brief @c VFMADD132PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 98 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD132PD_XMM_K1Z_XMM_XMMM128B64 = 3355,
	/// @brief @c VFMADD132PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 98 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD132PD_YMM_K1Z_YMM_YMMM256B64 = 3356,
	/// @brief @c VFMADD132PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W1 98 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD132PD_ZMM_K1Z_ZMM_ZMMM512B64_ER = 3357,
	/// @brief @c VFMADD132SS xmm1, xmm2, xmm3/m32
	/// @par
	/// @c VEX.LIG.66.0F38.W0 99 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADD132SS_XMM_XMM_XMMM32 = 3358,
	/// @brief @c VFMADD132SD xmm1, xmm2, xmm3/m64
	/// @par
	/// @c VEX.LIG.66.0F38.W1 99 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADD132SD_XMM_XMM_XMMM64 = 3359,
	/// @brief @c VFMADD132SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}
	/// @par
	/// @c EVEX.LIG.66.0F38.W0 99 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD132SS_XMM_K1Z_XMM_XMMM32_ER = 3360,
	/// @brief @c VFMADD132SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}
	/// @par
	/// @c EVEX.LIG.66.0F38.W1 99 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD132SD_XMM_K1Z_XMM_XMMM64_ER = 3361,
	/// @brief @c VFMSUB132PS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 9A /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUB132PS_XMM_XMM_XMMM128 = 3362,
	/// @brief @c VFMSUB132PS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 9A /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUB132PS_YMM_YMM_YMMM256 = 3363,
	/// @brief @c VFMSUB132PD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W1 9A /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUB132PD_XMM_XMM_XMMM128 = 3364,
	/// @brief @c VFMSUB132PD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W1 9A /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUB132PD_YMM_YMM_YMMM256 = 3365,
	/// @brief @c VFMSUB132PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 9A /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB132PS_XMM_K1Z_XMM_XMMM128B32 = 3366,
	/// @brief @c VFMSUB132PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 9A /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB132PS_YMM_K1Z_YMM_YMMM256B32 = 3367,
	/// @brief @c VFMSUB132PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W0 9A /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB132PS_ZMM_K1Z_ZMM_ZMMM512B32_ER = 3368,
	/// @brief @c VFMSUB132PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 9A /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB132PD_XMM_K1Z_XMM_XMMM128B64 = 3369,
	/// @brief @c VFMSUB132PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 9A /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB132PD_YMM_K1Z_YMM_YMMM256B64 = 3370,
	/// @brief @c VFMSUB132PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W1 9A /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB132PD_ZMM_K1Z_ZMM_ZMMM512B64_ER = 3371,
	/// @brief @c V4FMADDPS zmm1 {k1}{z}, zmm2+3, m128
	/// @par
	/// @c EVEX.512.F2.0F38.W0 9A /r
	/// @par
	/// @c AVX512_4FMAPS
	/// @par
	/// @c 16/32/64-bit
	EVEX_V4FMADDPS_ZMM_K1Z_ZMMP3_M128 = 3372,
	/// @brief @c VFMSUB132SS xmm1, xmm2, xmm3/m32
	/// @par
	/// @c VEX.LIG.66.0F38.W0 9B /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUB132SS_XMM_XMM_XMMM32 = 3373,
	/// @brief @c VFMSUB132SD xmm1, xmm2, xmm3/m64
	/// @par
	/// @c VEX.LIG.66.0F38.W1 9B /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUB132SD_XMM_XMM_XMMM64 = 3374,
	/// @brief @c VFMSUB132SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}
	/// @par
	/// @c EVEX.LIG.66.0F38.W0 9B /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB132SS_XMM_K1Z_XMM_XMMM32_ER = 3375,
	/// @brief @c VFMSUB132SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}
	/// @par
	/// @c EVEX.LIG.66.0F38.W1 9B /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB132SD_XMM_K1Z_XMM_XMMM64_ER = 3376,
	/// @brief @c V4FMADDSS xmm1 {k1}{z}, xmm2+3, m128
	/// @par
	/// @c EVEX.LIG.F2.0F38.W0 9B /r
	/// @par
	/// @c AVX512_4FMAPS
	/// @par
	/// @c 16/32/64-bit
	EVEX_V4FMADDSS_XMM_K1Z_XMMP3_M128 = 3377,
	/// @brief @c VFNMADD132PS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 9C /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMADD132PS_XMM_XMM_XMMM128 = 3378,
	/// @brief @c VFNMADD132PS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 9C /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMADD132PS_YMM_YMM_YMMM256 = 3379,
	/// @brief @c VFNMADD132PD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W1 9C /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMADD132PD_XMM_XMM_XMMM128 = 3380,
	/// @brief @c VFNMADD132PD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W1 9C /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMADD132PD_YMM_YMM_YMMM256 = 3381,
	/// @brief @c VFNMADD132PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 9C /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD132PS_XMM_K1Z_XMM_XMMM128B32 = 3382,
	/// @brief @c VFNMADD132PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 9C /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD132PS_YMM_K1Z_YMM_YMMM256B32 = 3383,
	/// @brief @c VFNMADD132PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W0 9C /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD132PS_ZMM_K1Z_ZMM_ZMMM512B32_ER = 3384,
	/// @brief @c VFNMADD132PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 9C /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD132PD_XMM_K1Z_XMM_XMMM128B64 = 3385,
	/// @brief @c VFNMADD132PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 9C /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD132PD_YMM_K1Z_YMM_YMMM256B64 = 3386,
	/// @brief @c VFNMADD132PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W1 9C /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD132PD_ZMM_K1Z_ZMM_ZMMM512B64_ER = 3387,
	/// @brief @c VFNMADD132SS xmm1, xmm2, xmm3/m32
	/// @par
	/// @c VEX.LIG.66.0F38.W0 9D /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMADD132SS_XMM_XMM_XMMM32 = 3388,
	/// @brief @c VFNMADD132SD xmm1, xmm2, xmm3/m64
	/// @par
	/// @c VEX.LIG.66.0F38.W1 9D /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMADD132SD_XMM_XMM_XMMM64 = 3389,
	/// @brief @c VFNMADD132SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}
	/// @par
	/// @c EVEX.LIG.66.0F38.W0 9D /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD132SS_XMM_K1Z_XMM_XMMM32_ER = 3390,
	/// @brief @c VFNMADD132SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}
	/// @par
	/// @c EVEX.LIG.66.0F38.W1 9D /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD132SD_XMM_K1Z_XMM_XMMM64_ER = 3391,
	/// @brief @c VFNMSUB132PS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 9E /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMSUB132PS_XMM_XMM_XMMM128 = 3392,
	/// @brief @c VFNMSUB132PS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 9E /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMSUB132PS_YMM_YMM_YMMM256 = 3393,
	/// @brief @c VFNMSUB132PD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W1 9E /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMSUB132PD_XMM_XMM_XMMM128 = 3394,
	/// @brief @c VFNMSUB132PD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W1 9E /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMSUB132PD_YMM_YMM_YMMM256 = 3395,
	/// @brief @c VFNMSUB132PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 9E /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB132PS_XMM_K1Z_XMM_XMMM128B32 = 3396,
	/// @brief @c VFNMSUB132PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 9E /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB132PS_YMM_K1Z_YMM_YMMM256B32 = 3397,
	/// @brief @c VFNMSUB132PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W0 9E /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB132PS_ZMM_K1Z_ZMM_ZMMM512B32_ER = 3398,
	/// @brief @c VFNMSUB132PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 9E /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB132PD_XMM_K1Z_XMM_XMMM128B64 = 3399,
	/// @brief @c VFNMSUB132PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 9E /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB132PD_YMM_K1Z_YMM_YMMM256B64 = 3400,
	/// @brief @c VFNMSUB132PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W1 9E /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB132PD_ZMM_K1Z_ZMM_ZMMM512B64_ER = 3401,
	/// @brief @c VFNMSUB132SS xmm1, xmm2, xmm3/m32
	/// @par
	/// @c VEX.LIG.66.0F38.W0 9F /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMSUB132SS_XMM_XMM_XMMM32 = 3402,
	/// @brief @c VFNMSUB132SD xmm1, xmm2, xmm3/m64
	/// @par
	/// @c VEX.LIG.66.0F38.W1 9F /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMSUB132SD_XMM_XMM_XMMM64 = 3403,
	/// @brief @c VFNMSUB132SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}
	/// @par
	/// @c EVEX.LIG.66.0F38.W0 9F /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB132SS_XMM_K1Z_XMM_XMMM32_ER = 3404,
	/// @brief @c VFNMSUB132SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}
	/// @par
	/// @c EVEX.LIG.66.0F38.W1 9F /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB132SD_XMM_K1Z_XMM_XMMM64_ER = 3405,
	/// @brief @c VPSCATTERDD vm32x {k1}, xmm1
	/// @par
	/// @c EVEX.128.66.0F38.W0 A0 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSCATTERDD_VM32X_K1_XMM = 3406,
	/// @brief @c VPSCATTERDD vm32y {k1}, ymm1
	/// @par
	/// @c EVEX.256.66.0F38.W0 A0 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSCATTERDD_VM32Y_K1_YMM = 3407,
	/// @brief @c VPSCATTERDD vm32z {k1}, zmm1
	/// @par
	/// @c EVEX.512.66.0F38.W0 A0 /vsib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSCATTERDD_VM32Z_K1_ZMM = 3408,
	/// @brief @c VPSCATTERDQ vm32x {k1}, xmm1
	/// @par
	/// @c EVEX.128.66.0F38.W1 A0 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSCATTERDQ_VM32X_K1_XMM = 3409,
	/// @brief @c VPSCATTERDQ vm32x {k1}, ymm1
	/// @par
	/// @c EVEX.256.66.0F38.W1 A0 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSCATTERDQ_VM32X_K1_YMM = 3410,
	/// @brief @c VPSCATTERDQ vm32y {k1}, zmm1
	/// @par
	/// @c EVEX.512.66.0F38.W1 A0 /vsib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSCATTERDQ_VM32Y_K1_ZMM = 3411,
	/// @brief @c VPSCATTERQD vm64x {k1}, xmm1
	/// @par
	/// @c EVEX.128.66.0F38.W0 A1 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSCATTERQD_VM64X_K1_XMM = 3412,
	/// @brief @c VPSCATTERQD vm64y {k1}, xmm1
	/// @par
	/// @c EVEX.256.66.0F38.W0 A1 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSCATTERQD_VM64Y_K1_XMM = 3413,
	/// @brief @c VPSCATTERQD vm64z {k1}, ymm1
	/// @par
	/// @c EVEX.512.66.0F38.W0 A1 /vsib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSCATTERQD_VM64Z_K1_YMM = 3414,
	/// @brief @c VPSCATTERQQ vm64x {k1}, xmm1
	/// @par
	/// @c EVEX.128.66.0F38.W1 A1 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSCATTERQQ_VM64X_K1_XMM = 3415,
	/// @brief @c VPSCATTERQQ vm64y {k1}, ymm1
	/// @par
	/// @c EVEX.256.66.0F38.W1 A1 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSCATTERQQ_VM64Y_K1_YMM = 3416,
	/// @brief @c VPSCATTERQQ vm64z {k1}, zmm1
	/// @par
	/// @c EVEX.512.66.0F38.W1 A1 /vsib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSCATTERQQ_VM64Z_K1_ZMM = 3417,
	/// @brief @c VSCATTERDPS vm32x {k1}, xmm1
	/// @par
	/// @c EVEX.128.66.0F38.W0 A2 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCATTERDPS_VM32X_K1_XMM = 3418,
	/// @brief @c VSCATTERDPS vm32y {k1}, ymm1
	/// @par
	/// @c EVEX.256.66.0F38.W0 A2 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCATTERDPS_VM32Y_K1_YMM = 3419,
	/// @brief @c VSCATTERDPS vm32z {k1}, zmm1
	/// @par
	/// @c EVEX.512.66.0F38.W0 A2 /vsib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCATTERDPS_VM32Z_K1_ZMM = 3420,
	/// @brief @c VSCATTERDPD vm32x {k1}, xmm1
	/// @par
	/// @c EVEX.128.66.0F38.W1 A2 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCATTERDPD_VM32X_K1_XMM = 3421,
	/// @brief @c VSCATTERDPD vm32x {k1}, ymm1
	/// @par
	/// @c EVEX.256.66.0F38.W1 A2 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCATTERDPD_VM32X_K1_YMM = 3422,
	/// @brief @c VSCATTERDPD vm32y {k1}, zmm1
	/// @par
	/// @c EVEX.512.66.0F38.W1 A2 /vsib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCATTERDPD_VM32Y_K1_ZMM = 3423,
	/// @brief @c VSCATTERQPS vm64x {k1}, xmm1
	/// @par
	/// @c EVEX.128.66.0F38.W0 A3 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCATTERQPS_VM64X_K1_XMM = 3424,
	/// @brief @c VSCATTERQPS vm64y {k1}, xmm1
	/// @par
	/// @c EVEX.256.66.0F38.W0 A3 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCATTERQPS_VM64Y_K1_XMM = 3425,
	/// @brief @c VSCATTERQPS vm64z {k1}, ymm1
	/// @par
	/// @c EVEX.512.66.0F38.W0 A3 /vsib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCATTERQPS_VM64Z_K1_YMM = 3426,
	/// @brief @c VSCATTERQPD vm64x {k1}, xmm1
	/// @par
	/// @c EVEX.128.66.0F38.W1 A3 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCATTERQPD_VM64X_K1_XMM = 3427,
	/// @brief @c VSCATTERQPD vm64y {k1}, ymm1
	/// @par
	/// @c EVEX.256.66.0F38.W1 A3 /vsib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCATTERQPD_VM64Y_K1_YMM = 3428,
	/// @brief @c VSCATTERQPD vm64z {k1}, zmm1
	/// @par
	/// @c EVEX.512.66.0F38.W1 A3 /vsib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCATTERQPD_VM64Z_K1_ZMM = 3429,
	/// @brief @c VFMADDSUB213PS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 A6 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDSUB213PS_XMM_XMM_XMMM128 = 3430,
	/// @brief @c VFMADDSUB213PS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 A6 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDSUB213PS_YMM_YMM_YMMM256 = 3431,
	/// @brief @c VFMADDSUB213PD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W1 A6 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDSUB213PD_XMM_XMM_XMMM128 = 3432,
	/// @brief @c VFMADDSUB213PD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W1 A6 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDSUB213PD_YMM_YMM_YMMM256 = 3433,
	/// @brief @c VFMADDSUB213PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 A6 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDSUB213PS_XMM_K1Z_XMM_XMMM128B32 = 3434,
	/// @brief @c VFMADDSUB213PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 A6 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDSUB213PS_YMM_K1Z_YMM_YMMM256B32 = 3435,
	/// @brief @c VFMADDSUB213PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W0 A6 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDSUB213PS_ZMM_K1Z_ZMM_ZMMM512B32_ER = 3436,
	/// @brief @c VFMADDSUB213PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 A6 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDSUB213PD_XMM_K1Z_XMM_XMMM128B64 = 3437,
	/// @brief @c VFMADDSUB213PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 A6 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDSUB213PD_YMM_K1Z_YMM_YMMM256B64 = 3438,
	/// @brief @c VFMADDSUB213PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W1 A6 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDSUB213PD_ZMM_K1Z_ZMM_ZMMM512B64_ER = 3439,
	/// @brief @c VFMSUBADD213PS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 A7 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBADD213PS_XMM_XMM_XMMM128 = 3440,
	/// @brief @c VFMSUBADD213PS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 A7 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBADD213PS_YMM_YMM_YMMM256 = 3441,
	/// @brief @c VFMSUBADD213PD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W1 A7 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBADD213PD_XMM_XMM_XMMM128 = 3442,
	/// @brief @c VFMSUBADD213PD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W1 A7 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBADD213PD_YMM_YMM_YMMM256 = 3443,
	/// @brief @c VFMSUBADD213PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 A7 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUBADD213PS_XMM_K1Z_XMM_XMMM128B32 = 3444,
	/// @brief @c VFMSUBADD213PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 A7 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUBADD213PS_YMM_K1Z_YMM_YMMM256B32 = 3445,
	/// @brief @c VFMSUBADD213PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W0 A7 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUBADD213PS_ZMM_K1Z_ZMM_ZMMM512B32_ER = 3446,
	/// @brief @c VFMSUBADD213PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 A7 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUBADD213PD_XMM_K1Z_XMM_XMMM128B64 = 3447,
	/// @brief @c VFMSUBADD213PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 A7 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUBADD213PD_YMM_K1Z_YMM_YMMM256B64 = 3448,
	/// @brief @c VFMSUBADD213PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W1 A7 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUBADD213PD_ZMM_K1Z_ZMM_ZMMM512B64_ER = 3449,
	/// @brief @c VFMADD213PS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 A8 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADD213PS_XMM_XMM_XMMM128 = 3450,
	/// @brief @c VFMADD213PS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 A8 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADD213PS_YMM_YMM_YMMM256 = 3451,
	/// @brief @c VFMADD213PD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W1 A8 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADD213PD_XMM_XMM_XMMM128 = 3452,
	/// @brief @c VFMADD213PD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W1 A8 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADD213PD_YMM_YMM_YMMM256 = 3453,
	/// @brief @c VFMADD213PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 A8 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD213PS_XMM_K1Z_XMM_XMMM128B32 = 3454,
	/// @brief @c VFMADD213PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 A8 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD213PS_YMM_K1Z_YMM_YMMM256B32 = 3455,
	/// @brief @c VFMADD213PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W0 A8 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD213PS_ZMM_K1Z_ZMM_ZMMM512B32_ER = 3456,
	/// @brief @c VFMADD213PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 A8 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD213PD_XMM_K1Z_XMM_XMMM128B64 = 3457,
	/// @brief @c VFMADD213PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 A8 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD213PD_YMM_K1Z_YMM_YMMM256B64 = 3458,
	/// @brief @c VFMADD213PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W1 A8 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD213PD_ZMM_K1Z_ZMM_ZMMM512B64_ER = 3459,
	/// @brief @c VFMADD213SS xmm1, xmm2, xmm3/m32
	/// @par
	/// @c VEX.LIG.66.0F38.W0 A9 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADD213SS_XMM_XMM_XMMM32 = 3460,
	/// @brief @c VFMADD213SD xmm1, xmm2, xmm3/m64
	/// @par
	/// @c VEX.LIG.66.0F38.W1 A9 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADD213SD_XMM_XMM_XMMM64 = 3461,
	/// @brief @c VFMADD213SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}
	/// @par
	/// @c EVEX.LIG.66.0F38.W0 A9 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD213SS_XMM_K1Z_XMM_XMMM32_ER = 3462,
	/// @brief @c VFMADD213SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}
	/// @par
	/// @c EVEX.LIG.66.0F38.W1 A9 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD213SD_XMM_K1Z_XMM_XMMM64_ER = 3463,
	/// @brief @c VFMSUB213PS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 AA /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUB213PS_XMM_XMM_XMMM128 = 3464,
	/// @brief @c VFMSUB213PS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 AA /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUB213PS_YMM_YMM_YMMM256 = 3465,
	/// @brief @c VFMSUB213PD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W1 AA /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUB213PD_XMM_XMM_XMMM128 = 3466,
	/// @brief @c VFMSUB213PD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W1 AA /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUB213PD_YMM_YMM_YMMM256 = 3467,
	/// @brief @c VFMSUB213PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 AA /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB213PS_XMM_K1Z_XMM_XMMM128B32 = 3468,
	/// @brief @c VFMSUB213PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 AA /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB213PS_YMM_K1Z_YMM_YMMM256B32 = 3469,
	/// @brief @c VFMSUB213PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W0 AA /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB213PS_ZMM_K1Z_ZMM_ZMMM512B32_ER = 3470,
	/// @brief @c VFMSUB213PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 AA /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB213PD_XMM_K1Z_XMM_XMMM128B64 = 3471,
	/// @brief @c VFMSUB213PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 AA /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB213PD_YMM_K1Z_YMM_YMMM256B64 = 3472,
	/// @brief @c VFMSUB213PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W1 AA /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB213PD_ZMM_K1Z_ZMM_ZMMM512B64_ER = 3473,
	/// @brief @c V4FNMADDPS zmm1 {k1}{z}, zmm2+3, m128
	/// @par
	/// @c EVEX.512.F2.0F38.W0 AA /r
	/// @par
	/// @c AVX512_4FMAPS
	/// @par
	/// @c 16/32/64-bit
	EVEX_V4FNMADDPS_ZMM_K1Z_ZMMP3_M128 = 3474,
	/// @brief @c VFMSUB213SS xmm1, xmm2, xmm3/m32
	/// @par
	/// @c VEX.LIG.66.0F38.W0 AB /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUB213SS_XMM_XMM_XMMM32 = 3475,
	/// @brief @c VFMSUB213SD xmm1, xmm2, xmm3/m64
	/// @par
	/// @c VEX.LIG.66.0F38.W1 AB /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUB213SD_XMM_XMM_XMMM64 = 3476,
	/// @brief @c VFMSUB213SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}
	/// @par
	/// @c EVEX.LIG.66.0F38.W0 AB /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB213SS_XMM_K1Z_XMM_XMMM32_ER = 3477,
	/// @brief @c VFMSUB213SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}
	/// @par
	/// @c EVEX.LIG.66.0F38.W1 AB /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB213SD_XMM_K1Z_XMM_XMMM64_ER = 3478,
	/// @brief @c V4FNMADDSS xmm1 {k1}{z}, xmm2+3, m128
	/// @par
	/// @c EVEX.LIG.F2.0F38.W0 AB /r
	/// @par
	/// @c AVX512_4FMAPS
	/// @par
	/// @c 16/32/64-bit
	EVEX_V4FNMADDSS_XMM_K1Z_XMMP3_M128 = 3479,
	/// @brief @c VFNMADD213PS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 AC /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMADD213PS_XMM_XMM_XMMM128 = 3480,
	/// @brief @c VFNMADD213PS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 AC /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMADD213PS_YMM_YMM_YMMM256 = 3481,
	/// @brief @c VFNMADD213PD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W1 AC /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMADD213PD_XMM_XMM_XMMM128 = 3482,
	/// @brief @c VFNMADD213PD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W1 AC /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMADD213PD_YMM_YMM_YMMM256 = 3483,
	/// @brief @c VFNMADD213PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 AC /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD213PS_XMM_K1Z_XMM_XMMM128B32 = 3484,
	/// @brief @c VFNMADD213PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 AC /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD213PS_YMM_K1Z_YMM_YMMM256B32 = 3485,
	/// @brief @c VFNMADD213PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W0 AC /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD213PS_ZMM_K1Z_ZMM_ZMMM512B32_ER = 3486,
	/// @brief @c VFNMADD213PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 AC /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD213PD_XMM_K1Z_XMM_XMMM128B64 = 3487,
	/// @brief @c VFNMADD213PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 AC /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD213PD_YMM_K1Z_YMM_YMMM256B64 = 3488,
	/// @brief @c VFNMADD213PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W1 AC /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD213PD_ZMM_K1Z_ZMM_ZMMM512B64_ER = 3489,
	/// @brief @c VFNMADD213SS xmm1, xmm2, xmm3/m32
	/// @par
	/// @c VEX.LIG.66.0F38.W0 AD /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMADD213SS_XMM_XMM_XMMM32 = 3490,
	/// @brief @c VFNMADD213SD xmm1, xmm2, xmm3/m64
	/// @par
	/// @c VEX.LIG.66.0F38.W1 AD /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMADD213SD_XMM_XMM_XMMM64 = 3491,
	/// @brief @c VFNMADD213SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}
	/// @par
	/// @c EVEX.LIG.66.0F38.W0 AD /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD213SS_XMM_K1Z_XMM_XMMM32_ER = 3492,
	/// @brief @c VFNMADD213SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}
	/// @par
	/// @c EVEX.LIG.66.0F38.W1 AD /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD213SD_XMM_K1Z_XMM_XMMM64_ER = 3493,
	/// @brief @c VFNMSUB213PS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 AE /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMSUB213PS_XMM_XMM_XMMM128 = 3494,
	/// @brief @c VFNMSUB213PS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 AE /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMSUB213PS_YMM_YMM_YMMM256 = 3495,
	/// @brief @c VFNMSUB213PD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W1 AE /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMSUB213PD_XMM_XMM_XMMM128 = 3496,
	/// @brief @c VFNMSUB213PD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W1 AE /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMSUB213PD_YMM_YMM_YMMM256 = 3497,
	/// @brief @c VFNMSUB213PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 AE /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB213PS_XMM_K1Z_XMM_XMMM128B32 = 3498,
	/// @brief @c VFNMSUB213PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 AE /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB213PS_YMM_K1Z_YMM_YMMM256B32 = 3499,
	/// @brief @c VFNMSUB213PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W0 AE /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB213PS_ZMM_K1Z_ZMM_ZMMM512B32_ER = 3500,
	/// @brief @c VFNMSUB213PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 AE /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB213PD_XMM_K1Z_XMM_XMMM128B64 = 3501,
	/// @brief @c VFNMSUB213PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 AE /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB213PD_YMM_K1Z_YMM_YMMM256B64 = 3502,
	/// @brief @c VFNMSUB213PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W1 AE /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB213PD_ZMM_K1Z_ZMM_ZMMM512B64_ER = 3503,
	/// @brief @c VFNMSUB213SS xmm1, xmm2, xmm3/m32
	/// @par
	/// @c VEX.LIG.66.0F38.W0 AF /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMSUB213SS_XMM_XMM_XMMM32 = 3504,
	/// @brief @c VFNMSUB213SD xmm1, xmm2, xmm3/m64
	/// @par
	/// @c VEX.LIG.66.0F38.W1 AF /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMSUB213SD_XMM_XMM_XMMM64 = 3505,
	/// @brief @c VFNMSUB213SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}
	/// @par
	/// @c EVEX.LIG.66.0F38.W0 AF /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB213SS_XMM_K1Z_XMM_XMMM32_ER = 3506,
	/// @brief @c VFNMSUB213SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}
	/// @par
	/// @c EVEX.LIG.66.0F38.W1 AF /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB213SD_XMM_K1Z_XMM_XMMM64_ER = 3507,
	/// @brief @c VPMADD52LUQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 B4 /r
	/// @par
	/// @c AVX512VL and AVX512_IFMA
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMADD52LUQ_XMM_K1Z_XMM_XMMM128B64 = 3508,
	/// @brief @c VPMADD52LUQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 B4 /r
	/// @par
	/// @c AVX512VL and AVX512_IFMA
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMADD52LUQ_YMM_K1Z_YMM_YMMM256B64 = 3509,
	/// @brief @c VPMADD52LUQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 B4 /r
	/// @par
	/// @c AVX512_IFMA
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMADD52LUQ_ZMM_K1Z_ZMM_ZMMM512B64 = 3510,
	/// @brief @c VPMADD52HUQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 B5 /r
	/// @par
	/// @c AVX512VL and AVX512_IFMA
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMADD52HUQ_XMM_K1Z_XMM_XMMM128B64 = 3511,
	/// @brief @c VPMADD52HUQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 B5 /r
	/// @par
	/// @c AVX512VL and AVX512_IFMA
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMADD52HUQ_YMM_K1Z_YMM_YMMM256B64 = 3512,
	/// @brief @c VPMADD52HUQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 B5 /r
	/// @par
	/// @c AVX512_IFMA
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPMADD52HUQ_ZMM_K1Z_ZMM_ZMMM512B64 = 3513,
	/// @brief @c VFMADDSUB231PS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 B6 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDSUB231PS_XMM_XMM_XMMM128 = 3514,
	/// @brief @c VFMADDSUB231PS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 B6 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDSUB231PS_YMM_YMM_YMMM256 = 3515,
	/// @brief @c VFMADDSUB231PD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W1 B6 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDSUB231PD_XMM_XMM_XMMM128 = 3516,
	/// @brief @c VFMADDSUB231PD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W1 B6 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDSUB231PD_YMM_YMM_YMMM256 = 3517,
	/// @brief @c VFMADDSUB231PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 B6 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDSUB231PS_XMM_K1Z_XMM_XMMM128B32 = 3518,
	/// @brief @c VFMADDSUB231PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 B6 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDSUB231PS_YMM_K1Z_YMM_YMMM256B32 = 3519,
	/// @brief @c VFMADDSUB231PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W0 B6 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDSUB231PS_ZMM_K1Z_ZMM_ZMMM512B32_ER = 3520,
	/// @brief @c VFMADDSUB231PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 B6 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDSUB231PD_XMM_K1Z_XMM_XMMM128B64 = 3521,
	/// @brief @c VFMADDSUB231PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 B6 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDSUB231PD_YMM_K1Z_YMM_YMMM256B64 = 3522,
	/// @brief @c VFMADDSUB231PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W1 B6 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDSUB231PD_ZMM_K1Z_ZMM_ZMMM512B64_ER = 3523,
	/// @brief @c VFMSUBADD231PS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 B7 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBADD231PS_XMM_XMM_XMMM128 = 3524,
	/// @brief @c VFMSUBADD231PS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 B7 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBADD231PS_YMM_YMM_YMMM256 = 3525,
	/// @brief @c VFMSUBADD231PD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W1 B7 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBADD231PD_XMM_XMM_XMMM128 = 3526,
	/// @brief @c VFMSUBADD231PD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W1 B7 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBADD231PD_YMM_YMM_YMMM256 = 3527,
	/// @brief @c VFMSUBADD231PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 B7 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUBADD231PS_XMM_K1Z_XMM_XMMM128B32 = 3528,
	/// @brief @c VFMSUBADD231PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 B7 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUBADD231PS_YMM_K1Z_YMM_YMMM256B32 = 3529,
	/// @brief @c VFMSUBADD231PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W0 B7 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUBADD231PS_ZMM_K1Z_ZMM_ZMMM512B32_ER = 3530,
	/// @brief @c VFMSUBADD231PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 B7 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUBADD231PD_XMM_K1Z_XMM_XMMM128B64 = 3531,
	/// @brief @c VFMSUBADD231PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 B7 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUBADD231PD_YMM_K1Z_YMM_YMMM256B64 = 3532,
	/// @brief @c VFMSUBADD231PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W1 B7 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUBADD231PD_ZMM_K1Z_ZMM_ZMMM512B64_ER = 3533,
	/// @brief @c VFMADD231PS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 B8 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADD231PS_XMM_XMM_XMMM128 = 3534,
	/// @brief @c VFMADD231PS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 B8 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADD231PS_YMM_YMM_YMMM256 = 3535,
	/// @brief @c VFMADD231PD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W1 B8 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADD231PD_XMM_XMM_XMMM128 = 3536,
	/// @brief @c VFMADD231PD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W1 B8 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADD231PD_YMM_YMM_YMMM256 = 3537,
	/// @brief @c VFMADD231PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 B8 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD231PS_XMM_K1Z_XMM_XMMM128B32 = 3538,
	/// @brief @c VFMADD231PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 B8 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD231PS_YMM_K1Z_YMM_YMMM256B32 = 3539,
	/// @brief @c VFMADD231PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W0 B8 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD231PS_ZMM_K1Z_ZMM_ZMMM512B32_ER = 3540,
	/// @brief @c VFMADD231PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 B8 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD231PD_XMM_K1Z_XMM_XMMM128B64 = 3541,
	/// @brief @c VFMADD231PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 B8 /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD231PD_YMM_K1Z_YMM_YMMM256B64 = 3542,
	/// @brief @c VFMADD231PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W1 B8 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD231PD_ZMM_K1Z_ZMM_ZMMM512B64_ER = 3543,
	/// @brief @c VFMADD231SS xmm1, xmm2, xmm3/m32
	/// @par
	/// @c VEX.LIG.66.0F38.W0 B9 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADD231SS_XMM_XMM_XMMM32 = 3544,
	/// @brief @c VFMADD231SD xmm1, xmm2, xmm3/m64
	/// @par
	/// @c VEX.LIG.66.0F38.W1 B9 /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADD231SD_XMM_XMM_XMMM64 = 3545,
	/// @brief @c VFMADD231SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}
	/// @par
	/// @c EVEX.LIG.66.0F38.W0 B9 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD231SS_XMM_K1Z_XMM_XMMM32_ER = 3546,
	/// @brief @c VFMADD231SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}
	/// @par
	/// @c EVEX.LIG.66.0F38.W1 B9 /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD231SD_XMM_K1Z_XMM_XMMM64_ER = 3547,
	/// @brief @c VFMSUB231PS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 BA /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUB231PS_XMM_XMM_XMMM128 = 3548,
	/// @brief @c VFMSUB231PS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 BA /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUB231PS_YMM_YMM_YMMM256 = 3549,
	/// @brief @c VFMSUB231PD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W1 BA /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUB231PD_XMM_XMM_XMMM128 = 3550,
	/// @brief @c VFMSUB231PD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W1 BA /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUB231PD_YMM_YMM_YMMM256 = 3551,
	/// @brief @c VFMSUB231PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 BA /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB231PS_XMM_K1Z_XMM_XMMM128B32 = 3552,
	/// @brief @c VFMSUB231PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 BA /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB231PS_YMM_K1Z_YMM_YMMM256B32 = 3553,
	/// @brief @c VFMSUB231PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W0 BA /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB231PS_ZMM_K1Z_ZMM_ZMMM512B32_ER = 3554,
	/// @brief @c VFMSUB231PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 BA /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB231PD_XMM_K1Z_XMM_XMMM128B64 = 3555,
	/// @brief @c VFMSUB231PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 BA /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB231PD_YMM_K1Z_YMM_YMMM256B64 = 3556,
	/// @brief @c VFMSUB231PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W1 BA /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB231PD_ZMM_K1Z_ZMM_ZMMM512B64_ER = 3557,
	/// @brief @c VFMSUB231SS xmm1, xmm2, xmm3/m32
	/// @par
	/// @c VEX.LIG.66.0F38.W0 BB /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUB231SS_XMM_XMM_XMMM32 = 3558,
	/// @brief @c VFMSUB231SD xmm1, xmm2, xmm3/m64
	/// @par
	/// @c VEX.LIG.66.0F38.W1 BB /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUB231SD_XMM_XMM_XMMM64 = 3559,
	/// @brief @c VFMSUB231SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}
	/// @par
	/// @c EVEX.LIG.66.0F38.W0 BB /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB231SS_XMM_K1Z_XMM_XMMM32_ER = 3560,
	/// @brief @c VFMSUB231SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}
	/// @par
	/// @c EVEX.LIG.66.0F38.W1 BB /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB231SD_XMM_K1Z_XMM_XMMM64_ER = 3561,
	/// @brief @c VFNMADD231PS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 BC /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMADD231PS_XMM_XMM_XMMM128 = 3562,
	/// @brief @c VFNMADD231PS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 BC /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMADD231PS_YMM_YMM_YMMM256 = 3563,
	/// @brief @c VFNMADD231PD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W1 BC /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMADD231PD_XMM_XMM_XMMM128 = 3564,
	/// @brief @c VFNMADD231PD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W1 BC /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMADD231PD_YMM_YMM_YMMM256 = 3565,
	/// @brief @c VFNMADD231PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 BC /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD231PS_XMM_K1Z_XMM_XMMM128B32 = 3566,
	/// @brief @c VFNMADD231PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 BC /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD231PS_YMM_K1Z_YMM_YMMM256B32 = 3567,
	/// @brief @c VFNMADD231PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W0 BC /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD231PS_ZMM_K1Z_ZMM_ZMMM512B32_ER = 3568,
	/// @brief @c VFNMADD231PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 BC /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD231PD_XMM_K1Z_XMM_XMMM128B64 = 3569,
	/// @brief @c VFNMADD231PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 BC /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD231PD_YMM_K1Z_YMM_YMMM256B64 = 3570,
	/// @brief @c VFNMADD231PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W1 BC /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD231PD_ZMM_K1Z_ZMM_ZMMM512B64_ER = 3571,
	/// @brief @c VFNMADD231SS xmm1, xmm2, xmm3/m32
	/// @par
	/// @c VEX.LIG.66.0F38.W0 BD /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMADD231SS_XMM_XMM_XMMM32 = 3572,
	/// @brief @c VFNMADD231SD xmm1, xmm2, xmm3/m64
	/// @par
	/// @c VEX.LIG.66.0F38.W1 BD /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMADD231SD_XMM_XMM_XMMM64 = 3573,
	/// @brief @c VFNMADD231SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}
	/// @par
	/// @c EVEX.LIG.66.0F38.W0 BD /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD231SS_XMM_K1Z_XMM_XMMM32_ER = 3574,
	/// @brief @c VFNMADD231SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}
	/// @par
	/// @c EVEX.LIG.66.0F38.W1 BD /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD231SD_XMM_K1Z_XMM_XMMM64_ER = 3575,
	/// @brief @c VFNMSUB231PS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 BE /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMSUB231PS_XMM_XMM_XMMM128 = 3576,
	/// @brief @c VFNMSUB231PS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 BE /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMSUB231PS_YMM_YMM_YMMM256 = 3577,
	/// @brief @c VFNMSUB231PD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W1 BE /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMSUB231PD_XMM_XMM_XMMM128 = 3578,
	/// @brief @c VFNMSUB231PD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W1 BE /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMSUB231PD_YMM_YMM_YMMM256 = 3579,
	/// @brief @c VFNMSUB231PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 BE /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB231PS_XMM_K1Z_XMM_XMMM128B32 = 3580,
	/// @brief @c VFNMSUB231PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 BE /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB231PS_YMM_K1Z_YMM_YMMM256B32 = 3581,
	/// @brief @c VFNMSUB231PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W0 BE /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB231PS_ZMM_K1Z_ZMM_ZMMM512B32_ER = 3582,
	/// @brief @c VFNMSUB231PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 BE /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB231PD_XMM_K1Z_XMM_XMMM128B64 = 3583,
	/// @brief @c VFNMSUB231PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 BE /r
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB231PD_YMM_K1Z_YMM_YMMM256B64 = 3584,
	/// @brief @c VFNMSUB231PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.66.0F38.W1 BE /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB231PD_ZMM_K1Z_ZMM_ZMMM512B64_ER = 3585,
	/// @brief @c VFNMSUB231SS xmm1, xmm2, xmm3/m32
	/// @par
	/// @c VEX.LIG.66.0F38.W0 BF /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMSUB231SS_XMM_XMM_XMMM32 = 3586,
	/// @brief @c VFNMSUB231SD xmm1, xmm2, xmm3/m64
	/// @par
	/// @c VEX.LIG.66.0F38.W1 BF /r
	/// @par
	/// @c FMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMSUB231SD_XMM_XMM_XMMM64 = 3587,
	/// @brief @c VFNMSUB231SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}
	/// @par
	/// @c EVEX.LIG.66.0F38.W0 BF /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB231SS_XMM_K1Z_XMM_XMMM32_ER = 3588,
	/// @brief @c VFNMSUB231SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}
	/// @par
	/// @c EVEX.LIG.66.0F38.W1 BF /r
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB231SD_XMM_K1Z_XMM_XMMM64_ER = 3589,
	/// @brief @c VPCONFLICTD xmm1 {k1}{z}, xmm2/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.0F38.W0 C4 /r
	/// @par
	/// @c AVX512VL and AVX512CD
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCONFLICTD_XMM_K1Z_XMMM128B32 = 3590,
	/// @brief @c VPCONFLICTD ymm1 {k1}{z}, ymm2/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.0F38.W0 C4 /r
	/// @par
	/// @c AVX512VL and AVX512CD
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCONFLICTD_YMM_K1Z_YMMM256B32 = 3591,
	/// @brief @c VPCONFLICTD zmm1 {k1}{z}, zmm2/m512/m32bcst
	/// @par
	/// @c EVEX.512.66.0F38.W0 C4 /r
	/// @par
	/// @c AVX512CD
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCONFLICTD_ZMM_K1Z_ZMMM512B32 = 3592,
	/// @brief @c VPCONFLICTQ xmm1 {k1}{z}, xmm2/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.0F38.W1 C4 /r
	/// @par
	/// @c AVX512VL and AVX512CD
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCONFLICTQ_XMM_K1Z_XMMM128B64 = 3593,
	/// @brief @c VPCONFLICTQ ymm1 {k1}{z}, ymm2/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.0F38.W1 C4 /r
	/// @par
	/// @c AVX512VL and AVX512CD
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCONFLICTQ_YMM_K1Z_YMMM256B64 = 3594,
	/// @brief @c VPCONFLICTQ zmm1 {k1}{z}, zmm2/m512/m64bcst
	/// @par
	/// @c EVEX.512.66.0F38.W1 C4 /r
	/// @par
	/// @c AVX512CD
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCONFLICTQ_ZMM_K1Z_ZMMM512B64 = 3595,
	/// @brief @c VGATHERPF0DPS vm32z {k1}
	/// @par
	/// @c EVEX.512.66.0F38.W0 C6 /1 /vsib
	/// @par
	/// @c AVX512PF
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGATHERPF0DPS_VM32Z_K1 = 3596,
	/// @brief @c VGATHERPF0DPD vm32y {k1}
	/// @par
	/// @c EVEX.512.66.0F38.W1 C6 /1 /vsib
	/// @par
	/// @c AVX512PF
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGATHERPF0DPD_VM32Y_K1 = 3597,
	/// @brief @c VGATHERPF1DPS vm32z {k1}
	/// @par
	/// @c EVEX.512.66.0F38.W0 C6 /2 /vsib
	/// @par
	/// @c AVX512PF
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGATHERPF1DPS_VM32Z_K1 = 3598,
	/// @brief @c VGATHERPF1DPD vm32y {k1}
	/// @par
	/// @c EVEX.512.66.0F38.W1 C6 /2 /vsib
	/// @par
	/// @c AVX512PF
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGATHERPF1DPD_VM32Y_K1 = 3599,
	/// @brief @c VSCATTERPF0DPS vm32z {k1}
	/// @par
	/// @c EVEX.512.66.0F38.W0 C6 /5 /vsib
	/// @par
	/// @c AVX512PF
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCATTERPF0DPS_VM32Z_K1 = 3600,
	/// @brief @c VSCATTERPF0DPD vm32y {k1}
	/// @par
	/// @c EVEX.512.66.0F38.W1 C6 /5 /vsib
	/// @par
	/// @c AVX512PF
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCATTERPF0DPD_VM32Y_K1 = 3601,
	/// @brief @c VSCATTERPF1DPS vm32z {k1}
	/// @par
	/// @c EVEX.512.66.0F38.W0 C6 /6 /vsib
	/// @par
	/// @c AVX512PF
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCATTERPF1DPS_VM32Z_K1 = 3602,
	/// @brief @c VSCATTERPF1DPD vm32y {k1}
	/// @par
	/// @c EVEX.512.66.0F38.W1 C6 /6 /vsib
	/// @par
	/// @c AVX512PF
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCATTERPF1DPD_VM32Y_K1 = 3603,
	/// @brief @c VGATHERPF0QPS vm64z {k1}
	/// @par
	/// @c EVEX.512.66.0F38.W0 C7 /1 /vsib
	/// @par
	/// @c AVX512PF
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGATHERPF0QPS_VM64Z_K1 = 3604,
	/// @brief @c VGATHERPF0QPD vm64z {k1}
	/// @par
	/// @c EVEX.512.66.0F38.W1 C7 /1 /vsib
	/// @par
	/// @c AVX512PF
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGATHERPF0QPD_VM64Z_K1 = 3605,
	/// @brief @c VGATHERPF1QPS vm64z {k1}
	/// @par
	/// @c EVEX.512.66.0F38.W0 C7 /2 /vsib
	/// @par
	/// @c AVX512PF
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGATHERPF1QPS_VM64Z_K1 = 3606,
	/// @brief @c VGATHERPF1QPD vm64z {k1}
	/// @par
	/// @c EVEX.512.66.0F38.W1 C7 /2 /vsib
	/// @par
	/// @c AVX512PF
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGATHERPF1QPD_VM64Z_K1 = 3607,
	/// @brief @c VSCATTERPF0QPS vm64z {k1}
	/// @par
	/// @c EVEX.512.66.0F38.W0 C7 /5 /vsib
	/// @par
	/// @c AVX512PF
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCATTERPF0QPS_VM64Z_K1 = 3608,
	/// @brief @c VSCATTERPF0QPD vm64z {k1}
	/// @par
	/// @c EVEX.512.66.0F38.W1 C7 /5 /vsib
	/// @par
	/// @c AVX512PF
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCATTERPF0QPD_VM64Z_K1 = 3609,
	/// @brief @c VSCATTERPF1QPS vm64z {k1}
	/// @par
	/// @c EVEX.512.66.0F38.W0 C7 /6 /vsib
	/// @par
	/// @c AVX512PF
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCATTERPF1QPS_VM64Z_K1 = 3610,
	/// @brief @c VSCATTERPF1QPD vm64z {k1}
	/// @par
	/// @c EVEX.512.66.0F38.W1 C7 /6 /vsib
	/// @par
	/// @c AVX512PF
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCATTERPF1QPD_VM64Z_K1 = 3611,
	/// @brief @c SHA1NEXTE xmm1, xmm2/m128
	/// @par
	/// @c NP 0F 38 C8 /r
	/// @par
	/// @c SHA
	/// @par
	/// @c 16/32/64-bit
	SHA1NEXTE_XMM_XMMM128 = 3612,
	/// @brief @c VEXP2PS zmm1 {k1}{z}, zmm2/m512/m32bcst{sae}
	/// @par
	/// @c EVEX.512.66.0F38.W0 C8 /r
	/// @par
	/// @c AVX512ER
	/// @par
	/// @c 16/32/64-bit
	EVEX_VEXP2PS_ZMM_K1Z_ZMMM512B32_SAE = 3613,
	/// @brief @c VEXP2PD zmm1 {k1}{z}, zmm2/m512/m64bcst{sae}
	/// @par
	/// @c EVEX.512.66.0F38.W1 C8 /r
	/// @par
	/// @c AVX512ER
	/// @par
	/// @c 16/32/64-bit
	EVEX_VEXP2PD_ZMM_K1Z_ZMMM512B64_SAE = 3614,
	/// @brief @c SHA1MSG1 xmm1, xmm2/m128
	/// @par
	/// @c NP 0F 38 C9 /r
	/// @par
	/// @c SHA
	/// @par
	/// @c 16/32/64-bit
	SHA1MSG1_XMM_XMMM128 = 3615,
	/// @brief @c SHA1MSG2 xmm1, xmm2/m128
	/// @par
	/// @c NP 0F 38 CA /r
	/// @par
	/// @c SHA
	/// @par
	/// @c 16/32/64-bit
	SHA1MSG2_XMM_XMMM128 = 3616,
	/// @brief @c VRCP28PS zmm1 {k1}{z}, zmm2/m512/m32bcst{sae}
	/// @par
	/// @c EVEX.512.66.0F38.W0 CA /r
	/// @par
	/// @c AVX512ER
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRCP28PS_ZMM_K1Z_ZMMM512B32_SAE = 3617,
	/// @brief @c VRCP28PD zmm1 {k1}{z}, zmm2/m512/m64bcst{sae}
	/// @par
	/// @c EVEX.512.66.0F38.W1 CA /r
	/// @par
	/// @c AVX512ER
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRCP28PD_ZMM_K1Z_ZMMM512B64_SAE = 3618,
	/// @brief @c SHA256RNDS2 xmm1, xmm2/m128, \<XMM0\>
	/// @par
	/// @c NP 0F 38 CB /r
	/// @par
	/// @c SHA
	/// @par
	/// @c 16/32/64-bit
	SHA256RNDS2_XMM_XMMM128 = 3619,
	/// @brief @c VRCP28SS xmm1 {k1}{z}, xmm2, xmm3/m32{sae}
	/// @par
	/// @c EVEX.LIG.66.0F38.W0 CB /r
	/// @par
	/// @c AVX512ER
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRCP28SS_XMM_K1Z_XMM_XMMM32_SAE = 3620,
	/// @brief @c VRCP28SD xmm1 {k1}{z}, xmm2, xmm3/m64{sae}
	/// @par
	/// @c EVEX.LIG.66.0F38.W1 CB /r
	/// @par
	/// @c AVX512ER
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRCP28SD_XMM_K1Z_XMM_XMMM64_SAE = 3621,
	/// @brief @c SHA256MSG1 xmm1, xmm2/m128
	/// @par
	/// @c NP 0F 38 CC /r
	/// @par
	/// @c SHA
	/// @par
	/// @c 16/32/64-bit
	SHA256MSG1_XMM_XMMM128 = 3622,
	/// @brief @c VRSQRT28PS zmm1 {k1}{z}, zmm2/m512/m32bcst{sae}
	/// @par
	/// @c EVEX.512.66.0F38.W0 CC /r
	/// @par
	/// @c AVX512ER
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRSQRT28PS_ZMM_K1Z_ZMMM512B32_SAE = 3623,
	/// @brief @c VRSQRT28PD zmm1 {k1}{z}, zmm2/m512/m64bcst{sae}
	/// @par
	/// @c EVEX.512.66.0F38.W1 CC /r
	/// @par
	/// @c AVX512ER
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRSQRT28PD_ZMM_K1Z_ZMMM512B64_SAE = 3624,
	/// @brief @c SHA256MSG2 xmm1, xmm2/m128
	/// @par
	/// @c NP 0F 38 CD /r
	/// @par
	/// @c SHA
	/// @par
	/// @c 16/32/64-bit
	SHA256MSG2_XMM_XMMM128 = 3625,
	/// @brief @c VRSQRT28SS xmm1 {k1}{z}, xmm2, xmm3/m32{sae}
	/// @par
	/// @c EVEX.LIG.66.0F38.W0 CD /r
	/// @par
	/// @c AVX512ER
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRSQRT28SS_XMM_K1Z_XMM_XMMM32_SAE = 3626,
	/// @brief @c VRSQRT28SD xmm1 {k1}{z}, xmm2, xmm3/m64{sae}
	/// @par
	/// @c EVEX.LIG.66.0F38.W1 CD /r
	/// @par
	/// @c AVX512ER
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRSQRT28SD_XMM_K1Z_XMM_XMMM64_SAE = 3627,
	/// @brief @c GF2P8MULB xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 CF /r
	/// @par
	/// @c GFNI
	/// @par
	/// @c 16/32/64-bit
	GF2P8MULB_XMM_XMMM128 = 3628,
	/// @brief @c VGF2P8MULB xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 CF /r
	/// @par
	/// @c AVX and GFNI
	/// @par
	/// @c 16/32/64-bit
	VEX_VGF2P8MULB_XMM_XMM_XMMM128 = 3629,
	/// @brief @c VGF2P8MULB ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 CF /r
	/// @par
	/// @c AVX and GFNI
	/// @par
	/// @c 16/32/64-bit
	VEX_VGF2P8MULB_YMM_YMM_YMMM256 = 3630,
	/// @brief @c VGF2P8MULB xmm1 {k1}{z}, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F38.W0 CF /r
	/// @par
	/// @c AVX512VL and GFNI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGF2P8MULB_XMM_K1Z_XMM_XMMM128 = 3631,
	/// @brief @c VGF2P8MULB ymm1 {k1}{z}, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F38.W0 CF /r
	/// @par
	/// @c AVX512VL and GFNI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGF2P8MULB_YMM_K1Z_YMM_YMMM256 = 3632,
	/// @brief @c VGF2P8MULB zmm1 {k1}{z}, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F38.W0 CF /r
	/// @par
	/// @c AVX512F and GFNI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGF2P8MULB_ZMM_K1Z_ZMM_ZMMM512 = 3633,
	/// @brief @c AESIMC xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 DB /r
	/// @par
	/// @c AES
	/// @par
	/// @c 16/32/64-bit
	AESIMC_XMM_XMMM128 = 3634,
	/// @brief @c VAESIMC xmm1, xmm2/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG DB /r
	/// @par
	/// @c AES and AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VAESIMC_XMM_XMMM128 = 3635,
	/// @brief @c AESENC xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 DC /r
	/// @par
	/// @c AES
	/// @par
	/// @c 16/32/64-bit
	AESENC_XMM_XMMM128 = 3636,
	/// @brief @c VAESENC xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG DC /r
	/// @par
	/// @c AES and AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VAESENC_XMM_XMM_XMMM128 = 3637,
	/// @brief @c VAESENC ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG DC /r
	/// @par
	/// @c VAES
	/// @par
	/// @c 16/32/64-bit
	VEX_VAESENC_YMM_YMM_YMMM256 = 3638,
	/// @brief @c VAESENC xmm1, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F38.WIG DC /r
	/// @par
	/// @c AVX512VL and VAES
	/// @par
	/// @c 16/32/64-bit
	EVEX_VAESENC_XMM_XMM_XMMM128 = 3639,
	/// @brief @c VAESENC ymm1, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F38.WIG DC /r
	/// @par
	/// @c AVX512VL and VAES
	/// @par
	/// @c 16/32/64-bit
	EVEX_VAESENC_YMM_YMM_YMMM256 = 3640,
	/// @brief @c VAESENC zmm1, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F38.WIG DC /r
	/// @par
	/// @c AVX512F and VAES
	/// @par
	/// @c 16/32/64-bit
	EVEX_VAESENC_ZMM_ZMM_ZMMM512 = 3641,
	/// @brief @c AESENCLAST xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 DD /r
	/// @par
	/// @c AES
	/// @par
	/// @c 16/32/64-bit
	AESENCLAST_XMM_XMMM128 = 3642,
	/// @brief @c VAESENCLAST xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG DD /r
	/// @par
	/// @c AES and AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VAESENCLAST_XMM_XMM_XMMM128 = 3643,
	/// @brief @c VAESENCLAST ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG DD /r
	/// @par
	/// @c VAES
	/// @par
	/// @c 16/32/64-bit
	VEX_VAESENCLAST_YMM_YMM_YMMM256 = 3644,
	/// @brief @c VAESENCLAST xmm1, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F38.WIG DD /r
	/// @par
	/// @c AVX512VL and VAES
	/// @par
	/// @c 16/32/64-bit
	EVEX_VAESENCLAST_XMM_XMM_XMMM128 = 3645,
	/// @brief @c VAESENCLAST ymm1, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F38.WIG DD /r
	/// @par
	/// @c AVX512VL and VAES
	/// @par
	/// @c 16/32/64-bit
	EVEX_VAESENCLAST_YMM_YMM_YMMM256 = 3646,
	/// @brief @c VAESENCLAST zmm1, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F38.WIG DD /r
	/// @par
	/// @c AVX512F and VAES
	/// @par
	/// @c 16/32/64-bit
	EVEX_VAESENCLAST_ZMM_ZMM_ZMMM512 = 3647,
	/// @brief @c AESDEC xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 DE /r
	/// @par
	/// @c AES
	/// @par
	/// @c 16/32/64-bit
	AESDEC_XMM_XMMM128 = 3648,
	/// @brief @c VAESDEC xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG DE /r
	/// @par
	/// @c AES and AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VAESDEC_XMM_XMM_XMMM128 = 3649,
	/// @brief @c VAESDEC ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG DE /r
	/// @par
	/// @c VAES
	/// @par
	/// @c 16/32/64-bit
	VEX_VAESDEC_YMM_YMM_YMMM256 = 3650,
	/// @brief @c VAESDEC xmm1, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F38.WIG DE /r
	/// @par
	/// @c AVX512VL and VAES
	/// @par
	/// @c 16/32/64-bit
	EVEX_VAESDEC_XMM_XMM_XMMM128 = 3651,
	/// @brief @c VAESDEC ymm1, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F38.WIG DE /r
	/// @par
	/// @c AVX512VL and VAES
	/// @par
	/// @c 16/32/64-bit
	EVEX_VAESDEC_YMM_YMM_YMMM256 = 3652,
	/// @brief @c VAESDEC zmm1, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F38.WIG DE /r
	/// @par
	/// @c AVX512F and VAES
	/// @par
	/// @c 16/32/64-bit
	EVEX_VAESDEC_ZMM_ZMM_ZMMM512 = 3653,
	/// @brief @c AESDECLAST xmm1, xmm2/m128
	/// @par
	/// @c 66 0F 38 DF /r
	/// @par
	/// @c AES
	/// @par
	/// @c 16/32/64-bit
	AESDECLAST_XMM_XMMM128 = 3654,
	/// @brief @c VAESDECLAST xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.WIG DF /r
	/// @par
	/// @c AES and AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VAESDECLAST_XMM_XMM_XMMM128 = 3655,
	/// @brief @c VAESDECLAST ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.WIG DF /r
	/// @par
	/// @c VAES
	/// @par
	/// @c 16/32/64-bit
	VEX_VAESDECLAST_YMM_YMM_YMMM256 = 3656,
	/// @brief @c VAESDECLAST xmm1, xmm2, xmm3/m128
	/// @par
	/// @c EVEX.128.66.0F38.WIG DF /r
	/// @par
	/// @c AVX512VL and VAES
	/// @par
	/// @c 16/32/64-bit
	EVEX_VAESDECLAST_XMM_XMM_XMMM128 = 3657,
	/// @brief @c VAESDECLAST ymm1, ymm2, ymm3/m256
	/// @par
	/// @c EVEX.256.66.0F38.WIG DF /r
	/// @par
	/// @c AVX512VL and VAES
	/// @par
	/// @c 16/32/64-bit
	EVEX_VAESDECLAST_YMM_YMM_YMMM256 = 3658,
	/// @brief @c VAESDECLAST zmm1, zmm2, zmm3/m512
	/// @par
	/// @c EVEX.512.66.0F38.WIG DF /r
	/// @par
	/// @c AVX512F and VAES
	/// @par
	/// @c 16/32/64-bit
	EVEX_VAESDECLAST_ZMM_ZMM_ZMMM512 = 3659,
	/// @brief @c MOVBE r16, m16
	/// @par
	/// @c o16 0F 38 F0 /r
	/// @par
	/// @c MOVBE
	/// @par
	/// @c 16/32/64-bit
	MOVBE_R16_M16 = 3660,
	/// @brief @c MOVBE r32, m32
	/// @par
	/// @c o32 0F 38 F0 /r
	/// @par
	/// @c MOVBE
	/// @par
	/// @c 16/32/64-bit
	MOVBE_R32_M32 = 3661,
	/// @brief @c MOVBE r64, m64
	/// @par
	/// @c o64 0F 38 F0 /r
	/// @par
	/// @c MOVBE
	/// @par
	/// @c 64-bit
	MOVBE_R64_M64 = 3662,
	/// @brief @c CRC32 r32, r/m8
	/// @par
	/// @c F2 0F 38 F0 /r
	/// @par
	/// @c SSE4.2
	/// @par
	/// @c 16/32/64-bit
	CRC32_R32_RM8 = 3663,
	/// @brief @c CRC32 r64, r/m8
	/// @par
	/// @c F2 o64 0F 38 F0 /r
	/// @par
	/// @c SSE4.2
	/// @par
	/// @c 64-bit
	CRC32_R64_RM8 = 3664,
	/// @brief @c MOVBE m16, r16
	/// @par
	/// @c o16 0F 38 F1 /r
	/// @par
	/// @c MOVBE
	/// @par
	/// @c 16/32/64-bit
	MOVBE_M16_R16 = 3665,
	/// @brief @c MOVBE m32, r32
	/// @par
	/// @c o32 0F 38 F1 /r
	/// @par
	/// @c MOVBE
	/// @par
	/// @c 16/32/64-bit
	MOVBE_M32_R32 = 3666,
	/// @brief @c MOVBE m64, r64
	/// @par
	/// @c o64 0F 38 F1 /r
	/// @par
	/// @c MOVBE
	/// @par
	/// @c 64-bit
	MOVBE_M64_R64 = 3667,
	/// @brief @c CRC32 r32, r/m16
	/// @par
	/// @c o16 F2 0F 38 F1 /r
	/// @par
	/// @c SSE4.2
	/// @par
	/// @c 16/32/64-bit
	CRC32_R32_RM16 = 3668,
	/// @brief @c CRC32 r32, r/m32
	/// @par
	/// @c o32 F2 0F 38 F1 /r
	/// @par
	/// @c SSE4.2
	/// @par
	/// @c 16/32/64-bit
	CRC32_R32_RM32 = 3669,
	/// @brief @c CRC32 r64, r/m64
	/// @par
	/// @c F2 o64 0F 38 F1 /r
	/// @par
	/// @c SSE4.2
	/// @par
	/// @c 64-bit
	CRC32_R64_RM64 = 3670,
	/// @brief @c ANDN r32a, r32b, r/m32
	/// @par
	/// @c VEX.LZ.0F38.W0 F2 /r
	/// @par
	/// @c BMI1
	/// @par
	/// @c 16/32/64-bit
	VEX_ANDN_R32_R32_RM32 = 3671,
	/// @brief @c ANDN r64a, r64b, r/m64
	/// @par
	/// @c VEX.LZ.0F38.W1 F2 /r
	/// @par
	/// @c BMI1
	/// @par
	/// @c 64-bit
	VEX_ANDN_R64_R64_RM64 = 3672,
	/// @brief @c BLSR r32, r/m32
	/// @par
	/// @c VEX.LZ.0F38.W0 F3 /1
	/// @par
	/// @c BMI1
	/// @par
	/// @c 16/32/64-bit
	VEX_BLSR_R32_RM32 = 3673,
	/// @brief @c BLSR r64, r/m64
	/// @par
	/// @c VEX.LZ.0F38.W1 F3 /1
	/// @par
	/// @c BMI1
	/// @par
	/// @c 64-bit
	VEX_BLSR_R64_RM64 = 3674,
	/// @brief @c BLSMSK r32, r/m32
	/// @par
	/// @c VEX.LZ.0F38.W0 F3 /2
	/// @par
	/// @c BMI1
	/// @par
	/// @c 16/32/64-bit
	VEX_BLSMSK_R32_RM32 = 3675,
	/// @brief @c BLSMSK r64, r/m64
	/// @par
	/// @c VEX.LZ.0F38.W1 F3 /2
	/// @par
	/// @c BMI1
	/// @par
	/// @c 64-bit
	VEX_BLSMSK_R64_RM64 = 3676,
	/// @brief @c BLSI r32, r/m32
	/// @par
	/// @c VEX.LZ.0F38.W0 F3 /3
	/// @par
	/// @c BMI1
	/// @par
	/// @c 16/32/64-bit
	VEX_BLSI_R32_RM32 = 3677,
	/// @brief @c BLSI r64, r/m64
	/// @par
	/// @c VEX.LZ.0F38.W1 F3 /3
	/// @par
	/// @c BMI1
	/// @par
	/// @c 64-bit
	VEX_BLSI_R64_RM64 = 3678,
	/// @brief @c BZHI r32a, r/m32, r32b
	/// @par
	/// @c VEX.LZ.0F38.W0 F5 /r
	/// @par
	/// @c BMI2
	/// @par
	/// @c 16/32/64-bit
	VEX_BZHI_R32_RM32_R32 = 3679,
	/// @brief @c BZHI r64a, r/m64, r64b
	/// @par
	/// @c VEX.LZ.0F38.W1 F5 /r
	/// @par
	/// @c BMI2
	/// @par
	/// @c 64-bit
	VEX_BZHI_R64_RM64_R64 = 3680,
	/// @brief @c WRUSSD m32, r32
	/// @par
	/// @c 66 0F 38 F5 /r
	/// @par
	/// @c CET_SS
	/// @par
	/// @c 16/32/64-bit
	WRUSSD_M32_R32 = 3681,
	/// @brief @c WRUSSQ m64, r64
	/// @par
	/// @c 66 o64 0F 38 F5 /r
	/// @par
	/// @c CET_SS
	/// @par
	/// @c 64-bit
	WRUSSQ_M64_R64 = 3682,
	/// @brief @c PEXT r32a, r32b, r/m32
	/// @par
	/// @c VEX.LZ.F3.0F38.W0 F5 /r
	/// @par
	/// @c BMI2
	/// @par
	/// @c 16/32/64-bit
	VEX_PEXT_R32_R32_RM32 = 3683,
	/// @brief @c PEXT r64a, r64b, r/m64
	/// @par
	/// @c VEX.LZ.F3.0F38.W1 F5 /r
	/// @par
	/// @c BMI2
	/// @par
	/// @c 64-bit
	VEX_PEXT_R64_R64_RM64 = 3684,
	/// @brief @c PDEP r32a, r32b, r/m32
	/// @par
	/// @c VEX.LZ.F2.0F38.W0 F5 /r
	/// @par
	/// @c BMI2
	/// @par
	/// @c 16/32/64-bit
	VEX_PDEP_R32_R32_RM32 = 3685,
	/// @brief @c PDEP r64a, r64b, r/m64
	/// @par
	/// @c VEX.LZ.F2.0F38.W1 F5 /r
	/// @par
	/// @c BMI2
	/// @par
	/// @c 64-bit
	VEX_PDEP_R64_R64_RM64 = 3686,
	/// @brief @c WRSSD m32, r32
	/// @par
	/// @c NP 0F 38 F6 /r
	/// @par
	/// @c CET_SS
	/// @par
	/// @c 16/32/64-bit
	WRSSD_M32_R32 = 3687,
	/// @brief @c WRSSQ m64, r64
	/// @par
	/// @c NP o64 0F 38 F6 /r
	/// @par
	/// @c CET_SS
	/// @par
	/// @c 64-bit
	WRSSQ_M64_R64 = 3688,
	/// @brief @c ADCX r32, r/m32
	/// @par
	/// @c 66 0F 38 F6 /r
	/// @par
	/// @c ADX
	/// @par
	/// @c 16/32/64-bit
	ADCX_R32_RM32 = 3689,
	/// @brief @c ADCX r64, r/m64
	/// @par
	/// @c 66 o64 0F 38 F6 /r
	/// @par
	/// @c ADX
	/// @par
	/// @c 64-bit
	ADCX_R64_RM64 = 3690,
	/// @brief @c ADOX r32, r/m32
	/// @par
	/// @c F3 0F 38 F6 /r
	/// @par
	/// @c ADX
	/// @par
	/// @c 16/32/64-bit
	ADOX_R32_RM32 = 3691,
	/// @brief @c ADOX r64, r/m64
	/// @par
	/// @c F3 o64 0F 38 F6 /r
	/// @par
	/// @c ADX
	/// @par
	/// @c 64-bit
	ADOX_R64_RM64 = 3692,
	/// @brief @c MULX r32a, r32b, r/m32
	/// @par
	/// @c VEX.LZ.F2.0F38.W0 F6 /r
	/// @par
	/// @c BMI2
	/// @par
	/// @c 16/32/64-bit
	VEX_MULX_R32_R32_RM32 = 3693,
	/// @brief @c MULX r64a, r64b, r/m64
	/// @par
	/// @c VEX.LZ.F2.0F38.W1 F6 /r
	/// @par
	/// @c BMI2
	/// @par
	/// @c 64-bit
	VEX_MULX_R64_R64_RM64 = 3694,
	/// @brief @c BEXTR r32a, r/m32, r32b
	/// @par
	/// @c VEX.LZ.0F38.W0 F7 /r
	/// @par
	/// @c BMI1
	/// @par
	/// @c 16/32/64-bit
	VEX_BEXTR_R32_RM32_R32 = 3695,
	/// @brief @c BEXTR r64a, r/m64, r64b
	/// @par
	/// @c VEX.LZ.0F38.W1 F7 /r
	/// @par
	/// @c BMI1
	/// @par
	/// @c 64-bit
	VEX_BEXTR_R64_RM64_R64 = 3696,
	/// @brief @c SHLX r32a, r/m32, r32b
	/// @par
	/// @c VEX.LZ.66.0F38.W0 F7 /r
	/// @par
	/// @c BMI2
	/// @par
	/// @c 16/32/64-bit
	VEX_SHLX_R32_RM32_R32 = 3697,
	/// @brief @c SHLX r64a, r/m64, r64b
	/// @par
	/// @c VEX.LZ.66.0F38.W1 F7 /r
	/// @par
	/// @c BMI2
	/// @par
	/// @c 64-bit
	VEX_SHLX_R64_RM64_R64 = 3698,
	/// @brief @c SARX r32a, r/m32, r32b
	/// @par
	/// @c VEX.LZ.F3.0F38.W0 F7 /r
	/// @par
	/// @c BMI2
	/// @par
	/// @c 16/32/64-bit
	VEX_SARX_R32_RM32_R32 = 3699,
	/// @brief @c SARX r64a, r/m64, r64b
	/// @par
	/// @c VEX.LZ.F3.0F38.W1 F7 /r
	/// @par
	/// @c BMI2
	/// @par
	/// @c 64-bit
	VEX_SARX_R64_RM64_R64 = 3700,
	/// @brief @c SHRX r32a, r/m32, r32b
	/// @par
	/// @c VEX.LZ.F2.0F38.W0 F7 /r
	/// @par
	/// @c BMI2
	/// @par
	/// @c 16/32/64-bit
	VEX_SHRX_R32_RM32_R32 = 3701,
	/// @brief @c SHRX r64a, r/m64, r64b
	/// @par
	/// @c VEX.LZ.F2.0F38.W1 F7 /r
	/// @par
	/// @c BMI2
	/// @par
	/// @c 64-bit
	VEX_SHRX_R64_RM64_R64 = 3702,
	/// @brief @c MOVDIR64B r16, m512
	/// @par
	/// @c a16 66 0F 38 F8 /r
	/// @par
	/// @c MOVDIR64B
	/// @par
	/// @c 16/32-bit
	MOVDIR64B_R16_M512 = 3703,
	/// @brief @c MOVDIR64B r32, m512
	/// @par
	/// @c a32 66 0F 38 F8 /r
	/// @par
	/// @c MOVDIR64B
	/// @par
	/// @c 16/32/64-bit
	MOVDIR64B_R32_M512 = 3704,
	/// @brief @c MOVDIR64B r64, m512
	/// @par
	/// @c a64 66 0F 38 F8 /r
	/// @par
	/// @c MOVDIR64B
	/// @par
	/// @c 64-bit
	MOVDIR64B_R64_M512 = 3705,
	/// @brief @c ENQCMDS r16, m512
	/// @par
	/// @c a16 F3 0F 38 F8 !(11):rrr:bbb
	/// @par
	/// @c ENQCMD
	/// @par
	/// @c 16/32-bit
	ENQCMDS_R16_M512 = 3706,
	/// @brief @c ENQCMDS r32, m512
	/// @par
	/// @c a32 F3 0F 38 F8 !(11):rrr:bbb
	/// @par
	/// @c ENQCMD
	/// @par
	/// @c 16/32/64-bit
	ENQCMDS_R32_M512 = 3707,
	/// @brief @c ENQCMDS r64, m512
	/// @par
	/// @c a64 F3 0F 38 F8 !(11):rrr:bbb
	/// @par
	/// @c ENQCMD
	/// @par
	/// @c 64-bit
	ENQCMDS_R64_M512 = 3708,
	/// @brief @c ENQCMD r16, m512
	/// @par
	/// @c a16 F2 0F 38 F8 !(11):rrr:bbb
	/// @par
	/// @c ENQCMD
	/// @par
	/// @c 16/32-bit
	ENQCMD_R16_M512 = 3709,
	/// @brief @c ENQCMD r32, m512
	/// @par
	/// @c a32 F2 0F 38 F8 !(11):rrr:bbb
	/// @par
	/// @c ENQCMD
	/// @par
	/// @c 16/32/64-bit
	ENQCMD_R32_M512 = 3710,
	/// @brief @c ENQCMD r64, m512
	/// @par
	/// @c a64 F2 0F 38 F8 !(11):rrr:bbb
	/// @par
	/// @c ENQCMD
	/// @par
	/// @c 64-bit
	ENQCMD_R64_M512 = 3711,
	/// @brief @c MOVDIRI m32, r32
	/// @par
	/// @c NP 0F 38 F9 /r
	/// @par
	/// @c MOVDIRI
	/// @par
	/// @c 16/32/64-bit
	MOVDIRI_M32_R32 = 3712,
	/// @brief @c MOVDIRI m64, r64
	/// @par
	/// @c NP o64 0F 38 F9 /r
	/// @par
	/// @c MOVDIRI
	/// @par
	/// @c 64-bit
	MOVDIRI_M64_R64 = 3713,
	/// @brief @c VPERMQ ymm1, ymm2/m256, imm8
	/// @par
	/// @c VEX.256.66.0F3A.W1 00 /r ib
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPERMQ_YMM_YMMM256_IMM8 = 3714,
	/// @brief @c VPERMQ ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W1 00 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMQ_YMM_K1Z_YMMM256B64_IMM8 = 3715,
	/// @brief @c VPERMQ zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 00 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMQ_ZMM_K1Z_ZMMM512B64_IMM8 = 3716,
	/// @brief @c VPERMPD ymm1, ymm2/m256, imm8
	/// @par
	/// @c VEX.256.66.0F3A.W1 01 /r ib
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPERMPD_YMM_YMMM256_IMM8 = 3717,
	/// @brief @c VPERMPD ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W1 01 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMPD_YMM_K1Z_YMMM256B64_IMM8 = 3718,
	/// @brief @c VPERMPD zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 01 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMPD_ZMM_K1Z_ZMMM512B64_IMM8 = 3719,
	/// @brief @c VPBLENDD xmm1, xmm2, xmm3/m128, imm8
	/// @par
	/// @c VEX.128.66.0F3A.W0 02 /r ib
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPBLENDD_XMM_XMM_XMMM128_IMM8 = 3720,
	/// @brief @c VPBLENDD ymm1, ymm2, ymm3/m256, imm8
	/// @par
	/// @c VEX.256.66.0F3A.W0 02 /r ib
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPBLENDD_YMM_YMM_YMMM256_IMM8 = 3721,
	/// @brief @c VALIGND xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W0 03 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VALIGND_XMM_K1Z_XMM_XMMM128B32_IMM8 = 3722,
	/// @brief @c VALIGND ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W0 03 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VALIGND_YMM_K1Z_YMM_YMMM256B32_IMM8 = 3723,
	/// @brief @c VALIGND zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W0 03 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VALIGND_ZMM_K1Z_ZMM_ZMMM512B32_IMM8 = 3724,
	/// @brief @c VALIGNQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W1 03 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VALIGNQ_XMM_K1Z_XMM_XMMM128B64_IMM8 = 3725,
	/// @brief @c VALIGNQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W1 03 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VALIGNQ_YMM_K1Z_YMM_YMMM256B64_IMM8 = 3726,
	/// @brief @c VALIGNQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 03 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VALIGNQ_ZMM_K1Z_ZMM_ZMMM512B64_IMM8 = 3727,
	/// @brief @c VPERMILPS xmm1, xmm2/m128, imm8
	/// @par
	/// @c VEX.128.66.0F3A.W0 04 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPERMILPS_XMM_XMMM128_IMM8 = 3728,
	/// @brief @c VPERMILPS ymm1, ymm2/m256, imm8
	/// @par
	/// @c VEX.256.66.0F3A.W0 04 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPERMILPS_YMM_YMMM256_IMM8 = 3729,
	/// @brief @c VPERMILPS xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W0 04 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMILPS_XMM_K1Z_XMMM128B32_IMM8 = 3730,
	/// @brief @c VPERMILPS ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W0 04 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMILPS_YMM_K1Z_YMMM256B32_IMM8 = 3731,
	/// @brief @c VPERMILPS zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W0 04 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMILPS_ZMM_K1Z_ZMMM512B32_IMM8 = 3732,
	/// @brief @c VPERMILPD xmm1, xmm2/m128, imm8
	/// @par
	/// @c VEX.128.66.0F3A.W0 05 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPERMILPD_XMM_XMMM128_IMM8 = 3733,
	/// @brief @c VPERMILPD ymm1, ymm2/m256, imm8
	/// @par
	/// @c VEX.256.66.0F3A.W0 05 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPERMILPD_YMM_YMMM256_IMM8 = 3734,
	/// @brief @c VPERMILPD xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W1 05 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMILPD_XMM_K1Z_XMMM128B64_IMM8 = 3735,
	/// @brief @c VPERMILPD ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W1 05 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMILPD_YMM_K1Z_YMMM256B64_IMM8 = 3736,
	/// @brief @c VPERMILPD zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 05 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPERMILPD_ZMM_K1Z_ZMMM512B64_IMM8 = 3737,
	/// @brief @c VPERM2F128 ymm1, ymm2, ymm3/m256, imm8
	/// @par
	/// @c VEX.256.66.0F3A.W0 06 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPERM2F128_YMM_YMM_YMMM256_IMM8 = 3738,
	/// @brief @c ROUNDPS xmm1, xmm2/m128, imm8
	/// @par
	/// @c 66 0F 3A 08 /r ib
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	ROUNDPS_XMM_XMMM128_IMM8 = 3739,
	/// @brief @c VROUNDPS xmm1, xmm2/m128, imm8
	/// @par
	/// @c VEX.128.66.0F3A.WIG 08 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VROUNDPS_XMM_XMMM128_IMM8 = 3740,
	/// @brief @c VROUNDPS ymm1, ymm2/m256, imm8
	/// @par
	/// @c VEX.256.66.0F3A.WIG 08 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VROUNDPS_YMM_YMMM256_IMM8 = 3741,
	/// @brief @c VRNDSCALEPS xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W0 08 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRNDSCALEPS_XMM_K1Z_XMMM128B32_IMM8 = 3742,
	/// @brief @c VRNDSCALEPS ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W0 08 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRNDSCALEPS_YMM_K1Z_YMMM256B32_IMM8 = 3743,
	/// @brief @c VRNDSCALEPS zmm1 {k1}{z}, zmm2/m512/m32bcst{sae}, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W0 08 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRNDSCALEPS_ZMM_K1Z_ZMMM512B32_IMM8_SAE = 3744,
	/// @brief @c ROUNDPD xmm1, xmm2/m128, imm8
	/// @par
	/// @c 66 0F 3A 09 /r ib
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	ROUNDPD_XMM_XMMM128_IMM8 = 3745,
	/// @brief @c VROUNDPD xmm1, xmm2/m128, imm8
	/// @par
	/// @c VEX.128.66.0F3A.WIG 09 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VROUNDPD_XMM_XMMM128_IMM8 = 3746,
	/// @brief @c VROUNDPD ymm1, ymm2/m256, imm8
	/// @par
	/// @c VEX.256.66.0F3A.WIG 09 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VROUNDPD_YMM_YMMM256_IMM8 = 3747,
	/// @brief @c VRNDSCALEPD xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W1 09 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRNDSCALEPD_XMM_K1Z_XMMM128B64_IMM8 = 3748,
	/// @brief @c VRNDSCALEPD ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W1 09 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRNDSCALEPD_YMM_K1Z_YMMM256B64_IMM8 = 3749,
	/// @brief @c VRNDSCALEPD zmm1 {k1}{z}, zmm2/m512/m64bcst{sae}, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 09 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRNDSCALEPD_ZMM_K1Z_ZMMM512B64_IMM8_SAE = 3750,
	/// @brief @c ROUNDSS xmm1, xmm2/m32, imm8
	/// @par
	/// @c 66 0F 3A 0A /r ib
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	ROUNDSS_XMM_XMMM32_IMM8 = 3751,
	/// @brief @c VROUNDSS xmm1, xmm2, xmm3/m32, imm8
	/// @par
	/// @c VEX.LIG.66.0F3A.WIG 0A /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VROUNDSS_XMM_XMM_XMMM32_IMM8 = 3752,
	/// @brief @c VRNDSCALESS xmm1 {k1}{z}, xmm2, xmm3/m32{sae}, imm8
	/// @par
	/// @c EVEX.LIG.66.0F3A.W0 0A /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRNDSCALESS_XMM_K1Z_XMM_XMMM32_IMM8_SAE = 3753,
	/// @brief @c ROUNDSD xmm1, xmm2/m64, imm8
	/// @par
	/// @c 66 0F 3A 0B /r ib
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	ROUNDSD_XMM_XMMM64_IMM8 = 3754,
	/// @brief @c VROUNDSD xmm1, xmm2, xmm3/m64, imm8
	/// @par
	/// @c VEX.LIG.66.0F3A.WIG 0B /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VROUNDSD_XMM_XMM_XMMM64_IMM8 = 3755,
	/// @brief @c VRNDSCALESD xmm1 {k1}{z}, xmm2, xmm3/m64{sae}, imm8
	/// @par
	/// @c EVEX.LIG.66.0F3A.W1 0B /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRNDSCALESD_XMM_K1Z_XMM_XMMM64_IMM8_SAE = 3756,
	/// @brief @c BLENDPS xmm1, xmm2/m128, imm8
	/// @par
	/// @c 66 0F 3A 0C /r ib
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	BLENDPS_XMM_XMMM128_IMM8 = 3757,
	/// @brief @c VBLENDPS xmm1, xmm2, xmm3/m128, imm8
	/// @par
	/// @c VEX.128.66.0F3A.WIG 0C /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VBLENDPS_XMM_XMM_XMMM128_IMM8 = 3758,
	/// @brief @c VBLENDPS ymm1, ymm2, ymm3/m256, imm8
	/// @par
	/// @c VEX.256.66.0F3A.WIG 0C /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VBLENDPS_YMM_YMM_YMMM256_IMM8 = 3759,
	/// @brief @c BLENDPD xmm1, xmm2/m128, imm8
	/// @par
	/// @c 66 0F 3A 0D /r ib
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	BLENDPD_XMM_XMMM128_IMM8 = 3760,
	/// @brief @c VBLENDPD xmm1, xmm2, xmm3/m128, imm8
	/// @par
	/// @c VEX.128.66.0F3A.WIG 0D /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VBLENDPD_XMM_XMM_XMMM128_IMM8 = 3761,
	/// @brief @c VBLENDPD ymm1, ymm2, ymm3/m256, imm8
	/// @par
	/// @c VEX.256.66.0F3A.WIG 0D /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VBLENDPD_YMM_YMM_YMMM256_IMM8 = 3762,
	/// @brief @c PBLENDW xmm1, xmm2/m128, imm8
	/// @par
	/// @c 66 0F 3A 0E /r ib
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PBLENDW_XMM_XMMM128_IMM8 = 3763,
	/// @brief @c VPBLENDW xmm1, xmm2, xmm3/m128, imm8
	/// @par
	/// @c VEX.128.66.0F3A.WIG 0E /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPBLENDW_XMM_XMM_XMMM128_IMM8 = 3764,
	/// @brief @c VPBLENDW ymm1, ymm2, ymm3/m256, imm8
	/// @par
	/// @c VEX.256.66.0F3A.WIG 0E /r ib
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPBLENDW_YMM_YMM_YMMM256_IMM8 = 3765,
	/// @brief @c PALIGNR mm1, mm2/m64, imm8
	/// @par
	/// @c NP 0F 3A 0F /r ib
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PALIGNR_MM_MMM64_IMM8 = 3766,
	/// @brief @c PALIGNR xmm1, xmm2/m128, imm8
	/// @par
	/// @c 66 0F 3A 0F /r ib
	/// @par
	/// @c SSSE3
	/// @par
	/// @c 16/32/64-bit
	PALIGNR_XMM_XMMM128_IMM8 = 3767,
	/// @brief @c VPALIGNR xmm1, xmm2, xmm3/m128, imm8
	/// @par
	/// @c VEX.128.66.0F3A.WIG 0F /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPALIGNR_XMM_XMM_XMMM128_IMM8 = 3768,
	/// @brief @c VPALIGNR ymm1, ymm2, ymm3/m256, imm8
	/// @par
	/// @c VEX.256.66.0F3A.WIG 0F /r ib
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPALIGNR_YMM_YMM_YMMM256_IMM8 = 3769,
	/// @brief @c VPALIGNR xmm1 {k1}{z}, xmm2, xmm3/m128, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.WIG 0F /r ib
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPALIGNR_XMM_K1Z_XMM_XMMM128_IMM8 = 3770,
	/// @brief @c VPALIGNR ymm1 {k1}{z}, ymm2, ymm3/m256, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.WIG 0F /r ib
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPALIGNR_YMM_K1Z_YMM_YMMM256_IMM8 = 3771,
	/// @brief @c VPALIGNR zmm1 {k1}{z}, zmm2, zmm3/m512, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.WIG 0F /r ib
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPALIGNR_ZMM_K1Z_ZMM_ZMMM512_IMM8 = 3772,
	/// @brief @c PEXTRB r32/m8, xmm2, imm8
	/// @par
	/// @c 66 0F 3A 14 /r ib
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PEXTRB_R32M8_XMM_IMM8 = 3773,
	/// @brief @c PEXTRB r64/m8, xmm2, imm8
	/// @par
	/// @c 66 o64 0F 3A 14 /r ib
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 64-bit
	PEXTRB_R64M8_XMM_IMM8 = 3774,
	/// @brief @c VPEXTRB r32/m8, xmm2, imm8
	/// @par
	/// @c VEX.128.66.0F3A.W0 14 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPEXTRB_R32M8_XMM_IMM8 = 3775,
	/// @brief @c VPEXTRB r64/m8, xmm2, imm8
	/// @par
	/// @c VEX.128.66.0F3A.W1 14 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 64-bit
	VEX_VPEXTRB_R64M8_XMM_IMM8 = 3776,
	/// @brief @c VPEXTRB r32/m8, xmm2, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W0 14 /r ib
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPEXTRB_R32M8_XMM_IMM8 = 3777,
	/// @brief @c VPEXTRB r64/m8, xmm2, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W1 14 /r ib
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 64-bit
	EVEX_VPEXTRB_R64M8_XMM_IMM8 = 3778,
	/// @brief @c PEXTRW r32/m16, xmm, imm8
	/// @par
	/// @c 66 0F 3A 15 /r ib
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PEXTRW_R32M16_XMM_IMM8 = 3779,
	/// @brief @c PEXTRW r64/m16, xmm, imm8
	/// @par
	/// @c 66 o64 0F 3A 15 /r ib
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 64-bit
	PEXTRW_R64M16_XMM_IMM8 = 3780,
	/// @brief @c VPEXTRW r32/m16, xmm2, imm8
	/// @par
	/// @c VEX.128.66.0F3A.W0 15 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPEXTRW_R32M16_XMM_IMM8 = 3781,
	/// @brief @c VPEXTRW r64/m16, xmm2, imm8
	/// @par
	/// @c VEX.128.66.0F3A.W1 15 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 64-bit
	VEX_VPEXTRW_R64M16_XMM_IMM8 = 3782,
	/// @brief @c VPEXTRW r32/m16, xmm2, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W0 15 /r ib
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPEXTRW_R32M16_XMM_IMM8 = 3783,
	/// @brief @c VPEXTRW r64/m16, xmm2, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W1 15 /r ib
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 64-bit
	EVEX_VPEXTRW_R64M16_XMM_IMM8 = 3784,
	/// @brief @c PEXTRD r/m32, xmm2, imm8
	/// @par
	/// @c 66 0F 3A 16 /r ib
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PEXTRD_RM32_XMM_IMM8 = 3785,
	/// @brief @c PEXTRQ r/m64, xmm2, imm8
	/// @par
	/// @c 66 o64 0F 3A 16 /r ib
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 64-bit
	PEXTRQ_RM64_XMM_IMM8 = 3786,
	/// @brief @c VPEXTRD r/m32, xmm2, imm8
	/// @par
	/// @c VEX.128.66.0F3A.W0 16 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPEXTRD_RM32_XMM_IMM8 = 3787,
	/// @brief @c VPEXTRQ r/m64, xmm2, imm8
	/// @par
	/// @c VEX.128.66.0F3A.W1 16 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 64-bit
	VEX_VPEXTRQ_RM64_XMM_IMM8 = 3788,
	/// @brief @c VPEXTRD r/m32, xmm2, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W0 16 /r ib
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPEXTRD_RM32_XMM_IMM8 = 3789,
	/// @brief @c VPEXTRQ r/m64, xmm2, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W1 16 /r ib
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 64-bit
	EVEX_VPEXTRQ_RM64_XMM_IMM8 = 3790,
	/// @brief @c EXTRACTPS r/m32, xmm1, imm8
	/// @par
	/// @c 66 0F 3A 17 /r ib
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	EXTRACTPS_RM32_XMM_IMM8 = 3791,
	/// @brief @c EXTRACTPS r64/m32, xmm1, imm8
	/// @par
	/// @c 66 o64 0F 3A 17 /r ib
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 64-bit
	EXTRACTPS_R64M32_XMM_IMM8 = 3792,
	/// @brief @c VEXTRACTPS r/m32, xmm1, imm8
	/// @par
	/// @c VEX.128.66.0F3A.W0 17 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VEXTRACTPS_RM32_XMM_IMM8 = 3793,
	/// @brief @c VEXTRACTPS r64/m32, xmm1, imm8
	/// @par
	/// @c VEX.128.66.0F3A.W1 17 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 64-bit
	VEX_VEXTRACTPS_R64M32_XMM_IMM8 = 3794,
	/// @brief @c VEXTRACTPS r/m32, xmm1, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W0 17 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VEXTRACTPS_RM32_XMM_IMM8 = 3795,
	/// @brief @c VEXTRACTPS r64/m32, xmm1, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W1 17 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 64-bit
	EVEX_VEXTRACTPS_R64M32_XMM_IMM8 = 3796,
	/// @brief @c VINSERTF128 ymm1, ymm2, xmm3/m128, imm8
	/// @par
	/// @c VEX.256.66.0F3A.W0 18 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VINSERTF128_YMM_YMM_XMMM128_IMM8 = 3797,
	/// @brief @c VINSERTF32X4 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W0 18 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VINSERTF32X4_YMM_K1Z_YMM_XMMM128_IMM8 = 3798,
	/// @brief @c VINSERTF32X4 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W0 18 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VINSERTF32X4_ZMM_K1Z_ZMM_XMMM128_IMM8 = 3799,
	/// @brief @c VINSERTF64X2 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W1 18 /r ib
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VINSERTF64X2_YMM_K1Z_YMM_XMMM128_IMM8 = 3800,
	/// @brief @c VINSERTF64X2 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 18 /r ib
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VINSERTF64X2_ZMM_K1Z_ZMM_XMMM128_IMM8 = 3801,
	/// @brief @c VEXTRACTF128 xmm1/m128, ymm2, imm8
	/// @par
	/// @c VEX.256.66.0F3A.W0 19 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VEXTRACTF128_XMMM128_YMM_IMM8 = 3802,
	/// @brief @c VEXTRACTF32X4 xmm1/m128 {k1}{z}, ymm2, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W0 19 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VEXTRACTF32X4_XMMM128_K1Z_YMM_IMM8 = 3803,
	/// @brief @c VEXTRACTF32X4 xmm1/m128 {k1}{z}, zmm2, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W0 19 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VEXTRACTF32X4_XMMM128_K1Z_ZMM_IMM8 = 3804,
	/// @brief @c VEXTRACTF64X2 xmm1/m128 {k1}{z}, ymm2, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W1 19 /r ib
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VEXTRACTF64X2_XMMM128_K1Z_YMM_IMM8 = 3805,
	/// @brief @c VEXTRACTF64X2 xmm1/m128 {k1}{z}, zmm2, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 19 /r ib
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VEXTRACTF64X2_XMMM128_K1Z_ZMM_IMM8 = 3806,
	/// @brief @c VINSERTF32X8 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W0 1A /r ib
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VINSERTF32X8_ZMM_K1Z_ZMM_YMMM256_IMM8 = 3807,
	/// @brief @c VINSERTF64X4 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 1A /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VINSERTF64X4_ZMM_K1Z_ZMM_YMMM256_IMM8 = 3808,
	/// @brief @c VEXTRACTF32X8 ymm1/m256 {k1}{z}, zmm2, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W0 1B /r ib
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VEXTRACTF32X8_YMMM256_K1Z_ZMM_IMM8 = 3809,
	/// @brief @c VEXTRACTF64X4 ymm1/m256 {k1}{z}, zmm2, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 1B /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VEXTRACTF64X4_YMMM256_K1Z_ZMM_IMM8 = 3810,
	/// @brief @c VCVTPS2PH xmm1/m64, xmm2, imm8
	/// @par
	/// @c VEX.128.66.0F3A.W0 1D /r ib
	/// @par
	/// @c F16C
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTPS2PH_XMMM64_XMM_IMM8 = 3811,
	/// @brief @c VCVTPS2PH xmm1/m128, ymm2, imm8
	/// @par
	/// @c VEX.256.66.0F3A.W0 1D /r ib
	/// @par
	/// @c F16C
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTPS2PH_XMMM128_YMM_IMM8 = 3812,
	/// @brief @c VCVTPS2PH xmm1/m64 {k1}{z}, xmm2, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W0 1D /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPS2PH_XMMM64_K1Z_XMM_IMM8 = 3813,
	/// @brief @c VCVTPS2PH xmm1/m128 {k1}{z}, ymm2, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W0 1D /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPS2PH_XMMM128_K1Z_YMM_IMM8 = 3814,
	/// @brief @c VCVTPS2PH ymm1/m256 {k1}{z}, zmm2{sae}, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W0 1D /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPS2PH_YMMM256_K1Z_ZMM_IMM8_SAE = 3815,
	/// @brief @c VPCMPUD k1 {k2}, xmm2, xmm3/m128/m32bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W0 1E /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPUD_KR_K1_XMM_XMMM128B32_IMM8 = 3816,
	/// @brief @c VPCMPUD k1 {k2}, ymm2, ymm3/m256/m32bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W0 1E /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPUD_KR_K1_YMM_YMMM256B32_IMM8 = 3817,
	/// @brief @c VPCMPUD k1 {k2}, zmm2, zmm3/m512/m32bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W0 1E /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPUD_KR_K1_ZMM_ZMMM512B32_IMM8 = 3818,
	/// @brief @c VPCMPUQ k1 {k2}, xmm2, xmm3/m128/m64bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W1 1E /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPUQ_KR_K1_XMM_XMMM128B64_IMM8 = 3819,
	/// @brief @c VPCMPUQ k1 {k2}, ymm2, ymm3/m256/m64bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W1 1E /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPUQ_KR_K1_YMM_YMMM256B64_IMM8 = 3820,
	/// @brief @c VPCMPUQ k1 {k2}, zmm2, zmm3/m512/m64bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 1E /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPUQ_KR_K1_ZMM_ZMMM512B64_IMM8 = 3821,
	/// @brief @c VPCMPD k1 {k2}, xmm2, xmm3/m128/m32bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W0 1F /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPD_KR_K1_XMM_XMMM128B32_IMM8 = 3822,
	/// @brief @c VPCMPD k1 {k2}, ymm2, ymm3/m256/m32bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W0 1F /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPD_KR_K1_YMM_YMMM256B32_IMM8 = 3823,
	/// @brief @c VPCMPD k1 {k2}, zmm2, zmm3/m512/m32bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W0 1F /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPD_KR_K1_ZMM_ZMMM512B32_IMM8 = 3824,
	/// @brief @c VPCMPQ k1 {k2}, xmm2, xmm3/m128/m64bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W1 1F /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPQ_KR_K1_XMM_XMMM128B64_IMM8 = 3825,
	/// @brief @c VPCMPQ k1 {k2}, ymm2, ymm3/m256/m64bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W1 1F /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPQ_KR_K1_YMM_YMMM256B64_IMM8 = 3826,
	/// @brief @c VPCMPQ k1 {k2}, zmm2, zmm3/m512/m64bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 1F /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPQ_KR_K1_ZMM_ZMMM512B64_IMM8 = 3827,
	/// @brief @c PINSRB xmm1, r32/m8, imm8
	/// @par
	/// @c 66 0F 3A 20 /r ib
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PINSRB_XMM_R32M8_IMM8 = 3828,
	/// @brief @c PINSRB xmm1, r64/m8, imm8
	/// @par
	/// @c 66 o64 0F 3A 20 /r ib
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 64-bit
	PINSRB_XMM_R64M8_IMM8 = 3829,
	/// @brief @c VPINSRB xmm1, xmm2, r32/m8, imm8
	/// @par
	/// @c VEX.128.66.0F3A.W0 20 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPINSRB_XMM_XMM_R32M8_IMM8 = 3830,
	/// @brief @c VPINSRB xmm1, xmm2, r64/m8, imm8
	/// @par
	/// @c VEX.128.66.0F3A.W1 20 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 64-bit
	VEX_VPINSRB_XMM_XMM_R64M8_IMM8 = 3831,
	/// @brief @c VPINSRB xmm1, xmm2, r32/m8, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W0 20 /r ib
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPINSRB_XMM_XMM_R32M8_IMM8 = 3832,
	/// @brief @c VPINSRB xmm1, xmm2, r64/m8, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W1 20 /r ib
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 64-bit
	EVEX_VPINSRB_XMM_XMM_R64M8_IMM8 = 3833,
	/// @brief @c INSERTPS xmm1, xmm2/m32, imm8
	/// @par
	/// @c 66 0F 3A 21 /r ib
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	INSERTPS_XMM_XMMM32_IMM8 = 3834,
	/// @brief @c VINSERTPS xmm1, xmm2, xmm3/m32, imm8
	/// @par
	/// @c VEX.128.66.0F3A.WIG 21 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VINSERTPS_XMM_XMM_XMMM32_IMM8 = 3835,
	/// @brief @c VINSERTPS xmm1, xmm2, xmm3/m32, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W0 21 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VINSERTPS_XMM_XMM_XMMM32_IMM8 = 3836,
	/// @brief @c PINSRD xmm1, r/m32, imm8
	/// @par
	/// @c 66 0F 3A 22 /r ib
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	PINSRD_XMM_RM32_IMM8 = 3837,
	/// @brief @c PINSRQ xmm1, r/m64, imm8
	/// @par
	/// @c 66 o64 0F 3A 22 /r ib
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 64-bit
	PINSRQ_XMM_RM64_IMM8 = 3838,
	/// @brief @c VPINSRD xmm1, xmm2, r/m32, imm8
	/// @par
	/// @c VEX.128.66.0F3A.W0 22 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPINSRD_XMM_XMM_RM32_IMM8 = 3839,
	/// @brief @c VPINSRQ xmm1, xmm2, r/m64, imm8
	/// @par
	/// @c VEX.128.66.0F3A.W1 22 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 64-bit
	VEX_VPINSRQ_XMM_XMM_RM64_IMM8 = 3840,
	/// @brief @c VPINSRD xmm1, xmm2, r/m32, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W0 22 /r ib
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPINSRD_XMM_XMM_RM32_IMM8 = 3841,
	/// @brief @c VPINSRQ xmm1, xmm2, r/m64, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W1 22 /r ib
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 64-bit
	EVEX_VPINSRQ_XMM_XMM_RM64_IMM8 = 3842,
	/// @brief @c VSHUFF32X4 ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W0 23 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSHUFF32X4_YMM_K1Z_YMM_YMMM256B32_IMM8 = 3843,
	/// @brief @c VSHUFF32X4 zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W0 23 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSHUFF32X4_ZMM_K1Z_ZMM_ZMMM512B32_IMM8 = 3844,
	/// @brief @c VSHUFF64X2 ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W1 23 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSHUFF64X2_YMM_K1Z_YMM_YMMM256B64_IMM8 = 3845,
	/// @brief @c VSHUFF64X2 zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 23 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSHUFF64X2_ZMM_K1Z_ZMM_ZMMM512B64_IMM8 = 3846,
	/// @brief @c VPTERNLOGD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W0 25 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPTERNLOGD_XMM_K1Z_XMM_XMMM128B32_IMM8 = 3847,
	/// @brief @c VPTERNLOGD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W0 25 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPTERNLOGD_YMM_K1Z_YMM_YMMM256B32_IMM8 = 3848,
	/// @brief @c VPTERNLOGD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W0 25 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPTERNLOGD_ZMM_K1Z_ZMM_ZMMM512B32_IMM8 = 3849,
	/// @brief @c VPTERNLOGQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W1 25 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPTERNLOGQ_XMM_K1Z_XMM_XMMM128B64_IMM8 = 3850,
	/// @brief @c VPTERNLOGQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W1 25 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPTERNLOGQ_YMM_K1Z_YMM_YMMM256B64_IMM8 = 3851,
	/// @brief @c VPTERNLOGQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 25 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPTERNLOGQ_ZMM_K1Z_ZMM_ZMMM512B64_IMM8 = 3852,
	/// @brief @c VGETMANTPS xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W0 26 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGETMANTPS_XMM_K1Z_XMMM128B32_IMM8 = 3853,
	/// @brief @c VGETMANTPS ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W0 26 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGETMANTPS_YMM_K1Z_YMMM256B32_IMM8 = 3854,
	/// @brief @c VGETMANTPS zmm1 {k1}{z}, zmm2/m512/m32bcst{sae}, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W0 26 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGETMANTPS_ZMM_K1Z_ZMMM512B32_IMM8_SAE = 3855,
	/// @brief @c VGETMANTPD xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W1 26 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGETMANTPD_XMM_K1Z_XMMM128B64_IMM8 = 3856,
	/// @brief @c VGETMANTPD ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W1 26 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGETMANTPD_YMM_K1Z_YMMM256B64_IMM8 = 3857,
	/// @brief @c VGETMANTPD zmm1 {k1}{z}, zmm2/m512/m64bcst{sae}, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 26 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGETMANTPD_ZMM_K1Z_ZMMM512B64_IMM8_SAE = 3858,
	/// @brief @c VGETMANTSS xmm1 {k1}{z}, xmm2, xmm3/m32{sae}, imm8
	/// @par
	/// @c EVEX.LIG.66.0F3A.W0 27 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGETMANTSS_XMM_K1Z_XMM_XMMM32_IMM8_SAE = 3859,
	/// @brief @c VGETMANTSD xmm1 {k1}{z}, xmm2, xmm3/m64{sae}, imm8
	/// @par
	/// @c EVEX.LIG.66.0F3A.W1 27 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGETMANTSD_XMM_K1Z_XMM_XMMM64_IMM8_SAE = 3860,
	/// @brief @c KSHIFTRB k1, k2, imm8
	/// @par
	/// @c VEX.L0.66.0F3A.W0 30 /r ib
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	VEX_KSHIFTRB_KR_KR_IMM8 = 3861,
	/// @brief @c KSHIFTRW k1, k2, imm8
	/// @par
	/// @c VEX.L0.66.0F3A.W1 30 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	VEX_KSHIFTRW_KR_KR_IMM8 = 3862,
	/// @brief @c KSHIFTRD k1, k2, imm8
	/// @par
	/// @c VEX.L0.66.0F3A.W0 31 /r ib
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	VEX_KSHIFTRD_KR_KR_IMM8 = 3863,
	/// @brief @c KSHIFTRQ k1, k2, imm8
	/// @par
	/// @c VEX.L0.66.0F3A.W1 31 /r ib
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	VEX_KSHIFTRQ_KR_KR_IMM8 = 3864,
	/// @brief @c KSHIFTLB k1, k2, imm8
	/// @par
	/// @c VEX.L0.66.0F3A.W0 32 /r ib
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	VEX_KSHIFTLB_KR_KR_IMM8 = 3865,
	/// @brief @c KSHIFTLW k1, k2, imm8
	/// @par
	/// @c VEX.L0.66.0F3A.W1 32 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	VEX_KSHIFTLW_KR_KR_IMM8 = 3866,
	/// @brief @c KSHIFTLD k1, k2, imm8
	/// @par
	/// @c VEX.L0.66.0F3A.W0 33 /r ib
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	VEX_KSHIFTLD_KR_KR_IMM8 = 3867,
	/// @brief @c KSHIFTLQ k1, k2, imm8
	/// @par
	/// @c VEX.L0.66.0F3A.W1 33 /r ib
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	VEX_KSHIFTLQ_KR_KR_IMM8 = 3868,
	/// @brief @c VINSERTI128 ymm1, ymm2, xmm3/m128, imm8
	/// @par
	/// @c VEX.256.66.0F3A.W0 38 /r ib
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VINSERTI128_YMM_YMM_XMMM128_IMM8 = 3869,
	/// @brief @c VINSERTI32X4 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W0 38 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VINSERTI32X4_YMM_K1Z_YMM_XMMM128_IMM8 = 3870,
	/// @brief @c VINSERTI32X4 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W0 38 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VINSERTI32X4_ZMM_K1Z_ZMM_XMMM128_IMM8 = 3871,
	/// @brief @c VINSERTI64X2 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W1 38 /r ib
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VINSERTI64X2_YMM_K1Z_YMM_XMMM128_IMM8 = 3872,
	/// @brief @c VINSERTI64X2 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 38 /r ib
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VINSERTI64X2_ZMM_K1Z_ZMM_XMMM128_IMM8 = 3873,
	/// @brief @c VEXTRACTI128 xmm1/m128, ymm2, imm8
	/// @par
	/// @c VEX.256.66.0F3A.W0 39 /r ib
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VEXTRACTI128_XMMM128_YMM_IMM8 = 3874,
	/// @brief @c VEXTRACTI32X4 xmm1/m128 {k1}{z}, ymm2, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W0 39 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VEXTRACTI32X4_XMMM128_K1Z_YMM_IMM8 = 3875,
	/// @brief @c VEXTRACTI32X4 xmm1/m128 {k1}{z}, zmm2, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W0 39 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VEXTRACTI32X4_XMMM128_K1Z_ZMM_IMM8 = 3876,
	/// @brief @c VEXTRACTI64X2 xmm1/m128 {k1}{z}, ymm2, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W1 39 /r ib
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VEXTRACTI64X2_XMMM128_K1Z_YMM_IMM8 = 3877,
	/// @brief @c VEXTRACTI64X2 xmm1/m128 {k1}{z}, zmm2, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 39 /r ib
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VEXTRACTI64X2_XMMM128_K1Z_ZMM_IMM8 = 3878,
	/// @brief @c VINSERTI32X8 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W0 3A /r ib
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VINSERTI32X8_ZMM_K1Z_ZMM_YMMM256_IMM8 = 3879,
	/// @brief @c VINSERTI64X4 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 3A /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VINSERTI64X4_ZMM_K1Z_ZMM_YMMM256_IMM8 = 3880,
	/// @brief @c VEXTRACTI32X8 ymm1/m256 {k1}{z}, zmm2, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W0 3B /r ib
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VEXTRACTI32X8_YMMM256_K1Z_ZMM_IMM8 = 3881,
	/// @brief @c VEXTRACTI64X4 ymm1/m256 {k1}{z}, zmm2, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 3B /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VEXTRACTI64X4_YMMM256_K1Z_ZMM_IMM8 = 3882,
	/// @brief @c VPCMPUB k1 {k2}, xmm2, xmm3/m128, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W0 3E /r ib
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPUB_KR_K1_XMM_XMMM128_IMM8 = 3883,
	/// @brief @c VPCMPUB k1 {k2}, ymm2, ymm3/m256, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W0 3E /r ib
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPUB_KR_K1_YMM_YMMM256_IMM8 = 3884,
	/// @brief @c VPCMPUB k1 {k2}, zmm2, zmm3/m512, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W0 3E /r ib
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPUB_KR_K1_ZMM_ZMMM512_IMM8 = 3885,
	/// @brief @c VPCMPUW k1 {k2}, xmm2, xmm3/m128, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W1 3E /r ib
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPUW_KR_K1_XMM_XMMM128_IMM8 = 3886,
	/// @brief @c VPCMPUW k1 {k2}, ymm2, ymm3/m256, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W1 3E /r ib
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPUW_KR_K1_YMM_YMMM256_IMM8 = 3887,
	/// @brief @c VPCMPUW k1 {k2}, zmm2, zmm3/m512, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 3E /r ib
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPUW_KR_K1_ZMM_ZMMM512_IMM8 = 3888,
	/// @brief @c VPCMPB k1 {k2}, xmm2, xmm3/m128, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W0 3F /r ib
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPB_KR_K1_XMM_XMMM128_IMM8 = 3889,
	/// @brief @c VPCMPB k1 {k2}, ymm2, ymm3/m256, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W0 3F /r ib
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPB_KR_K1_YMM_YMMM256_IMM8 = 3890,
	/// @brief @c VPCMPB k1 {k2}, zmm2, zmm3/m512, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W0 3F /r ib
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPB_KR_K1_ZMM_ZMMM512_IMM8 = 3891,
	/// @brief @c VPCMPW k1 {k2}, xmm2, xmm3/m128, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W1 3F /r ib
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPW_KR_K1_XMM_XMMM128_IMM8 = 3892,
	/// @brief @c VPCMPW k1 {k2}, ymm2, ymm3/m256, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W1 3F /r ib
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPW_KR_K1_YMM_YMMM256_IMM8 = 3893,
	/// @brief @c VPCMPW k1 {k2}, zmm2, zmm3/m512, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 3F /r ib
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCMPW_KR_K1_ZMM_ZMMM512_IMM8 = 3894,
	/// @brief @c DPPS xmm1, xmm2/m128, imm8
	/// @par
	/// @c 66 0F 3A 40 /r ib
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	DPPS_XMM_XMMM128_IMM8 = 3895,
	/// @brief @c VDPPS xmm1, xmm2, xmm3/m128, imm8
	/// @par
	/// @c VEX.128.66.0F3A.WIG 40 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VDPPS_XMM_XMM_XMMM128_IMM8 = 3896,
	/// @brief @c VDPPS ymm1, ymm2, ymm3/m256, imm8
	/// @par
	/// @c VEX.256.66.0F3A.WIG 40 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VDPPS_YMM_YMM_YMMM256_IMM8 = 3897,
	/// @brief @c DPPD xmm1, xmm2/m128, imm8
	/// @par
	/// @c 66 0F 3A 41 /r ib
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	DPPD_XMM_XMMM128_IMM8 = 3898,
	/// @brief @c VDPPD xmm1, xmm2, xmm3/m128, imm8
	/// @par
	/// @c VEX.128.66.0F3A.WIG 41 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VDPPD_XMM_XMM_XMMM128_IMM8 = 3899,
	/// @brief @c MPSADBW xmm1, xmm2/m128, imm8
	/// @par
	/// @c 66 0F 3A 42 /r ib
	/// @par
	/// @c SSE4.1
	/// @par
	/// @c 16/32/64-bit
	MPSADBW_XMM_XMMM128_IMM8 = 3900,
	/// @brief @c VMPSADBW xmm1, xmm2, xmm3/m128, imm8
	/// @par
	/// @c VEX.128.66.0F3A.WIG 42 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VMPSADBW_XMM_XMM_XMMM128_IMM8 = 3901,
	/// @brief @c VMPSADBW ymm1, ymm2, ymm3/m256, imm8
	/// @par
	/// @c VEX.256.66.0F3A.WIG 42 /r ib
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VMPSADBW_YMM_YMM_YMMM256_IMM8 = 3902,
	/// @brief @c VDBPSADBW xmm1 {k1}{z}, xmm2, xmm3/m128, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W0 42 /r ib
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VDBPSADBW_XMM_K1Z_XMM_XMMM128_IMM8 = 3903,
	/// @brief @c VDBPSADBW ymm1 {k1}{z}, ymm2, ymm3/m256, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W0 42 /r ib
	/// @par
	/// @c AVX512VL and AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VDBPSADBW_YMM_K1Z_YMM_YMMM256_IMM8 = 3904,
	/// @brief @c VDBPSADBW zmm1 {k1}{z}, zmm2, zmm3/m512, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W0 42 /r ib
	/// @par
	/// @c AVX512BW
	/// @par
	/// @c 16/32/64-bit
	EVEX_VDBPSADBW_ZMM_K1Z_ZMM_ZMMM512_IMM8 = 3905,
	/// @brief @c VSHUFI32X4 ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W0 43 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSHUFI32X4_YMM_K1Z_YMM_YMMM256B32_IMM8 = 3906,
	/// @brief @c VSHUFI32X4 zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W0 43 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSHUFI32X4_ZMM_K1Z_ZMM_ZMMM512B32_IMM8 = 3907,
	/// @brief @c VSHUFI64X2 ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W1 43 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSHUFI64X2_YMM_K1Z_YMM_YMMM256B64_IMM8 = 3908,
	/// @brief @c VSHUFI64X2 zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 43 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSHUFI64X2_ZMM_K1Z_ZMM_ZMMM512B64_IMM8 = 3909,
	/// @brief @c PCLMULQDQ xmm1, xmm2/m128, imm8
	/// @par
	/// @c 66 0F 3A 44 /r ib
	/// @par
	/// @c PCLMULQDQ
	/// @par
	/// @c 16/32/64-bit
	PCLMULQDQ_XMM_XMMM128_IMM8 = 3910,
	/// @brief @c VPCLMULQDQ xmm1, xmm2, xmm3/m128, imm8
	/// @par
	/// @c VEX.128.66.0F3A.WIG 44 /r ib
	/// @par
	/// @c PCLMULQDQ and AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPCLMULQDQ_XMM_XMM_XMMM128_IMM8 = 3911,
	/// @brief @c VPCLMULQDQ ymm1, ymm2, ymm3/m256, imm8
	/// @par
	/// @c VEX.256.66.0F3A.WIG 44 /r ib
	/// @par
	/// @c VPCLMULQDQ
	/// @par
	/// @c 16/32/64-bit
	VEX_VPCLMULQDQ_YMM_YMM_YMMM256_IMM8 = 3912,
	/// @brief @c VPCLMULQDQ xmm1, xmm2, xmm3/m128, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.WIG 44 /r ib
	/// @par
	/// @c AVX512VL and VPCLMULQDQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCLMULQDQ_XMM_XMM_XMMM128_IMM8 = 3913,
	/// @brief @c VPCLMULQDQ ymm1, ymm2, ymm3/m256, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.WIG 44 /r ib
	/// @par
	/// @c AVX512VL and VPCLMULQDQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCLMULQDQ_YMM_YMM_YMMM256_IMM8 = 3914,
	/// @brief @c VPCLMULQDQ zmm1, zmm2, zmm3/m512, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.WIG 44 /r ib
	/// @par
	/// @c AVX512F and VPCLMULQDQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPCLMULQDQ_ZMM_ZMM_ZMMM512_IMM8 = 3915,
	/// @brief @c VPERM2I128 ymm1, ymm2, ymm3/m256, imm8
	/// @par
	/// @c VEX.256.66.0F3A.W0 46 /r ib
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPERM2I128_YMM_YMM_YMMM256_IMM8 = 3916,
	/// @brief @c VPERMIL2PS xmm1, xmm2, xmm3/m128, xmm4, imm4
	/// @par
	/// @c VEX.128.66.0F3A.W0 48 /r /is5
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	VEX_VPERMIL2PS_XMM_XMM_XMMM128_XMM_IMM4 = 3917,
	/// @brief @c VPERMIL2PS ymm1, ymm2, ymm3/m256, ymm4, imm4
	/// @par
	/// @c VEX.256.66.0F3A.W0 48 /r /is5
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	VEX_VPERMIL2PS_YMM_YMM_YMMM256_YMM_IMM4 = 3918,
	/// @brief @c VPERMIL2PS xmm1, xmm2, xmm3, xmm4/m128, imm4
	/// @par
	/// @c VEX.128.66.0F3A.W1 48 /r /is5
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	VEX_VPERMIL2PS_XMM_XMM_XMM_XMMM128_IMM4 = 3919,
	/// @brief @c VPERMIL2PS ymm1, ymm2, ymm3, ymm4/m256, imm4
	/// @par
	/// @c VEX.256.66.0F3A.W1 48 /r /is5
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	VEX_VPERMIL2PS_YMM_YMM_YMM_YMMM256_IMM4 = 3920,
	/// @brief @c VPERMIL2PD xmm1, xmm2, xmm3/m128, xmm4, imm4
	/// @par
	/// @c VEX.128.66.0F3A.W0 49 /r /is5
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	VEX_VPERMIL2PD_XMM_XMM_XMMM128_XMM_IMM4 = 3921,
	/// @brief @c VPERMIL2PD ymm1, ymm2, ymm3/m256, ymm4, imm4
	/// @par
	/// @c VEX.256.66.0F3A.W0 49 /r /is5
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	VEX_VPERMIL2PD_YMM_YMM_YMMM256_YMM_IMM4 = 3922,
	/// @brief @c VPERMIL2PD xmm1, xmm2, xmm3, xmm4/m128, imm4
	/// @par
	/// @c VEX.128.66.0F3A.W1 49 /r /is5
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	VEX_VPERMIL2PD_XMM_XMM_XMM_XMMM128_IMM4 = 3923,
	/// @brief @c VPERMIL2PD ymm1, ymm2, ymm3, ymm4/m256, imm4
	/// @par
	/// @c VEX.256.66.0F3A.W1 49 /r /is5
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	VEX_VPERMIL2PD_YMM_YMM_YMM_YMMM256_IMM4 = 3924,
	/// @brief @c VBLENDVPS xmm1, xmm2, xmm3/m128, xmm4
	/// @par
	/// @c VEX.128.66.0F3A.W0 4A /r /is4
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VBLENDVPS_XMM_XMM_XMMM128_XMM = 3925,
	/// @brief @c VBLENDVPS ymm1, ymm2, ymm3/m256, ymm4
	/// @par
	/// @c VEX.256.66.0F3A.W0 4A /r /is4
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VBLENDVPS_YMM_YMM_YMMM256_YMM = 3926,
	/// @brief @c VBLENDVPD xmm1, xmm2, xmm3/m128, xmm4
	/// @par
	/// @c VEX.128.66.0F3A.W0 4B /r /is4
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VBLENDVPD_XMM_XMM_XMMM128_XMM = 3927,
	/// @brief @c VBLENDVPD ymm1, ymm2, ymm3/m256, ymm4
	/// @par
	/// @c VEX.256.66.0F3A.W0 4B /r /is4
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VBLENDVPD_YMM_YMM_YMMM256_YMM = 3928,
	/// @brief @c VPBLENDVB xmm1, xmm2, xmm3/m128, xmm4
	/// @par
	/// @c VEX.128.66.0F3A.W0 4C /r /is4
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPBLENDVB_XMM_XMM_XMMM128_XMM = 3929,
	/// @brief @c VPBLENDVB ymm1, ymm2, ymm3/m256, ymm4
	/// @par
	/// @c VEX.256.66.0F3A.W0 4C /r /is4
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VPBLENDVB_YMM_YMM_YMMM256_YMM = 3930,
	/// @brief @c VRANGEPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W0 50 /r ib
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRANGEPS_XMM_K1Z_XMM_XMMM128B32_IMM8 = 3931,
	/// @brief @c VRANGEPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W0 50 /r ib
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRANGEPS_YMM_K1Z_YMM_YMMM256B32_IMM8 = 3932,
	/// @brief @c VRANGEPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{sae}, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W0 50 /r ib
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRANGEPS_ZMM_K1Z_ZMM_ZMMM512B32_IMM8_SAE = 3933,
	/// @brief @c VRANGEPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W1 50 /r ib
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRANGEPD_XMM_K1Z_XMM_XMMM128B64_IMM8 = 3934,
	/// @brief @c VRANGEPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W1 50 /r ib
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRANGEPD_YMM_K1Z_YMM_YMMM256B64_IMM8 = 3935,
	/// @brief @c VRANGEPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{sae}, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 50 /r ib
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRANGEPD_ZMM_K1Z_ZMM_ZMMM512B64_IMM8_SAE = 3936,
	/// @brief @c VRANGESS xmm1 {k1}{z}, xmm2, xmm3/m32{sae}, imm8
	/// @par
	/// @c EVEX.LIG.66.0F3A.W0 51 /r ib
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRANGESS_XMM_K1Z_XMM_XMMM32_IMM8_SAE = 3937,
	/// @brief @c VRANGESD xmm1 {k1}{z}, xmm2, xmm3/m64{sae}, imm8
	/// @par
	/// @c EVEX.LIG.66.0F3A.W1 51 /r ib
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRANGESD_XMM_K1Z_XMM_XMMM64_IMM8_SAE = 3938,
	/// @brief @c VFIXUPIMMPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W0 54 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFIXUPIMMPS_XMM_K1Z_XMM_XMMM128B32_IMM8 = 3939,
	/// @brief @c VFIXUPIMMPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W0 54 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFIXUPIMMPS_YMM_K1Z_YMM_YMMM256B32_IMM8 = 3940,
	/// @brief @c VFIXUPIMMPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{sae}, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W0 54 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFIXUPIMMPS_ZMM_K1Z_ZMM_ZMMM512B32_IMM8_SAE = 3941,
	/// @brief @c VFIXUPIMMPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W1 54 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFIXUPIMMPD_XMM_K1Z_XMM_XMMM128B64_IMM8 = 3942,
	/// @brief @c VFIXUPIMMPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W1 54 /r ib
	/// @par
	/// @c AVX512VL and AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFIXUPIMMPD_YMM_K1Z_YMM_YMMM256B64_IMM8 = 3943,
	/// @brief @c VFIXUPIMMPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{sae}, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 54 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFIXUPIMMPD_ZMM_K1Z_ZMM_ZMMM512B64_IMM8_SAE = 3944,
	/// @brief @c VFIXUPIMMSS xmm1 {k1}{z}, xmm2, xmm3/m32{sae}, imm8
	/// @par
	/// @c EVEX.LIG.66.0F3A.W0 55 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFIXUPIMMSS_XMM_K1Z_XMM_XMMM32_IMM8_SAE = 3945,
	/// @brief @c VFIXUPIMMSD xmm1 {k1}{z}, xmm2, xmm3/m64{sae}, imm8
	/// @par
	/// @c EVEX.LIG.66.0F3A.W1 55 /r ib
	/// @par
	/// @c AVX512F
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFIXUPIMMSD_XMM_K1Z_XMM_XMMM64_IMM8_SAE = 3946,
	/// @brief @c VREDUCEPS xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W0 56 /r ib
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VREDUCEPS_XMM_K1Z_XMMM128B32_IMM8 = 3947,
	/// @brief @c VREDUCEPS ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W0 56 /r ib
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VREDUCEPS_YMM_K1Z_YMMM256B32_IMM8 = 3948,
	/// @brief @c VREDUCEPS zmm1 {k1}{z}, zmm2/m512/m32bcst{sae}, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W0 56 /r ib
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VREDUCEPS_ZMM_K1Z_ZMMM512B32_IMM8_SAE = 3949,
	/// @brief @c VREDUCEPD xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W1 56 /r ib
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VREDUCEPD_XMM_K1Z_XMMM128B64_IMM8 = 3950,
	/// @brief @c VREDUCEPD ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W1 56 /r ib
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VREDUCEPD_YMM_K1Z_YMMM256B64_IMM8 = 3951,
	/// @brief @c VREDUCEPD zmm1 {k1}{z}, zmm2/m512/m64bcst{sae}, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 56 /r ib
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VREDUCEPD_ZMM_K1Z_ZMMM512B64_IMM8_SAE = 3952,
	/// @brief @c VREDUCESS xmm1 {k1}{z}, xmm2, xmm3/m32{sae}, imm8
	/// @par
	/// @c EVEX.LIG.66.0F3A.W0 57 /r ib
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VREDUCESS_XMM_K1Z_XMM_XMMM32_IMM8_SAE = 3953,
	/// @brief @c VREDUCESD xmm1 {k1}{z}, xmm2, xmm3/m64{sae}, imm8
	/// @par
	/// @c EVEX.LIG.66.0F3A.W1 57 /r ib
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VREDUCESD_XMM_K1Z_XMM_XMMM64_IMM8_SAE = 3954,
	/// @brief @c VFMADDSUBPS xmm1, xmm2, xmm3/m128, xmm4
	/// @par
	/// @c VEX.128.66.0F3A.W0 5C /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDSUBPS_XMM_XMM_XMMM128_XMM = 3955,
	/// @brief @c VFMADDSUBPS ymm1, ymm2, ymm3/m256, ymm4
	/// @par
	/// @c VEX.256.66.0F3A.W0 5C /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDSUBPS_YMM_YMM_YMMM256_YMM = 3956,
	/// @brief @c VFMADDSUBPS xmm1, xmm2, xmm3, xmm4/m128
	/// @par
	/// @c VEX.128.66.0F3A.W1 5C /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDSUBPS_XMM_XMM_XMM_XMMM128 = 3957,
	/// @brief @c VFMADDSUBPS ymm1, ymm2, ymm3, ymm4/m256
	/// @par
	/// @c VEX.256.66.0F3A.W1 5C /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDSUBPS_YMM_YMM_YMM_YMMM256 = 3958,
	/// @brief @c VFMADDSUBPD xmm1, xmm2, xmm3/m128, xmm4
	/// @par
	/// @c VEX.128.66.0F3A.W0 5D /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDSUBPD_XMM_XMM_XMMM128_XMM = 3959,
	/// @brief @c VFMADDSUBPD ymm1, ymm2, ymm3/m256, ymm4
	/// @par
	/// @c VEX.256.66.0F3A.W0 5D /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDSUBPD_YMM_YMM_YMMM256_YMM = 3960,
	/// @brief @c VFMADDSUBPD xmm1, xmm2, xmm3, xmm4/m128
	/// @par
	/// @c VEX.128.66.0F3A.W1 5D /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDSUBPD_XMM_XMM_XMM_XMMM128 = 3961,
	/// @brief @c VFMADDSUBPD ymm1, ymm2, ymm3, ymm4/m256
	/// @par
	/// @c VEX.256.66.0F3A.W1 5D /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDSUBPD_YMM_YMM_YMM_YMMM256 = 3962,
	/// @brief @c VFMSUBADDPS xmm1, xmm2, xmm3/m128, xmm4
	/// @par
	/// @c VEX.128.66.0F3A.W0 5E /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBADDPS_XMM_XMM_XMMM128_XMM = 3963,
	/// @brief @c VFMSUBADDPS ymm1, ymm2, ymm3/m256, ymm4
	/// @par
	/// @c VEX.256.66.0F3A.W0 5E /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBADDPS_YMM_YMM_YMMM256_YMM = 3964,
	/// @brief @c VFMSUBADDPS xmm1, xmm2, xmm3, xmm4/m128
	/// @par
	/// @c VEX.128.66.0F3A.W1 5E /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBADDPS_XMM_XMM_XMM_XMMM128 = 3965,
	/// @brief @c VFMSUBADDPS ymm1, ymm2, ymm3, ymm4/m256
	/// @par
	/// @c VEX.256.66.0F3A.W1 5E /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBADDPS_YMM_YMM_YMM_YMMM256 = 3966,
	/// @brief @c VFMSUBADDPD xmm1, xmm2, xmm3/m128, xmm4
	/// @par
	/// @c VEX.128.66.0F3A.W0 5F /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBADDPD_XMM_XMM_XMMM128_XMM = 3967,
	/// @brief @c VFMSUBADDPD ymm1, ymm2, ymm3/m256, ymm4
	/// @par
	/// @c VEX.256.66.0F3A.W0 5F /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBADDPD_YMM_YMM_YMMM256_YMM = 3968,
	/// @brief @c VFMSUBADDPD xmm1, xmm2, xmm3, xmm4/m128
	/// @par
	/// @c VEX.128.66.0F3A.W1 5F /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBADDPD_XMM_XMM_XMM_XMMM128 = 3969,
	/// @brief @c VFMSUBADDPD ymm1, ymm2, ymm3, ymm4/m256
	/// @par
	/// @c VEX.256.66.0F3A.W1 5F /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBADDPD_YMM_YMM_YMM_YMMM256 = 3970,
	/// @brief @c PCMPESTRM xmm1, xmm2/m128, imm8
	/// @par
	/// @c 66 0F 3A 60 /r ib
	/// @par
	/// @c SSE4.2
	/// @par
	/// @c 16/32/64-bit
	PCMPESTRM_XMM_XMMM128_IMM8 = 3971,
	/// @brief @c PCMPESTRM64 xmm1, xmm2/m128, imm8
	/// @par
	/// @c 66 o64 0F 3A 60 /r ib
	/// @par
	/// @c SSE4.2
	/// @par
	/// @c 64-bit
	PCMPESTRM64_XMM_XMMM128_IMM8 = 3972,
	/// @brief @c VPCMPESTRM xmm1, xmm2/m128, imm8
	/// @par
	/// @c VEX.128.66.0F3A.W0 60 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPCMPESTRM_XMM_XMMM128_IMM8 = 3973,
	/// @brief @c VPCMPESTRM64 xmm1, xmm2/m128, imm8
	/// @par
	/// @c VEX.128.66.0F3A.W1 60 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 64-bit
	VEX_VPCMPESTRM64_XMM_XMMM128_IMM8 = 3974,
	/// @brief @c PCMPESTRI xmm1, xmm2/m128, imm8
	/// @par
	/// @c 66 0F 3A 61 /r ib
	/// @par
	/// @c SSE4.2
	/// @par
	/// @c 16/32/64-bit
	PCMPESTRI_XMM_XMMM128_IMM8 = 3975,
	/// @brief @c PCMPESTRI64 xmm1, xmm2/m128, imm8
	/// @par
	/// @c 66 o64 0F 3A 61 /r ib
	/// @par
	/// @c SSE4.2
	/// @par
	/// @c 64-bit
	PCMPESTRI64_XMM_XMMM128_IMM8 = 3976,
	/// @brief @c VPCMPESTRI xmm1, xmm2/m128, imm8
	/// @par
	/// @c VEX.128.66.0F3A.W0 61 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPCMPESTRI_XMM_XMMM128_IMM8 = 3977,
	/// @brief @c VPCMPESTRI64 xmm1, xmm2/m128, imm8
	/// @par
	/// @c VEX.128.66.0F3A.W1 61 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 64-bit
	VEX_VPCMPESTRI64_XMM_XMMM128_IMM8 = 3978,
	/// @brief @c PCMPISTRM xmm1, xmm2/m128, imm8
	/// @par
	/// @c 66 0F 3A 62 /r ib
	/// @par
	/// @c SSE4.2
	/// @par
	/// @c 16/32/64-bit
	PCMPISTRM_XMM_XMMM128_IMM8 = 3979,
	/// @brief @c VPCMPISTRM xmm1, xmm2/m128, imm8
	/// @par
	/// @c VEX.128.66.0F3A.WIG 62 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPCMPISTRM_XMM_XMMM128_IMM8 = 3980,
	/// @brief @c PCMPISTRI xmm1, xmm2/m128, imm8
	/// @par
	/// @c 66 0F 3A 63 /r ib
	/// @par
	/// @c SSE4.2
	/// @par
	/// @c 16/32/64-bit
	PCMPISTRI_XMM_XMMM128_IMM8 = 3981,
	/// @brief @c VPCMPISTRI xmm1, xmm2/m128, imm8
	/// @par
	/// @c VEX.128.66.0F3A.WIG 63 /r ib
	/// @par
	/// @c AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VPCMPISTRI_XMM_XMMM128_IMM8 = 3982,
	/// @brief @c VFPCLASSPS k2 {k1}, xmm2/m128/m32bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W0 66 /r ib
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFPCLASSPS_KR_K1_XMMM128B32_IMM8 = 3983,
	/// @brief @c VFPCLASSPS k2 {k1}, ymm2/m256/m32bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W0 66 /r ib
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFPCLASSPS_KR_K1_YMMM256B32_IMM8 = 3984,
	/// @brief @c VFPCLASSPS k2 {k1}, zmm2/m512/m32bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W0 66 /r ib
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFPCLASSPS_KR_K1_ZMMM512B32_IMM8 = 3985,
	/// @brief @c VFPCLASSPD k2 {k1}, xmm2/m128/m64bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W1 66 /r ib
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFPCLASSPD_KR_K1_XMMM128B64_IMM8 = 3986,
	/// @brief @c VFPCLASSPD k2 {k1}, ymm2/m256/m64bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W1 66 /r ib
	/// @par
	/// @c AVX512VL and AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFPCLASSPD_KR_K1_YMMM256B64_IMM8 = 3987,
	/// @brief @c VFPCLASSPD k2 {k1}, zmm2/m512/m64bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 66 /r ib
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFPCLASSPD_KR_K1_ZMMM512B64_IMM8 = 3988,
	/// @brief @c VFPCLASSSS k2 {k1}, xmm2/m32, imm8
	/// @par
	/// @c EVEX.LIG.66.0F3A.W0 67 /r ib
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFPCLASSSS_KR_K1_XMMM32_IMM8 = 3989,
	/// @brief @c VFPCLASSSD k2 {k1}, xmm2/m64, imm8
	/// @par
	/// @c EVEX.LIG.66.0F3A.W1 67 /r ib
	/// @par
	/// @c AVX512DQ
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFPCLASSSD_KR_K1_XMMM64_IMM8 = 3990,
	/// @brief @c VFMADDPS xmm1, xmm2, xmm3/m128, xmm4
	/// @par
	/// @c VEX.128.66.0F3A.W0 68 /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDPS_XMM_XMM_XMMM128_XMM = 3991,
	/// @brief @c VFMADDPS ymm1, ymm2, ymm3/m256, ymm4
	/// @par
	/// @c VEX.256.66.0F3A.W0 68 /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDPS_YMM_YMM_YMMM256_YMM = 3992,
	/// @brief @c VFMADDPS xmm1, xmm2, xmm3, xmm4/m128
	/// @par
	/// @c VEX.128.66.0F3A.W1 68 /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDPS_XMM_XMM_XMM_XMMM128 = 3993,
	/// @brief @c VFMADDPS ymm1, ymm2, ymm3, ymm4/m256
	/// @par
	/// @c VEX.256.66.0F3A.W1 68 /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDPS_YMM_YMM_YMM_YMMM256 = 3994,
	/// @brief @c VFMADDPD xmm1, xmm2, xmm3/m128, xmm4
	/// @par
	/// @c VEX.128.66.0F3A.W0 69 /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDPD_XMM_XMM_XMMM128_XMM = 3995,
	/// @brief @c VFMADDPD ymm1, ymm2, ymm3/m256, ymm4
	/// @par
	/// @c VEX.256.66.0F3A.W0 69 /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDPD_YMM_YMM_YMMM256_YMM = 3996,
	/// @brief @c VFMADDPD xmm1, xmm2, xmm3, xmm4/m128
	/// @par
	/// @c VEX.128.66.0F3A.W1 69 /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDPD_XMM_XMM_XMM_XMMM128 = 3997,
	/// @brief @c VFMADDPD ymm1, ymm2, ymm3, ymm4/m256
	/// @par
	/// @c VEX.256.66.0F3A.W1 69 /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDPD_YMM_YMM_YMM_YMMM256 = 3998,
	/// @brief @c VFMADDSS xmm1, xmm2, xmm3/m32, xmm4
	/// @par
	/// @c VEX.LIG.66.0F3A.W0 6A /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDSS_XMM_XMM_XMMM32_XMM = 3999,
	/// @brief @c VFMADDSS xmm1, xmm2, xmm3, xmm4/m32
	/// @par
	/// @c VEX.LIG.66.0F3A.W1 6A /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDSS_XMM_XMM_XMM_XMMM32 = 4000,
	/// @brief @c VFMADDSD xmm1, xmm2, xmm3/m64, xmm4
	/// @par
	/// @c VEX.LIG.66.0F3A.W0 6B /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDSD_XMM_XMM_XMMM64_XMM = 4001,
	/// @brief @c VFMADDSD xmm1, xmm2, xmm3, xmm4/m64
	/// @par
	/// @c VEX.LIG.66.0F3A.W1 6B /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMADDSD_XMM_XMM_XMM_XMMM64 = 4002,
	/// @brief @c VFMSUBPS xmm1, xmm2, xmm3/m128, xmm4
	/// @par
	/// @c VEX.128.66.0F3A.W0 6C /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBPS_XMM_XMM_XMMM128_XMM = 4003,
	/// @brief @c VFMSUBPS ymm1, ymm2, ymm3/m256, ymm4
	/// @par
	/// @c VEX.256.66.0F3A.W0 6C /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBPS_YMM_YMM_YMMM256_YMM = 4004,
	/// @brief @c VFMSUBPS xmm1, xmm2, xmm3, xmm4/m128
	/// @par
	/// @c VEX.128.66.0F3A.W1 6C /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBPS_XMM_XMM_XMM_XMMM128 = 4005,
	/// @brief @c VFMSUBPS ymm1, ymm2, ymm3, ymm4/m256
	/// @par
	/// @c VEX.256.66.0F3A.W1 6C /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBPS_YMM_YMM_YMM_YMMM256 = 4006,
	/// @brief @c VFMSUBPD xmm1, xmm2, xmm3/m128, xmm4
	/// @par
	/// @c VEX.128.66.0F3A.W0 6D /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBPD_XMM_XMM_XMMM128_XMM = 4007,
	/// @brief @c VFMSUBPD ymm1, ymm2, ymm3/m256, ymm4
	/// @par
	/// @c VEX.256.66.0F3A.W0 6D /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBPD_YMM_YMM_YMMM256_YMM = 4008,
	/// @brief @c VFMSUBPD xmm1, xmm2, xmm3, xmm4/m128
	/// @par
	/// @c VEX.128.66.0F3A.W1 6D /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBPD_XMM_XMM_XMM_XMMM128 = 4009,
	/// @brief @c VFMSUBPD ymm1, ymm2, ymm3, ymm4/m256
	/// @par
	/// @c VEX.256.66.0F3A.W1 6D /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBPD_YMM_YMM_YMM_YMMM256 = 4010,
	/// @brief @c VFMSUBSS xmm1, xmm2, xmm3/m32, xmm4
	/// @par
	/// @c VEX.LIG.66.0F3A.W0 6E /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBSS_XMM_XMM_XMMM32_XMM = 4011,
	/// @brief @c VFMSUBSS xmm1, xmm2, xmm3, xmm4/m32
	/// @par
	/// @c VEX.LIG.66.0F3A.W1 6E /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBSS_XMM_XMM_XMM_XMMM32 = 4012,
	/// @brief @c VFMSUBSD xmm1, xmm2, xmm3/m64, xmm4
	/// @par
	/// @c VEX.LIG.66.0F3A.W0 6F /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBSD_XMM_XMM_XMMM64_XMM = 4013,
	/// @brief @c VFMSUBSD xmm1, xmm2, xmm3, xmm4/m64
	/// @par
	/// @c VEX.LIG.66.0F3A.W1 6F /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFMSUBSD_XMM_XMM_XMM_XMMM64 = 4014,
	/// @brief @c VPSHLDW xmm1 {k1}{z}, xmm2, xmm3/m128, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W1 70 /r ib
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHLDW_XMM_K1Z_XMM_XMMM128_IMM8 = 4015,
	/// @brief @c VPSHLDW ymm1 {k1}{z}, ymm2, ymm3/m256, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W1 70 /r ib
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHLDW_YMM_K1Z_YMM_YMMM256_IMM8 = 4016,
	/// @brief @c VPSHLDW zmm1 {k1}{z}, zmm2, zmm3/m512, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 70 /r ib
	/// @par
	/// @c AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHLDW_ZMM_K1Z_ZMM_ZMMM512_IMM8 = 4017,
	/// @brief @c VPSHLDD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W0 71 /r ib
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHLDD_XMM_K1Z_XMM_XMMM128B32_IMM8 = 4018,
	/// @brief @c VPSHLDD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W0 71 /r ib
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHLDD_YMM_K1Z_YMM_YMMM256B32_IMM8 = 4019,
	/// @brief @c VPSHLDD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W0 71 /r ib
	/// @par
	/// @c AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHLDD_ZMM_K1Z_ZMM_ZMMM512B32_IMM8 = 4020,
	/// @brief @c VPSHLDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W1 71 /r ib
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHLDQ_XMM_K1Z_XMM_XMMM128B64_IMM8 = 4021,
	/// @brief @c VPSHLDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W1 71 /r ib
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHLDQ_YMM_K1Z_YMM_YMMM256B64_IMM8 = 4022,
	/// @brief @c VPSHLDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 71 /r ib
	/// @par
	/// @c AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHLDQ_ZMM_K1Z_ZMM_ZMMM512B64_IMM8 = 4023,
	/// @brief @c VPSHRDW xmm1 {k1}{z}, xmm2, xmm3/m128, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W1 72 /r ib
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHRDW_XMM_K1Z_XMM_XMMM128_IMM8 = 4024,
	/// @brief @c VPSHRDW ymm1 {k1}{z}, ymm2, ymm3/m256, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W1 72 /r ib
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHRDW_YMM_K1Z_YMM_YMMM256_IMM8 = 4025,
	/// @brief @c VPSHRDW zmm1 {k1}{z}, zmm2, zmm3/m512, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 72 /r ib
	/// @par
	/// @c AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHRDW_ZMM_K1Z_ZMM_ZMMM512_IMM8 = 4026,
	/// @brief @c VPSHRDD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W0 73 /r ib
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHRDD_XMM_K1Z_XMM_XMMM128B32_IMM8 = 4027,
	/// @brief @c VPSHRDD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W0 73 /r ib
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHRDD_YMM_K1Z_YMM_YMMM256B32_IMM8 = 4028,
	/// @brief @c VPSHRDD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W0 73 /r ib
	/// @par
	/// @c AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHRDD_ZMM_K1Z_ZMM_ZMMM512B32_IMM8 = 4029,
	/// @brief @c VPSHRDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W1 73 /r ib
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHRDQ_XMM_K1Z_XMM_XMMM128B64_IMM8 = 4030,
	/// @brief @c VPSHRDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W1 73 /r ib
	/// @par
	/// @c AVX512VL and AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHRDQ_YMM_K1Z_YMM_YMMM256B64_IMM8 = 4031,
	/// @brief @c VPSHRDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 73 /r ib
	/// @par
	/// @c AVX512_VBMI2
	/// @par
	/// @c 16/32/64-bit
	EVEX_VPSHRDQ_ZMM_K1Z_ZMM_ZMMM512B64_IMM8 = 4032,
	/// @brief @c VFNMADDPS xmm1, xmm2, xmm3/m128, xmm4
	/// @par
	/// @c VEX.128.66.0F3A.W0 78 /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMADDPS_XMM_XMM_XMMM128_XMM = 4033,
	/// @brief @c VFNMADDPS ymm1, ymm2, ymm3/m256, ymm4
	/// @par
	/// @c VEX.256.66.0F3A.W0 78 /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMADDPS_YMM_YMM_YMMM256_YMM = 4034,
	/// @brief @c VFNMADDPS xmm1, xmm2, xmm3, xmm4/m128
	/// @par
	/// @c VEX.128.66.0F3A.W1 78 /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMADDPS_XMM_XMM_XMM_XMMM128 = 4035,
	/// @brief @c VFNMADDPS ymm1, ymm2, ymm3, ymm4/m256
	/// @par
	/// @c VEX.256.66.0F3A.W1 78 /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMADDPS_YMM_YMM_YMM_YMMM256 = 4036,
	/// @brief @c VFNMADDPD xmm1, xmm2, xmm3/m128, xmm4
	/// @par
	/// @c VEX.128.66.0F3A.W0 79 /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMADDPD_XMM_XMM_XMMM128_XMM = 4037,
	/// @brief @c VFNMADDPD ymm1, ymm2, ymm3/m256, ymm4
	/// @par
	/// @c VEX.256.66.0F3A.W0 79 /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMADDPD_YMM_YMM_YMMM256_YMM = 4038,
	/// @brief @c VFNMADDPD xmm1, xmm2, xmm3, xmm4/m128
	/// @par
	/// @c VEX.128.66.0F3A.W1 79 /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMADDPD_XMM_XMM_XMM_XMMM128 = 4039,
	/// @brief @c VFNMADDPD ymm1, ymm2, ymm3, ymm4/m256
	/// @par
	/// @c VEX.256.66.0F3A.W1 79 /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMADDPD_YMM_YMM_YMM_YMMM256 = 4040,
	/// @brief @c VFNMADDSS xmm1, xmm2, xmm3/m32, xmm4
	/// @par
	/// @c VEX.LIG.66.0F3A.W0 7A /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMADDSS_XMM_XMM_XMMM32_XMM = 4041,
	/// @brief @c VFNMADDSS xmm1, xmm2, xmm3, xmm4/m32
	/// @par
	/// @c VEX.LIG.66.0F3A.W1 7A /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMADDSS_XMM_XMM_XMM_XMMM32 = 4042,
	/// @brief @c VFNMADDSD xmm1, xmm2, xmm3/m64, xmm4
	/// @par
	/// @c VEX.LIG.66.0F3A.W0 7B /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMADDSD_XMM_XMM_XMMM64_XMM = 4043,
	/// @brief @c VFNMADDSD xmm1, xmm2, xmm3, xmm4/m64
	/// @par
	/// @c VEX.LIG.66.0F3A.W1 7B /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMADDSD_XMM_XMM_XMM_XMMM64 = 4044,
	/// @brief @c VFNMSUBPS xmm1, xmm2, xmm3/m128, xmm4
	/// @par
	/// @c VEX.128.66.0F3A.W0 7C /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMSUBPS_XMM_XMM_XMMM128_XMM = 4045,
	/// @brief @c VFNMSUBPS ymm1, ymm2, ymm3/m256, ymm4
	/// @par
	/// @c VEX.256.66.0F3A.W0 7C /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMSUBPS_YMM_YMM_YMMM256_YMM = 4046,
	/// @brief @c VFNMSUBPS xmm1, xmm2, xmm3, xmm4/m128
	/// @par
	/// @c VEX.128.66.0F3A.W1 7C /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMSUBPS_XMM_XMM_XMM_XMMM128 = 4047,
	/// @brief @c VFNMSUBPS ymm1, ymm2, ymm3, ymm4/m256
	/// @par
	/// @c VEX.256.66.0F3A.W1 7C /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMSUBPS_YMM_YMM_YMM_YMMM256 = 4048,
	/// @brief @c VFNMSUBPD xmm1, xmm2, xmm3/m128, xmm4
	/// @par
	/// @c VEX.128.66.0F3A.W0 7D /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMSUBPD_XMM_XMM_XMMM128_XMM = 4049,
	/// @brief @c VFNMSUBPD ymm1, ymm2, ymm3/m256, ymm4
	/// @par
	/// @c VEX.256.66.0F3A.W0 7D /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMSUBPD_YMM_YMM_YMMM256_YMM = 4050,
	/// @brief @c VFNMSUBPD xmm1, xmm2, xmm3, xmm4/m128
	/// @par
	/// @c VEX.128.66.0F3A.W1 7D /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMSUBPD_XMM_XMM_XMM_XMMM128 = 4051,
	/// @brief @c VFNMSUBPD ymm1, ymm2, ymm3, ymm4/m256
	/// @par
	/// @c VEX.256.66.0F3A.W1 7D /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMSUBPD_YMM_YMM_YMM_YMMM256 = 4052,
	/// @brief @c VFNMSUBSS xmm1, xmm2, xmm3/m32, xmm4
	/// @par
	/// @c VEX.LIG.66.0F3A.W0 7E /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMSUBSS_XMM_XMM_XMMM32_XMM = 4053,
	/// @brief @c VFNMSUBSS xmm1, xmm2, xmm3, xmm4/m32
	/// @par
	/// @c VEX.LIG.66.0F3A.W1 7E /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMSUBSS_XMM_XMM_XMM_XMMM32 = 4054,
	/// @brief @c VFNMSUBSD xmm1, xmm2, xmm3/m64, xmm4
	/// @par
	/// @c VEX.LIG.66.0F3A.W0 7F /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMSUBSD_XMM_XMM_XMMM64_XMM = 4055,
	/// @brief @c VFNMSUBSD xmm1, xmm2, xmm3, xmm4/m64
	/// @par
	/// @c VEX.LIG.66.0F3A.W1 7F /r /is4
	/// @par
	/// @c FMA4
	/// @par
	/// @c 16/32/64-bit
	VEX_VFNMSUBSD_XMM_XMM_XMM_XMMM64 = 4056,
	/// @brief @c SHA1RNDS4 xmm1, xmm2/m128, imm8
	/// @par
	/// @c NP 0F 3A CC /r ib
	/// @par
	/// @c SHA
	/// @par
	/// @c 16/32/64-bit
	SHA1RNDS4_XMM_XMMM128_IMM8 = 4057,
	/// @brief @c GF2P8AFFINEQB xmm1, xmm2/m128, imm8
	/// @par
	/// @c 66 0F 3A CE /r ib
	/// @par
	/// @c GFNI
	/// @par
	/// @c 16/32/64-bit
	GF2P8AFFINEQB_XMM_XMMM128_IMM8 = 4058,
	/// @brief @c VGF2P8AFFINEQB xmm1, xmm2, xmm3/m128, imm8
	/// @par
	/// @c VEX.128.66.0F3A.W1 CE /r ib
	/// @par
	/// @c AVX and GFNI
	/// @par
	/// @c 16/32/64-bit
	VEX_VGF2P8AFFINEQB_XMM_XMM_XMMM128_IMM8 = 4059,
	/// @brief @c VGF2P8AFFINEQB ymm1, ymm2, ymm3/m256, imm8
	/// @par
	/// @c VEX.256.66.0F3A.W1 CE /r ib
	/// @par
	/// @c AVX and GFNI
	/// @par
	/// @c 16/32/64-bit
	VEX_VGF2P8AFFINEQB_YMM_YMM_YMMM256_IMM8 = 4060,
	/// @brief @c VGF2P8AFFINEQB xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W1 CE /r ib
	/// @par
	/// @c AVX512VL and GFNI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGF2P8AFFINEQB_XMM_K1Z_XMM_XMMM128B64_IMM8 = 4061,
	/// @brief @c VGF2P8AFFINEQB ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W1 CE /r ib
	/// @par
	/// @c AVX512VL and GFNI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGF2P8AFFINEQB_YMM_K1Z_YMM_YMMM256B64_IMM8 = 4062,
	/// @brief @c VGF2P8AFFINEQB zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 CE /r ib
	/// @par
	/// @c AVX512F and GFNI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGF2P8AFFINEQB_ZMM_K1Z_ZMM_ZMMM512B64_IMM8 = 4063,
	/// @brief @c GF2P8AFFINEINVQB xmm1, xmm2/m128, imm8
	/// @par
	/// @c 66 0F 3A CF /r ib
	/// @par
	/// @c GFNI
	/// @par
	/// @c 16/32/64-bit
	GF2P8AFFINEINVQB_XMM_XMMM128_IMM8 = 4064,
	/// @brief @c VGF2P8AFFINEINVQB xmm1, xmm2, xmm3/m128, imm8
	/// @par
	/// @c VEX.128.66.0F3A.W1 CF /r ib
	/// @par
	/// @c AVX and GFNI
	/// @par
	/// @c 16/32/64-bit
	VEX_VGF2P8AFFINEINVQB_XMM_XMM_XMMM128_IMM8 = 4065,
	/// @brief @c VGF2P8AFFINEINVQB ymm1, ymm2, ymm3/m256, imm8
	/// @par
	/// @c VEX.256.66.0F3A.W1 CF /r ib
	/// @par
	/// @c AVX and GFNI
	/// @par
	/// @c 16/32/64-bit
	VEX_VGF2P8AFFINEINVQB_YMM_YMM_YMMM256_IMM8 = 4066,
	/// @brief @c VGF2P8AFFINEINVQB xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst, imm8
	/// @par
	/// @c EVEX.128.66.0F3A.W1 CF /r ib
	/// @par
	/// @c AVX512VL and GFNI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGF2P8AFFINEINVQB_XMM_K1Z_XMM_XMMM128B64_IMM8 = 4067,
	/// @brief @c VGF2P8AFFINEINVQB ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst, imm8
	/// @par
	/// @c EVEX.256.66.0F3A.W1 CF /r ib
	/// @par
	/// @c AVX512VL and GFNI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGF2P8AFFINEINVQB_YMM_K1Z_YMM_YMMM256B64_IMM8 = 4068,
	/// @brief @c VGF2P8AFFINEINVQB zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst, imm8
	/// @par
	/// @c EVEX.512.66.0F3A.W1 CF /r ib
	/// @par
	/// @c AVX512F and GFNI
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGF2P8AFFINEINVQB_ZMM_K1Z_ZMM_ZMMM512B64_IMM8 = 4069,
	/// @brief @c AESKEYGENASSIST xmm1, xmm2/m128, imm8
	/// @par
	/// @c 66 0F 3A DF /r ib
	/// @par
	/// @c AES
	/// @par
	/// @c 16/32/64-bit
	AESKEYGENASSIST_XMM_XMMM128_IMM8 = 4070,
	/// @brief @c VAESKEYGENASSIST xmm1, xmm2/m128, imm8
	/// @par
	/// @c VEX.128.66.0F3A.WIG DF /r ib
	/// @par
	/// @c AES and AVX
	/// @par
	/// @c 16/32/64-bit
	VEX_VAESKEYGENASSIST_XMM_XMMM128_IMM8 = 4071,
	/// @brief @c RORX r32, r/m32, imm8
	/// @par
	/// @c VEX.LZ.F2.0F3A.W0 F0 /r ib
	/// @par
	/// @c BMI2
	/// @par
	/// @c 16/32/64-bit
	VEX_RORX_R32_RM32_IMM8 = 4072,
	/// @brief @c RORX r64, r/m64, imm8
	/// @par
	/// @c VEX.LZ.F2.0F3A.W1 F0 /r ib
	/// @par
	/// @c BMI2
	/// @par
	/// @c 64-bit
	VEX_RORX_R64_RM64_IMM8 = 4073,
	/// @brief @c VPMACSSWW xmm1, xmm2, xmm3/m128, xmm4
	/// @par
	/// @c XOP.128.X8.W0 85 /r /is4
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPMACSSWW_XMM_XMM_XMMM128_XMM = 4074,
	/// @brief @c VPMACSSWD xmm1, xmm2, xmm3/m128, xmm4
	/// @par
	/// @c XOP.128.X8.W0 86 /r /is4
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPMACSSWD_XMM_XMM_XMMM128_XMM = 4075,
	/// @brief @c VPMACSSDQL xmm1, xmm2, xmm3/m128, xmm4
	/// @par
	/// @c XOP.128.X8.W0 87 /r /is4
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPMACSSDQL_XMM_XMM_XMMM128_XMM = 4076,
	/// @brief @c VPMACSSDD xmm1, xmm2, xmm3/m128, xmm4
	/// @par
	/// @c XOP.128.X8.W0 8E /r /is4
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPMACSSDD_XMM_XMM_XMMM128_XMM = 4077,
	/// @brief @c VPMACSSDQH xmm1, xmm2, xmm3/m128, xmm4
	/// @par
	/// @c XOP.128.X8.W0 8F /r /is4
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPMACSSDQH_XMM_XMM_XMMM128_XMM = 4078,
	/// @brief @c VPMACSWW xmm1, xmm2, xmm3/m128, xmm4
	/// @par
	/// @c XOP.128.X8.W0 95 /r /is4
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPMACSWW_XMM_XMM_XMMM128_XMM = 4079,
	/// @brief @c VPMACSWD xmm1, xmm2, xmm3/m128, xmm4
	/// @par
	/// @c XOP.128.X8.W0 96 /r /is4
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPMACSWD_XMM_XMM_XMMM128_XMM = 4080,
	/// @brief @c VPMACSDQL xmm1, xmm2, xmm3/m128, xmm4
	/// @par
	/// @c XOP.128.X8.W0 97 /r /is4
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPMACSDQL_XMM_XMM_XMMM128_XMM = 4081,
	/// @brief @c VPMACSDD xmm1, xmm2, xmm3/m128, xmm4
	/// @par
	/// @c XOP.128.X8.W0 9E /r /is4
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPMACSDD_XMM_XMM_XMMM128_XMM = 4082,
	/// @brief @c VPMACSDQH xmm1, xmm2, xmm3/m128, xmm4
	/// @par
	/// @c XOP.128.X8.W0 9F /r /is4
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPMACSDQH_XMM_XMM_XMMM128_XMM = 4083,
	/// @brief @c VPCMOV xmm1, xmm2, xmm3/m128, xmm4
	/// @par
	/// @c XOP.128.X8.W0 A2 /r /is4
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPCMOV_XMM_XMM_XMMM128_XMM = 4084,
	/// @brief @c VPCMOV ymm1, ymm2, ymm3/m256, ymm4
	/// @par
	/// @c XOP.256.X8.W0 A2 /r /is4
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPCMOV_YMM_YMM_YMMM256_YMM = 4085,
	/// @brief @c VPCMOV xmm1, xmm2, xmm3, xmm4/m128
	/// @par
	/// @c XOP.128.X8.W1 A2 /r /is4
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPCMOV_XMM_XMM_XMM_XMMM128 = 4086,
	/// @brief @c VPCMOV ymm1, ymm2, ymm3, ymm4/m256
	/// @par
	/// @c XOP.256.X8.W1 A2 /r /is4
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPCMOV_YMM_YMM_YMM_YMMM256 = 4087,
	/// @brief @c VPPERM xmm1, xmm2, xmm3/m128, xmm4
	/// @par
	/// @c XOP.128.X8.W0 A3 /r /is4
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPPERM_XMM_XMM_XMMM128_XMM = 4088,
	/// @brief @c VPPERM xmm1, xmm2, xmm3, xmm4/m128
	/// @par
	/// @c XOP.128.X8.W1 A3 /r /is4
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPPERM_XMM_XMM_XMM_XMMM128 = 4089,
	/// @brief @c VPMADCSSWD xmm1, xmm2, xmm3/m128, xmm4
	/// @par
	/// @c XOP.128.X8.W0 A6 /r /is4
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPMADCSSWD_XMM_XMM_XMMM128_XMM = 4090,
	/// @brief @c VPMADCSWD xmm1, xmm2, xmm3/m128, xmm4
	/// @par
	/// @c XOP.128.X8.W0 B6 /r /is4
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPMADCSWD_XMM_XMM_XMMM128_XMM = 4091,
	/// @brief @c VPROTB xmm1, xmm2/m128, imm8
	/// @par
	/// @c XOP.128.X8.W0 C0 /r ib
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPROTB_XMM_XMMM128_IMM8 = 4092,
	/// @brief @c VPROTW xmm1, xmm2/m128, imm8
	/// @par
	/// @c XOP.128.X8.W0 C1 /r ib
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPROTW_XMM_XMMM128_IMM8 = 4093,
	/// @brief @c VPROTD xmm1, xmm2/m128, imm8
	/// @par
	/// @c XOP.128.X8.W0 C2 /r ib
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPROTD_XMM_XMMM128_IMM8 = 4094,
	/// @brief @c VPROTQ xmm1, xmm2/m128, imm8
	/// @par
	/// @c XOP.128.X8.W0 C3 /r ib
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPROTQ_XMM_XMMM128_IMM8 = 4095,
	/// @brief @c VPCOMB xmm1, xmm2, xmm3/m128, imm8
	/// @par
	/// @c XOP.128.X8.W0 CC /r ib
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPCOMB_XMM_XMM_XMMM128_IMM8 = 4096,
	/// @brief @c VPCOMW xmm1, xmm2, xmm3/m128, imm8
	/// @par
	/// @c XOP.128.X8.W0 CD /r ib
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPCOMW_XMM_XMM_XMMM128_IMM8 = 4097,
	/// @brief @c VPCOMD xmm1, xmm2, xmm3/m128, imm8
	/// @par
	/// @c XOP.128.X8.W0 CE /r ib
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPCOMD_XMM_XMM_XMMM128_IMM8 = 4098,
	/// @brief @c VPCOMQ xmm1, xmm2, xmm3/m128, imm8
	/// @par
	/// @c XOP.128.X8.W0 CF /r ib
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPCOMQ_XMM_XMM_XMMM128_IMM8 = 4099,
	/// @brief @c VPCOMUB xmm1, xmm2, xmm3/m128, imm8
	/// @par
	/// @c XOP.128.X8.W0 EC /r ib
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPCOMUB_XMM_XMM_XMMM128_IMM8 = 4100,
	/// @brief @c VPCOMUW xmm1, xmm2, xmm3/m128, imm8
	/// @par
	/// @c XOP.128.X8.W0 ED /r ib
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPCOMUW_XMM_XMM_XMMM128_IMM8 = 4101,
	/// @brief @c VPCOMUD xmm1, xmm2, xmm3/m128, imm8
	/// @par
	/// @c XOP.128.X8.W0 EE /r ib
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPCOMUD_XMM_XMM_XMMM128_IMM8 = 4102,
	/// @brief @c VPCOMUQ xmm1, xmm2, xmm3/m128, imm8
	/// @par
	/// @c XOP.128.X8.W0 EF /r ib
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPCOMUQ_XMM_XMM_XMMM128_IMM8 = 4103,
	/// @brief @c BLCFILL r32, r/m32
	/// @par
	/// @c XOP.L0.X9.W0 01 /1
	/// @par
	/// @c TBM
	/// @par
	/// @c 16/32/64-bit
	XOP_BLCFILL_R32_RM32 = 4104,
	/// @brief @c BLCFILL r64, r/m64
	/// @par
	/// @c XOP.L0.X9.W1 01 /1
	/// @par
	/// @c TBM
	/// @par
	/// @c 64-bit
	XOP_BLCFILL_R64_RM64 = 4105,
	/// @brief @c BLSFILL r32, r/m32
	/// @par
	/// @c XOP.L0.X9.W0 01 /2
	/// @par
	/// @c TBM
	/// @par
	/// @c 16/32/64-bit
	XOP_BLSFILL_R32_RM32 = 4106,
	/// @brief @c BLSFILL r64, r/m64
	/// @par
	/// @c XOP.L0.X9.W1 01 /2
	/// @par
	/// @c TBM
	/// @par
	/// @c 64-bit
	XOP_BLSFILL_R64_RM64 = 4107,
	/// @brief @c BLCS r32, r/m32
	/// @par
	/// @c XOP.L0.X9.W0 01 /3
	/// @par
	/// @c TBM
	/// @par
	/// @c 16/32/64-bit
	XOP_BLCS_R32_RM32 = 4108,
	/// @brief @c BLCS r64, r/m64
	/// @par
	/// @c XOP.L0.X9.W1 01 /3
	/// @par
	/// @c TBM
	/// @par
	/// @c 64-bit
	XOP_BLCS_R64_RM64 = 4109,
	/// @brief @c TZMSK r32, r/m32
	/// @par
	/// @c XOP.L0.X9.W0 01 /4
	/// @par
	/// @c TBM
	/// @par
	/// @c 16/32/64-bit
	XOP_TZMSK_R32_RM32 = 4110,
	/// @brief @c TZMSK r64, r/m64
	/// @par
	/// @c XOP.L0.X9.W1 01 /4
	/// @par
	/// @c TBM
	/// @par
	/// @c 64-bit
	XOP_TZMSK_R64_RM64 = 4111,
	/// @brief @c BLCIC r32, r/m32
	/// @par
	/// @c XOP.L0.X9.W0 01 /5
	/// @par
	/// @c TBM
	/// @par
	/// @c 16/32/64-bit
	XOP_BLCIC_R32_RM32 = 4112,
	/// @brief @c BLCIC r64, r/m64
	/// @par
	/// @c XOP.L0.X9.W1 01 /5
	/// @par
	/// @c TBM
	/// @par
	/// @c 64-bit
	XOP_BLCIC_R64_RM64 = 4113,
	/// @brief @c BLSIC r32, r/m32
	/// @par
	/// @c XOP.L0.X9.W0 01 /6
	/// @par
	/// @c TBM
	/// @par
	/// @c 16/32/64-bit
	XOP_BLSIC_R32_RM32 = 4114,
	/// @brief @c BLSIC r64, r/m64
	/// @par
	/// @c XOP.L0.X9.W1 01 /6
	/// @par
	/// @c TBM
	/// @par
	/// @c 64-bit
	XOP_BLSIC_R64_RM64 = 4115,
	/// @brief @c T1MSKC r32, r/m32
	/// @par
	/// @c XOP.L0.X9.W0 01 /7
	/// @par
	/// @c TBM
	/// @par
	/// @c 16/32/64-bit
	XOP_T1MSKC_R32_RM32 = 4116,
	/// @brief @c T1MSKC r64, r/m64
	/// @par
	/// @c XOP.L0.X9.W1 01 /7
	/// @par
	/// @c TBM
	/// @par
	/// @c 64-bit
	XOP_T1MSKC_R64_RM64 = 4117,
	/// @brief @c BLCMSK r32, r/m32
	/// @par
	/// @c XOP.L0.X9.W0 02 /1
	/// @par
	/// @c TBM
	/// @par
	/// @c 16/32/64-bit
	XOP_BLCMSK_R32_RM32 = 4118,
	/// @brief @c BLCMSK r64, r/m64
	/// @par
	/// @c XOP.L0.X9.W1 02 /1
	/// @par
	/// @c TBM
	/// @par
	/// @c 64-bit
	XOP_BLCMSK_R64_RM64 = 4119,
	/// @brief @c BLCI r32, r/m32
	/// @par
	/// @c XOP.L0.X9.W0 02 /6
	/// @par
	/// @c TBM
	/// @par
	/// @c 16/32/64-bit
	XOP_BLCI_R32_RM32 = 4120,
	/// @brief @c BLCI r64, r/m64
	/// @par
	/// @c XOP.L0.X9.W1 02 /6
	/// @par
	/// @c TBM
	/// @par
	/// @c 64-bit
	XOP_BLCI_R64_RM64 = 4121,
	/// @brief @c LLWPCB r32
	/// @par
	/// @c XOP.L0.X9.W0 12 /0
	/// @par
	/// @c LWP
	/// @par
	/// @c 16/32/64-bit
	XOP_LLWPCB_R32 = 4122,
	/// @brief @c LLWPCB r64
	/// @par
	/// @c XOP.L0.X9.W1 12 /0
	/// @par
	/// @c LWP
	/// @par
	/// @c 64-bit
	XOP_LLWPCB_R64 = 4123,
	/// @brief @c SLWPCB r32
	/// @par
	/// @c XOP.L0.X9.W0 12 /1
	/// @par
	/// @c LWP
	/// @par
	/// @c 16/32/64-bit
	XOP_SLWPCB_R32 = 4124,
	/// @brief @c SLWPCB r64
	/// @par
	/// @c XOP.L0.X9.W1 12 /1
	/// @par
	/// @c LWP
	/// @par
	/// @c 64-bit
	XOP_SLWPCB_R64 = 4125,
	/// @brief @c VFRCZPS xmm1, xmm2/m128
	/// @par
	/// @c XOP.128.X9.W0 80 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VFRCZPS_XMM_XMMM128 = 4126,
	/// @brief @c VFRCZPS ymm1, ymm2/m256
	/// @par
	/// @c XOP.256.X9.W0 80 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VFRCZPS_YMM_YMMM256 = 4127,
	/// @brief @c VFRCZPD xmm1, xmm2/m128
	/// @par
	/// @c XOP.128.X9.W0 81 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VFRCZPD_XMM_XMMM128 = 4128,
	/// @brief @c VFRCZPD ymm1, ymm2/m256
	/// @par
	/// @c XOP.256.X9.W0 81 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VFRCZPD_YMM_YMMM256 = 4129,
	/// @brief @c VFRCZSS xmm1, xmm2/m32
	/// @par
	/// @c XOP.128.X9.W0 82 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VFRCZSS_XMM_XMMM32 = 4130,
	/// @brief @c VFRCZSD xmm1, xmm2/m64
	/// @par
	/// @c XOP.128.X9.W0 83 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VFRCZSD_XMM_XMMM64 = 4131,
	/// @brief @c VPROTB xmm1, xmm2/m128, xmm3
	/// @par
	/// @c XOP.128.X9.W0 90 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPROTB_XMM_XMMM128_XMM = 4132,
	/// @brief @c VPROTB xmm1, xmm2, xmm3/m128
	/// @par
	/// @c XOP.128.X9.W1 90 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPROTB_XMM_XMM_XMMM128 = 4133,
	/// @brief @c VPROTW xmm1, xmm2/m128, xmm3
	/// @par
	/// @c XOP.128.X9.W0 91 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPROTW_XMM_XMMM128_XMM = 4134,
	/// @brief @c VPROTW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c XOP.128.X9.W1 91 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPROTW_XMM_XMM_XMMM128 = 4135,
	/// @brief @c VPROTD xmm1, xmm2/m128, xmm3
	/// @par
	/// @c XOP.128.X9.W0 92 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPROTD_XMM_XMMM128_XMM = 4136,
	/// @brief @c VPROTD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c XOP.128.X9.W1 92 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPROTD_XMM_XMM_XMMM128 = 4137,
	/// @brief @c VPROTQ xmm1, xmm2/m128, xmm3
	/// @par
	/// @c XOP.128.X9.W0 93 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPROTQ_XMM_XMMM128_XMM = 4138,
	/// @brief @c VPROTQ xmm1, xmm2, xmm3/m128
	/// @par
	/// @c XOP.128.X9.W1 93 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPROTQ_XMM_XMM_XMMM128 = 4139,
	/// @brief @c VPSHLB xmm1, xmm2/m128, xmm3
	/// @par
	/// @c XOP.128.X9.W0 94 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPSHLB_XMM_XMMM128_XMM = 4140,
	/// @brief @c VPSHLB xmm1, xmm2, xmm3/m128
	/// @par
	/// @c XOP.128.X9.W1 94 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPSHLB_XMM_XMM_XMMM128 = 4141,
	/// @brief @c VPSHLW xmm1, xmm2/m128, xmm3
	/// @par
	/// @c XOP.128.X9.W0 95 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPSHLW_XMM_XMMM128_XMM = 4142,
	/// @brief @c VPSHLW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c XOP.128.X9.W1 95 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPSHLW_XMM_XMM_XMMM128 = 4143,
	/// @brief @c VPSHLD xmm1, xmm2/m128, xmm3
	/// @par
	/// @c XOP.128.X9.W0 96 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPSHLD_XMM_XMMM128_XMM = 4144,
	/// @brief @c VPSHLD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c XOP.128.X9.W1 96 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPSHLD_XMM_XMM_XMMM128 = 4145,
	/// @brief @c VPSHLQ xmm1, xmm2/m128, xmm3
	/// @par
	/// @c XOP.128.X9.W0 97 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPSHLQ_XMM_XMMM128_XMM = 4146,
	/// @brief @c VPSHLQ xmm1, xmm2, xmm3/m128
	/// @par
	/// @c XOP.128.X9.W1 97 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPSHLQ_XMM_XMM_XMMM128 = 4147,
	/// @brief @c VPSHAB xmm1, xmm2/m128, xmm3
	/// @par
	/// @c XOP.128.X9.W0 98 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPSHAB_XMM_XMMM128_XMM = 4148,
	/// @brief @c VPSHAB xmm1, xmm2, xmm3/m128
	/// @par
	/// @c XOP.128.X9.W1 98 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPSHAB_XMM_XMM_XMMM128 = 4149,
	/// @brief @c VPSHAW xmm1, xmm2/m128, xmm3
	/// @par
	/// @c XOP.128.X9.W0 99 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPSHAW_XMM_XMMM128_XMM = 4150,
	/// @brief @c VPSHAW xmm1, xmm2, xmm3/m128
	/// @par
	/// @c XOP.128.X9.W1 99 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPSHAW_XMM_XMM_XMMM128 = 4151,
	/// @brief @c VPSHAD xmm1, xmm2/m128, xmm3
	/// @par
	/// @c XOP.128.X9.W0 9A /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPSHAD_XMM_XMMM128_XMM = 4152,
	/// @brief @c VPSHAD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c XOP.128.X9.W1 9A /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPSHAD_XMM_XMM_XMMM128 = 4153,
	/// @brief @c VPSHAQ xmm1, xmm2/m128, xmm3
	/// @par
	/// @c XOP.128.X9.W0 9B /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPSHAQ_XMM_XMMM128_XMM = 4154,
	/// @brief @c VPSHAQ xmm1, xmm2, xmm3/m128
	/// @par
	/// @c XOP.128.X9.W1 9B /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPSHAQ_XMM_XMM_XMMM128 = 4155,
	/// @brief @c VPHADDBW xmm1, xmm2/m128
	/// @par
	/// @c XOP.128.X9.W0 C1 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPHADDBW_XMM_XMMM128 = 4156,
	/// @brief @c VPHADDBD xmm1, xmm2/m128
	/// @par
	/// @c XOP.128.X9.W0 C2 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPHADDBD_XMM_XMMM128 = 4157,
	/// @brief @c VPHADDBQ xmm1, xmm2/m128
	/// @par
	/// @c XOP.128.X9.W0 C3 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPHADDBQ_XMM_XMMM128 = 4158,
	/// @brief @c VPHADDWD xmm1, xmm2/m128
	/// @par
	/// @c XOP.128.X9.W0 C6 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPHADDWD_XMM_XMMM128 = 4159,
	/// @brief @c VPHADDWQ xmm1, xmm2/m128
	/// @par
	/// @c XOP.128.X9.W0 C7 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPHADDWQ_XMM_XMMM128 = 4160,
	/// @brief @c VPHADDDQ xmm1, xmm2/m128
	/// @par
	/// @c XOP.128.X9.W0 CB /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPHADDDQ_XMM_XMMM128 = 4161,
	/// @brief @c VPHADDUBW xmm1, xmm2/m128
	/// @par
	/// @c XOP.128.X9.W0 D1 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPHADDUBW_XMM_XMMM128 = 4162,
	/// @brief @c VPHADDUBD xmm1, xmm2/m128
	/// @par
	/// @c XOP.128.X9.W0 D2 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPHADDUBD_XMM_XMMM128 = 4163,
	/// @brief @c VPHADDUBQ xmm1, xmm2/m128
	/// @par
	/// @c XOP.128.X9.W0 D3 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPHADDUBQ_XMM_XMMM128 = 4164,
	/// @brief @c VPHADDUWD xmm1, xmm2/m128
	/// @par
	/// @c XOP.128.X9.W0 D6 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPHADDUWD_XMM_XMMM128 = 4165,
	/// @brief @c VPHADDUWQ xmm1, xmm2/m128
	/// @par
	/// @c XOP.128.X9.W0 D7 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPHADDUWQ_XMM_XMMM128 = 4166,
	/// @brief @c VPHADDUDQ xmm1, xmm2/m128
	/// @par
	/// @c XOP.128.X9.W0 DB /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPHADDUDQ_XMM_XMMM128 = 4167,
	/// @brief @c VPHSUBBW xmm1, xmm2/m128
	/// @par
	/// @c XOP.128.X9.W0 E1 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPHSUBBW_XMM_XMMM128 = 4168,
	/// @brief @c VPHSUBWD xmm1, xmm2/m128
	/// @par
	/// @c XOP.128.X9.W0 E2 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPHSUBWD_XMM_XMMM128 = 4169,
	/// @brief @c VPHSUBDQ xmm1, xmm2/m128
	/// @par
	/// @c XOP.128.X9.W0 E3 /r
	/// @par
	/// @c XOP
	/// @par
	/// @c 16/32/64-bit
	XOP_VPHSUBDQ_XMM_XMMM128 = 4170,
	/// @brief @c BEXTR r32, r/m32, imm32
	/// @par
	/// @c XOP.L0.XA.W0 10 /r id
	/// @par
	/// @c TBM
	/// @par
	/// @c 16/32/64-bit
	XOP_BEXTR_R32_RM32_IMM32 = 4171,
	/// @brief @c BEXTR r64, r/m64, imm32
	/// @par
	/// @c XOP.L0.XA.W1 10 /r id
	/// @par
	/// @c TBM
	/// @par
	/// @c 64-bit
	XOP_BEXTR_R64_RM64_IMM32 = 4172,
	/// @brief @c LWPINS r32, r/m32, imm32
	/// @par
	/// @c XOP.L0.XA.W0 12 /0 id
	/// @par
	/// @c LWP
	/// @par
	/// @c 16/32/64-bit
	XOP_LWPINS_R32_RM32_IMM32 = 4173,
	/// @brief @c LWPINS r64, r/m32, imm32
	/// @par
	/// @c XOP.L0.XA.W1 12 /0 id
	/// @par
	/// @c LWP
	/// @par
	/// @c 64-bit
	XOP_LWPINS_R64_RM32_IMM32 = 4174,
	/// @brief @c LWPVAL r32, r/m32, imm32
	/// @par
	/// @c XOP.L0.XA.W0 12 /1 id
	/// @par
	/// @c LWP
	/// @par
	/// @c 16/32/64-bit
	XOP_LWPVAL_R32_RM32_IMM32 = 4175,
	/// @brief @c LWPVAL r64, r/m32, imm32
	/// @par
	/// @c XOP.L0.XA.W1 12 /1 id
	/// @par
	/// @c LWP
	/// @par
	/// @c 64-bit
	XOP_LWPVAL_R64_RM32_IMM32 = 4176,
	/// @brief @c PI2FW mm, mm/m64
	/// @par
	/// @c 0F 0F /r 0C
	/// @par
	/// @c 3DNOWEXT
	/// @par
	/// @c 16/32/64-bit
	D3_NOW_PI2FW_MM_MMM64 = 4177,
	/// @brief @c PI2FD mm, mm/m64
	/// @par
	/// @c 0F 0F /r 0D
	/// @par
	/// @c 3DNOW
	/// @par
	/// @c 16/32/64-bit
	D3_NOW_PI2FD_MM_MMM64 = 4178,
	/// @brief @c PF2IW mm, mm/m64
	/// @par
	/// @c 0F 0F /r 1C
	/// @par
	/// @c 3DNOWEXT
	/// @par
	/// @c 16/32/64-bit
	D3_NOW_PF2IW_MM_MMM64 = 4179,
	/// @brief @c PF2ID mm, mm/m64
	/// @par
	/// @c 0F 0F /r 1D
	/// @par
	/// @c 3DNOW
	/// @par
	/// @c 16/32/64-bit
	D3_NOW_PF2ID_MM_MMM64 = 4180,
	/// @brief @c PFRCPV mm, mm/m64
	/// @par
	/// @c 0F 0F /r 86
	/// @par
	/// @c AMD Geode GX/LX
	/// @par
	/// @c 16/32-bit
	D3_NOW_PFRCPV_MM_MMM64 = 4181,
	/// @brief @c PFRSQRTV mm, mm/m64
	/// @par
	/// @c 0F 0F /r 87
	/// @par
	/// @c AMD Geode GX/LX
	/// @par
	/// @c 16/32-bit
	D3_NOW_PFRSQRTV_MM_MMM64 = 4182,
	/// @brief @c PFNACC mm, mm/m64
	/// @par
	/// @c 0F 0F /r 8A
	/// @par
	/// @c 3DNOWEXT
	/// @par
	/// @c 16/32/64-bit
	D3_NOW_PFNACC_MM_MMM64 = 4183,
	/// @brief @c PFPNACC mm, mm/m64
	/// @par
	/// @c 0F 0F /r 8E
	/// @par
	/// @c 3DNOWEXT
	/// @par
	/// @c 16/32/64-bit
	D3_NOW_PFPNACC_MM_MMM64 = 4184,
	/// @brief @c PFCMPGE mm, mm/m64
	/// @par
	/// @c 0F 0F /r 90
	/// @par
	/// @c 3DNOW
	/// @par
	/// @c 16/32/64-bit
	D3_NOW_PFCMPGE_MM_MMM64 = 4185,
	/// @brief @c PFMIN mm, mm/m64
	/// @par
	/// @c 0F 0F /r 94
	/// @par
	/// @c 3DNOW
	/// @par
	/// @c 16/32/64-bit
	D3_NOW_PFMIN_MM_MMM64 = 4186,
	/// @brief @c PFRCP mm, mm/m64
	/// @par
	/// @c 0F 0F /r 96
	/// @par
	/// @c 3DNOW
	/// @par
	/// @c 16/32/64-bit
	D3_NOW_PFRCP_MM_MMM64 = 4187,
	/// @brief @c PFRSQRT mm, mm/m64
	/// @par
	/// @c 0F 0F /r 97
	/// @par
	/// @c 3DNOW
	/// @par
	/// @c 16/32/64-bit
	D3_NOW_PFRSQRT_MM_MMM64 = 4188,
	/// @brief @c PFSUB mm, mm/m64
	/// @par
	/// @c 0F 0F /r 9A
	/// @par
	/// @c 3DNOW
	/// @par
	/// @c 16/32/64-bit
	D3_NOW_PFSUB_MM_MMM64 = 4189,
	/// @brief @c PFADD mm, mm/m64
	/// @par
	/// @c 0F 0F /r 9E
	/// @par
	/// @c 3DNOW
	/// @par
	/// @c 16/32/64-bit
	D3_NOW_PFADD_MM_MMM64 = 4190,
	/// @brief @c PFCMPGT mm, mm/m64
	/// @par
	/// @c 0F 0F /r A0
	/// @par
	/// @c 3DNOW
	/// @par
	/// @c 16/32/64-bit
	D3_NOW_PFCMPGT_MM_MMM64 = 4191,
	/// @brief @c PFMAX mm, mm/m64
	/// @par
	/// @c 0F 0F /r A4
	/// @par
	/// @c 3DNOW
	/// @par
	/// @c 16/32/64-bit
	D3_NOW_PFMAX_MM_MMM64 = 4192,
	/// @brief @c PFRCPIT1 mm, mm/m64
	/// @par
	/// @c 0F 0F /r A6
	/// @par
	/// @c 3DNOW
	/// @par
	/// @c 16/32/64-bit
	D3_NOW_PFRCPIT1_MM_MMM64 = 4193,
	/// @brief @c PFRSQIT1 mm, mm/m64
	/// @par
	/// @c 0F 0F /r A7
	/// @par
	/// @c 3DNOW
	/// @par
	/// @c 16/32/64-bit
	D3_NOW_PFRSQIT1_MM_MMM64 = 4194,
	/// @brief @c PFSUBR mm, mm/m64
	/// @par
	/// @c 0F 0F /r AA
	/// @par
	/// @c 3DNOW
	/// @par
	/// @c 16/32/64-bit
	D3_NOW_PFSUBR_MM_MMM64 = 4195,
	/// @brief @c PFACC mm, mm/m64
	/// @par
	/// @c 0F 0F /r AE
	/// @par
	/// @c 3DNOW
	/// @par
	/// @c 16/32/64-bit
	D3_NOW_PFACC_MM_MMM64 = 4196,
	/// @brief @c PFCMPEQ mm, mm/m64
	/// @par
	/// @c 0F 0F /r B0
	/// @par
	/// @c 3DNOW
	/// @par
	/// @c 16/32/64-bit
	D3_NOW_PFCMPEQ_MM_MMM64 = 4197,
	/// @brief @c PFMUL mm, mm/m64
	/// @par
	/// @c 0F 0F /r B4
	/// @par
	/// @c 3DNOW
	/// @par
	/// @c 16/32/64-bit
	D3_NOW_PFMUL_MM_MMM64 = 4198,
	/// @brief @c PFRCPIT2 mm, mm/m64
	/// @par
	/// @c 0F 0F /r B6
	/// @par
	/// @c 3DNOW
	/// @par
	/// @c 16/32/64-bit
	D3_NOW_PFRCPIT2_MM_MMM64 = 4199,
	/// @brief @c PMULHRW mm, mm/m64
	/// @par
	/// @c 0F 0F /r B7
	/// @par
	/// @c 3DNOW
	/// @par
	/// @c 16/32/64-bit
	D3_NOW_PMULHRW_MM_MMM64 = 4200,
	/// @brief @c PSWAPD mm, mm/m64
	/// @par
	/// @c 0F 0F /r BB
	/// @par
	/// @c 3DNOWEXT
	/// @par
	/// @c 16/32/64-bit
	D3_NOW_PSWAPD_MM_MMM64 = 4201,
	/// @brief @c PAVGUSB mm, mm/m64
	/// @par
	/// @c 0F 0F /r BF
	/// @par
	/// @c 3DNOW
	/// @par
	/// @c 16/32/64-bit
	D3_NOW_PAVGUSB_MM_MMM64 = 4202,
	/// @brief @c RMPADJUST
	/// @par
	/// @c F3 0F 01 FE
	/// @par
	/// @c SEV-SNP
	/// @par
	/// @c 64-bit
	RMPADJUST = 4203,
	/// @brief @c RMPUPDATE
	/// @par
	/// @c F2 0F 01 FE
	/// @par
	/// @c SEV-SNP
	/// @par
	/// @c 64-bit
	RMPUPDATE = 4204,
	/// @brief @c PSMASH
	/// @par
	/// @c F3 0F 01 FF
	/// @par
	/// @c SEV-SNP
	/// @par
	/// @c 64-bit
	PSMASH = 4205,
	/// @brief @c PVALIDATE
	/// @par
	/// @c a16 F2 0F 01 FF
	/// @par
	/// @c SEV-SNP
	/// @par
	/// @c 16/32-bit
	PVALIDATEW = 4206,
	/// @brief @c PVALIDATE
	/// @par
	/// @c a32 F2 0F 01 FF
	/// @par
	/// @c SEV-SNP
	/// @par
	/// @c 16/32/64-bit
	PVALIDATED = 4207,
	/// @brief @c PVALIDATE
	/// @par
	/// @c a64 F2 0F 01 FF
	/// @par
	/// @c SEV-SNP
	/// @par
	/// @c 64-bit
	PVALIDATEQ = 4208,
	/// @brief @c SERIALIZE
	/// @par
	/// @c NP 0F 01 E8
	/// @par
	/// @c SERIALIZE
	/// @par
	/// @c 16/32/64-bit
	SERIALIZE = 4209,
	/// @brief @c XSUSLDTRK
	/// @par
	/// @c F2 0F 01 E8
	/// @par
	/// @c TSXLDTRK
	/// @par
	/// @c 16/32/64-bit
	XSUSLDTRK = 4210,
	/// @brief @c XRESLDTRK
	/// @par
	/// @c F2 0F 01 E9
	/// @par
	/// @c TSXLDTRK
	/// @par
	/// @c 16/32/64-bit
	XRESLDTRK = 4211,
	/// @brief @c INVLPGB
	/// @par
	/// @c a16 NP 0F 01 FE
	/// @par
	/// @c INVLPGB
	/// @par
	/// @c 16/32-bit
	INVLPGBW = 4212,
	/// @brief @c INVLPGB
	/// @par
	/// @c a32 NP 0F 01 FE
	/// @par
	/// @c INVLPGB
	/// @par
	/// @c 16/32/64-bit
	INVLPGBD = 4213,
	/// @brief @c INVLPGB
	/// @par
	/// @c a64 NP 0F 01 FE
	/// @par
	/// @c INVLPGB
	/// @par
	/// @c 64-bit
	INVLPGBQ = 4214,
	/// @brief @c TLBSYNC
	/// @par
	/// @c NP 0F 01 FF
	/// @par
	/// @c INVLPGB
	/// @par
	/// @c 16/32/64-bit
	TLBSYNC = 4215,
	/// @brief @c PREFETCHW m8
	/// @par
	/// @c 0F 0D /3
	/// @par
	/// @c PREFETCHW
	/// @par
	/// @c 16/32/64-bit
	PREFETCHRESERVED3_M8 = 4216,
	/// @brief @c PREFETCH m8
	/// @par
	/// @c 0F 0D /4
	/// @par
	/// @c PREFETCHW
	/// @par
	/// @c 16/32/64-bit
	PREFETCHRESERVED4_M8 = 4217,
	/// @brief @c PREFETCH m8
	/// @par
	/// @c 0F 0D /5
	/// @par
	/// @c PREFETCHW
	/// @par
	/// @c 16/32/64-bit
	PREFETCHRESERVED5_M8 = 4218,
	/// @brief @c PREFETCH m8
	/// @par
	/// @c 0F 0D /6
	/// @par
	/// @c PREFETCHW
	/// @par
	/// @c 16/32/64-bit
	PREFETCHRESERVED6_M8 = 4219,
	/// @brief @c PREFETCH m8
	/// @par
	/// @c 0F 0D /7
	/// @par
	/// @c PREFETCHW
	/// @par
	/// @c 16/32/64-bit
	PREFETCHRESERVED7_M8 = 4220,
	/// @brief @c UD0
	/// @par
	/// @c 0F FF
	/// @par
	/// @c 286+
	/// @par
	/// @c 16/32/64-bit
	UD0 = 4221,
	/// @brief @c VMGEXIT
	/// @par
	/// @c F3 0F 01 D9
	/// @par
	/// @c SEV-ES
	/// @par
	/// @c 16/32/64-bit
	VMGEXIT = 4222,
	/// @brief @c GETSECQ
	/// @par
	/// @c NP o64 0F 37
	/// @par
	/// @c SMX
	/// @par
	/// @c 64-bit
	GETSECQ = 4223,
	/// @brief @c LDTILECFG m512
	/// @par
	/// @c VEX.128.0F38.W0 49 !(11):000:bbb
	/// @par
	/// @c AMX-TILE
	/// @par
	/// @c 64-bit
	VEX_LDTILECFG_M512 = 4224,
	/// @brief @c TILERELEASE
	/// @par
	/// @c VEX.128.0F38.W0 49 C0
	/// @par
	/// @c AMX-TILE
	/// @par
	/// @c 64-bit
	VEX_TILERELEASE = 4225,
	/// @brief @c STTILECFG m512
	/// @par
	/// @c VEX.128.66.0F38.W0 49 !(11):000:bbb
	/// @par
	/// @c AMX-TILE
	/// @par
	/// @c 64-bit
	VEX_STTILECFG_M512 = 4226,
	/// @brief @c TILEZERO tmm1
	/// @par
	/// @c VEX.128.F2.0F38.W0 49 11:rrr:000
	/// @par
	/// @c AMX-TILE
	/// @par
	/// @c 64-bit
	VEX_TILEZERO_TMM = 4227,
	/// @brief @c TILELOADDT1 tmm1, sibmem
	/// @par
	/// @c VEX.128.66.0F38.W0 4B !(11):rrr:100
	/// @par
	/// @c AMX-TILE
	/// @par
	/// @c 64-bit
	VEX_TILELOADDT1_TMM_SIBMEM = 4228,
	/// @brief @c TILESTORED sibmem, tmm1
	/// @par
	/// @c VEX.128.F3.0F38.W0 4B !(11):rrr:100
	/// @par
	/// @c AMX-TILE
	/// @par
	/// @c 64-bit
	VEX_TILESTORED_SIBMEM_TMM = 4229,
	/// @brief @c TILELOADD tmm1, sibmem
	/// @par
	/// @c VEX.128.F2.0F38.W0 4B !(11):rrr:100
	/// @par
	/// @c AMX-TILE
	/// @par
	/// @c 64-bit
	VEX_TILELOADD_TMM_SIBMEM = 4230,
	/// @brief @c TDPBF16PS tmm1, tmm2, tmm3
	/// @par
	/// @c VEX.128.F3.0F38.W0 5C 11:rrr:bbb
	/// @par
	/// @c AMX-BF16
	/// @par
	/// @c 64-bit
	VEX_TDPBF16PS_TMM_TMM_TMM = 4231,
	/// @brief @c TDPBUUD tmm1, tmm2, tmm3
	/// @par
	/// @c VEX.128.0F38.W0 5E 11:rrr:bbb
	/// @par
	/// @c AMX-INT8
	/// @par
	/// @c 64-bit
	VEX_TDPBUUD_TMM_TMM_TMM = 4232,
	/// @brief @c TDPBUSD tmm1, tmm2, tmm3
	/// @par
	/// @c VEX.128.66.0F38.W0 5E 11:rrr:bbb
	/// @par
	/// @c AMX-INT8
	/// @par
	/// @c 64-bit
	VEX_TDPBUSD_TMM_TMM_TMM = 4233,
	/// @brief @c TDPBSUD tmm1, tmm2, tmm3
	/// @par
	/// @c VEX.128.F3.0F38.W0 5E 11:rrr:bbb
	/// @par
	/// @c AMX-INT8
	/// @par
	/// @c 64-bit
	VEX_TDPBSUD_TMM_TMM_TMM = 4234,
	/// @brief @c TDPBSSD tmm1, tmm2, tmm3
	/// @par
	/// @c VEX.128.F2.0F38.W0 5E 11:rrr:bbb
	/// @par
	/// @c AMX-INT8
	/// @par
	/// @c 64-bit
	VEX_TDPBSSD_TMM_TMM_TMM = 4235,
	/// @brief @c FNSTDW AX
	/// @par
	/// @c DF E1
	/// @par
	/// @c 387 SL
	/// @par
	/// @c 16/32-bit
	FNSTDW_AX = 4236,
	/// @brief @c FNSTSG AX
	/// @par
	/// @c DF E2
	/// @par
	/// @c 387 SL
	/// @par
	/// @c 16/32-bit
	FNSTSG_AX = 4237,
	/// @brief @c RDSHR r/m32
	/// @par
	/// @c 0F 36 /0
	/// @par
	/// @c Cyrix 6x86MX, M II, III
	/// @par
	/// @c 16/32-bit
	RDSHR_RM32 = 4238,
	/// @brief @c WRSHR r/m32
	/// @par
	/// @c 0F 37 /0
	/// @par
	/// @c Cyrix 6x86MX, M II, III
	/// @par
	/// @c 16/32-bit
	WRSHR_RM32 = 4239,
	/// @brief @c SMINT
	/// @par
	/// @c 0F 38
	/// @par
	/// @c Cyrix 6x86MX+, AMD Geode GX/LX
	/// @par
	/// @c 16/32-bit
	SMINT = 4240,
	/// @brief @c DMINT
	/// @par
	/// @c 0F 39
	/// @par
	/// @c AMD Geode GX/LX
	/// @par
	/// @c 16/32-bit
	DMINT = 4241,
	/// @brief @c RDM
	/// @par
	/// @c 0F 3A
	/// @par
	/// @c AMD Geode GX/LX
	/// @par
	/// @c 16/32-bit
	RDM = 4242,
	/// @brief @c SVDC m80, Sreg
	/// @par
	/// @c 0F 78 /r
	/// @par
	/// @c Cyrix, AMD Geode GX/LX
	/// @par
	/// @c 16/32-bit
	SVDC_M80_SREG = 4243,
	/// @brief @c RSDC Sreg, m80
	/// @par
	/// @c 0F 79 /r
	/// @par
	/// @c Cyrix, AMD Geode GX/LX
	/// @par
	/// @c 16/32-bit
	RSDC_SREG_M80 = 4244,
	/// @brief @c SVLDT m80
	/// @par
	/// @c 0F 7A /0
	/// @par
	/// @c Cyrix, AMD Geode GX/LX
	/// @par
	/// @c 16/32-bit
	SVLDT_M80 = 4245,
	/// @brief @c RSLDT m80
	/// @par
	/// @c 0F 7B /0
	/// @par
	/// @c Cyrix, AMD Geode GX/LX
	/// @par
	/// @c 16/32-bit
	RSLDT_M80 = 4246,
	/// @brief @c SVTS m80
	/// @par
	/// @c 0F 7C /0
	/// @par
	/// @c Cyrix, AMD Geode GX/LX
	/// @par
	/// @c 16/32-bit
	SVTS_M80 = 4247,
	/// @brief @c RSTS m80
	/// @par
	/// @c 0F 7D /0
	/// @par
	/// @c Cyrix, AMD Geode GX/LX
	/// @par
	/// @c 16/32-bit
	RSTS_M80 = 4248,
	/// @brief @c SMINT
	/// @par
	/// @c 0F 7E
	/// @par
	/// @c Cyrix 6x86 or earlier
	/// @par
	/// @c 16/32-bit
	SMINT_0_F7_E = 4249,
	/// @brief @c BB0_RESET
	/// @par
	/// @c 0F 3A
	/// @par
	/// @c Cyrix MediaGX, GXm, GXLV, GX1
	/// @par
	/// @c 16/32-bit
	BB0_RESET = 4250,
	/// @brief @c BB1_RESET
	/// @par
	/// @c 0F 3B
	/// @par
	/// @c Cyrix MediaGX, GXm, GXLV, GX1
	/// @par
	/// @c 16/32-bit
	BB1_RESET = 4251,
	/// @brief @c CPU_WRITE
	/// @par
	/// @c 0F 3C
	/// @par
	/// @c Cyrix MediaGX, GXm, GXLV, GX1
	/// @par
	/// @c 16/32-bit
	CPU_WRITE = 4252,
	/// @brief @c CPU_READ
	/// @par
	/// @c 0F 3D
	/// @par
	/// @c Cyrix MediaGX, GXm, GXLV, GX1
	/// @par
	/// @c 16/32-bit
	CPU_READ = 4253,
	/// @brief @c ALTINST
	/// @par
	/// @c 0F 3F
	/// @par
	/// @c Centaur AIS
	/// @par
	/// @c 16/32-bit
	ALTINST = 4254,
	/// @brief @c PAVEB mm, mm/m64
	/// @par
	/// @c 0F 50 /r
	/// @par
	/// @c CYRIX_EMMI
	/// @par
	/// @c 16/32-bit
	PAVEB_MM_MMM64 = 4255,
	/// @brief @c PADDSIW mm, mm/m64
	/// @par
	/// @c 0F 51 /r
	/// @par
	/// @c CYRIX_EMMI
	/// @par
	/// @c 16/32-bit
	PADDSIW_MM_MMM64 = 4256,
	/// @brief @c PMAGW mm, mm/m64
	/// @par
	/// @c 0F 52 /r
	/// @par
	/// @c CYRIX_EMMI
	/// @par
	/// @c 16/32-bit
	PMAGW_MM_MMM64 = 4257,
	/// @brief @c PDISTIB mm, m64
	/// @par
	/// @c 0F 54 /r
	/// @par
	/// @c CYRIX_EMMI
	/// @par
	/// @c 16/32-bit
	PDISTIB_MM_M64 = 4258,
	/// @brief @c PSUBSIW mm, mm/m64
	/// @par
	/// @c 0F 55 /r
	/// @par
	/// @c CYRIX_EMMI
	/// @par
	/// @c 16/32-bit
	PSUBSIW_MM_MMM64 = 4259,
	/// @brief @c PMVZB mm, m64
	/// @par
	/// @c 0F 58 /r
	/// @par
	/// @c CYRIX_EMMI
	/// @par
	/// @c 16/32-bit
	PMVZB_MM_M64 = 4260,
	/// @brief @c PMULHRW mm, mm/m64
	/// @par
	/// @c 0F 59 /r
	/// @par
	/// @c CYRIX_EMMI
	/// @par
	/// @c 16/32-bit
	PMULHRW_MM_MMM64 = 4261,
	/// @brief @c PMVNZB mm, m64
	/// @par
	/// @c 0F 5A /r
	/// @par
	/// @c CYRIX_EMMI
	/// @par
	/// @c 16/32-bit
	PMVNZB_MM_M64 = 4262,
	/// @brief @c PMVLZB mm, m64
	/// @par
	/// @c 0F 5B /r
	/// @par
	/// @c CYRIX_EMMI
	/// @par
	/// @c 16/32-bit
	PMVLZB_MM_M64 = 4263,
	/// @brief @c PMVGEZB mm, m64
	/// @par
	/// @c 0F 5C /r
	/// @par
	/// @c CYRIX_EMMI
	/// @par
	/// @c 16/32-bit
	PMVGEZB_MM_M64 = 4264,
	/// @brief @c PMULHRIW mm, mm/m64
	/// @par
	/// @c 0F 5D /r
	/// @par
	/// @c CYRIX_EMMI
	/// @par
	/// @c 16/32-bit
	PMULHRIW_MM_MMM64 = 4265,
	/// @brief @c PMACHRIW mm, m64
	/// @par
	/// @c 0F 5E /r
	/// @par
	/// @c CYRIX_EMMI
	/// @par
	/// @c 16/32-bit
	PMACHRIW_MM_M64 = 4266,
	/// @brief @c UNDOC
	/// @par
	/// @c D9 D7
	/// @par
	/// @c Cyrix, AMD Geode GX/LX
	/// @par
	/// @c 16/32-bit
	CYRIX_D9_D7 = 4267,
	/// @brief @c UNDOC
	/// @par
	/// @c D9 E2
	/// @par
	/// @c Cyrix, AMD Geode GX/LX
	/// @par
	/// @c 16/32-bit
	CYRIX_D9_E2 = 4268,
	/// @brief @c FTSTP
	/// @par
	/// @c D9 E6
	/// @par
	/// @c Cyrix, AMD Geode GX/LX
	/// @par
	/// @c 16/32-bit
	FTSTP = 4269,
	/// @brief @c UNDOC
	/// @par
	/// @c D9 E7
	/// @par
	/// @c Cyrix, AMD Geode GX/LX
	/// @par
	/// @c 16/32-bit
	CYRIX_D9_E7 = 4270,
	/// @brief @c FRINT2
	/// @par
	/// @c DB FC
	/// @par
	/// @c Cyrix, AMD Geode GX/LX
	/// @par
	/// @c 16/32-bit
	FRINT2 = 4271,
	/// @brief @c FRICHOP
	/// @par
	/// @c DD FC
	/// @par
	/// @c Cyrix, AMD Geode GX/LX
	/// @par
	/// @c 16/32-bit
	FRICHOP = 4272,
	/// @brief @c UNDOC
	/// @par
	/// @c DE D8
	/// @par
	/// @c Cyrix, AMD Geode GX/LX
	/// @par
	/// @c 16/32-bit
	CYRIX_DED8 = 4273,
	/// @brief @c UNDOC
	/// @par
	/// @c DE DA
	/// @par
	/// @c Cyrix, AMD Geode GX/LX
	/// @par
	/// @c 16/32-bit
	CYRIX_DEDA = 4274,
	/// @brief @c UNDOC
	/// @par
	/// @c DE DC
	/// @par
	/// @c Cyrix, AMD Geode GX/LX
	/// @par
	/// @c 16/32-bit
	CYRIX_DEDC = 4275,
	/// @brief @c UNDOC
	/// @par
	/// @c DE DD
	/// @par
	/// @c Cyrix, AMD Geode GX/LX
	/// @par
	/// @c 16/32-bit
	CYRIX_DEDD = 4276,
	/// @brief @c UNDOC
	/// @par
	/// @c DE DE
	/// @par
	/// @c Cyrix, AMD Geode GX/LX
	/// @par
	/// @c 16/32-bit
	CYRIX_DEDE = 4277,
	/// @brief @c FRINEAR
	/// @par
	/// @c DF FC
	/// @par
	/// @c Cyrix, AMD Geode GX/LX
	/// @par
	/// @c 16/32-bit
	FRINEAR = 4278,
	/// @brief @c TDCALL
	/// @par
	/// @c 66 0F 01 CC
	/// @par
	/// @c TDX
	/// @par
	/// @c 16/32/64-bit
	TDCALL = 4279,
	/// @brief @c SEAMRET
	/// @par
	/// @c 66 0F 01 CD
	/// @par
	/// @c TDX
	/// @par
	/// @c 64-bit
	SEAMRET = 4280,
	/// @brief @c SEAMOPS
	/// @par
	/// @c 66 0F 01 CE
	/// @par
	/// @c TDX
	/// @par
	/// @c 64-bit
	SEAMOPS = 4281,
	/// @brief @c SEAMCALL
	/// @par
	/// @c 66 0F 01 CF
	/// @par
	/// @c TDX
	/// @par
	/// @c 64-bit
	SEAMCALL = 4282,
	/// @brief @c AESENCWIDE128KL m384, \<XMM0-7\>
	/// @par
	/// @c F3 0F 38 D8 !(11):000:bbb
	/// @par
	/// @c AESKLE and WIDE_KL
	/// @par
	/// @c 16/32/64-bit
	AESENCWIDE128KL_M384 = 4283,
	/// @brief @c AESDECWIDE128KL m384, \<XMM0-7\>
	/// @par
	/// @c F3 0F 38 D8 !(11):001:bbb
	/// @par
	/// @c AESKLE and WIDE_KL
	/// @par
	/// @c 16/32/64-bit
	AESDECWIDE128KL_M384 = 4284,
	/// @brief @c AESENCWIDE256KL m512, \<XMM0-7\>
	/// @par
	/// @c F3 0F 38 D8 !(11):010:bbb
	/// @par
	/// @c AESKLE and WIDE_KL
	/// @par
	/// @c 16/32/64-bit
	AESENCWIDE256KL_M512 = 4285,
	/// @brief @c AESDECWIDE256KL m512, \<XMM0-7\>
	/// @par
	/// @c F3 0F 38 D8 !(11):011:bbb
	/// @par
	/// @c AESKLE and WIDE_KL
	/// @par
	/// @c 16/32/64-bit
	AESDECWIDE256KL_M512 = 4286,
	/// @brief @c LOADIWKEY xmm1, xmm2, \<EAX\>, \<XMM0\>
	/// @par
	/// @c F3 0F 38 DC 11:rrr:bbb
	/// @par
	/// @c KL
	/// @par
	/// @c 16/32/64-bit
	LOADIWKEY_XMM_XMM = 4287,
	/// @brief @c AESENC128KL xmm, m384
	/// @par
	/// @c F3 0F 38 DC !(11):rrr:bbb
	/// @par
	/// @c AESKLE
	/// @par
	/// @c 16/32/64-bit
	AESENC128KL_XMM_M384 = 4288,
	/// @brief @c AESDEC128KL xmm, m384
	/// @par
	/// @c F3 0F 38 DD !(11):rrr:bbb
	/// @par
	/// @c AESKLE
	/// @par
	/// @c 16/32/64-bit
	AESDEC128KL_XMM_M384 = 4289,
	/// @brief @c AESENC256KL xmm, m512
	/// @par
	/// @c F3 0F 38 DE !(11):rrr:bbb
	/// @par
	/// @c AESKLE
	/// @par
	/// @c 16/32/64-bit
	AESENC256KL_XMM_M512 = 4290,
	/// @brief @c AESDEC256KL xmm, m512
	/// @par
	/// @c F3 0F 38 DF !(11):rrr:bbb
	/// @par
	/// @c AESKLE
	/// @par
	/// @c 16/32/64-bit
	AESDEC256KL_XMM_M512 = 4291,
	/// @brief @c ENCODEKEY128 r32, r32, \<XMM0-2\>, \<XMM4-6\>
	/// @par
	/// @c F3 0F 38 FA 11:rrr:bbb
	/// @par
	/// @c AESKLE
	/// @par
	/// @c 16/32/64-bit
	ENCODEKEY128_R32_R32 = 4292,
	/// @brief @c ENCODEKEY256 r32, r32, \<XMM0-6\>
	/// @par
	/// @c F3 0F 38 FB 11:rrr:bbb
	/// @par
	/// @c AESKLE
	/// @par
	/// @c 16/32/64-bit
	ENCODEKEY256_R32_R32 = 4293,
	/// @brief @c VBROADCASTSS xmm1, xmm2
	/// @par
	/// @c VEX.128.66.0F38.W0 18 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VBROADCASTSS_XMM_XMM = 4294,
	/// @brief @c VBROADCASTSS ymm1, xmm2
	/// @par
	/// @c VEX.256.66.0F38.W0 18 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VBROADCASTSS_YMM_XMM = 4295,
	/// @brief @c VBROADCASTSD ymm1, xmm2
	/// @par
	/// @c VEX.256.66.0F38.W0 19 /r
	/// @par
	/// @c AVX2
	/// @par
	/// @c 16/32/64-bit
	VEX_VBROADCASTSD_YMM_XMM = 4296,
	/// @brief @c VMGEXIT
	/// @par
	/// @c F2 0F 01 D9
	/// @par
	/// @c SEV-ES
	/// @par
	/// @c 16/32/64-bit
	VMGEXIT_F2 = 4297,
	/// @brief @c UIRET
	/// @par
	/// @c F3 0F 01 EC
	/// @par
	/// @c UINTR
	/// @par
	/// @c 64-bit
	UIRET = 4298,
	/// @brief @c TESTUI
	/// @par
	/// @c F3 0F 01 ED
	/// @par
	/// @c UINTR
	/// @par
	/// @c 64-bit
	TESTUI = 4299,
	/// @brief @c CLUI
	/// @par
	/// @c F3 0F 01 EE
	/// @par
	/// @c UINTR
	/// @par
	/// @c 64-bit
	CLUI = 4300,
	/// @brief @c STUI
	/// @par
	/// @c F3 0F 01 EF
	/// @par
	/// @c UINTR
	/// @par
	/// @c 64-bit
	STUI = 4301,
	/// @brief @c SENDUIPI r64
	/// @par
	/// @c F3 0F C7 /6
	/// @par
	/// @c UINTR
	/// @par
	/// @c 64-bit
	SENDUIPI_R64 = 4302,
	/// @brief @c HRESET imm8, \<EAX\>
	/// @par
	/// @c F3 0F 3A F0 C0 ib
	/// @par
	/// @c HRESET
	/// @par
	/// @c 16/32/64-bit
	HRESET_IMM8 = 4303,
	/// @brief @c VPDPBUSD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 50 /r
	/// @par
	/// @c AVX-VNNI
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPBUSD_XMM_XMM_XMMM128 = 4304,
	/// @brief @c VPDPBUSD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 50 /r
	/// @par
	/// @c AVX-VNNI
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPBUSD_YMM_YMM_YMMM256 = 4305,
	/// @brief @c VPDPBUSDS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 51 /r
	/// @par
	/// @c AVX-VNNI
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPBUSDS_XMM_XMM_XMMM128 = 4306,
	/// @brief @c VPDPBUSDS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 51 /r
	/// @par
	/// @c AVX-VNNI
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPBUSDS_YMM_YMM_YMMM256 = 4307,
	/// @brief @c VPDPWSSD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 52 /r
	/// @par
	/// @c AVX-VNNI
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPWSSD_XMM_XMM_XMMM128 = 4308,
	/// @brief @c VPDPWSSD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 52 /r
	/// @par
	/// @c AVX-VNNI
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPWSSD_YMM_YMM_YMMM256 = 4309,
	/// @brief @c VPDPWSSDS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 53 /r
	/// @par
	/// @c AVX-VNNI
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPWSSDS_XMM_XMM_XMMM128 = 4310,
	/// @brief @c VPDPWSSDS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 53 /r
	/// @par
	/// @c AVX-VNNI
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPWSSDS_YMM_YMM_YMMM256 = 4311,
	/// @brief @c CCS_HASH
	/// @par
	/// @c a16 F3 0F A6 E8
	/// @par
	/// @c PADLOCK_GMI
	/// @par
	/// @c 16/32-bit
	CCS_HASH_16 = 4312,
	/// @brief @c CCS_HASH
	/// @par
	/// @c a32 F3 0F A6 E8
	/// @par
	/// @c PADLOCK_GMI
	/// @par
	/// @c 16/32/64-bit
	CCS_HASH_32 = 4313,
	/// @brief @c CCS_HASH
	/// @par
	/// @c a64 F3 0F A6 E8
	/// @par
	/// @c PADLOCK_GMI
	/// @par
	/// @c 64-bit
	CCS_HASH_64 = 4314,
	/// @brief @c CCS_ENCRYPT
	/// @par
	/// @c a16 F3 0F A7 F0
	/// @par
	/// @c PADLOCK_GMI
	/// @par
	/// @c 16/32-bit
	CCS_ENCRYPT_16 = 4315,
	/// @brief @c CCS_ENCRYPT
	/// @par
	/// @c a32 F3 0F A7 F0
	/// @par
	/// @c PADLOCK_GMI
	/// @par
	/// @c 16/32/64-bit
	CCS_ENCRYPT_32 = 4316,
	/// @brief @c CCS_ENCRYPT
	/// @par
	/// @c a64 F3 0F A7 F0
	/// @par
	/// @c PADLOCK_GMI
	/// @par
	/// @c 64-bit
	CCS_ENCRYPT_64 = 4317,
	/// @brief @c LKGS r/m16
	/// @par
	/// @c o16 F2 0F 00 /6
	/// @par
	/// @c LKGS
	/// @par
	/// @c 64-bit
	LKGS_RM16 = 4318,
	/// @brief @c LKGS r32/m16
	/// @par
	/// @c o32 F2 0F 00 /6
	/// @par
	/// @c LKGS
	/// @par
	/// @c 64-bit
	LKGS_R32M16 = 4319,
	/// @brief @c LKGS r64/m16
	/// @par
	/// @c F2 o64 0F 00 /6
	/// @par
	/// @c LKGS
	/// @par
	/// @c 64-bit
	LKGS_R64M16 = 4320,
	/// @brief @c ERETU
	/// @par
	/// @c F3 0F 01 CA
	/// @par
	/// @c FRED
	/// @par
	/// @c 64-bit
	ERETU = 4321,
	/// @brief @c ERETS
	/// @par
	/// @c F2 0F 01 CA
	/// @par
	/// @c FRED
	/// @par
	/// @c 64-bit
	ERETS = 4322,
	/// @brief @c VADDPH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst
	/// @par
	/// @c EVEX.128.MAP5.W0 58 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VADDPH_XMM_K1Z_XMM_XMMM128B16 = 4323,
	/// @brief @c VADDPH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst
	/// @par
	/// @c EVEX.256.MAP5.W0 58 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VADDPH_YMM_K1Z_YMM_YMMM256B16 = 4324,
	/// @brief @c VADDPH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er}
	/// @par
	/// @c EVEX.512.MAP5.W0 58 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VADDPH_ZMM_K1Z_ZMM_ZMMM512B16_ER = 4325,
	/// @brief @c VADDSH xmm1 {k1}{z}, xmm2, xmm3/m16{er}
	/// @par
	/// @c EVEX.LIG.F3.MAP5.W0 58 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VADDSH_XMM_K1Z_XMM_XMMM16_ER = 4326,
	/// @brief @c VCMPPH k1 {k2}, xmm2, xmm3/m128/m16bcst, imm8
	/// @par
	/// @c EVEX.128.0F3A.W0 C2 /r ib
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCMPPH_KR_K1_XMM_XMMM128B16_IMM8 = 4327,
	/// @brief @c VCMPPH k1 {k2}, ymm2, ymm3/m256/m16bcst, imm8
	/// @par
	/// @c EVEX.256.0F3A.W0 C2 /r ib
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCMPPH_KR_K1_YMM_YMMM256B16_IMM8 = 4328,
	/// @brief @c VCMPPH k1 {k2}, zmm2, zmm3/m512/m16bcst{sae}, imm8
	/// @par
	/// @c EVEX.512.0F3A.W0 C2 /r ib
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCMPPH_KR_K1_ZMM_ZMMM512B16_IMM8_SAE = 4329,
	/// @brief @c VCMPSH k1 {k2}, xmm2, xmm3/m16{sae}, imm8
	/// @par
	/// @c EVEX.LIG.F3.0F3A.W0 C2 /r ib
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCMPSH_KR_K1_XMM_XMMM16_IMM8_SAE = 4330,
	/// @brief @c VCOMISH xmm1, xmm2/m16{sae}
	/// @par
	/// @c EVEX.LIG.MAP5.W0 2F /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCOMISH_XMM_XMMM16_SAE = 4331,
	/// @brief @c VCVTDQ2PH xmm1 {k1}{z}, xmm2/m128/m32bcst
	/// @par
	/// @c EVEX.128.MAP5.W0 5B /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTDQ2PH_XMM_K1Z_XMMM128B32 = 4332,
	/// @brief @c VCVTDQ2PH xmm1 {k1}{z}, ymm2/m256/m32bcst
	/// @par
	/// @c EVEX.256.MAP5.W0 5B /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTDQ2PH_XMM_K1Z_YMMM256B32 = 4333,
	/// @brief @c VCVTDQ2PH ymm1 {k1}{z}, zmm2/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.MAP5.W0 5B /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTDQ2PH_YMM_K1Z_ZMMM512B32_ER = 4334,
	/// @brief @c VCVTPD2PH xmm1 {k1}{z}, xmm2/m128/m64bcst
	/// @par
	/// @c EVEX.128.66.MAP5.W1 5A /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPD2PH_XMM_K1Z_XMMM128B64 = 4335,
	/// @brief @c VCVTPD2PH xmm1 {k1}{z}, ymm2/m256/m64bcst
	/// @par
	/// @c EVEX.256.66.MAP5.W1 5A /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPD2PH_XMM_K1Z_YMMM256B64 = 4336,
	/// @brief @c VCVTPD2PH xmm1 {k1}{z}, zmm2/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.66.MAP5.W1 5A /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPD2PH_XMM_K1Z_ZMMM512B64_ER = 4337,
	/// @brief @c VCVTPH2DQ xmm1 {k1}{z}, xmm2/m64/m16bcst
	/// @par
	/// @c EVEX.128.66.MAP5.W0 5B /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPH2DQ_XMM_K1Z_XMMM64B16 = 4338,
	/// @brief @c VCVTPH2DQ ymm1 {k1}{z}, xmm2/m128/m16bcst
	/// @par
	/// @c EVEX.256.66.MAP5.W0 5B /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPH2DQ_YMM_K1Z_XMMM128B16 = 4339,
	/// @brief @c VCVTPH2DQ zmm1 {k1}{z}, ymm2/m256/m16bcst{er}
	/// @par
	/// @c EVEX.512.66.MAP5.W0 5B /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPH2DQ_ZMM_K1Z_YMMM256B16_ER = 4340,
	/// @brief @c VCVTPH2PD xmm1 {k1}{z}, xmm2/m32/m16bcst
	/// @par
	/// @c EVEX.128.MAP5.W0 5A /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPH2PD_XMM_K1Z_XMMM32B16 = 4341,
	/// @brief @c VCVTPH2PD ymm1 {k1}{z}, xmm2/m64/m16bcst
	/// @par
	/// @c EVEX.256.MAP5.W0 5A /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPH2PD_YMM_K1Z_XMMM64B16 = 4342,
	/// @brief @c VCVTPH2PD zmm1 {k1}{z}, xmm2/m128/m16bcst{sae}
	/// @par
	/// @c EVEX.512.MAP5.W0 5A /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPH2PD_ZMM_K1Z_XMMM128B16_SAE = 4343,
	/// @brief @c VCVTPH2PSX xmm1 {k1}{z}, xmm2/m64/m16bcst
	/// @par
	/// @c EVEX.128.66.MAP6.W0 13 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPH2PSX_XMM_K1Z_XMMM64B16 = 4344,
	/// @brief @c VCVTPH2PSX ymm1 {k1}{z}, xmm2/m128/m16bcst
	/// @par
	/// @c EVEX.256.66.MAP6.W0 13 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPH2PSX_YMM_K1Z_XMMM128B16 = 4345,
	/// @brief @c VCVTPH2PSX zmm1 {k1}{z}, ymm2/m256/m16bcst{sae}
	/// @par
	/// @c EVEX.512.66.MAP6.W0 13 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPH2PSX_ZMM_K1Z_YMMM256B16_SAE = 4346,
	/// @brief @c VCVTPH2QQ xmm1 {k1}{z}, xmm2/m32/m16bcst
	/// @par
	/// @c EVEX.128.66.MAP5.W0 7B /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPH2QQ_XMM_K1Z_XMMM32B16 = 4347,
	/// @brief @c VCVTPH2QQ ymm1 {k1}{z}, xmm2/m64/m16bcst
	/// @par
	/// @c EVEX.256.66.MAP5.W0 7B /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPH2QQ_YMM_K1Z_XMMM64B16 = 4348,
	/// @brief @c VCVTPH2QQ zmm1 {k1}{z}, xmm2/m128/m16bcst{er}
	/// @par
	/// @c EVEX.512.66.MAP5.W0 7B /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPH2QQ_ZMM_K1Z_XMMM128B16_ER = 4349,
	/// @brief @c VCVTPH2UDQ xmm1 {k1}{z}, xmm2/m64/m16bcst
	/// @par
	/// @c EVEX.128.MAP5.W0 79 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPH2UDQ_XMM_K1Z_XMMM64B16 = 4350,
	/// @brief @c VCVTPH2UDQ ymm1 {k1}{z}, xmm2/m128/m16bcst
	/// @par
	/// @c EVEX.256.MAP5.W0 79 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPH2UDQ_YMM_K1Z_XMMM128B16 = 4351,
	/// @brief @c VCVTPH2UDQ zmm1 {k1}{z}, ymm2/m256/m16bcst{er}
	/// @par
	/// @c EVEX.512.MAP5.W0 79 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPH2UDQ_ZMM_K1Z_YMMM256B16_ER = 4352,
	/// @brief @c VCVTPH2UQQ xmm1 {k1}{z}, xmm2/m32/m16bcst
	/// @par
	/// @c EVEX.128.66.MAP5.W0 79 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPH2UQQ_XMM_K1Z_XMMM32B16 = 4353,
	/// @brief @c VCVTPH2UQQ ymm1 {k1}{z}, xmm2/m64/m16bcst
	/// @par
	/// @c EVEX.256.66.MAP5.W0 79 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPH2UQQ_YMM_K1Z_XMMM64B16 = 4354,
	/// @brief @c VCVTPH2UQQ zmm1 {k1}{z}, xmm2/m128/m16bcst{er}
	/// @par
	/// @c EVEX.512.66.MAP5.W0 79 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPH2UQQ_ZMM_K1Z_XMMM128B16_ER = 4355,
	/// @brief @c VCVTPH2UW xmm1 {k1}{z}, xmm2/m128/m16bcst
	/// @par
	/// @c EVEX.128.MAP5.W0 7D /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPH2UW_XMM_K1Z_XMMM128B16 = 4356,
	/// @brief @c VCVTPH2UW ymm1 {k1}{z}, ymm2/m256/m16bcst
	/// @par
	/// @c EVEX.256.MAP5.W0 7D /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPH2UW_YMM_K1Z_YMMM256B16 = 4357,
	/// @brief @c VCVTPH2UW zmm1 {k1}{z}, zmm2/m512/m16bcst{er}
	/// @par
	/// @c EVEX.512.MAP5.W0 7D /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPH2UW_ZMM_K1Z_ZMMM512B16_ER = 4358,
	/// @brief @c VCVTPH2W xmm1 {k1}{z}, xmm2/m128/m16bcst
	/// @par
	/// @c EVEX.128.66.MAP5.W0 7D /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPH2W_XMM_K1Z_XMMM128B16 = 4359,
	/// @brief @c VCVTPH2W ymm1 {k1}{z}, ymm2/m256/m16bcst
	/// @par
	/// @c EVEX.256.66.MAP5.W0 7D /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPH2W_YMM_K1Z_YMMM256B16 = 4360,
	/// @brief @c VCVTPH2W zmm1 {k1}{z}, zmm2/m512/m16bcst{er}
	/// @par
	/// @c EVEX.512.66.MAP5.W0 7D /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPH2W_ZMM_K1Z_ZMMM512B16_ER = 4361,
	/// @brief @c VCVTPS2PHX xmm1 {k1}{z}, xmm2/m128/m32bcst
	/// @par
	/// @c EVEX.128.66.MAP5.W0 1D /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPS2PHX_XMM_K1Z_XMMM128B32 = 4362,
	/// @brief @c VCVTPS2PHX xmm1 {k1}{z}, ymm2/m256/m32bcst
	/// @par
	/// @c EVEX.256.66.MAP5.W0 1D /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPS2PHX_XMM_K1Z_YMMM256B32 = 4363,
	/// @brief @c VCVTPS2PHX ymm1 {k1}{z}, zmm2/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.66.MAP5.W0 1D /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTPS2PHX_YMM_K1Z_ZMMM512B32_ER = 4364,
	/// @brief @c VCVTQQ2PH xmm1 {k1}{z}, xmm2/m128/m64bcst
	/// @par
	/// @c EVEX.128.MAP5.W1 5B /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTQQ2PH_XMM_K1Z_XMMM128B64 = 4365,
	/// @brief @c VCVTQQ2PH xmm1 {k1}{z}, ymm2/m256/m64bcst
	/// @par
	/// @c EVEX.256.MAP5.W1 5B /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTQQ2PH_XMM_K1Z_YMMM256B64 = 4366,
	/// @brief @c VCVTQQ2PH xmm1 {k1}{z}, zmm2/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.MAP5.W1 5B /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTQQ2PH_XMM_K1Z_ZMMM512B64_ER = 4367,
	/// @brief @c VCVTSD2SH xmm1 {k1}{z}, xmm2, xmm3/m64{er}
	/// @par
	/// @c EVEX.LIG.F2.MAP5.W1 5A /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTSD2SH_XMM_K1Z_XMM_XMMM64_ER = 4368,
	/// @brief @c VCVTSH2SD xmm1 {k1}{z}, xmm2, xmm3/m16{sae}
	/// @par
	/// @c EVEX.LIG.F3.MAP5.W0 5A /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTSH2SD_XMM_K1Z_XMM_XMMM16_SAE = 4369,
	/// @brief @c VCVTSH2SI r32, xmm1/m16{er}
	/// @par
	/// @c EVEX.LIG.F3.MAP5.W0 2D /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTSH2SI_R32_XMMM16_ER = 4370,
	/// @brief @c VCVTSH2SI r64, xmm1/m16{er}
	/// @par
	/// @c EVEX.LIG.F3.MAP5.W1 2D /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 64-bit
	EVEX_VCVTSH2SI_R64_XMMM16_ER = 4371,
	/// @brief @c VCVTSH2SS xmm1 {k1}{z}, xmm2, xmm3/m16{sae}
	/// @par
	/// @c EVEX.LIG.MAP6.W0 13 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTSH2SS_XMM_K1Z_XMM_XMMM16_SAE = 4372,
	/// @brief @c VCVTSH2USI r32, xmm1/m16{er}
	/// @par
	/// @c EVEX.LIG.F3.MAP5.W0 79 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTSH2USI_R32_XMMM16_ER = 4373,
	/// @brief @c VCVTSH2USI r64, xmm1/m16{er}
	/// @par
	/// @c EVEX.LIG.F3.MAP5.W1 79 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 64-bit
	EVEX_VCVTSH2USI_R64_XMMM16_ER = 4374,
	/// @brief @c VCVTSI2SH xmm1, xmm2, r/m32{er}
	/// @par
	/// @c EVEX.LIG.F3.MAP5.W0 2A /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTSI2SH_XMM_XMM_RM32_ER = 4375,
	/// @brief @c VCVTSI2SH xmm1, xmm2, r/m64{er}
	/// @par
	/// @c EVEX.LIG.F3.MAP5.W1 2A /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 64-bit
	EVEX_VCVTSI2SH_XMM_XMM_RM64_ER = 4376,
	/// @brief @c VCVTSS2SH xmm1 {k1}{z}, xmm2, xmm3/m32{er}
	/// @par
	/// @c EVEX.LIG.MAP5.W0 1D /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTSS2SH_XMM_K1Z_XMM_XMMM32_ER = 4377,
	/// @brief @c VCVTTPH2DQ xmm1 {k1}{z}, xmm2/m64/m16bcst
	/// @par
	/// @c EVEX.128.F3.MAP5.W0 5B /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPH2DQ_XMM_K1Z_XMMM64B16 = 4378,
	/// @brief @c VCVTTPH2DQ ymm1 {k1}{z}, xmm2/m128/m16bcst
	/// @par
	/// @c EVEX.256.F3.MAP5.W0 5B /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPH2DQ_YMM_K1Z_XMMM128B16 = 4379,
	/// @brief @c VCVTTPH2DQ zmm1 {k1}{z}, ymm2/m256/m16bcst{sae}
	/// @par
	/// @c EVEX.512.F3.MAP5.W0 5B /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPH2DQ_ZMM_K1Z_YMMM256B16_SAE = 4380,
	/// @brief @c VCVTTPH2QQ xmm1 {k1}{z}, xmm2/m32/m16bcst
	/// @par
	/// @c EVEX.128.66.MAP5.W0 7A /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPH2QQ_XMM_K1Z_XMMM32B16 = 4381,
	/// @brief @c VCVTTPH2QQ ymm1 {k1}{z}, xmm2/m64/m16bcst
	/// @par
	/// @c EVEX.256.66.MAP5.W0 7A /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPH2QQ_YMM_K1Z_XMMM64B16 = 4382,
	/// @brief @c VCVTTPH2QQ zmm1 {k1}{z}, xmm2/m128/m16bcst{sae}
	/// @par
	/// @c EVEX.512.66.MAP5.W0 7A /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPH2QQ_ZMM_K1Z_XMMM128B16_SAE = 4383,
	/// @brief @c VCVTTPH2UDQ xmm1 {k1}{z}, xmm2/m64/m16bcst
	/// @par
	/// @c EVEX.128.MAP5.W0 78 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPH2UDQ_XMM_K1Z_XMMM64B16 = 4384,
	/// @brief @c VCVTTPH2UDQ ymm1 {k1}{z}, xmm2/m128/m16bcst
	/// @par
	/// @c EVEX.256.MAP5.W0 78 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPH2UDQ_YMM_K1Z_XMMM128B16 = 4385,
	/// @brief @c VCVTTPH2UDQ zmm1 {k1}{z}, ymm2/m256/m16bcst{sae}
	/// @par
	/// @c EVEX.512.MAP5.W0 78 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPH2UDQ_ZMM_K1Z_YMMM256B16_SAE = 4386,
	/// @brief @c VCVTTPH2UQQ xmm1 {k1}{z}, xmm2/m32/m16bcst
	/// @par
	/// @c EVEX.128.66.MAP5.W0 78 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPH2UQQ_XMM_K1Z_XMMM32B16 = 4387,
	/// @brief @c VCVTTPH2UQQ ymm1 {k1}{z}, xmm2/m64/m16bcst
	/// @par
	/// @c EVEX.256.66.MAP5.W0 78 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPH2UQQ_YMM_K1Z_XMMM64B16 = 4388,
	/// @brief @c VCVTTPH2UQQ zmm1 {k1}{z}, xmm2/m128/m16bcst{sae}
	/// @par
	/// @c EVEX.512.66.MAP5.W0 78 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPH2UQQ_ZMM_K1Z_XMMM128B16_SAE = 4389,
	/// @brief @c VCVTTPH2UW xmm1 {k1}{z}, xmm2/m128/m16bcst
	/// @par
	/// @c EVEX.128.MAP5.W0 7C /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPH2UW_XMM_K1Z_XMMM128B16 = 4390,
	/// @brief @c VCVTTPH2UW ymm1 {k1}{z}, ymm2/m256/m16bcst
	/// @par
	/// @c EVEX.256.MAP5.W0 7C /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPH2UW_YMM_K1Z_YMMM256B16 = 4391,
	/// @brief @c VCVTTPH2UW zmm1 {k1}{z}, zmm2/m512/m16bcst{sae}
	/// @par
	/// @c EVEX.512.MAP5.W0 7C /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPH2UW_ZMM_K1Z_ZMMM512B16_SAE = 4392,
	/// @brief @c VCVTTPH2W xmm1 {k1}{z}, xmm2/m128/m16bcst
	/// @par
	/// @c EVEX.128.66.MAP5.W0 7C /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPH2W_XMM_K1Z_XMMM128B16 = 4393,
	/// @brief @c VCVTTPH2W ymm1 {k1}{z}, ymm2/m256/m16bcst
	/// @par
	/// @c EVEX.256.66.MAP5.W0 7C /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPH2W_YMM_K1Z_YMMM256B16 = 4394,
	/// @brief @c VCVTTPH2W zmm1 {k1}{z}, zmm2/m512/m16bcst{sae}
	/// @par
	/// @c EVEX.512.66.MAP5.W0 7C /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTPH2W_ZMM_K1Z_ZMMM512B16_SAE = 4395,
	/// @brief @c VCVTTSH2SI r32, xmm1/m16{sae}
	/// @par
	/// @c EVEX.LIG.F3.MAP5.W0 2C /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTSH2SI_R32_XMMM16_SAE = 4396,
	/// @brief @c VCVTTSH2SI r64, xmm1/m16{sae}
	/// @par
	/// @c EVEX.LIG.F3.MAP5.W1 2C /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 64-bit
	EVEX_VCVTTSH2SI_R64_XMMM16_SAE = 4397,
	/// @brief @c VCVTTSH2USI r32, xmm1/m16{sae}
	/// @par
	/// @c EVEX.LIG.F3.MAP5.W0 78 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTTSH2USI_R32_XMMM16_SAE = 4398,
	/// @brief @c VCVTTSH2USI r64, xmm1/m16{sae}
	/// @par
	/// @c EVEX.LIG.F3.MAP5.W1 78 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 64-bit
	EVEX_VCVTTSH2USI_R64_XMMM16_SAE = 4399,
	/// @brief @c VCVTUDQ2PH xmm1 {k1}{z}, xmm2/m128/m32bcst
	/// @par
	/// @c EVEX.128.F2.MAP5.W0 7A /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTUDQ2PH_XMM_K1Z_XMMM128B32 = 4400,
	/// @brief @c VCVTUDQ2PH xmm1 {k1}{z}, ymm2/m256/m32bcst
	/// @par
	/// @c EVEX.256.F2.MAP5.W0 7A /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTUDQ2PH_XMM_K1Z_YMMM256B32 = 4401,
	/// @brief @c VCVTUDQ2PH ymm1 {k1}{z}, zmm2/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.F2.MAP5.W0 7A /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTUDQ2PH_YMM_K1Z_ZMMM512B32_ER = 4402,
	/// @brief @c VCVTUQQ2PH xmm1 {k1}{z}, xmm2/m128/m64bcst
	/// @par
	/// @c EVEX.128.F2.MAP5.W1 7A /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTUQQ2PH_XMM_K1Z_XMMM128B64 = 4403,
	/// @brief @c VCVTUQQ2PH xmm1 {k1}{z}, ymm2/m256/m64bcst
	/// @par
	/// @c EVEX.256.F2.MAP5.W1 7A /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTUQQ2PH_XMM_K1Z_YMMM256B64 = 4404,
	/// @brief @c VCVTUQQ2PH xmm1 {k1}{z}, zmm2/m512/m64bcst{er}
	/// @par
	/// @c EVEX.512.F2.MAP5.W1 7A /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTUQQ2PH_XMM_K1Z_ZMMM512B64_ER = 4405,
	/// @brief @c VCVTUSI2SH xmm1, xmm2, r/m32{er}
	/// @par
	/// @c EVEX.LIG.F3.MAP5.W0 7B /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTUSI2SH_XMM_XMM_RM32_ER = 4406,
	/// @brief @c VCVTUSI2SH xmm1, xmm2, r/m64{er}
	/// @par
	/// @c EVEX.LIG.F3.MAP5.W1 7B /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 64-bit
	EVEX_VCVTUSI2SH_XMM_XMM_RM64_ER = 4407,
	/// @brief @c VCVTUW2PH xmm1 {k1}{z}, xmm2/m128/m16bcst
	/// @par
	/// @c EVEX.128.F2.MAP5.W0 7D /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTUW2PH_XMM_K1Z_XMMM128B16 = 4408,
	/// @brief @c VCVTUW2PH ymm1 {k1}{z}, ymm2/m256/m16bcst
	/// @par
	/// @c EVEX.256.F2.MAP5.W0 7D /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTUW2PH_YMM_K1Z_YMMM256B16 = 4409,
	/// @brief @c VCVTUW2PH zmm1 {k1}{z}, zmm2/m512/m16bcst{er}
	/// @par
	/// @c EVEX.512.F2.MAP5.W0 7D /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTUW2PH_ZMM_K1Z_ZMMM512B16_ER = 4410,
	/// @brief @c VCVTW2PH xmm1 {k1}{z}, xmm2/m128/m16bcst
	/// @par
	/// @c EVEX.128.F3.MAP5.W0 7D /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTW2PH_XMM_K1Z_XMMM128B16 = 4411,
	/// @brief @c VCVTW2PH ymm1 {k1}{z}, ymm2/m256/m16bcst
	/// @par
	/// @c EVEX.256.F3.MAP5.W0 7D /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTW2PH_YMM_K1Z_YMMM256B16 = 4412,
	/// @brief @c VCVTW2PH zmm1 {k1}{z}, zmm2/m512/m16bcst{er}
	/// @par
	/// @c EVEX.512.F3.MAP5.W0 7D /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VCVTW2PH_ZMM_K1Z_ZMMM512B16_ER = 4413,
	/// @brief @c VDIVPH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst
	/// @par
	/// @c EVEX.128.MAP5.W0 5E /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VDIVPH_XMM_K1Z_XMM_XMMM128B16 = 4414,
	/// @brief @c VDIVPH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst
	/// @par
	/// @c EVEX.256.MAP5.W0 5E /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VDIVPH_YMM_K1Z_YMM_YMMM256B16 = 4415,
	/// @brief @c VDIVPH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er}
	/// @par
	/// @c EVEX.512.MAP5.W0 5E /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VDIVPH_ZMM_K1Z_ZMM_ZMMM512B16_ER = 4416,
	/// @brief @c VDIVSH xmm1 {k1}{z}, xmm2, xmm3/m16{er}
	/// @par
	/// @c EVEX.LIG.F3.MAP5.W0 5E /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VDIVSH_XMM_K1Z_XMM_XMMM16_ER = 4417,
	/// @brief @c VFCMADDCPH xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.F2.MAP6.W0 56 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFCMADDCPH_XMM_K1Z_XMM_XMMM128B32 = 4418,
	/// @brief @c VFCMADDCPH ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.F2.MAP6.W0 56 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFCMADDCPH_YMM_K1Z_YMM_YMMM256B32 = 4419,
	/// @brief @c VFCMADDCPH zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.F2.MAP6.W0 56 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFCMADDCPH_ZMM_K1Z_ZMM_ZMMM512B32_ER = 4420,
	/// @brief @c VFMADDCPH xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.F3.MAP6.W0 56 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDCPH_XMM_K1Z_XMM_XMMM128B32 = 4421,
	/// @brief @c VFMADDCPH ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.F3.MAP6.W0 56 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDCPH_YMM_K1Z_YMM_YMMM256B32 = 4422,
	/// @brief @c VFMADDCPH zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.F3.MAP6.W0 56 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDCPH_ZMM_K1Z_ZMM_ZMMM512B32_ER = 4423,
	/// @brief @c VFCMADDCSH xmm1 {k1}{z}, xmm2, xmm3/m32{er}
	/// @par
	/// @c EVEX.LIG.F2.MAP6.W0 57 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFCMADDCSH_XMM_K1Z_XMM_XMMM32_ER = 4424,
	/// @brief @c VFMADDCSH xmm1 {k1}{z}, xmm2, xmm3/m32{er}
	/// @par
	/// @c EVEX.LIG.F3.MAP6.W0 57 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDCSH_XMM_K1Z_XMM_XMMM32_ER = 4425,
	/// @brief @c VFCMULCPH xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.F2.MAP6.W0 D6 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFCMULCPH_XMM_K1Z_XMM_XMMM128B32 = 4426,
	/// @brief @c VFCMULCPH ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.F2.MAP6.W0 D6 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFCMULCPH_YMM_K1Z_YMM_YMMM256B32 = 4427,
	/// @brief @c VFCMULCPH zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.F2.MAP6.W0 D6 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFCMULCPH_ZMM_K1Z_ZMM_ZMMM512B32_ER = 4428,
	/// @brief @c VFMULCPH xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
	/// @par
	/// @c EVEX.128.F3.MAP6.W0 D6 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMULCPH_XMM_K1Z_XMM_XMMM128B32 = 4429,
	/// @brief @c VFMULCPH ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
	/// @par
	/// @c EVEX.256.F3.MAP6.W0 D6 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMULCPH_YMM_K1Z_YMM_YMMM256B32 = 4430,
	/// @brief @c VFMULCPH zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}
	/// @par
	/// @c EVEX.512.F3.MAP6.W0 D6 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMULCPH_ZMM_K1Z_ZMM_ZMMM512B32_ER = 4431,
	/// @brief @c VFCMULCSH xmm1 {k1}{z}, xmm2, xmm3/m32{er}
	/// @par
	/// @c EVEX.LIG.F2.MAP6.W0 D7 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFCMULCSH_XMM_K1Z_XMM_XMMM32_ER = 4432,
	/// @brief @c VFMULCSH xmm1 {k1}{z}, xmm2, xmm3/m32{er}
	/// @par
	/// @c EVEX.LIG.F3.MAP6.W0 D7 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMULCSH_XMM_K1Z_XMM_XMMM32_ER = 4433,
	/// @brief @c VFMADDSUB132PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst
	/// @par
	/// @c EVEX.128.66.MAP6.W0 96 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDSUB132PH_XMM_K1Z_XMM_XMMM128B16 = 4434,
	/// @brief @c VFMADDSUB132PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst
	/// @par
	/// @c EVEX.256.66.MAP6.W0 96 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDSUB132PH_YMM_K1Z_YMM_YMMM256B16 = 4435,
	/// @brief @c VFMADDSUB132PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er}
	/// @par
	/// @c EVEX.512.66.MAP6.W0 96 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDSUB132PH_ZMM_K1Z_ZMM_ZMMM512B16_ER = 4436,
	/// @brief @c VFMADDSUB213PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst
	/// @par
	/// @c EVEX.128.66.MAP6.W0 A6 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDSUB213PH_XMM_K1Z_XMM_XMMM128B16 = 4437,
	/// @brief @c VFMADDSUB213PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst
	/// @par
	/// @c EVEX.256.66.MAP6.W0 A6 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDSUB213PH_YMM_K1Z_YMM_YMMM256B16 = 4438,
	/// @brief @c VFMADDSUB213PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er}
	/// @par
	/// @c EVEX.512.66.MAP6.W0 A6 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDSUB213PH_ZMM_K1Z_ZMM_ZMMM512B16_ER = 4439,
	/// @brief @c VFMADDSUB231PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst
	/// @par
	/// @c EVEX.128.66.MAP6.W0 B6 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDSUB231PH_XMM_K1Z_XMM_XMMM128B16 = 4440,
	/// @brief @c VFMADDSUB231PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst
	/// @par
	/// @c EVEX.256.66.MAP6.W0 B6 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDSUB231PH_YMM_K1Z_YMM_YMMM256B16 = 4441,
	/// @brief @c VFMADDSUB231PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er}
	/// @par
	/// @c EVEX.512.66.MAP6.W0 B6 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADDSUB231PH_ZMM_K1Z_ZMM_ZMMM512B16_ER = 4442,
	/// @brief @c VFMSUBADD132PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst
	/// @par
	/// @c EVEX.128.66.MAP6.W0 97 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUBADD132PH_XMM_K1Z_XMM_XMMM128B16 = 4443,
	/// @brief @c VFMSUBADD132PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst
	/// @par
	/// @c EVEX.256.66.MAP6.W0 97 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUBADD132PH_YMM_K1Z_YMM_YMMM256B16 = 4444,
	/// @brief @c VFMSUBADD132PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er}
	/// @par
	/// @c EVEX.512.66.MAP6.W0 97 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUBADD132PH_ZMM_K1Z_ZMM_ZMMM512B16_ER = 4445,
	/// @brief @c VFMSUBADD213PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst
	/// @par
	/// @c EVEX.128.66.MAP6.W0 A7 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUBADD213PH_XMM_K1Z_XMM_XMMM128B16 = 4446,
	/// @brief @c VFMSUBADD213PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst
	/// @par
	/// @c EVEX.256.66.MAP6.W0 A7 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUBADD213PH_YMM_K1Z_YMM_YMMM256B16 = 4447,
	/// @brief @c VFMSUBADD213PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er}
	/// @par
	/// @c EVEX.512.66.MAP6.W0 A7 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUBADD213PH_ZMM_K1Z_ZMM_ZMMM512B16_ER = 4448,
	/// @brief @c VFMSUBADD231PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst
	/// @par
	/// @c EVEX.128.66.MAP6.W0 B7 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUBADD231PH_XMM_K1Z_XMM_XMMM128B16 = 4449,
	/// @brief @c VFMSUBADD231PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst
	/// @par
	/// @c EVEX.256.66.MAP6.W0 B7 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUBADD231PH_YMM_K1Z_YMM_YMMM256B16 = 4450,
	/// @brief @c VFMSUBADD231PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er}
	/// @par
	/// @c EVEX.512.66.MAP6.W0 B7 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUBADD231PH_ZMM_K1Z_ZMM_ZMMM512B16_ER = 4451,
	/// @brief @c VFMADD132PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst
	/// @par
	/// @c EVEX.128.66.MAP6.W0 98 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD132PH_XMM_K1Z_XMM_XMMM128B16 = 4452,
	/// @brief @c VFMADD132PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst
	/// @par
	/// @c EVEX.256.66.MAP6.W0 98 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD132PH_YMM_K1Z_YMM_YMMM256B16 = 4453,
	/// @brief @c VFMADD132PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er}
	/// @par
	/// @c EVEX.512.66.MAP6.W0 98 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD132PH_ZMM_K1Z_ZMM_ZMMM512B16_ER = 4454,
	/// @brief @c VFMADD213PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst
	/// @par
	/// @c EVEX.128.66.MAP6.W0 A8 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD213PH_XMM_K1Z_XMM_XMMM128B16 = 4455,
	/// @brief @c VFMADD213PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst
	/// @par
	/// @c EVEX.256.66.MAP6.W0 A8 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD213PH_YMM_K1Z_YMM_YMMM256B16 = 4456,
	/// @brief @c VFMADD213PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er}
	/// @par
	/// @c EVEX.512.66.MAP6.W0 A8 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD213PH_ZMM_K1Z_ZMM_ZMMM512B16_ER = 4457,
	/// @brief @c VFMADD231PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst
	/// @par
	/// @c EVEX.128.66.MAP6.W0 B8 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD231PH_XMM_K1Z_XMM_XMMM128B16 = 4458,
	/// @brief @c VFMADD231PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst
	/// @par
	/// @c EVEX.256.66.MAP6.W0 B8 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD231PH_YMM_K1Z_YMM_YMMM256B16 = 4459,
	/// @brief @c VFMADD231PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er}
	/// @par
	/// @c EVEX.512.66.MAP6.W0 B8 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD231PH_ZMM_K1Z_ZMM_ZMMM512B16_ER = 4460,
	/// @brief @c VFNMADD132PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst
	/// @par
	/// @c EVEX.128.66.MAP6.W0 9C /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD132PH_XMM_K1Z_XMM_XMMM128B16 = 4461,
	/// @brief @c VFNMADD132PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst
	/// @par
	/// @c EVEX.256.66.MAP6.W0 9C /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD132PH_YMM_K1Z_YMM_YMMM256B16 = 4462,
	/// @brief @c VFNMADD132PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er}
	/// @par
	/// @c EVEX.512.66.MAP6.W0 9C /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD132PH_ZMM_K1Z_ZMM_ZMMM512B16_ER = 4463,
	/// @brief @c VFNMADD213PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst
	/// @par
	/// @c EVEX.128.66.MAP6.W0 AC /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD213PH_XMM_K1Z_XMM_XMMM128B16 = 4464,
	/// @brief @c VFNMADD213PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst
	/// @par
	/// @c EVEX.256.66.MAP6.W0 AC /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD213PH_YMM_K1Z_YMM_YMMM256B16 = 4465,
	/// @brief @c VFNMADD213PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er}
	/// @par
	/// @c EVEX.512.66.MAP6.W0 AC /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD213PH_ZMM_K1Z_ZMM_ZMMM512B16_ER = 4466,
	/// @brief @c VFNMADD231PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst
	/// @par
	/// @c EVEX.128.66.MAP6.W0 BC /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD231PH_XMM_K1Z_XMM_XMMM128B16 = 4467,
	/// @brief @c VFNMADD231PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst
	/// @par
	/// @c EVEX.256.66.MAP6.W0 BC /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD231PH_YMM_K1Z_YMM_YMMM256B16 = 4468,
	/// @brief @c VFNMADD231PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er}
	/// @par
	/// @c EVEX.512.66.MAP6.W0 BC /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD231PH_ZMM_K1Z_ZMM_ZMMM512B16_ER = 4469,
	/// @brief @c VFMADD132SH xmm1 {k1}{z}, xmm2, xmm3/m16{er}
	/// @par
	/// @c EVEX.LIG.66.MAP6.W0 99 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD132SH_XMM_K1Z_XMM_XMMM16_ER = 4470,
	/// @brief @c VFMADD213SH xmm1 {k1}{z}, xmm2, xmm3/m16{er}
	/// @par
	/// @c EVEX.LIG.66.MAP6.W0 A9 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD213SH_XMM_K1Z_XMM_XMMM16_ER = 4471,
	/// @brief @c VFMADD231SH xmm1 {k1}{z}, xmm2, xmm3/m16{er}
	/// @par
	/// @c EVEX.LIG.66.MAP6.W0 B9 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMADD231SH_XMM_K1Z_XMM_XMMM16_ER = 4472,
	/// @brief @c VFNMADD132SH xmm1 {k1}{z}, xmm2, xmm3/m16{er}
	/// @par
	/// @c EVEX.LIG.66.MAP6.W0 9D /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD132SH_XMM_K1Z_XMM_XMMM16_ER = 4473,
	/// @brief @c VFNMADD213SH xmm1 {k1}{z}, xmm2, xmm3/m16{er}
	/// @par
	/// @c EVEX.LIG.66.MAP6.W0 AD /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD213SH_XMM_K1Z_XMM_XMMM16_ER = 4474,
	/// @brief @c VFNMADD231SH xmm1 {k1}{z}, xmm2, xmm3/m16{er}
	/// @par
	/// @c EVEX.LIG.66.MAP6.W0 BD /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMADD231SH_XMM_K1Z_XMM_XMMM16_ER = 4475,
	/// @brief @c VFMSUB132PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst
	/// @par
	/// @c EVEX.128.66.MAP6.W0 9A /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB132PH_XMM_K1Z_XMM_XMMM128B16 = 4476,
	/// @brief @c VFMSUB132PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst
	/// @par
	/// @c EVEX.256.66.MAP6.W0 9A /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB132PH_YMM_K1Z_YMM_YMMM256B16 = 4477,
	/// @brief @c VFMSUB132PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er}
	/// @par
	/// @c EVEX.512.66.MAP6.W0 9A /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB132PH_ZMM_K1Z_ZMM_ZMMM512B16_ER = 4478,
	/// @brief @c VFMSUB213PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst
	/// @par
	/// @c EVEX.128.66.MAP6.W0 AA /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB213PH_XMM_K1Z_XMM_XMMM128B16 = 4479,
	/// @brief @c VFMSUB213PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst
	/// @par
	/// @c EVEX.256.66.MAP6.W0 AA /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB213PH_YMM_K1Z_YMM_YMMM256B16 = 4480,
	/// @brief @c VFMSUB213PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er}
	/// @par
	/// @c EVEX.512.66.MAP6.W0 AA /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB213PH_ZMM_K1Z_ZMM_ZMMM512B16_ER = 4481,
	/// @brief @c VFMSUB231PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst
	/// @par
	/// @c EVEX.128.66.MAP6.W0 BA /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB231PH_XMM_K1Z_XMM_XMMM128B16 = 4482,
	/// @brief @c VFMSUB231PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst
	/// @par
	/// @c EVEX.256.66.MAP6.W0 BA /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB231PH_YMM_K1Z_YMM_YMMM256B16 = 4483,
	/// @brief @c VFMSUB231PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er}
	/// @par
	/// @c EVEX.512.66.MAP6.W0 BA /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB231PH_ZMM_K1Z_ZMM_ZMMM512B16_ER = 4484,
	/// @brief @c VFNMSUB132PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst
	/// @par
	/// @c EVEX.128.66.MAP6.W0 9E /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB132PH_XMM_K1Z_XMM_XMMM128B16 = 4485,
	/// @brief @c VFNMSUB132PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst
	/// @par
	/// @c EVEX.256.66.MAP6.W0 9E /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB132PH_YMM_K1Z_YMM_YMMM256B16 = 4486,
	/// @brief @c VFNMSUB132PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er}
	/// @par
	/// @c EVEX.512.66.MAP6.W0 9E /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB132PH_ZMM_K1Z_ZMM_ZMMM512B16_ER = 4487,
	/// @brief @c VFNMSUB213PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst
	/// @par
	/// @c EVEX.128.66.MAP6.W0 AE /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB213PH_XMM_K1Z_XMM_XMMM128B16 = 4488,
	/// @brief @c VFNMSUB213PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst
	/// @par
	/// @c EVEX.256.66.MAP6.W0 AE /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB213PH_YMM_K1Z_YMM_YMMM256B16 = 4489,
	/// @brief @c VFNMSUB213PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er}
	/// @par
	/// @c EVEX.512.66.MAP6.W0 AE /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB213PH_ZMM_K1Z_ZMM_ZMMM512B16_ER = 4490,
	/// @brief @c VFNMSUB231PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst
	/// @par
	/// @c EVEX.128.66.MAP6.W0 BE /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB231PH_XMM_K1Z_XMM_XMMM128B16 = 4491,
	/// @brief @c VFNMSUB231PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst
	/// @par
	/// @c EVEX.256.66.MAP6.W0 BE /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB231PH_YMM_K1Z_YMM_YMMM256B16 = 4492,
	/// @brief @c VFNMSUB231PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er}
	/// @par
	/// @c EVEX.512.66.MAP6.W0 BE /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB231PH_ZMM_K1Z_ZMM_ZMMM512B16_ER = 4493,
	/// @brief @c VFMSUB132SH xmm1 {k1}{z}, xmm2, xmm3/m16{er}
	/// @par
	/// @c EVEX.LIG.66.MAP6.W0 9B /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB132SH_XMM_K1Z_XMM_XMMM16_ER = 4494,
	/// @brief @c VFMSUB213SH xmm1 {k1}{z}, xmm2, xmm3/m16{er}
	/// @par
	/// @c EVEX.LIG.66.MAP6.W0 AB /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB213SH_XMM_K1Z_XMM_XMMM16_ER = 4495,
	/// @brief @c VFMSUB231SH xmm1 {k1}{z}, xmm2, xmm3/m16{er}
	/// @par
	/// @c EVEX.LIG.66.MAP6.W0 BB /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFMSUB231SH_XMM_K1Z_XMM_XMMM16_ER = 4496,
	/// @brief @c VFNMSUB132SH xmm1 {k1}{z}, xmm2, xmm3/m16{er}
	/// @par
	/// @c EVEX.LIG.66.MAP6.W0 9F /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB132SH_XMM_K1Z_XMM_XMMM16_ER = 4497,
	/// @brief @c VFNMSUB213SH xmm1 {k1}{z}, xmm2, xmm3/m16{er}
	/// @par
	/// @c EVEX.LIG.66.MAP6.W0 AF /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB213SH_XMM_K1Z_XMM_XMMM16_ER = 4498,
	/// @brief @c VFNMSUB231SH xmm1 {k1}{z}, xmm2, xmm3/m16{er}
	/// @par
	/// @c EVEX.LIG.66.MAP6.W0 BF /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFNMSUB231SH_XMM_K1Z_XMM_XMMM16_ER = 4499,
	/// @brief @c VFPCLASSPH k1 {k2}, xmm2/m128/m16bcst, imm8
	/// @par
	/// @c EVEX.128.0F3A.W0 66 /r ib
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFPCLASSPH_KR_K1_XMMM128B16_IMM8 = 4500,
	/// @brief @c VFPCLASSPH k1 {k2}, ymm2/m256/m16bcst, imm8
	/// @par
	/// @c EVEX.256.0F3A.W0 66 /r ib
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFPCLASSPH_KR_K1_YMMM256B16_IMM8 = 4501,
	/// @brief @c VFPCLASSPH k1 {k2}, zmm2/m512/m16bcst, imm8
	/// @par
	/// @c EVEX.512.0F3A.W0 66 /r ib
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFPCLASSPH_KR_K1_ZMMM512B16_IMM8 = 4502,
	/// @brief @c VFPCLASSSH k1 {k2}, xmm2/m16, imm8
	/// @par
	/// @c EVEX.LIG.0F3A.W0 67 /r ib
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VFPCLASSSH_KR_K1_XMMM16_IMM8 = 4503,
	/// @brief @c VGETEXPPH xmm1 {k1}{z}, xmm2/m128/m16bcst
	/// @par
	/// @c EVEX.128.66.MAP6.W0 42 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGETEXPPH_XMM_K1Z_XMMM128B16 = 4504,
	/// @brief @c VGETEXPPH ymm1 {k1}{z}, ymm2/m256/m16bcst
	/// @par
	/// @c EVEX.256.66.MAP6.W0 42 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGETEXPPH_YMM_K1Z_YMMM256B16 = 4505,
	/// @brief @c VGETEXPPH zmm1 {k1}{z}, zmm2/m512/m16bcst{sae}
	/// @par
	/// @c EVEX.512.66.MAP6.W0 42 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGETEXPPH_ZMM_K1Z_ZMMM512B16_SAE = 4506,
	/// @brief @c VGETEXPSH xmm1 {k1}{z}, xmm2, xmm3/m16{sae}
	/// @par
	/// @c EVEX.LIG.66.MAP6.W0 43 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGETEXPSH_XMM_K1Z_XMM_XMMM16_SAE = 4507,
	/// @brief @c VGETMANTPH xmm1 {k1}{z}, xmm2/m128/m16bcst, imm8
	/// @par
	/// @c EVEX.128.0F3A.W0 26 /r ib
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGETMANTPH_XMM_K1Z_XMMM128B16_IMM8 = 4508,
	/// @brief @c VGETMANTPH ymm1 {k1}{z}, ymm2/m256/m16bcst, imm8
	/// @par
	/// @c EVEX.256.0F3A.W0 26 /r ib
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGETMANTPH_YMM_K1Z_YMMM256B16_IMM8 = 4509,
	/// @brief @c VGETMANTPH zmm1 {k1}{z}, zmm2/m512/m16bcst{sae}, imm8
	/// @par
	/// @c EVEX.512.0F3A.W0 26 /r ib
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGETMANTPH_ZMM_K1Z_ZMMM512B16_IMM8_SAE = 4510,
	/// @brief @c VGETMANTSH xmm1 {k1}{z}, xmm2, xmm3/m16{sae}, imm8
	/// @par
	/// @c EVEX.LIG.0F3A.W0 27 /r ib
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VGETMANTSH_XMM_K1Z_XMM_XMMM16_IMM8_SAE = 4511,
	/// @brief @c VMAXPH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst
	/// @par
	/// @c EVEX.128.MAP5.W0 5F /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMAXPH_XMM_K1Z_XMM_XMMM128B16 = 4512,
	/// @brief @c VMAXPH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst
	/// @par
	/// @c EVEX.256.MAP5.W0 5F /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMAXPH_YMM_K1Z_YMM_YMMM256B16 = 4513,
	/// @brief @c VMAXPH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{sae}
	/// @par
	/// @c EVEX.512.MAP5.W0 5F /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMAXPH_ZMM_K1Z_ZMM_ZMMM512B16_SAE = 4514,
	/// @brief @c VMAXSH xmm1 {k1}{z}, xmm2, xmm3/m16{sae}
	/// @par
	/// @c EVEX.LIG.F3.MAP5.W0 5F /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMAXSH_XMM_K1Z_XMM_XMMM16_SAE = 4515,
	/// @brief @c VMINPH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst
	/// @par
	/// @c EVEX.128.MAP5.W0 5D /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMINPH_XMM_K1Z_XMM_XMMM128B16 = 4516,
	/// @brief @c VMINPH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst
	/// @par
	/// @c EVEX.256.MAP5.W0 5D /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMINPH_YMM_K1Z_YMM_YMMM256B16 = 4517,
	/// @brief @c VMINPH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{sae}
	/// @par
	/// @c EVEX.512.MAP5.W0 5D /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMINPH_ZMM_K1Z_ZMM_ZMMM512B16_SAE = 4518,
	/// @brief @c VMINSH xmm1 {k1}{z}, xmm2, xmm3/m16{sae}
	/// @par
	/// @c EVEX.LIG.F3.MAP5.W0 5D /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMINSH_XMM_K1Z_XMM_XMMM16_SAE = 4519,
	/// @brief @c VMOVSH xmm1 {k1}{z}, m16
	/// @par
	/// @c EVEX.LIG.F3.MAP5.W0 10 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVSH_XMM_K1Z_M16 = 4520,
	/// @brief @c VMOVSH m16 {k1}, xmm1
	/// @par
	/// @c EVEX.LIG.F3.MAP5.W0 11 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVSH_M16_K1_XMM = 4521,
	/// @brief @c VMOVSH xmm1 {k1}{z}, xmm2, xmm3
	/// @par
	/// @c EVEX.LIG.F3.MAP5.W0 10 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVSH_XMM_K1Z_XMM_XMM = 4522,
	/// @brief @c VMOVSH xmm1 {k1}{z}, xmm2, xmm3
	/// @par
	/// @c EVEX.LIG.F3.MAP5.W0 11 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVSH_XMM_K1Z_XMM_XMM_MAP5_11 = 4523,
	/// @brief @c VMOVW xmm1, r32/m16
	/// @par
	/// @c EVEX.128.66.MAP5.W0 6E /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVW_XMM_R32M16 = 4524,
	/// @brief @c VMOVW xmm1, r64/m16
	/// @par
	/// @c EVEX.128.66.MAP5.W1 6E /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 64-bit
	EVEX_VMOVW_XMM_R64M16 = 4525,
	/// @brief @c VMOVW r32/m16, xmm1
	/// @par
	/// @c EVEX.128.66.MAP5.W0 7E /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMOVW_R32M16_XMM = 4526,
	/// @brief @c VMOVW r64/m16, xmm1
	/// @par
	/// @c EVEX.128.66.MAP5.W1 7E /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 64-bit
	EVEX_VMOVW_R64M16_XMM = 4527,
	/// @brief @c VMULPH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst
	/// @par
	/// @c EVEX.128.MAP5.W0 59 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMULPH_XMM_K1Z_XMM_XMMM128B16 = 4528,
	/// @brief @c VMULPH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst
	/// @par
	/// @c EVEX.256.MAP5.W0 59 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMULPH_YMM_K1Z_YMM_YMMM256B16 = 4529,
	/// @brief @c VMULPH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er}
	/// @par
	/// @c EVEX.512.MAP5.W0 59 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMULPH_ZMM_K1Z_ZMM_ZMMM512B16_ER = 4530,
	/// @brief @c VMULSH xmm1 {k1}{z}, xmm2, xmm3/m16{er}
	/// @par
	/// @c EVEX.LIG.F3.MAP5.W0 59 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VMULSH_XMM_K1Z_XMM_XMMM16_ER = 4531,
	/// @brief @c VRCPPH xmm1 {k1}{z}, xmm2/m128/m16bcst
	/// @par
	/// @c EVEX.128.66.MAP6.W0 4C /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRCPPH_XMM_K1Z_XMMM128B16 = 4532,
	/// @brief @c VRCPPH ymm1 {k1}{z}, ymm2/m256/m16bcst
	/// @par
	/// @c EVEX.256.66.MAP6.W0 4C /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRCPPH_YMM_K1Z_YMMM256B16 = 4533,
	/// @brief @c VRCPPH zmm1 {k1}{z}, zmm2/m512/m16bcst
	/// @par
	/// @c EVEX.512.66.MAP6.W0 4C /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRCPPH_ZMM_K1Z_ZMMM512B16 = 4534,
	/// @brief @c VRCPSH xmm1 {k1}{z}, xmm2, xmm3/m16
	/// @par
	/// @c EVEX.LIG.66.MAP6.W0 4D /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRCPSH_XMM_K1Z_XMM_XMMM16 = 4535,
	/// @brief @c VREDUCEPH xmm1 {k1}{z}, xmm2/m128/m16bcst, imm8
	/// @par
	/// @c EVEX.128.0F3A.W0 56 /r ib
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VREDUCEPH_XMM_K1Z_XMMM128B16_IMM8 = 4536,
	/// @brief @c VREDUCEPH ymm1 {k1}{z}, ymm2/m256/m16bcst, imm8
	/// @par
	/// @c EVEX.256.0F3A.W0 56 /r ib
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VREDUCEPH_YMM_K1Z_YMMM256B16_IMM8 = 4537,
	/// @brief @c VREDUCEPH zmm1 {k1}{z}, zmm2/m512/m16bcst{sae}, imm8
	/// @par
	/// @c EVEX.512.0F3A.W0 56 /r ib
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VREDUCEPH_ZMM_K1Z_ZMMM512B16_IMM8_SAE = 4538,
	/// @brief @c VREDUCESH xmm1 {k1}{z}, xmm2, xmm3/m16{sae}, imm8
	/// @par
	/// @c EVEX.LIG.0F3A.W0 57 /r ib
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VREDUCESH_XMM_K1Z_XMM_XMMM16_IMM8_SAE = 4539,
	/// @brief @c VRNDSCALEPH xmm1 {k1}{z}, xmm2/m128/m16bcst, imm8
	/// @par
	/// @c EVEX.128.0F3A.W0 08 /r ib
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRNDSCALEPH_XMM_K1Z_XMMM128B16_IMM8 = 4540,
	/// @brief @c VRNDSCALEPH ymm1 {k1}{z}, ymm2/m256/m16bcst, imm8
	/// @par
	/// @c EVEX.256.0F3A.W0 08 /r ib
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRNDSCALEPH_YMM_K1Z_YMMM256B16_IMM8 = 4541,
	/// @brief @c VRNDSCALEPH zmm1 {k1}{z}, zmm2/m512/m16bcst{sae}, imm8
	/// @par
	/// @c EVEX.512.0F3A.W0 08 /r ib
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRNDSCALEPH_ZMM_K1Z_ZMMM512B16_IMM8_SAE = 4542,
	/// @brief @c VRNDSCALESH xmm1 {k1}{z}, xmm2, xmm3/m16{sae}, imm8
	/// @par
	/// @c EVEX.LIG.0F3A.W0 0A /r ib
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRNDSCALESH_XMM_K1Z_XMM_XMMM16_IMM8_SAE = 4543,
	/// @brief @c VRSQRTPH xmm1 {k1}{z}, xmm2/m128/m16bcst
	/// @par
	/// @c EVEX.128.66.MAP6.W0 4E /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRSQRTPH_XMM_K1Z_XMMM128B16 = 4544,
	/// @brief @c VRSQRTPH ymm1 {k1}{z}, ymm2/m256/m16bcst
	/// @par
	/// @c EVEX.256.66.MAP6.W0 4E /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRSQRTPH_YMM_K1Z_YMMM256B16 = 4545,
	/// @brief @c VRSQRTPH zmm1 {k1}{z}, zmm2/m512/m16bcst
	/// @par
	/// @c EVEX.512.66.MAP6.W0 4E /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRSQRTPH_ZMM_K1Z_ZMMM512B16 = 4546,
	/// @brief @c VRSQRTSH xmm1 {k1}{z}, xmm2, xmm3/m16
	/// @par
	/// @c EVEX.LIG.66.MAP6.W0 4F /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VRSQRTSH_XMM_K1Z_XMM_XMMM16 = 4547,
	/// @brief @c VSCALEFPH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst
	/// @par
	/// @c EVEX.128.66.MAP6.W0 2C /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCALEFPH_XMM_K1Z_XMM_XMMM128B16 = 4548,
	/// @brief @c VSCALEFPH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst
	/// @par
	/// @c EVEX.256.66.MAP6.W0 2C /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCALEFPH_YMM_K1Z_YMM_YMMM256B16 = 4549,
	/// @brief @c VSCALEFPH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er}
	/// @par
	/// @c EVEX.512.66.MAP6.W0 2C /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCALEFPH_ZMM_K1Z_ZMM_ZMMM512B16_ER = 4550,
	/// @brief @c VSCALEFSH xmm1 {k1}{z}, xmm2, xmm3/m16{er}
	/// @par
	/// @c EVEX.LIG.66.MAP6.W0 2D /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSCALEFSH_XMM_K1Z_XMM_XMMM16_ER = 4551,
	/// @brief @c VSQRTPH xmm1 {k1}{z}, xmm2/m128/m16bcst
	/// @par
	/// @c EVEX.128.MAP5.W0 51 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSQRTPH_XMM_K1Z_XMMM128B16 = 4552,
	/// @brief @c VSQRTPH ymm1 {k1}{z}, ymm2/m256/m16bcst
	/// @par
	/// @c EVEX.256.MAP5.W0 51 /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSQRTPH_YMM_K1Z_YMMM256B16 = 4553,
	/// @brief @c VSQRTPH zmm1 {k1}{z}, zmm2/m512/m16bcst{er}
	/// @par
	/// @c EVEX.512.MAP5.W0 51 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSQRTPH_ZMM_K1Z_ZMMM512B16_ER = 4554,
	/// @brief @c VSQRTSH xmm1 {k1}{z}, xmm2, xmm3/m16{er}
	/// @par
	/// @c EVEX.LIG.F3.MAP5.W0 51 /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSQRTSH_XMM_K1Z_XMM_XMMM16_ER = 4555,
	/// @brief @c VSUBPH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst
	/// @par
	/// @c EVEX.128.MAP5.W0 5C /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSUBPH_XMM_K1Z_XMM_XMMM128B16 = 4556,
	/// @brief @c VSUBPH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst
	/// @par
	/// @c EVEX.256.MAP5.W0 5C /r
	/// @par
	/// @c AVX512VL and AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSUBPH_YMM_K1Z_YMM_YMMM256B16 = 4557,
	/// @brief @c VSUBPH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er}
	/// @par
	/// @c EVEX.512.MAP5.W0 5C /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSUBPH_ZMM_K1Z_ZMM_ZMMM512B16_ER = 4558,
	/// @brief @c VSUBSH xmm1 {k1}{z}, xmm2, xmm3/m16{er}
	/// @par
	/// @c EVEX.LIG.F3.MAP5.W0 5C /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VSUBSH_XMM_K1Z_XMM_XMMM16_ER = 4559,
	/// @brief @c VUCOMISH xmm1, xmm2/m16{sae}
	/// @par
	/// @c EVEX.LIG.MAP5.W0 2E /r
	/// @par
	/// @c AVX512-FP16
	/// @par
	/// @c 16/32/64-bit
	EVEX_VUCOMISH_XMM_XMMM16_SAE = 4560,
	/// @brief @c RDUDBG
	/// @par
	/// @c 0F 0E
	/// @par
	/// @c UDBG
	/// @par
	/// @c 16/32/64-bit
	RDUDBG = 4561,
	/// @brief @c WRUDBG
	/// @par
	/// @c 0F 0F
	/// @par
	/// @c UDBG
	/// @par
	/// @c 16/32/64-bit
	WRUDBG = 4562,
	/// @brief @c JKZD k1, rel8
	/// @par
	/// @c VEX.128.W0 74 cb
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_JKZD_KR_REL8_64 = 4563,
	/// @brief @c JKNZD k1, rel8
	/// @par
	/// @c VEX.128.W0 75 cb
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_JKNZD_KR_REL8_64 = 4564,
	/// @brief @c VPREFETCHNTA m8
	/// @par
	/// @c VEX.128.0F.WIG 18 /0
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_VPREFETCHNTA_M8 = 4565,
	/// @brief @c VPREFETCH0 m8
	/// @par
	/// @c VEX.128.0F.WIG 18 /1
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_VPREFETCH0_M8 = 4566,
	/// @brief @c VPREFETCH1 m8
	/// @par
	/// @c VEX.128.0F.WIG 18 /2
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_VPREFETCH1_M8 = 4567,
	/// @brief @c VPREFETCH2 m8
	/// @par
	/// @c VEX.128.0F.WIG 18 /3
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_VPREFETCH2_M8 = 4568,
	/// @brief @c VPREFETCHENTA m8
	/// @par
	/// @c VEX.128.0F.WIG 18 /4
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_VPREFETCHENTA_M8 = 4569,
	/// @brief @c VPREFETCHE0 m8
	/// @par
	/// @c VEX.128.0F.WIG 18 /5
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_VPREFETCHE0_M8 = 4570,
	/// @brief @c VPREFETCHE1 m8
	/// @par
	/// @c VEX.128.0F.WIG 18 /6
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_VPREFETCHE1_M8 = 4571,
	/// @brief @c VPREFETCHE2 m8
	/// @par
	/// @c VEX.128.0F.WIG 18 /7
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_VPREFETCHE2_M8 = 4572,
	/// @brief @c KAND k1, k2
	/// @par
	/// @c VEX.128.0F.W0 41 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_KAND_KR_KR = 4573,
	/// @brief @c KANDN k1, k2
	/// @par
	/// @c VEX.128.0F.W0 42 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_KANDN_KR_KR = 4574,
	/// @brief @c KANDNR k1, k2
	/// @par
	/// @c VEX.128.0F.W0 43 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_KANDNR_KR_KR = 4575,
	/// @brief @c KNOT k1, k2
	/// @par
	/// @c VEX.128.0F.W0 44 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_KNOT_KR_KR = 4576,
	/// @brief @c KOR k1, k2
	/// @par
	/// @c VEX.128.0F.W0 45 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_KOR_KR_KR = 4577,
	/// @brief @c KXNOR k1, k2
	/// @par
	/// @c VEX.128.0F.W0 46 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_KXNOR_KR_KR = 4578,
	/// @brief @c KXOR k1, k2
	/// @par
	/// @c VEX.128.0F.W0 47 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_KXOR_KR_KR = 4579,
	/// @brief @c KMERGE2L1H k1, k2
	/// @par
	/// @c VEX.128.0F.W0 48 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_KMERGE2L1H_KR_KR = 4580,
	/// @brief @c KMERGE2L1L k1, k2
	/// @par
	/// @c VEX.128.0F.W0 49 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_KMERGE2L1L_KR_KR = 4581,
	/// @brief @c JKZD k1, rel32
	/// @par
	/// @c VEX.128.0F.W0 84 cd
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_JKZD_KR_REL32_64 = 4582,
	/// @brief @c JKNZD k1, rel32
	/// @par
	/// @c VEX.128.0F.W0 85 cd
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_JKNZD_KR_REL32_64 = 4583,
	/// @brief @c KMOV k1, k2
	/// @par
	/// @c VEX.128.0F.W0 90 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_KMOV_KR_KR = 4584,
	/// @brief @c KMOV k1, r32
	/// @par
	/// @c VEX.128.0F.W0 92 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_KMOV_KR_R32 = 4585,
	/// @brief @c KMOV r32, k1
	/// @par
	/// @c VEX.128.0F.W0 93 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_KMOV_R32_KR = 4586,
	/// @brief @c KCONCATH r64, k1, k2
	/// @par
	/// @c VEX.128.0F.W0 95 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_KCONCATH_R64_KR_KR = 4587,
	/// @brief @c KCONCATL r64, k1, k2
	/// @par
	/// @c VEX.128.0F.W0 97 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_KCONCATL_R64_KR_KR = 4588,
	/// @brief @c KORTEST k1, k2
	/// @par
	/// @c VEX.128.0F.W0 98 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_KORTEST_KR_KR = 4589,
	/// @brief @c DELAY r32
	/// @par
	/// @c VEX.128.F3.0F.W0 AE /6
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_DELAY_R32 = 4590,
	/// @brief @c DELAY r64
	/// @par
	/// @c VEX.128.F3.0F.W1 AE /6
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_DELAY_R64 = 4591,
	/// @brief @c SPFLT r32
	/// @par
	/// @c VEX.128.F2.0F.W0 AE /6
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_SPFLT_R32 = 4592,
	/// @brief @c SPFLT r64
	/// @par
	/// @c VEX.128.F2.0F.W1 AE /6
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_SPFLT_R64 = 4593,
	/// @brief @c CLEVICT1 m8
	/// @par
	/// @c VEX.128.F3.0F.WIG AE /7
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_CLEVICT1_M8 = 4594,
	/// @brief @c CLEVICT0 m8
	/// @par
	/// @c VEX.128.F2.0F.WIG AE /7
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_CLEVICT0_M8 = 4595,
	/// @brief @c POPCNT r32, r32
	/// @par
	/// @c VEX.128.F3.0F.W0 B8 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_POPCNT_R32_R32 = 4596,
	/// @brief @c POPCNT r64, r64
	/// @par
	/// @c VEX.128.F3.0F.W1 B8 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_POPCNT_R64_R64 = 4597,
	/// @brief @c TZCNT r32, r32
	/// @par
	/// @c VEX.128.F3.0F.W0 BC /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_TZCNT_R32_R32 = 4598,
	/// @brief @c TZCNT r64, r64
	/// @par
	/// @c VEX.128.F3.0F.W1 BC /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_TZCNT_R64_R64 = 4599,
	/// @brief @c TZCNTI r32, r32
	/// @par
	/// @c VEX.128.F2.0F.W0 BC /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_TZCNTI_R32_R32 = 4600,
	/// @brief @c TZCNTI r64, r64
	/// @par
	/// @c VEX.128.F2.0F.W1 BC /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_TZCNTI_R64_R64 = 4601,
	/// @brief @c LZCNT r32, r32
	/// @par
	/// @c VEX.128.F3.0F.W0 BD /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_LZCNT_R32_R32 = 4602,
	/// @brief @c LZCNT r64, r64
	/// @par
	/// @c VEX.128.F3.0F.W1 BD /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_LZCNT_R64_R64 = 4603,
	/// @brief @c UNDOC r32, r/m32
	/// @par
	/// @c VEX.128.F3.0F38.W0 F0 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_UNDOC_R32_RM32_128_F3_0_F38_W0_F0 = 4604,
	/// @brief @c UNDOC r64, r/m64
	/// @par
	/// @c VEX.128.F3.0F38.W1 F0 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_UNDOC_R64_RM64_128_F3_0_F38_W1_F0 = 4605,
	/// @brief @c UNDOC r32, r/m32
	/// @par
	/// @c VEX.128.F2.0F38.W0 F0 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_UNDOC_R32_RM32_128_F2_0_F38_W0_F0 = 4606,
	/// @brief @c UNDOC r64, r/m64
	/// @par
	/// @c VEX.128.F2.0F38.W1 F0 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_UNDOC_R64_RM64_128_F2_0_F38_W1_F0 = 4607,
	/// @brief @c UNDOC r32, r/m32
	/// @par
	/// @c VEX.128.F2.0F38.W0 F1 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_UNDOC_R32_RM32_128_F2_0_F38_W0_F1 = 4608,
	/// @brief @c UNDOC r64, r/m64
	/// @par
	/// @c VEX.128.F2.0F38.W1 F1 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_UNDOC_R64_RM64_128_F2_0_F38_W1_F1 = 4609,
	/// @brief @c KEXTRACT k1, r64, imm8
	/// @par
	/// @c VEX.128.66.0F3A.W0 3E /r ib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	VEX_KNC_KEXTRACT_KR_R64_IMM8 = 4610,
	/// @brief @c VPREFETCHNTA m
	/// @par
	/// @c MVEX.512.0F.WIG 18 /0
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPREFETCHNTA_M = 4611,
	/// @brief @c VPREFETCH0 m
	/// @par
	/// @c MVEX.512.0F.WIG 18 /1
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPREFETCH0_M = 4612,
	/// @brief @c VPREFETCH1 m
	/// @par
	/// @c MVEX.512.0F.WIG 18 /2
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPREFETCH1_M = 4613,
	/// @brief @c VPREFETCH2 m
	/// @par
	/// @c MVEX.512.0F.WIG 18 /3
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPREFETCH2_M = 4614,
	/// @brief @c VPREFETCHENTA m
	/// @par
	/// @c MVEX.512.0F.WIG 18 /4
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPREFETCHENTA_M = 4615,
	/// @brief @c VPREFETCHE0 m
	/// @par
	/// @c MVEX.512.0F.WIG 18 /5
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPREFETCHE0_M = 4616,
	/// @brief @c VPREFETCHE1 m
	/// @par
	/// @c MVEX.512.0F.WIG 18 /6
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPREFETCHE1_M = 4617,
	/// @brief @c VPREFETCHE2 m
	/// @par
	/// @c MVEX.512.0F.WIG 18 /7
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPREFETCHE2_M = 4618,
	/// @brief @c VMOVAPS zmm1 {k1}, Sf32(zmm2/mt)
	/// @par
	/// @c MVEX.512.0F.W0 28 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VMOVAPS_ZMM_K1_ZMMMT = 4619,
	/// @brief @c VMOVAPD zmm1 {k1}, Sf64(zmm2/mt)
	/// @par
	/// @c MVEX.512.66.0F.W1 28 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VMOVAPD_ZMM_K1_ZMMMT = 4620,
	/// @brief @c VMOVAPS mt {k1}, Df32(zmm1)
	/// @par
	/// @c MVEX.512.0F.W0 29 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VMOVAPS_MT_K1_ZMM = 4621,
	/// @brief @c VMOVAPD mt {k1}, Df64(zmm1)
	/// @par
	/// @c MVEX.512.66.0F.W1 29 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VMOVAPD_MT_K1_ZMM = 4622,
	/// @brief @c VMOVNRAPD m {k1}, Df64(zmm1)
	/// @par
	/// @c MVEX.512.F3.0F.W1.EH0 29 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VMOVNRAPD_M_K1_ZMM = 4623,
	/// @brief @c VMOVNRNGOAPD m {k1}, Df64(zmm1)
	/// @par
	/// @c MVEX.512.F3.0F.W1.EH1 29 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VMOVNRNGOAPD_M_K1_ZMM = 4624,
	/// @brief @c VMOVNRAPS m {k1}, Df32(zmm1)
	/// @par
	/// @c MVEX.512.F2.0F.W0.EH0 29 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VMOVNRAPS_M_K1_ZMM = 4625,
	/// @brief @c VMOVNRNGOAPS m {k1}, Df32(zmm1)
	/// @par
	/// @c MVEX.512.F2.0F.W0.EH1 29 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VMOVNRNGOAPS_M_K1_ZMM = 4626,
	/// @brief @c VADDPS zmm1 {k1}, zmm2, Sf32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.0F.W0 58 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VADDPS_ZMM_K1_ZMM_ZMMMT = 4627,
	/// @brief @c VADDPD zmm1 {k1}, zmm2, Sf64(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F.W1 58 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VADDPD_ZMM_K1_ZMM_ZMMMT = 4628,
	/// @brief @c VMULPS zmm1 {k1}, zmm2, Sf32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.0F.W0 59 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VMULPS_ZMM_K1_ZMM_ZMMMT = 4629,
	/// @brief @c VMULPD zmm1 {k1}, zmm2, Sf64(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F.W1 59 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VMULPD_ZMM_K1_ZMM_ZMMMT = 4630,
	/// @brief @c VCVTPS2PD zmm1 {k1}, Sf32(zmm2/mt)
	/// @par
	/// @c MVEX.512.0F.W0 5A /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VCVTPS2PD_ZMM_K1_ZMMMT = 4631,
	/// @brief @c VCVTPD2PS zmm1 {k1}, Sf64(zmm2/mt)
	/// @par
	/// @c MVEX.512.66.0F.W1 5A /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VCVTPD2PS_ZMM_K1_ZMMMT = 4632,
	/// @brief @c VSUBPS zmm1 {k1}, zmm2, Sf32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.0F.W0 5C /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VSUBPS_ZMM_K1_ZMM_ZMMMT = 4633,
	/// @brief @c VSUBPD zmm1 {k1}, zmm2, Sf64(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F.W1 5C /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VSUBPD_ZMM_K1_ZMM_ZMMMT = 4634,
	/// @brief @c VPCMPGTD k2 {k1}, zmm1, Si32(zmm2/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F.W0 66 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPCMPGTD_KR_K1_ZMM_ZMMMT = 4635,
	/// @brief @c VMOVDQA32 zmm1 {k1}, Si32(zmm2/mt)
	/// @par
	/// @c MVEX.512.66.0F.W0 6F /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VMOVDQA32_ZMM_K1_ZMMMT = 4636,
	/// @brief @c VMOVDQA64 zmm1 {k1}, Si64(zmm2/mt)
	/// @par
	/// @c MVEX.512.66.0F.W1 6F /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VMOVDQA64_ZMM_K1_ZMMMT = 4637,
	/// @brief @c VPSHUFD zmm1 {k1}, zmm2/mt, imm8
	/// @par
	/// @c MVEX.512.66.0F.W0 70 /r ib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPSHUFD_ZMM_K1_ZMMMT_IMM8 = 4638,
	/// @brief @c VPSRLD zmm1 {k1}, Si32(zmm2/mt), imm8
	/// @par
	/// @c MVEX.NDD.512.66.0F.W0 72 /2 ib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPSRLD_ZMM_K1_ZMMMT_IMM8 = 4639,
	/// @brief @c VPSRAD zmm1 {k1}, Si32(zmm2/mt), imm8
	/// @par
	/// @c MVEX.NDD.512.66.0F.W0 72 /4 ib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPSRAD_ZMM_K1_ZMMMT_IMM8 = 4640,
	/// @brief @c VPSLLD zmm1 {k1}, Si32(zmm2/mt), imm8
	/// @par
	/// @c MVEX.NDD.512.66.0F.W0 72 /6 ib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPSLLD_ZMM_K1_ZMMMT_IMM8 = 4641,
	/// @brief @c VPCMPEQD k2 {k1}, zmm1, Si32(zmm2/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F.W0 76 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPCMPEQD_KR_K1_ZMM_ZMMMT = 4642,
	/// @brief @c VCVTUDQ2PD zmm1 {k1}, Si32(zmm2/mt)
	/// @par
	/// @c MVEX.512.F3.0F.W0 7A /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VCVTUDQ2PD_ZMM_K1_ZMMMT = 4643,
	/// @brief @c VMOVDQA32 mt {k1}, Di32(zmm1)
	/// @par
	/// @c MVEX.512.66.0F.W0 7F /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VMOVDQA32_MT_K1_ZMM = 4644,
	/// @brief @c VMOVDQA64 mt {k1}, Di64(zmm1)
	/// @par
	/// @c MVEX.512.66.0F.W1 7F /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VMOVDQA64_MT_K1_ZMM = 4645,
	/// @brief @c CLEVICT1 m
	/// @par
	/// @c MVEX.512.F3.0F.WIG AE /7
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_CLEVICT1_M = 4646,
	/// @brief @c CLEVICT0 m
	/// @par
	/// @c MVEX.512.F2.0F.WIG AE /7
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_CLEVICT0_M = 4647,
	/// @brief @c VCMPPS k2 {k1}, zmm1, Sf32(zmm2/mt), imm8
	/// @par
	/// @c MVEX.NDS.512.0F.W0 C2 /r ib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VCMPPS_KR_K1_ZMM_ZMMMT_IMM8 = 4648,
	/// @brief @c VCMPPD k2 {k1}, zmm1, Sf64(zmm2/mt), imm8
	/// @par
	/// @c MVEX.NDS.512.66.0F.W1 C2 /r ib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VCMPPD_KR_K1_ZMM_ZMMMT_IMM8 = 4649,
	/// @brief @c VPANDD zmm1 {k1}, zmm2, Si32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F.W0 DB /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPANDD_ZMM_K1_ZMM_ZMMMT = 4650,
	/// @brief @c VPANDQ zmm1 {k1}, zmm2, Si64(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F.W1 DB /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPANDQ_ZMM_K1_ZMM_ZMMMT = 4651,
	/// @brief @c VPANDND zmm1 {k1}, zmm2, Si32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F.W0 DF /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPANDND_ZMM_K1_ZMM_ZMMMT = 4652,
	/// @brief @c VPANDNQ zmm1 {k1}, zmm2, Si64(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F.W1 DF /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPANDNQ_ZMM_K1_ZMM_ZMMMT = 4653,
	/// @brief @c VCVTDQ2PD zmm1 {k1}, Si32(zmm2/mt)
	/// @par
	/// @c MVEX.512.F3.0F.W0 E6 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VCVTDQ2PD_ZMM_K1_ZMMMT = 4654,
	/// @brief @c VPORD zmm1 {k1}, zmm2, Si32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F.W0 EB /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPORD_ZMM_K1_ZMM_ZMMMT = 4655,
	/// @brief @c VPORQ zmm1 {k1}, zmm2, Si64(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F.W1 EB /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPORQ_ZMM_K1_ZMM_ZMMMT = 4656,
	/// @brief @c VPXORD zmm1 {k1}, zmm2, Si32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F.W0 EF /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPXORD_ZMM_K1_ZMM_ZMMMT = 4657,
	/// @brief @c VPXORQ zmm1 {k1}, zmm2, Si64(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F.W1 EF /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPXORQ_ZMM_K1_ZMM_ZMMMT = 4658,
	/// @brief @c VPSUBD zmm1 {k1}, zmm2, Si32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F.W0 FA /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPSUBD_ZMM_K1_ZMM_ZMMMT = 4659,
	/// @brief @c VPADDD zmm1 {k1}, zmm2, Si32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F.W0 FE /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPADDD_ZMM_K1_ZMM_ZMMMT = 4660,
	/// @brief @c VBROADCASTSS zmm1 {k1}, Uf32(mt)
	/// @par
	/// @c MVEX.512.66.0F38.W0 18 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VBROADCASTSS_ZMM_K1_MT = 4661,
	/// @brief @c VBROADCASTSD zmm1 {k1}, Uf64(mt)
	/// @par
	/// @c MVEX.512.66.0F38.W1 19 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VBROADCASTSD_ZMM_K1_MT = 4662,
	/// @brief @c VBROADCASTF32X4 zmm1 {k1}, Uf32(mt)
	/// @par
	/// @c MVEX.512.66.0F38.W0 1A /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VBROADCASTF32X4_ZMM_K1_MT = 4663,
	/// @brief @c VBROADCASTF64X4 zmm1 {k1}, Uf64(mt)
	/// @par
	/// @c MVEX.512.66.0F38.W1 1B /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VBROADCASTF64X4_ZMM_K1_MT = 4664,
	/// @brief @c VPTESTMD k2 {k1}, zmm1, Si32(zmm2/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 27 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPTESTMD_KR_K1_ZMM_ZMMMT = 4665,
	/// @brief @c VPERMD zmm1 {k1}, zmm2, zmm3/mt
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 36 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPERMD_ZMM_K1_ZMM_ZMMMT = 4666,
	/// @brief @c VPMINSD zmm1 {k1}, zmm2, Si32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 39 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPMINSD_ZMM_K1_ZMM_ZMMMT = 4667,
	/// @brief @c VPMINUD zmm1 {k1}, zmm2, Si32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 3B /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPMINUD_ZMM_K1_ZMM_ZMMMT = 4668,
	/// @brief @c VPMAXSD zmm1 {k1}, zmm2, Si32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 3D /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPMAXSD_ZMM_K1_ZMM_ZMMMT = 4669,
	/// @brief @c VPMAXUD zmm1 {k1}, zmm2, Si32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 3F /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPMAXUD_ZMM_K1_ZMM_ZMMMT = 4670,
	/// @brief @c VPMULLD zmm1 {k1}, zmm2, Si32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 40 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPMULLD_ZMM_K1_ZMM_ZMMMT = 4671,
	/// @brief @c VGETEXPPS zmm1 {k1}, Sf32(zmm2/mt)
	/// @par
	/// @c MVEX.512.66.0F38.W0 42 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VGETEXPPS_ZMM_K1_ZMMMT = 4672,
	/// @brief @c VGETEXPPD zmm1 {k1}, Sf64(zmm2/mt)
	/// @par
	/// @c MVEX.512.66.0F38.W1 42 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VGETEXPPD_ZMM_K1_ZMMMT = 4673,
	/// @brief @c VPSRLVD zmm1 {k1}, zmm2, Si32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 45 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPSRLVD_ZMM_K1_ZMM_ZMMMT = 4674,
	/// @brief @c VPSRAVD zmm1 {k1}, zmm2, Si32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 46 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPSRAVD_ZMM_K1_ZMM_ZMMMT = 4675,
	/// @brief @c VPSLLVD zmm1 {k1}, zmm2, Si32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 47 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPSLLVD_ZMM_K1_ZMM_ZMMMT = 4676,
	/// @brief @c UNDOC zmm1 {k1}, zmm2/mt
	/// @par
	/// @c MVEX.512.66.0F38.W0 48 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_ZMMMT_512_66_0_F38_W0_48 = 4677,
	/// @brief @c UNDOC zmm1 {k1}, zmm2/mt
	/// @par
	/// @c MVEX.512.66.0F38.W0 49 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_ZMMMT_512_66_0_F38_W0_49 = 4678,
	/// @brief @c UNDOC zmm1 {k1}, zmm2/mt
	/// @par
	/// @c MVEX.512.66.0F38.W0 4A /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_ZMMMT_512_66_0_F38_W0_4_A = 4679,
	/// @brief @c UNDOC zmm1 {k1}, zmm2/mt
	/// @par
	/// @c MVEX.512.66.0F38.W0 4B /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_ZMMMT_512_66_0_F38_W0_4_B = 4680,
	/// @brief @c VADDNPS zmm1 {k1}, zmm2, Sf32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 50 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VADDNPS_ZMM_K1_ZMM_ZMMMT = 4681,
	/// @brief @c VADDNPD zmm1 {k1}, zmm2, Sf64(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W1 50 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VADDNPD_ZMM_K1_ZMM_ZMMMT = 4682,
	/// @brief @c VGMAXABSPS zmm1 {k1}, zmm2, Sf32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 51 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VGMAXABSPS_ZMM_K1_ZMM_ZMMMT = 4683,
	/// @brief @c VGMINPS zmm1 {k1}, zmm2, Sf32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 52 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VGMINPS_ZMM_K1_ZMM_ZMMMT = 4684,
	/// @brief @c VGMINPD zmm1 {k1}, zmm2, Sf64(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W1 52 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VGMINPD_ZMM_K1_ZMM_ZMMMT = 4685,
	/// @brief @c VGMAXPS zmm1 {k1}, zmm2, Sf32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 53 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VGMAXPS_ZMM_K1_ZMM_ZMMMT = 4686,
	/// @brief @c VGMAXPD zmm1 {k1}, zmm2, Sf64(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W1 53 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VGMAXPD_ZMM_K1_ZMM_ZMMMT = 4687,
	/// @brief @c UNDOC zmm1 {k1}, zmm2, zmm3/mt
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 54 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_ZMM_ZMMMT_512_66_0_F38_W0_54 = 4688,
	/// @brief @c VFIXUPNANPS zmm1 {k1}, zmm2, Si32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 55 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VFIXUPNANPS_ZMM_K1_ZMM_ZMMMT = 4689,
	/// @brief @c VFIXUPNANPD zmm1 {k1}, zmm2, Si64(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W1 55 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VFIXUPNANPD_ZMM_K1_ZMM_ZMMMT = 4690,
	/// @brief @c UNDOC zmm1 {k1}, zmm2, zmm3/mt
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 56 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_ZMM_ZMMMT_512_66_0_F38_W0_56 = 4691,
	/// @brief @c UNDOC zmm1 {k1}, zmm2, zmm3/mt
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 57 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_ZMM_ZMMMT_512_66_0_F38_W0_57 = 4692,
	/// @brief @c VPBROADCASTD zmm1 {k1}, Ui32(mt)
	/// @par
	/// @c MVEX.512.66.0F38.W0 58 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPBROADCASTD_ZMM_K1_MT = 4693,
	/// @brief @c VPBROADCASTQ zmm1 {k1}, Ui64(mt)
	/// @par
	/// @c MVEX.512.66.0F38.W1 59 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPBROADCASTQ_ZMM_K1_MT = 4694,
	/// @brief @c VBROADCASTI32X4 zmm1 {k1}, Ui32(mt)
	/// @par
	/// @c MVEX.512.66.0F38.W0 5A /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VBROADCASTI32X4_ZMM_K1_MT = 4695,
	/// @brief @c VBROADCASTI64X4 zmm1 {k1}, Ui64(mt)
	/// @par
	/// @c MVEX.512.66.0F38.W1 5B /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VBROADCASTI64X4_ZMM_K1_MT = 4696,
	/// @brief @c VPADCD zmm1 {k1}, k2, Si32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 5C /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPADCD_ZMM_K1_KR_ZMMMT = 4697,
	/// @brief @c VPADDSETCD zmm1 {k1}, k2, Si32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 5D /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPADDSETCD_ZMM_K1_KR_ZMMMT = 4698,
	/// @brief @c VPSBBD zmm1 {k1}, k2, Si32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 5E /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPSBBD_ZMM_K1_KR_ZMMMT = 4699,
	/// @brief @c VPSUBSETBD zmm1 {k1}, k2, Si32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 5F /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPSUBSETBD_ZMM_K1_KR_ZMMMT = 4700,
	/// @brief @c VPBLENDMD zmm1 {k1}, zmm2, Si32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 64 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPBLENDMD_ZMM_K1_ZMM_ZMMMT = 4701,
	/// @brief @c VPBLENDMQ zmm1 {k1}, zmm2, Si64(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W1 64 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPBLENDMQ_ZMM_K1_ZMM_ZMMMT = 4702,
	/// @brief @c VBLENDMPS zmm1 {k1}, zmm2, Sf32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 65 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VBLENDMPS_ZMM_K1_ZMM_ZMMMT = 4703,
	/// @brief @c VBLENDMPD zmm1 {k1}, zmm2, Sf64(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W1 65 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VBLENDMPD_ZMM_K1_ZMM_ZMMMT = 4704,
	/// @brief @c UNDOC zmm1 {k1}, zmm2, zmm3/mt
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 67 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_ZMM_ZMMMT_512_66_0_F38_W0_67 = 4705,
	/// @brief @c UNDOC zmm1 {k1}, zmm2/mt
	/// @par
	/// @c MVEX.512.66.0F38.W0 68 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_ZMMMT_512_66_0_F38_W0_68 = 4706,
	/// @brief @c UNDOC zmm1 {k1}, zmm2/mt
	/// @par
	/// @c MVEX.512.66.0F38.W0 69 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_ZMMMT_512_66_0_F38_W0_69 = 4707,
	/// @brief @c UNDOC zmm1 {k1}, zmm2/mt
	/// @par
	/// @c MVEX.512.66.0F38.W0 6A /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_ZMMMT_512_66_0_F38_W0_6_A = 4708,
	/// @brief @c UNDOC zmm1 {k1}, zmm2/mt
	/// @par
	/// @c MVEX.512.66.0F38.W0 6B /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_ZMMMT_512_66_0_F38_W0_6_B = 4709,
	/// @brief @c VPSUBRD zmm1 {k1}, zmm2, Si32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 6C /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPSUBRD_ZMM_K1_ZMM_ZMMMT = 4710,
	/// @brief @c VSUBRPS zmm1 {k1}, zmm2, Sf32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 6D /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VSUBRPS_ZMM_K1_ZMM_ZMMMT = 4711,
	/// @brief @c VSUBRPD zmm1 {k1}, zmm2, Sf64(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W1 6D /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VSUBRPD_ZMM_K1_ZMM_ZMMMT = 4712,
	/// @brief @c VPSBBRD zmm1 {k1}, k2, Si32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 6E /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPSBBRD_ZMM_K1_KR_ZMMMT = 4713,
	/// @brief @c VPSUBRSETBD zmm1 {k1}, k2, Si32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 6F /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPSUBRSETBD_ZMM_K1_KR_ZMMMT = 4714,
	/// @brief @c UNDOC zmm1 {k1}, zmm2, zmm3/mt
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 70 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_ZMM_ZMMMT_512_66_0_F38_W0_70 = 4715,
	/// @brief @c UNDOC zmm1 {k1}, zmm2, zmm3/mt
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 71 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_ZMM_ZMMMT_512_66_0_F38_W0_71 = 4716,
	/// @brief @c UNDOC zmm1 {k1}, zmm2, zmm3/mt
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 72 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_ZMM_ZMMMT_512_66_0_F38_W0_72 = 4717,
	/// @brief @c UNDOC zmm1 {k1}, zmm2, zmm3/mt
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 73 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_ZMM_ZMMMT_512_66_0_F38_W0_73 = 4718,
	/// @brief @c VPCMPLTD k2 {k1}, zmm1, Si32(zmm2/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 74 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPCMPLTD_KR_K1_ZMM_ZMMMT = 4719,
	/// @brief @c VSCALEPS zmm1 {k1}, zmm2, Si32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 84 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VSCALEPS_ZMM_K1_ZMM_ZMMMT = 4720,
	/// @brief @c VPMULHUD zmm1 {k1}, zmm2, Si32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 86 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPMULHUD_ZMM_K1_ZMM_ZMMMT = 4721,
	/// @brief @c VPMULHD zmm1 {k1}, zmm2, Si32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 87 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPMULHD_ZMM_K1_ZMM_ZMMMT = 4722,
	/// @brief @c VPGATHERDD zmm1 {k1}, Ui32(mvt)
	/// @par
	/// @c MVEX.512.66.0F38.W0 90 /vsib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPGATHERDD_ZMM_K1_MVT = 4723,
	/// @brief @c VPGATHERDQ zmm1 {k1}, Ui64(mvt)
	/// @par
	/// @c MVEX.512.66.0F38.W1 90 /vsib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPGATHERDQ_ZMM_K1_MVT = 4724,
	/// @brief @c VGATHERDPS zmm1 {k1}, Uf32(mvt)
	/// @par
	/// @c MVEX.512.66.0F38.W0 92 /vsib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VGATHERDPS_ZMM_K1_MVT = 4725,
	/// @brief @c VGATHERDPD zmm1 {k1}, Uf64(mvt)
	/// @par
	/// @c MVEX.512.66.0F38.W1 92 /vsib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VGATHERDPD_ZMM_K1_MVT = 4726,
	/// @brief @c UNDOC zmm1 {k1}, zmm2, zmm3/mt
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 94 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_ZMM_ZMMMT_512_66_0_F38_W0_94 = 4727,
	/// @brief @c UNDOC zmm1 {k1}, zmm2, zmm3/mt
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W1 94 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_ZMM_ZMMMT_512_66_0_F38_W1_94 = 4728,
	/// @brief @c VFMADD132PS zmm1 {k1}, zmm2, Sf32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 98 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VFMADD132PS_ZMM_K1_ZMM_ZMMMT = 4729,
	/// @brief @c VFMADD132PD zmm1 {k1}, zmm2, Sf64(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W1 98 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VFMADD132PD_ZMM_K1_ZMM_ZMMMT = 4730,
	/// @brief @c VFMSUB132PS zmm1 {k1}, zmm2, Sf32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 9A /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VFMSUB132PS_ZMM_K1_ZMM_ZMMMT = 4731,
	/// @brief @c VFMSUB132PD zmm1 {k1}, zmm2, Sf64(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W1 9A /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VFMSUB132PD_ZMM_K1_ZMM_ZMMMT = 4732,
	/// @brief @c VFNMADD132PS zmm1 {k1}, zmm2, Sf32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 9C /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VFNMADD132PS_ZMM_K1_ZMM_ZMMMT = 4733,
	/// @brief @c VFNMADD132PD zmm1 {k1}, zmm2, Sf64(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W1 9C /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VFNMADD132PD_ZMM_K1_ZMM_ZMMMT = 4734,
	/// @brief @c VFNMSUB132PS zmm1 {k1}, zmm2, Sf32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 9E /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VFNMSUB132PS_ZMM_K1_ZMM_ZMMMT = 4735,
	/// @brief @c VFNMSUB132PD zmm1 {k1}, zmm2, Sf64(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W1 9E /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VFNMSUB132PD_ZMM_K1_ZMM_ZMMMT = 4736,
	/// @brief @c VPSCATTERDD mvt {k1}, Di32(zmm1)
	/// @par
	/// @c MVEX.512.66.0F38.W0 A0 /vsib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPSCATTERDD_MVT_K1_ZMM = 4737,
	/// @brief @c VPSCATTERDQ mvt {k1}, Di64(zmm1)
	/// @par
	/// @c MVEX.512.66.0F38.W1 A0 /vsib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPSCATTERDQ_MVT_K1_ZMM = 4738,
	/// @brief @c VSCATTERDPS mvt {k1}, Df32(zmm1)
	/// @par
	/// @c MVEX.512.66.0F38.W0 A2 /vsib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VSCATTERDPS_MVT_K1_ZMM = 4739,
	/// @brief @c VSCATTERDPD mvt {k1}, Df64(zmm1)
	/// @par
	/// @c MVEX.512.66.0F38.W1 A2 /vsib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VSCATTERDPD_MVT_K1_ZMM = 4740,
	/// @brief @c VFMADD233PS zmm1 {k1}, zmm2, Sf32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 A4 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VFMADD233PS_ZMM_K1_ZMM_ZMMMT = 4741,
	/// @brief @c VFMADD213PS zmm1 {k1}, zmm2, Sf32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 A8 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VFMADD213PS_ZMM_K1_ZMM_ZMMMT = 4742,
	/// @brief @c VFMADD213PD zmm1 {k1}, zmm2, Sf64(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W1 A8 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VFMADD213PD_ZMM_K1_ZMM_ZMMMT = 4743,
	/// @brief @c VFMSUB213PS zmm1 {k1}, zmm2, Sf32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 AA /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VFMSUB213PS_ZMM_K1_ZMM_ZMMMT = 4744,
	/// @brief @c VFMSUB213PD zmm1 {k1}, zmm2, Sf64(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W1 AA /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VFMSUB213PD_ZMM_K1_ZMM_ZMMMT = 4745,
	/// @brief @c VFNMADD213PS zmm1 {k1}, zmm2, Sf32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 AC /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VFNMADD213PS_ZMM_K1_ZMM_ZMMMT = 4746,
	/// @brief @c VFNMADD213PD zmm1 {k1}, zmm2, Sf64(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W1 AC /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VFNMADD213PD_ZMM_K1_ZMM_ZMMMT = 4747,
	/// @brief @c VFNMSUB213PS zmm1 {k1}, zmm2, Sf32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 AE /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VFNMSUB213PS_ZMM_K1_ZMM_ZMMMT = 4748,
	/// @brief @c VFNMSUB213PD zmm1 {k1}, zmm2, Sf64(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W1 AE /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VFNMSUB213PD_ZMM_K1_ZMM_ZMMMT = 4749,
	/// @brief @c UNDOC zmm1 {k1}, mvt
	/// @par
	/// @c MVEX.512.66.0F38.W0 B0 /vsib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_MVT_512_66_0_F38_W0_B0 = 4750,
	/// @brief @c UNDOC zmm1 {k1}, mvt
	/// @par
	/// @c MVEX.512.66.0F38.W0 B2 /vsib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_MVT_512_66_0_F38_W0_B2 = 4751,
	/// @brief @c VPMADD233D zmm1 {k1}, zmm2, Si32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 B4 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPMADD233D_ZMM_K1_ZMM_ZMMMT = 4752,
	/// @brief @c VPMADD231D zmm1 {k1}, zmm2, Si32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 B5 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPMADD231D_ZMM_K1_ZMM_ZMMMT = 4753,
	/// @brief @c VFMADD231PS zmm1 {k1}, zmm2, Sf32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 B8 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VFMADD231PS_ZMM_K1_ZMM_ZMMMT = 4754,
	/// @brief @c VFMADD231PD zmm1 {k1}, zmm2, Sf64(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W1 B8 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VFMADD231PD_ZMM_K1_ZMM_ZMMMT = 4755,
	/// @brief @c VFMSUB231PS zmm1 {k1}, zmm2, Sf32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 BA /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VFMSUB231PS_ZMM_K1_ZMM_ZMMMT = 4756,
	/// @brief @c VFMSUB231PD zmm1 {k1}, zmm2, Sf64(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W1 BA /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VFMSUB231PD_ZMM_K1_ZMM_ZMMMT = 4757,
	/// @brief @c VFNMADD231PS zmm1 {k1}, zmm2, Sf32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 BC /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VFNMADD231PS_ZMM_K1_ZMM_ZMMMT = 4758,
	/// @brief @c VFNMADD231PD zmm1 {k1}, zmm2, Sf64(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W1 BC /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VFNMADD231PD_ZMM_K1_ZMM_ZMMMT = 4759,
	/// @brief @c VFNMSUB231PS zmm1 {k1}, zmm2, Sf32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 BE /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VFNMSUB231PS_ZMM_K1_ZMM_ZMMMT = 4760,
	/// @brief @c VFNMSUB231PD zmm1 {k1}, zmm2, Sf64(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W1 BE /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VFNMSUB231PD_ZMM_K1_ZMM_ZMMMT = 4761,
	/// @brief @c UNDOC zmm1 {k1}, mvt
	/// @par
	/// @c MVEX.512.66.0F38.W0 C0 /vsib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_MVT_512_66_0_F38_W0_C0 = 4762,
	/// @brief @c VGATHERPF0HINTDPS Uf32(mvt) {k1}
	/// @par
	/// @c MVEX.512.66.0F38.W0 C6 /0 /vsib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VGATHERPF0HINTDPS_MVT_K1 = 4763,
	/// @brief @c VGATHERPF0HINTDPD Uf64(mvt) {k1}
	/// @par
	/// @c MVEX.512.66.0F38.W1 C6 /0 /vsib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VGATHERPF0HINTDPD_MVT_K1 = 4764,
	/// @brief @c VGATHERPF0DPS Uf32(mvt) {k1}
	/// @par
	/// @c MVEX.512.66.0F38.W0 C6 /1 /vsib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VGATHERPF0DPS_MVT_K1 = 4765,
	/// @brief @c VGATHERPF1DPS Uf32(mvt) {k1}
	/// @par
	/// @c MVEX.512.66.0F38.W0 C6 /2 /vsib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VGATHERPF1DPS_MVT_K1 = 4766,
	/// @brief @c VSCATTERPF0HINTDPS Uf32(mvt) {k1}
	/// @par
	/// @c MVEX.512.66.0F38.W0 C6 /4 /vsib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VSCATTERPF0HINTDPS_MVT_K1 = 4767,
	/// @brief @c VSCATTERPF0HINTDPD Uf64(mvt) {k1}
	/// @par
	/// @c MVEX.512.66.0F38.W1 C6 /4 /vsib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VSCATTERPF0HINTDPD_MVT_K1 = 4768,
	/// @brief @c VSCATTERPF0DPS Uf32(mvt) {k1}
	/// @par
	/// @c MVEX.512.66.0F38.W0 C6 /5 /vsib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VSCATTERPF0DPS_MVT_K1 = 4769,
	/// @brief @c VSCATTERPF1DPS Uf32(mvt) {k1}
	/// @par
	/// @c MVEX.512.66.0F38.W0 C6 /6 /vsib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VSCATTERPF1DPS_MVT_K1 = 4770,
	/// @brief @c VEXP223PS zmm1 {k1}, zmm2/mt
	/// @par
	/// @c MVEX.512.66.0F38.W0 C8 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VEXP223PS_ZMM_K1_ZMMMT = 4771,
	/// @brief @c VLOG2PS zmm1 {k1}, zmm2/mt
	/// @par
	/// @c MVEX.512.66.0F38.W0 C9 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VLOG2PS_ZMM_K1_ZMMMT = 4772,
	/// @brief @c VRCP23PS zmm1 {k1}, zmm2/mt
	/// @par
	/// @c MVEX.512.66.0F38.W0 CA /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VRCP23PS_ZMM_K1_ZMMMT = 4773,
	/// @brief @c VRSQRT23PS zmm1 {k1}, zmm2/mt
	/// @par
	/// @c MVEX.512.66.0F38.W0 CB /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VRSQRT23PS_ZMM_K1_ZMMMT = 4774,
	/// @brief @c VADDSETSPS zmm1 {k1}, zmm2, Sf32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 CC /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VADDSETSPS_ZMM_K1_ZMM_ZMMMT = 4775,
	/// @brief @c VPADDSETSD zmm1 {k1}, zmm2, Si32(zmm3/mt)
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 CD /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPADDSETSD_ZMM_K1_ZMM_ZMMMT = 4776,
	/// @brief @c UNDOC zmm1 {k1}, zmm2, zmm3/mt
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 CE /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_ZMM_ZMMMT_512_66_0_F38_W0_CE = 4777,
	/// @brief @c UNDOC zmm1 {k1}, zmm2, zmm3/mt
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W1 CE /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_ZMM_ZMMMT_512_66_0_F38_W1_CE = 4778,
	/// @brief @c UNDOC zmm1 {k1}, zmm2, zmm3/mt
	/// @par
	/// @c MVEX.NDS.512.66.0F38.W0 CF /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_ZMM_ZMMMT_512_66_0_F38_W0_CF = 4779,
	/// @brief @c VLOADUNPACKLD zmm1 {k1}, Ui32(mt)
	/// @par
	/// @c MVEX.512.0F38.W0 D0 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VLOADUNPACKLD_ZMM_K1_MT = 4780,
	/// @brief @c VLOADUNPACKLQ zmm1 {k1}, Ui64(mt)
	/// @par
	/// @c MVEX.512.0F38.W1 D0 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VLOADUNPACKLQ_ZMM_K1_MT = 4781,
	/// @brief @c VPACKSTORELD mt {k1}, Di32(zmm1)
	/// @par
	/// @c MVEX.512.66.0F38.W0 D0 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPACKSTORELD_MT_K1_ZMM = 4782,
	/// @brief @c VPACKSTORELQ mt {k1}, Di64(zmm1)
	/// @par
	/// @c MVEX.512.66.0F38.W1 D0 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPACKSTORELQ_MT_K1_ZMM = 4783,
	/// @brief @c VLOADUNPACKLPS zmm1 {k1}, Uf32(mt)
	/// @par
	/// @c MVEX.512.0F38.W0 D1 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VLOADUNPACKLPS_ZMM_K1_MT = 4784,
	/// @brief @c VLOADUNPACKLPD zmm1 {k1}, Uf64(mt)
	/// @par
	/// @c MVEX.512.0F38.W1 D1 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VLOADUNPACKLPD_ZMM_K1_MT = 4785,
	/// @brief @c VPACKSTORELPS mt {k1}, Df32(zmm1)
	/// @par
	/// @c MVEX.512.66.0F38.W0 D1 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPACKSTORELPS_MT_K1_ZMM = 4786,
	/// @brief @c VPACKSTORELPD mt {k1}, Df64(zmm1)
	/// @par
	/// @c MVEX.512.66.0F38.W1 D1 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPACKSTORELPD_MT_K1_ZMM = 4787,
	/// @brief @c UNDOC zmm1 {k1}, zmm2/mt
	/// @par
	/// @c MVEX.512.0F38.W0 D2 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_ZMMMT_512_0_F38_W0_D2 = 4788,
	/// @brief @c UNDOC zmm1 {k1}, zmm2/mt
	/// @par
	/// @c MVEX.512.66.0F38.W0 D2 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_ZMMMT_512_66_0_F38_W0_D2 = 4789,
	/// @brief @c UNDOC zmm1 {k1}, zmm2/mt
	/// @par
	/// @c MVEX.512.0F38.W0 D3 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_ZMMMT_512_0_F38_W0_D3 = 4790,
	/// @brief @c VLOADUNPACKHD zmm1 {k1}, Ui32(mt)
	/// @par
	/// @c MVEX.512.0F38.W0 D4 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VLOADUNPACKHD_ZMM_K1_MT = 4791,
	/// @brief @c VLOADUNPACKHQ zmm1 {k1}, Ui64(mt)
	/// @par
	/// @c MVEX.512.0F38.W1 D4 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VLOADUNPACKHQ_ZMM_K1_MT = 4792,
	/// @brief @c VPACKSTOREHD mt {k1}, Di32(zmm1)
	/// @par
	/// @c MVEX.512.66.0F38.W0 D4 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPACKSTOREHD_MT_K1_ZMM = 4793,
	/// @brief @c VPACKSTOREHQ mt {k1}, Di64(zmm1)
	/// @par
	/// @c MVEX.512.66.0F38.W1 D4 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPACKSTOREHQ_MT_K1_ZMM = 4794,
	/// @brief @c VLOADUNPACKHPS zmm1 {k1}, Uf32(mt)
	/// @par
	/// @c MVEX.512.0F38.W0 D5 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VLOADUNPACKHPS_ZMM_K1_MT = 4795,
	/// @brief @c VLOADUNPACKHPD zmm1 {k1}, Uf64(mt)
	/// @par
	/// @c MVEX.512.0F38.W1 D5 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VLOADUNPACKHPD_ZMM_K1_MT = 4796,
	/// @brief @c VPACKSTOREHPS mt {k1}, Df32(zmm1)
	/// @par
	/// @c MVEX.512.66.0F38.W0 D5 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPACKSTOREHPS_MT_K1_ZMM = 4797,
	/// @brief @c VPACKSTOREHPD mt {k1}, Df64(zmm1)
	/// @par
	/// @c MVEX.512.66.0F38.W1 D5 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPACKSTOREHPD_MT_K1_ZMM = 4798,
	/// @brief @c UNDOC zmm1 {k1}, zmm2/mt
	/// @par
	/// @c MVEX.512.0F38.W0 D6 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_ZMMMT_512_0_F38_W0_D6 = 4799,
	/// @brief @c UNDOC zmm1 {k1}, zmm2/mt
	/// @par
	/// @c MVEX.512.66.0F38.W0 D6 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_ZMMMT_512_66_0_F38_W0_D6 = 4800,
	/// @brief @c UNDOC zmm1 {k1}, zmm2/mt
	/// @par
	/// @c MVEX.512.0F38.W0 D7 /r
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_ZMMMT_512_0_F38_W0_D7 = 4801,
	/// @brief @c VALIGND zmm1 {k1}, zmm2, zmm3/mt, imm8
	/// @par
	/// @c MVEX.NDS.512.66.0F3A.W0 03 /r ib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VALIGND_ZMM_K1_ZMM_ZMMMT_IMM8 = 4802,
	/// @brief @c VPERMF32X4 zmm1 {k1}, zmm2/mt, imm8
	/// @par
	/// @c MVEX.512.66.0F3A.W0 07 /r ib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPERMF32X4_ZMM_K1_ZMMMT_IMM8 = 4803,
	/// @brief @c VPCMPUD k2 {k1}, zmm1, Si32(zmm2/mt), imm8
	/// @par
	/// @c MVEX.NDS.512.66.0F3A.W0 1E /r ib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPCMPUD_KR_K1_ZMM_ZMMMT_IMM8 = 4804,
	/// @brief @c VPCMPD k2 {k1}, zmm1, Si32(zmm2/mt), imm8
	/// @par
	/// @c MVEX.NDS.512.66.0F3A.W0 1F /r ib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VPCMPD_KR_K1_ZMM_ZMMMT_IMM8 = 4805,
	/// @brief @c VGETMANTPS zmm1 {k1}, Sf32(zmm2/mt), imm8
	/// @par
	/// @c MVEX.512.66.0F3A.W0 26 /r ib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VGETMANTPS_ZMM_K1_ZMMMT_IMM8 = 4806,
	/// @brief @c VGETMANTPD zmm1 {k1}, Sf64(zmm2/mt), imm8
	/// @par
	/// @c MVEX.512.66.0F3A.W1 26 /r ib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VGETMANTPD_ZMM_K1_ZMMMT_IMM8 = 4807,
	/// @brief @c VRNDFXPNTPS zmm1 {k1}, Sf32(zmm2/mt), imm8
	/// @par
	/// @c MVEX.512.66.0F3A.W0 52 /r ib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VRNDFXPNTPS_ZMM_K1_ZMMMT_IMM8 = 4808,
	/// @brief @c VRNDFXPNTPD zmm1 {k1}, Sf64(zmm2/mt), imm8
	/// @par
	/// @c MVEX.512.66.0F3A.W1 52 /r ib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VRNDFXPNTPD_ZMM_K1_ZMMMT_IMM8 = 4809,
	/// @brief @c VCVTFXPNTUDQ2PS zmm1 {k1}, Si32(zmm2/mt), imm8
	/// @par
	/// @c MVEX.512.0F3A.W0 CA /r ib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VCVTFXPNTUDQ2PS_ZMM_K1_ZMMMT_IMM8 = 4810,
	/// @brief @c VCVTFXPNTPS2UDQ zmm1 {k1}, Sf32(zmm2/mt), imm8
	/// @par
	/// @c MVEX.512.66.0F3A.W0 CA /r ib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VCVTFXPNTPS2UDQ_ZMM_K1_ZMMMT_IMM8 = 4811,
	/// @brief @c VCVTFXPNTPD2UDQ zmm1 {k1}, Sf64(zmm2/mt), imm8
	/// @par
	/// @c MVEX.512.F2.0F3A.W1 CA /r ib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VCVTFXPNTPD2UDQ_ZMM_K1_ZMMMT_IMM8 = 4812,
	/// @brief @c VCVTFXPNTDQ2PS zmm1 {k1}, Si32(zmm2/mt), imm8
	/// @par
	/// @c MVEX.512.0F3A.W0 CB /r ib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VCVTFXPNTDQ2PS_ZMM_K1_ZMMMT_IMM8 = 4813,
	/// @brief @c VCVTFXPNTPS2DQ zmm1 {k1}, Sf32(zmm2/mt), imm8
	/// @par
	/// @c MVEX.512.66.0F3A.W0 CB /r ib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VCVTFXPNTPS2DQ_ZMM_K1_ZMMMT_IMM8 = 4814,
	/// @brief @c UNDOC zmm1 {k1}, zmm2/mt, imm8
	/// @par
	/// @c MVEX.512.66.0F3A.W0 D0 /r ib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_ZMMMT_IMM8_512_66_0_F3_A_W0_D0 = 4815,
	/// @brief @c UNDOC zmm1 {k1}, zmm2/mt, imm8
	/// @par
	/// @c MVEX.512.66.0F3A.W0 D1 /r ib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_UNDOC_ZMM_K1_ZMMMT_IMM8_512_66_0_F3_A_W0_D1 = 4816,
	/// @brief @c VCVTFXPNTPD2DQ zmm1 {k1}, Sf64(zmm2/mt), imm8
	/// @par
	/// @c MVEX.512.F2.0F3A.W1 E6 /r ib
	/// @par
	/// @c KNC
	/// @par
	/// @c 64-bit
	MVEX_VCVTFXPNTPD2DQ_ZMM_K1_ZMMMT_IMM8 = 4817,
	/// @brief @c UNDOC
	/// @par
	/// @c a16 F3 0F A6 F0
	/// @par
	/// @c PADLOCK_UNDOC
	/// @par
	/// @c 16/32-bit
	VIA_UNDOC_F30_FA6_F0_16 = 4818,
	/// @brief @c UNDOC
	/// @par
	/// @c a32 F3 0F A6 F0
	/// @par
	/// @c PADLOCK_UNDOC
	/// @par
	/// @c 16/32/64-bit
	VIA_UNDOC_F30_FA6_F0_32 = 4819,
	/// @brief @c UNDOC
	/// @par
	/// @c a64 F3 0F A6 F0
	/// @par
	/// @c PADLOCK_UNDOC
	/// @par
	/// @c 64-bit
	VIA_UNDOC_F30_FA6_F0_64 = 4820,
	/// @brief @c UNDOC
	/// @par
	/// @c a16 F3 0F A6 F8
	/// @par
	/// @c PADLOCK_UNDOC
	/// @par
	/// @c 16/32-bit
	VIA_UNDOC_F30_FA6_F8_16 = 4821,
	/// @brief @c UNDOC
	/// @par
	/// @c a32 F3 0F A6 F8
	/// @par
	/// @c PADLOCK_UNDOC
	/// @par
	/// @c 16/32/64-bit
	VIA_UNDOC_F30_FA6_F8_32 = 4822,
	/// @brief @c UNDOC
	/// @par
	/// @c a64 F3 0F A6 F8
	/// @par
	/// @c PADLOCK_UNDOC
	/// @par
	/// @c 64-bit
	VIA_UNDOC_F30_FA6_F8_64 = 4823,
	/// @brief @c XSHA512
	/// @par
	/// @c a16 F3 0F A6 E0
	/// @par
	/// @c PADLOCK_PHE
	/// @par
	/// @c 16/32-bit
	XSHA512_16 = 4824,
	/// @brief @c XSHA512
	/// @par
	/// @c a32 F3 0F A6 E0
	/// @par
	/// @c PADLOCK_PHE
	/// @par
	/// @c 16/32/64-bit
	XSHA512_32 = 4825,
	/// @brief @c XSHA512
	/// @par
	/// @c a64 F3 0F A6 E0
	/// @par
	/// @c PADLOCK_PHE
	/// @par
	/// @c 64-bit
	XSHA512_64 = 4826,
	/// @brief @c XSTORE_ALT
	/// @par
	/// @c a16 F3 0F A7 F8
	/// @par
	/// @c PADLOCK_RNG
	/// @par
	/// @c 16/32-bit
	XSTORE_ALT_16 = 4827,
	/// @brief @c XSTORE_ALT
	/// @par
	/// @c a32 F3 0F A7 F8
	/// @par
	/// @c PADLOCK_RNG
	/// @par
	/// @c 16/32/64-bit
	XSTORE_ALT_32 = 4828,
	/// @brief @c XSTORE_ALT
	/// @par
	/// @c a64 F3 0F A7 F8
	/// @par
	/// @c PADLOCK_RNG
	/// @par
	/// @c 64-bit
	XSTORE_ALT_64 = 4829,
	/// @brief @c XSHA512_ALT
	/// @par
	/// @c a16 F3 0F A6 D8
	/// @par
	/// @c PADLOCK_PHE
	/// @par
	/// @c 16/32-bit
	XSHA512_ALT_16 = 4830,
	/// @brief @c XSHA512_ALT
	/// @par
	/// @c a32 F3 0F A6 D8
	/// @par
	/// @c PADLOCK_PHE
	/// @par
	/// @c 16/32/64-bit
	XSHA512_ALT_32 = 4831,
	/// @brief @c XSHA512_ALT
	/// @par
	/// @c a64 F3 0F A6 D8
	/// @par
	/// @c PADLOCK_PHE
	/// @par
	/// @c 64-bit
	XSHA512_ALT_64 = 4832,
	/// @brief A zero-sized instruction. Can be used as a label.
	ZERO_BYTES = 4833,
	/// @brief @c WRMSRNS
	/// @par
	/// @c NP 0F 01 C6
	/// @par
	/// @c WRMSRNS
	/// @par
	/// @c 16/32/64-bit
	WRMSRNS = 4834,
	/// @brief @c WRMSRLIST
	/// @par
	/// @c F3 0F 01 C6
	/// @par
	/// @c MSRLIST
	/// @par
	/// @c 64-bit
	WRMSRLIST = 4835,
	/// @brief @c RDMSRLIST
	/// @par
	/// @c F2 0F 01 C6
	/// @par
	/// @c MSRLIST
	/// @par
	/// @c 64-bit
	RDMSRLIST = 4836,
	/// @brief @c RMPQUERY
	/// @par
	/// @c F3 0F 01 FD
	/// @par
	/// @c RMPQUERY
	/// @par
	/// @c 64-bit
	RMPQUERY = 4837,
	/// @brief @c PREFETCHIT1 m8
	/// @par
	/// @c 0F 18 /6
	/// @par
	/// @c PREFETCHITI
	/// @par
	/// @c 16/32/64-bit
	PREFETCHIT1_M8 = 4838,
	/// @brief @c PREFETCHIT0 m8
	/// @par
	/// @c 0F 18 /7
	/// @par
	/// @c PREFETCHITI
	/// @par
	/// @c 16/32/64-bit
	PREFETCHIT0_M8 = 4839,
	/// @brief @c AADD m32, r32
	/// @par
	/// @c NP 0F 38 FC !(11):rrr:bbb
	/// @par
	/// @c RAO-INT
	/// @par
	/// @c 16/32/64-bit
	AADD_M32_R32 = 4840,
	/// @brief @c AADD m64, r64
	/// @par
	/// @c NP o64 0F 38 FC !(11):rrr:bbb
	/// @par
	/// @c RAO-INT
	/// @par
	/// @c 64-bit
	AADD_M64_R64 = 4841,
	/// @brief @c AAND m32, r32
	/// @par
	/// @c 66 0F 38 FC !(11):rrr:bbb
	/// @par
	/// @c RAO-INT
	/// @par
	/// @c 16/32/64-bit
	AAND_M32_R32 = 4842,
	/// @brief @c AAND m64, r64
	/// @par
	/// @c 66 o64 0F 38 FC !(11):rrr:bbb
	/// @par
	/// @c RAO-INT
	/// @par
	/// @c 64-bit
	AAND_M64_R64 = 4843,
	/// @brief @c AXOR m32, r32
	/// @par
	/// @c F3 0F 38 FC !(11):rrr:bbb
	/// @par
	/// @c RAO-INT
	/// @par
	/// @c 16/32/64-bit
	AXOR_M32_R32 = 4844,
	/// @brief @c AXOR m64, r64
	/// @par
	/// @c F3 o64 0F 38 FC !(11):rrr:bbb
	/// @par
	/// @c RAO-INT
	/// @par
	/// @c 64-bit
	AXOR_M64_R64 = 4845,
	/// @brief @c AOR m32, r32
	/// @par
	/// @c F2 0F 38 FC !(11):rrr:bbb
	/// @par
	/// @c RAO-INT
	/// @par
	/// @c 16/32/64-bit
	AOR_M32_R32 = 4846,
	/// @brief @c AOR m64, r64
	/// @par
	/// @c F2 o64 0F 38 FC !(11):rrr:bbb
	/// @par
	/// @c RAO-INT
	/// @par
	/// @c 64-bit
	AOR_M64_R64 = 4847,
	/// @brief @c VPDPBUUD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.0F38.W0 50 /r
	/// @par
	/// @c AVX-VNNI-INT8
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPBUUD_XMM_XMM_XMMM128 = 4848,
	/// @brief @c VPDPBUUD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.0F38.W0 50 /r
	/// @par
	/// @c AVX-VNNI-INT8
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPBUUD_YMM_YMM_YMMM256 = 4849,
	/// @brief @c VPDPBSUD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.F3.0F38.W0 50 /r
	/// @par
	/// @c AVX-VNNI-INT8
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPBSUD_XMM_XMM_XMMM128 = 4850,
	/// @brief @c VPDPBSUD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.F3.0F38.W0 50 /r
	/// @par
	/// @c AVX-VNNI-INT8
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPBSUD_YMM_YMM_YMMM256 = 4851,
	/// @brief @c VPDPBSSD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.F2.0F38.W0 50 /r
	/// @par
	/// @c AVX-VNNI-INT8
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPBSSD_XMM_XMM_XMMM128 = 4852,
	/// @brief @c VPDPBSSD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.F2.0F38.W0 50 /r
	/// @par
	/// @c AVX-VNNI-INT8
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPBSSD_YMM_YMM_YMMM256 = 4853,
	/// @brief @c VPDPBUUDS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.0F38.W0 51 /r
	/// @par
	/// @c AVX-VNNI-INT8
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPBUUDS_XMM_XMM_XMMM128 = 4854,
	/// @brief @c VPDPBUUDS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.0F38.W0 51 /r
	/// @par
	/// @c AVX-VNNI-INT8
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPBUUDS_YMM_YMM_YMMM256 = 4855,
	/// @brief @c VPDPBSUDS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.F3.0F38.W0 51 /r
	/// @par
	/// @c AVX-VNNI-INT8
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPBSUDS_XMM_XMM_XMMM128 = 4856,
	/// @brief @c VPDPBSUDS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.F3.0F38.W0 51 /r
	/// @par
	/// @c AVX-VNNI-INT8
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPBSUDS_YMM_YMM_YMMM256 = 4857,
	/// @brief @c VPDPBSSDS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.F2.0F38.W0 51 /r
	/// @par
	/// @c AVX-VNNI-INT8
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPBSSDS_XMM_XMM_XMMM128 = 4858,
	/// @brief @c VPDPBSSDS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.F2.0F38.W0 51 /r
	/// @par
	/// @c AVX-VNNI-INT8
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPBSSDS_YMM_YMM_YMMM256 = 4859,
	/// @brief @c TDPFP16PS tmm1, tmm2, tmm3
	/// @par
	/// @c VEX.128.F2.0F38.W0 5C 11:rrr:bbb
	/// @par
	/// @c AMX-FP16
	/// @par
	/// @c 64-bit
	VEX_TDPFP16PS_TMM_TMM_TMM = 4860,
	/// @brief @c VCVTNEPS2BF16 xmm1, xmm2/m128
	/// @par
	/// @c VEX.128.F3.0F38.W0 72 /r
	/// @par
	/// @c AVX-NE-CONVERT
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTNEPS2BF16_XMM_XMMM128 = 4861,
	/// @brief @c VCVTNEPS2BF16 xmm1, ymm2/m256
	/// @par
	/// @c VEX.256.F3.0F38.W0 72 /r
	/// @par
	/// @c AVX-NE-CONVERT
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTNEPS2BF16_XMM_YMMM256 = 4862,
	/// @brief @c VCVTNEOPH2PS xmm1, m128
	/// @par
	/// @c VEX.128.0F38.W0 B0 !(11):rrr:bbb
	/// @par
	/// @c AVX-NE-CONVERT
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTNEOPH2PS_XMM_M128 = 4863,
	/// @brief @c VCVTNEOPH2PS ymm1, m256
	/// @par
	/// @c VEX.256.0F38.W0 B0 !(11):rrr:bbb
	/// @par
	/// @c AVX-NE-CONVERT
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTNEOPH2PS_YMM_M256 = 4864,
	/// @brief @c VCVTNEEPH2PS xmm1, m128
	/// @par
	/// @c VEX.128.66.0F38.W0 B0 !(11):rrr:bbb
	/// @par
	/// @c AVX-NE-CONVERT
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTNEEPH2PS_XMM_M128 = 4865,
	/// @brief @c VCVTNEEPH2PS ymm1, m256
	/// @par
	/// @c VEX.256.66.0F38.W0 B0 !(11):rrr:bbb
	/// @par
	/// @c AVX-NE-CONVERT
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTNEEPH2PS_YMM_M256 = 4866,
	/// @brief @c VCVTNEEBF162PS xmm1, m128
	/// @par
	/// @c VEX.128.F3.0F38.W0 B0 !(11):rrr:bbb
	/// @par
	/// @c AVX-NE-CONVERT
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTNEEBF162PS_XMM_M128 = 4867,
	/// @brief @c VCVTNEEBF162PS ymm1, m256
	/// @par
	/// @c VEX.256.F3.0F38.W0 B0 !(11):rrr:bbb
	/// @par
	/// @c AVX-NE-CONVERT
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTNEEBF162PS_YMM_M256 = 4868,
	/// @brief @c VCVTNEOBF162PS xmm1, m128
	/// @par
	/// @c VEX.128.F2.0F38.W0 B0 !(11):rrr:bbb
	/// @par
	/// @c AVX-NE-CONVERT
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTNEOBF162PS_XMM_M128 = 4869,
	/// @brief @c VCVTNEOBF162PS ymm1, m256
	/// @par
	/// @c VEX.256.F2.0F38.W0 B0 !(11):rrr:bbb
	/// @par
	/// @c AVX-NE-CONVERT
	/// @par
	/// @c 16/32/64-bit
	VEX_VCVTNEOBF162PS_YMM_M256 = 4870,
	/// @brief @c VBCSTNESH2PS xmm1, m16
	/// @par
	/// @c VEX.128.66.0F38.W0 B1 !(11):rrr:bbb
	/// @par
	/// @c AVX-NE-CONVERT
	/// @par
	/// @c 16/32/64-bit
	VEX_VBCSTNESH2PS_XMM_M16 = 4871,
	/// @brief @c VBCSTNESH2PS ymm1, m16
	/// @par
	/// @c VEX.256.66.0F38.W0 B1 !(11):rrr:bbb
	/// @par
	/// @c AVX-NE-CONVERT
	/// @par
	/// @c 16/32/64-bit
	VEX_VBCSTNESH2PS_YMM_M16 = 4872,
	/// @brief @c VBCSTNEBF162PS xmm1, m16
	/// @par
	/// @c VEX.128.F3.0F38.W0 B1 !(11):rrr:bbb
	/// @par
	/// @c AVX-NE-CONVERT
	/// @par
	/// @c 16/32/64-bit
	VEX_VBCSTNEBF162PS_XMM_M16 = 4873,
	/// @brief @c VBCSTNEBF162PS ymm1, m16
	/// @par
	/// @c VEX.256.F3.0F38.W0 B1 !(11):rrr:bbb
	/// @par
	/// @c AVX-NE-CONVERT
	/// @par
	/// @c 16/32/64-bit
	VEX_VBCSTNEBF162PS_YMM_M16 = 4874,
	/// @brief @c VPMADD52LUQ xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W1 B4 /r
	/// @par
	/// @c AVX-IFMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMADD52LUQ_XMM_XMM_XMMM128 = 4875,
	/// @brief @c VPMADD52LUQ ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W1 B4 /r
	/// @par
	/// @c AVX-IFMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMADD52LUQ_YMM_YMM_YMMM256 = 4876,
	/// @brief @c VPMADD52HUQ xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W1 B5 /r
	/// @par
	/// @c AVX-IFMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMADD52HUQ_XMM_XMM_XMMM128 = 4877,
	/// @brief @c VPMADD52HUQ ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W1 B5 /r
	/// @par
	/// @c AVX-IFMA
	/// @par
	/// @c 16/32/64-bit
	VEX_VPMADD52HUQ_YMM_YMM_YMMM256 = 4878,
	/// @brief @c CMPOXADD m32, r32, r32
	/// @par
	/// @c VEX.128.66.0F38.W0 E0 !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPOXADD_M32_R32_R32 = 4879,
	/// @brief @c CMPOXADD m64, r64, r64
	/// @par
	/// @c VEX.128.66.0F38.W1 E0 !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPOXADD_M64_R64_R64 = 4880,
	/// @brief @c CMPNOXADD m32, r32, r32
	/// @par
	/// @c VEX.128.66.0F38.W0 E1 !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPNOXADD_M32_R32_R32 = 4881,
	/// @brief @c CMPNOXADD m64, r64, r64
	/// @par
	/// @c VEX.128.66.0F38.W1 E1 !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPNOXADD_M64_R64_R64 = 4882,
	/// @brief @c CMPBXADD m32, r32, r32
	/// @par
	/// @c VEX.128.66.0F38.W0 E2 !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPBXADD_M32_R32_R32 = 4883,
	/// @brief @c CMPBXADD m64, r64, r64
	/// @par
	/// @c VEX.128.66.0F38.W1 E2 !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPBXADD_M64_R64_R64 = 4884,
	/// @brief @c CMPNBXADD m32, r32, r32
	/// @par
	/// @c VEX.128.66.0F38.W0 E3 !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPNBXADD_M32_R32_R32 = 4885,
	/// @brief @c CMPNBXADD m64, r64, r64
	/// @par
	/// @c VEX.128.66.0F38.W1 E3 !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPNBXADD_M64_R64_R64 = 4886,
	/// @brief @c CMPZXADD m32, r32, r32
	/// @par
	/// @c VEX.128.66.0F38.W0 E4 !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPZXADD_M32_R32_R32 = 4887,
	/// @brief @c CMPZXADD m64, r64, r64
	/// @par
	/// @c VEX.128.66.0F38.W1 E4 !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPZXADD_M64_R64_R64 = 4888,
	/// @brief @c CMPNZXADD m32, r32, r32
	/// @par
	/// @c VEX.128.66.0F38.W0 E5 !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPNZXADD_M32_R32_R32 = 4889,
	/// @brief @c CMPNZXADD m64, r64, r64
	/// @par
	/// @c VEX.128.66.0F38.W1 E5 !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPNZXADD_M64_R64_R64 = 4890,
	/// @brief @c CMPBEXADD m32, r32, r32
	/// @par
	/// @c VEX.128.66.0F38.W0 E6 !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPBEXADD_M32_R32_R32 = 4891,
	/// @brief @c CMPBEXADD m64, r64, r64
	/// @par
	/// @c VEX.128.66.0F38.W1 E6 !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPBEXADD_M64_R64_R64 = 4892,
	/// @brief @c CMPNBEXADD m32, r32, r32
	/// @par
	/// @c VEX.128.66.0F38.W0 E7 !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPNBEXADD_M32_R32_R32 = 4893,
	/// @brief @c CMPNBEXADD m64, r64, r64
	/// @par
	/// @c VEX.128.66.0F38.W1 E7 !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPNBEXADD_M64_R64_R64 = 4894,
	/// @brief @c CMPSXADD m32, r32, r32
	/// @par
	/// @c VEX.128.66.0F38.W0 E8 !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPSXADD_M32_R32_R32 = 4895,
	/// @brief @c CMPSXADD m64, r64, r64
	/// @par
	/// @c VEX.128.66.0F38.W1 E8 !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPSXADD_M64_R64_R64 = 4896,
	/// @brief @c CMPNSXADD m32, r32, r32
	/// @par
	/// @c VEX.128.66.0F38.W0 E9 !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPNSXADD_M32_R32_R32 = 4897,
	/// @brief @c CMPNSXADD m64, r64, r64
	/// @par
	/// @c VEX.128.66.0F38.W1 E9 !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPNSXADD_M64_R64_R64 = 4898,
	/// @brief @c CMPPXADD m32, r32, r32
	/// @par
	/// @c VEX.128.66.0F38.W0 EA !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPPXADD_M32_R32_R32 = 4899,
	/// @brief @c CMPPXADD m64, r64, r64
	/// @par
	/// @c VEX.128.66.0F38.W1 EA !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPPXADD_M64_R64_R64 = 4900,
	/// @brief @c CMPNPXADD m32, r32, r32
	/// @par
	/// @c VEX.128.66.0F38.W0 EB !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPNPXADD_M32_R32_R32 = 4901,
	/// @brief @c CMPNPXADD m64, r64, r64
	/// @par
	/// @c VEX.128.66.0F38.W1 EB !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPNPXADD_M64_R64_R64 = 4902,
	/// @brief @c CMPLXADD m32, r32, r32
	/// @par
	/// @c VEX.128.66.0F38.W0 EC !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPLXADD_M32_R32_R32 = 4903,
	/// @brief @c CMPLXADD m64, r64, r64
	/// @par
	/// @c VEX.128.66.0F38.W1 EC !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPLXADD_M64_R64_R64 = 4904,
	/// @brief @c CMPNLXADD m32, r32, r32
	/// @par
	/// @c VEX.128.66.0F38.W0 ED !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPNLXADD_M32_R32_R32 = 4905,
	/// @brief @c CMPNLXADD m64, r64, r64
	/// @par
	/// @c VEX.128.66.0F38.W1 ED !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPNLXADD_M64_R64_R64 = 4906,
	/// @brief @c CMPLEXADD m32, r32, r32
	/// @par
	/// @c VEX.128.66.0F38.W0 EE !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPLEXADD_M32_R32_R32 = 4907,
	/// @brief @c CMPLEXADD m64, r64, r64
	/// @par
	/// @c VEX.128.66.0F38.W1 EE !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPLEXADD_M64_R64_R64 = 4908,
	/// @brief @c CMPNLEXADD m32, r32, r32
	/// @par
	/// @c VEX.128.66.0F38.W0 EF !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPNLEXADD_M32_R32_R32 = 4909,
	/// @brief @c CMPNLEXADD m64, r64, r64
	/// @par
	/// @c VEX.128.66.0F38.W1 EF !(11):rrr:bbb
	/// @par
	/// @c CMPCCXADD
	/// @par
	/// @c 64-bit
	VEX_CMPNLEXADD_M64_R64_R64 = 4910,
	/// @brief @c TCMMRLFP16PS tmm1, tmm2, tmm3
	/// @par
	/// @c VEX.128.0F38.W0 6C 11:rrr:bbb
	/// @par
	/// @c AMX-COMPLEX
	/// @par
	/// @c 64-bit
	VEX_TCMMRLFP16PS_TMM_TMM_TMM = 4911,
	/// @brief @c TCMMIMFP16PS tmm1, tmm2, tmm3
	/// @par
	/// @c VEX.128.66.0F38.W0 6C 11:rrr:bbb
	/// @par
	/// @c AMX-COMPLEX
	/// @par
	/// @c 64-bit
	VEX_TCMMIMFP16PS_TMM_TMM_TMM = 4912,
	/// @brief @c PBNDKB
	/// @par
	/// @c NP 0F 01 C7
	/// @par
	/// @c TSE
	/// @par
	/// @c 64-bit
	PBNDKB = 4913,
	/// @brief @c VSHA512RNDS2 ymm1, ymm2, xmm3
	/// @par
	/// @c VEX.256.F2.0F38.W0 CB 11:rrr:bbb
	/// @par
	/// @c AVX and SHA512
	/// @par
	/// @c 16/32/64-bit
	VEX_VSHA512RNDS2_YMM_YMM_XMM = 4914,
	/// @brief @c VSHA512MSG1 ymm1, xmm2
	/// @par
	/// @c VEX.256.F2.0F38.W0 CC 11:rrr:bbb
	/// @par
	/// @c AVX and SHA512
	/// @par
	/// @c 16/32/64-bit
	VEX_VSHA512MSG1_YMM_XMM = 4915,
	/// @brief @c VSHA512MSG2 ymm1, ymm2
	/// @par
	/// @c VEX.256.F2.0F38.W0 CD 11:rrr:bbb
	/// @par
	/// @c AVX and SHA512
	/// @par
	/// @c 16/32/64-bit
	VEX_VSHA512MSG2_YMM_YMM = 4916,
	/// @brief @c VPDPWUUD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.0F38.W0 D2 /r
	/// @par
	/// @c AVX-VNNI-INT16
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPWUUD_XMM_XMM_XMMM128 = 4917,
	/// @brief @c VPDPWUUD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.0F38.W0 D2 /r
	/// @par
	/// @c AVX-VNNI-INT16
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPWUUD_YMM_YMM_YMMM256 = 4918,
	/// @brief @c VPDPWUSD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 D2 /r
	/// @par
	/// @c AVX-VNNI-INT16
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPWUSD_XMM_XMM_XMMM128 = 4919,
	/// @brief @c VPDPWUSD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 D2 /r
	/// @par
	/// @c AVX-VNNI-INT16
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPWUSD_YMM_YMM_YMMM256 = 4920,
	/// @brief @c VPDPWSUD xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.F3.0F38.W0 D2 /r
	/// @par
	/// @c AVX-VNNI-INT16
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPWSUD_XMM_XMM_XMMM128 = 4921,
	/// @brief @c VPDPWSUD ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.F3.0F38.W0 D2 /r
	/// @par
	/// @c AVX-VNNI-INT16
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPWSUD_YMM_YMM_YMMM256 = 4922,
	/// @brief @c VPDPWUUDS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.0F38.W0 D3 /r
	/// @par
	/// @c AVX-VNNI-INT16
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPWUUDS_XMM_XMM_XMMM128 = 4923,
	/// @brief @c VPDPWUUDS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.0F38.W0 D3 /r
	/// @par
	/// @c AVX-VNNI-INT16
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPWUUDS_YMM_YMM_YMMM256 = 4924,
	/// @brief @c VPDPWUSDS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 D3 /r
	/// @par
	/// @c AVX-VNNI-INT16
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPWUSDS_XMM_XMM_XMMM128 = 4925,
	/// @brief @c VPDPWUSDS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.66.0F38.W0 D3 /r
	/// @par
	/// @c AVX-VNNI-INT16
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPWUSDS_YMM_YMM_YMMM256 = 4926,
	/// @brief @c VPDPWSUDS xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.F3.0F38.W0 D3 /r
	/// @par
	/// @c AVX-VNNI-INT16
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPWSUDS_XMM_XMM_XMMM128 = 4927,
	/// @brief @c VPDPWSUDS ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.F3.0F38.W0 D3 /r
	/// @par
	/// @c AVX-VNNI-INT16
	/// @par
	/// @c 16/32/64-bit
	VEX_VPDPWSUDS_YMM_YMM_YMMM256 = 4928,
	/// @brief @c VSM3MSG1 xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.0F38.W0 DA /r
	/// @par
	/// @c AVX and SM3
	/// @par
	/// @c 16/32/64-bit
	VEX_VSM3MSG1_XMM_XMM_XMMM128 = 4929,
	/// @brief @c VSM3MSG2 xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.66.0F38.W0 DA /r
	/// @par
	/// @c AVX and SM3
	/// @par
	/// @c 16/32/64-bit
	VEX_VSM3MSG2_XMM_XMM_XMMM128 = 4930,
	/// @brief @c VSM4KEY4 xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.F3.0F38.W0 DA /r
	/// @par
	/// @c AVX and SM4
	/// @par
	/// @c 16/32/64-bit
	VEX_VSM4KEY4_XMM_XMM_XMMM128 = 4931,
	/// @brief @c VSM4KEY4 ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.F3.0F38.W0 DA /r
	/// @par
	/// @c AVX and SM4
	/// @par
	/// @c 16/32/64-bit
	VEX_VSM4KEY4_YMM_YMM_YMMM256 = 4932,
	/// @brief @c VSM4RNDS4 xmm1, xmm2, xmm3/m128
	/// @par
	/// @c VEX.128.F2.0F38.W0 DA /r
	/// @par
	/// @c AVX and SM4
	/// @par
	/// @c 16/32/64-bit
	VEX_VSM4RNDS4_XMM_XMM_XMMM128 = 4933,
	/// @brief @c VSM4RNDS4 ymm1, ymm2, ymm3/m256
	/// @par
	/// @c VEX.256.F2.0F38.W0 DA /r
	/// @par
	/// @c AVX and SM4
	/// @par
	/// @c 16/32/64-bit
	VEX_VSM4RNDS4_YMM_YMM_YMMM256 = 4934,
	/// @brief @c VSM3RNDS2 xmm1, xmm2, xmm3/m128, imm8
	/// @par
	/// @c VEX.128.66.0F3A.W0 DE /r ib
	/// @par
	/// @c AVX and SM3
	/// @par
	/// @c 16/32/64-bit
	VEX_VSM3RNDS2_XMM_XMM_XMMM128_IMM8 = 4935
};

/// @brief Number of Code enum values.
constexpr std::size_t CODE_COUNT = 4936;

} // namespace iced_x86

#endif // ICED_X86_CODE_HPP
