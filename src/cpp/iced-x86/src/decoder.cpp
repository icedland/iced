// SPDX-License-Identifier: MIT
// Copyright (C) 2018-present iced project and contributors

// ‚ö†Ô∏èThis file was generated by GENERATOR!ü¶π‚Äç‚ôÇÔ∏è

#include "iced_x86/decoder.hpp"
#include "iced_x86/internal/table_deserializer.hpp"

#include <algorithm>

namespace iced_x86 {

#if ICED_X86_CONSTEXPR_HANDLERS
// Constexpr tables - zero runtime initialization overhead
const Decoder::Tables& Decoder::get_tables() {
	// Return reference to constexpr tables
	// Note: Can't use constexpr here because std::span's constructor may not be constexpr
	// in all implementations, but the underlying arrays are compile-time constants
	static const Tables tables{
		internal::constexpr_handlers::legacy_handlers_map0,
		internal::constexpr_handlers::legacy_handlers_0f,
		internal::constexpr_handlers::legacy_handlers_0f38,
		internal::constexpr_handlers::legacy_handlers_0f3a,
		internal::constexpr_handlers::vex_handlers_0f,
		internal::constexpr_handlers::vex_handlers_0f38,
		internal::constexpr_handlers::vex_handlers_0f3a,
		internal::constexpr_handlers::evex_handlers_0f,
		internal::constexpr_handlers::evex_handlers_0f38,
		internal::constexpr_handlers::evex_handlers_0f3a,
		internal::constexpr_handlers::evex_handlers_map5,
		internal::constexpr_handlers::evex_handlers_map6,
		internal::constexpr_handlers::xop_handlers_map8,
		internal::constexpr_handlers::xop_handlers_map9,
		internal::constexpr_handlers::xop_handlers_map10,
		internal::constexpr_handlers::mvex_handlers_0f,
		internal::constexpr_handlers::mvex_handlers_0f38,
		internal::constexpr_handlers::mvex_handlers_0f3a
	};
	return tables;
}
#else
// Runtime-deserialized tables - Meyers singleton
const Decoder::Tables& Decoder::get_tables() {
	// Meyers singleton - thread-safe in C++11 and later
	static Tables tables = []() {
		Tables t;
		t.handlers_map0 = internal::read_legacy_tables();

		auto vex_tables = internal::read_vex_tables();
		if ( vex_tables.size() >= 3 ) {
		  t.handlers_vex_0f = std::move( vex_tables[0] );
		  t.handlers_vex_0f38 = std::move( vex_tables[1] );
		  t.handlers_vex_0f3a = std::move( vex_tables[2] );
		}

		auto evex_tables = internal::read_evex_tables();
		if ( evex_tables.size() >= 5 ) {
		  t.handlers_evex_0f = std::move( evex_tables[0] );
		  t.handlers_evex_0f38 = std::move( evex_tables[1] );
		  t.handlers_evex_0f3a = std::move( evex_tables[2] );
		  t.handlers_evex_map5 = std::move( evex_tables[3] );
		  t.handlers_evex_map6 = std::move( evex_tables[4] );
		}

		return t;
	}();
	return tables;
}
#endif // !ICED_X86_CONSTEXPR_HANDLERS

Decoder::Decoder(
  uint32_t bitness,
  std::span< const uint8_t > data,
  uint64_t ip,
  DecoderOptions::Value options
) noexcept
  : data_ptr_( data.data() )
  , data_ptr_end_( data.data() + data.size() )
  , max_data_ptr_( data.data() )
  , instr_start_ptr_( data.data() )
  , data_( data )
  , ip_( ip )
  , bitness_( bitness )
  , options_( options )
{
	// Set default sizes based on bitness
	switch ( bitness ) {
	  case 64:
	    default_operand_size_ = OpSize::SIZE32;
	    default_inverted_operand_size_ = OpSize::SIZE16;
	    default_address_size_ = OpSize::SIZE64;
	    default_inverted_address_size_ = OpSize::SIZE32;
	    default_code_size_ = CodeSize::CODE64;
	    break;
	  case 32:
	    default_operand_size_ = OpSize::SIZE32;
	    default_inverted_operand_size_ = OpSize::SIZE16;
	    default_address_size_ = OpSize::SIZE32;
	    default_inverted_address_size_ = OpSize::SIZE16;
	    default_code_size_ = CodeSize::CODE32;
	    break;
	  case 16:
	  default:
	    default_operand_size_ = OpSize::SIZE16;
	    default_inverted_operand_size_ = OpSize::SIZE32;
	    default_address_size_ = OpSize::SIZE16;
	    default_inverted_address_size_ = OpSize::SIZE32;
	    default_code_size_ = CodeSize::CODE16;
	    break;
	}

	// Get reference to static tables (initialized once, shared by all decoders)
	const auto& tables = get_tables();
	handlers_map0_ = tables.handlers_map0;
	handlers_vex_0f_ = tables.handlers_vex_0f;
	handlers_vex_0f38_ = tables.handlers_vex_0f38;
	handlers_vex_0f3a_ = tables.handlers_vex_0f3a;
	handlers_evex_0f_ = tables.handlers_evex_0f;
	handlers_evex_0f38_ = tables.handlers_evex_0f38;
	handlers_evex_0f3a_ = tables.handlers_evex_0f3a;
	handlers_evex_map5_ = tables.handlers_evex_map5;
	handlers_evex_map6_ = tables.handlers_evex_map6;

	// Set up masks for bitness-dependent behavior
	mask_e0_ = ( bitness == 64 ) ? 0xE0u : 0u;
	// invalid_check_mask is based on NO_INVALID_CHECK option, not bitness (matches Rust)
	invalid_check_mask_ = ( ( options & DecoderOptions::NO_INVALID_CHECK ) == 0 ) ? 0xFFFFFFFFu : 0u;
}

std::expected< Instruction, DecodeError > Decoder::decode() noexcept {
	DecoderError error = DecoderError::NONE;
	Instruction instr = decode_out( error );
	if ( error != DecoderError::NONE ) {
	  return std::unexpected( DecodeError{ error, ip_ } );
	}
	return instr;
}

Instruction Decoder::decode_out( DecoderError& error ) noexcept {
	Instruction instr{};
	error = DecoderError::NONE;

	if ( data_ptr_ >= data_ptr_end_ ) {
	  error = DecoderError::NO_MORE_BYTES;
	  return instr;
	}

	decode_internal( instr );

	// Check for errors
	if ( ( state_.flags & StateFlags::NO_MORE_BYTES ) != 0 ) {
	  error = DecoderError::NO_MORE_BYTES;
	} else if ( ( state_.flags & StateFlags::IS_INVALID ) != 0 ) {
	  error = DecoderError::INVALID_INSTRUCTION;
	}

	return instr;
}

void Decoder::decode_internal( Instruction& instruction ) noexcept {
	// Reset state - clear 5 consecutive uint32_t fields at once
	// Fields: extra_register_base, extra_index_register_base, extra_base_register_base,
	//         extra_index_register_base_vsib, flags
	std::memset( &state_.extra_register_base, 0, 5 * sizeof( uint32_t ) );

	// Clear vvvv fields (2 consecutive uint32_t)
	state_.vvvv = 0;
	state_.vvvv_invalid_check = 0;

	// Set address/operand size (these are set, not cleared)
	state_.address_size = default_address_size_;
	state_.operand_size = default_operand_size_;
	state_.segment_prio = 0;
	state_.dummy = 0;

	// Less frequently used
	state_.mandatory_prefix = DecoderMandatoryPrefix::PNP;
	state_.modrm_read = false;

	// Set up pointers for this instruction
	instr_start_ptr_ = data_ptr_;
	// Max instruction length is 15 bytes, but don't exceed data end
	auto remaining = static_cast<std::size_t>( data_ptr_end_ - data_ptr_ );
	max_data_ptr_ = data_ptr_ + ( remaining < MAX_INSTRUCTION_LENGTH ? remaining : MAX_INSTRUCTION_LENGTH );

	// Read first byte - use direct pointer access for speed
	if ( data_ptr_ >= max_data_ptr_ ) [[unlikely]] {
	  state_.flags |= StateFlags::IS_INVALID | StateFlags::NO_MORE_BYTES;
	  return;
	}
	auto b = static_cast<std::size_t>( *data_ptr_++ );

	// Check for REX prefix in 64-bit mode
	if ( bitness_ == 64 && ( b & 0xF0 ) == 0x40 ) {
	  // REX prefix - need another byte
	  if ( data_ptr_ >= max_data_ptr_ ) [[unlikely]] {
	    state_.flags |= StateFlags::IS_INVALID | StateFlags::NO_MORE_BYTES;
	    return;
	  }

	  uint32_t flags = state_.flags | StateFlags::HAS_REX;
	  if ( ( b & 8 ) != 0 ) {
	    flags |= StateFlags::W;
	    state_.operand_size = OpSize::SIZE64;
	  }
	  state_.flags = flags;
	  state_.extra_register_base = ( static_cast<uint32_t>( b ) & 4 ) << 1;
	  state_.extra_index_register_base = ( static_cast<uint32_t>( b ) & 2 ) << 2;
	  state_.extra_base_register_base = ( static_cast<uint32_t>( b ) & 1 ) << 3;

	  b = static_cast<std::size_t>( *data_ptr_++ );
	}

	// Look up handler
	if ( b < handlers_map0_.size() ) {
	  auto& handler = handlers_map0_[b];
	  decode_table( handler, instruction );
	} else {
	  set_invalid_instruction();
	}

	// Calculate instruction length from pointers
	auto instr_len = static_cast<uint32_t>( data_ptr_ - instr_start_ptr_ );
	instruction.set_length( instr_len );

	// Update IP
	auto orig_ip = ip_;
	ip_ += instr_len;
	instruction.set_next_ip( ip_ );
	instruction.set_code_size( default_code_size_ );

	// Post-process RIP/EIP-relative addressing: convert displacement to absolute address
	auto flags = state_.flags;
	if ( ( flags & ( StateFlags::IP_REL64 | StateFlags::IP_REL32 | StateFlags::IS_INVALID ) ) != 0 ) {
	  if ( ( flags & StateFlags::IP_REL64 ) != 0 ) {
	    // RIP-relative: target = next_ip + displacement
	    auto addr = ip_ + instruction.memory_displacement64();
	    instruction.set_memory_displacement64( addr );
	  } else if ( ( flags & StateFlags::IP_REL32 ) != 0 ) {
	    // EIP-relative: target = next_ip + displacement (32-bit)
	    auto addr = static_cast<uint32_t>( ip_ ) + static_cast<uint32_t>( instruction.memory_displacement64() );
	    instruction.set_memory_displacement64( addr );
	  }
	}

	// Handle invalid instructions and LOCK prefix validation (matches Rust decoder.rs line ~1442-1443)
	// Invalid if: IS_INVALID flag is set, OR LOCK prefix used without ALLOW_LOCK (when invalid checking is enabled)
	bool is_invalid = ( state_.flags & StateFlags::IS_INVALID ) != 0;
	if ( !is_invalid ) {
	  // Check LOCK prefix validation: LOCK set but ALLOW_LOCK not set
	  is_invalid = ( ( ( state_.flags & ( StateFlags::LOCK | StateFlags::ALLOW_LOCK ) ) & invalid_check_mask_ ) == StateFlags::LOCK );
	}
	if ( is_invalid ) {
	  instruction = Instruction{};
	  instruction.set_code( Code::INVALID );

	  instr_len = static_cast<uint32_t>( data_ptr_ - instr_start_ptr_ );
	  instruction.set_length( instr_len );
	  ip_ = orig_ip + instr_len;
	  instruction.set_next_ip( ip_ );
	  instruction.set_code_size( default_code_size_ );
	  state_.flags |= StateFlags::IS_INVALID;
	}
}

void Decoder::decode_table( internal::HandlerEntry handler, Instruction& instruction ) noexcept {
	// Only read modrm if:
	// 1. Handler requires modrm, AND
	// 2. Modrm hasn't already been read for this instruction
	if ( handler.handler->has_modrm && !state_.modrm_read ) {
	  if ( data_ptr_ >= max_data_ptr_ ) [[unlikely]] {
	    set_invalid_instruction();
	    return;
	  }
	  auto m = static_cast<uint32_t>( *data_ptr_++ );
	  state_.modrm = m;
	  state_.reg = ( m >> 3 ) & 7;
	  state_.mod_ = m >> 6;
	  state_.rm = m & 7;
	  state_.mem_index = ( state_.mod_ << 3 ) | state_.rm;
	  state_.modrm_read = true;
	}

	handler.decode( handler.handler, *this, instruction );
}

bool Decoder::can_decode() const noexcept {
	return data_ptr_ < data_ptr_end_;
}

void Decoder::set_position( std::size_t pos ) noexcept {
	if ( pos <= data_.size() ) {
	  auto new_ptr = data_.data() + pos;
	  int64_t diff = new_ptr - data_ptr_;
	  data_ptr_ = new_ptr;
	  ip_ = static_cast<uint64_t>( static_cast<int64_t>( ip_ ) + diff );
	}
}

std::optional<uint8_t> Decoder::read_byte() noexcept {
	if ( data_ptr_ >= max_data_ptr_ ) {
	  state_.flags |= StateFlags::IS_INVALID | StateFlags::NO_MORE_BYTES;
	  return std::nullopt;
	}
	return *data_ptr_++;
}

std::optional<uint16_t> Decoder::read_u16() noexcept {
	if ( data_ptr_ + 2 > max_data_ptr_ ) {
	  state_.flags |= StateFlags::IS_INVALID | StateFlags::NO_MORE_BYTES;
	  return std::nullopt;
	}
	uint16_t result;
	std::memcpy( &result, data_ptr_, 2 );
	data_ptr_ += 2;
	return result;
}

std::optional<uint32_t> Decoder::read_u32() noexcept {
	if ( data_ptr_ + 4 > max_data_ptr_ ) {
	  state_.flags |= StateFlags::IS_INVALID | StateFlags::NO_MORE_BYTES;
	  return std::nullopt;
	}
	uint32_t result;
	std::memcpy( &result, data_ptr_, 4 );
	data_ptr_ += 4;
	return result;
}

std::optional<uint64_t> Decoder::read_u64() noexcept {
	if ( data_ptr_ + 8 > max_data_ptr_ ) {
	  state_.flags |= StateFlags::IS_INVALID | StateFlags::NO_MORE_BYTES;
	  return std::nullopt;
	}
	uint64_t result;
	std::memcpy( &result, data_ptr_, 8 );
	data_ptr_ += 8;
	return result;
}

void Decoder::set_invalid_instruction() noexcept {
	state_.flags |= StateFlags::IS_INVALID;
}

void Decoder::reset_rex_prefix_state() noexcept {
	state_.flags &= ~( StateFlags::HAS_REX | StateFlags::W );
	if ( ( state_.flags & StateFlags::HAS66 ) == 0 ) {
	  state_.operand_size = default_operand_size_;
	} else {
	  state_.operand_size = default_inverted_operand_size_;
	}
	state_.extra_register_base = 0;
	state_.extra_index_register_base = 0;
	state_.extra_base_register_base = 0;
}

void Decoder::call_opcode_handlers_map0_table( Instruction& instruction ) noexcept {
	auto b_opt = read_byte();
	if ( !b_opt ) {
	  set_invalid_instruction();
	  return;
	}
	auto b = static_cast<std::size_t>( *b_opt );
	if ( b < handlers_map0_.size() ) {
	  decode_table( handlers_map0_[b], instruction );
	} else {
	  set_invalid_instruction();
	}
}

void Decoder::read_op_mem( Instruction& instruction, uint32_t operand_index ) noexcept {
	if ( state_.address_size == OpSize::SIZE16 ) {
	  read_op_mem_16( instruction, operand_index );
	} else {
	  read_op_mem_32_or_64( instruction, operand_index );
	}
}

void Decoder::read_op_mem_32_or_64( Instruction& instruction, uint32_t operand_index ) noexcept {
	// Base register for 32 vs 64-bit addressing
	Register base_reg = ( state_.address_size == OpSize::SIZE64 ) ? Register::RAX : Register::EAX;

	if ( state_.mod_ == 0 ) {
	  // No displacement (except special cases)
	  if ( state_.rm == 4 ) {
	    // SIB byte
	    read_sib( instruction );
	  } else if ( state_.rm == 5 ) {
	    // RIP/EIP-relative or disp32
	    auto disp = read_u32();
	    if ( !disp ) return;
	    instruction.set_memory_displacement64( static_cast<int32_t>( *disp ) );
	    instruction.set_memory_displ_size( 4 );
	    if ( bitness_ == 64 ) {
	      instruction.set_memory_base( Register::RIP );
	      state_.flags |= StateFlags::IP_REL64;
	    } else if ( state_.address_size == OpSize::SIZE64 ) {
	      instruction.set_memory_base( Register::EIP );
	      state_.flags |= StateFlags::IP_REL32;
	    }
	  } else {
	    // Simple base register
	    instruction.set_memory_base( static_cast<Register>(
	      static_cast<uint32_t>( base_reg ) + state_.rm + state_.extra_base_register_base ) );
	  }
	} else if ( state_.mod_ == 1 ) {
	  // 8-bit displacement
	  if ( state_.rm == 4 ) {
	    read_sib( instruction );
	  } else {
	    instruction.set_memory_base( static_cast<Register>(
	      static_cast<uint32_t>( base_reg ) + state_.rm + state_.extra_base_register_base ) );
	  }
	  auto disp = read_byte();
	  if ( !disp ) return;
	  instruction.set_memory_displacement64( static_cast<int8_t>( *disp ) );
	  instruction.set_memory_displ_size( 1 );
	} else if ( state_.mod_ == 2 ) {
	  // 32-bit displacement
	  if ( state_.rm == 4 ) {
	    read_sib( instruction );
	  } else {
	    instruction.set_memory_base( static_cast<Register>(
	      static_cast<uint32_t>( base_reg ) + state_.rm + state_.extra_base_register_base ) );
	  }
	  auto disp = read_u32();
	  if ( !disp ) return;
	  instruction.set_memory_displacement64( static_cast<int32_t>( *disp ) );
	  instruction.set_memory_displ_size( 4 );
	}

	// Set operand kind based on operand_index
	switch ( operand_index ) {
	  case 0: instruction.set_op0_kind( OpKind::MEMORY ); break;
	  case 1: instruction.set_op1_kind( OpKind::MEMORY ); break;
	  case 2: instruction.set_op2_kind( OpKind::MEMORY ); break;
	  case 3: instruction.set_op3_kind( OpKind::MEMORY ); break;
	}
}

bool Decoder::read_sib( Instruction& instruction ) noexcept {
	auto sib_opt = read_byte();
	if ( !sib_opt ) return false;
	auto sib = static_cast<uint32_t>( *sib_opt );

	// Scale: bits 7-6 (0-3 maps to 1, 2, 4, 8)
	instruction.set_memory_index_scale( 1u << ( sib >> 6 ) );

	// Base register for 32 vs 64-bit addressing
	Register base_reg = ( state_.address_size == OpSize::SIZE64 ) ? Register::RAX : Register::EAX;

	// Index: bits 5-3 + REX.X extension
	uint32_t index = ( ( sib >> 3 ) & 7 ) + state_.extra_index_register_base;
	if ( index != 4 ) {  // index=4 means no index register
	  instruction.set_memory_index( static_cast<Register>(
	    static_cast<uint32_t>( base_reg ) + index ) );
	}

	// Base: bits 2-0 + REX.B extension
	uint32_t base = ( sib & 7 ) + state_.extra_base_register_base;
	if ( ( sib & 7 ) == 5 && state_.mod_ == 0 ) {
	  // Special case: base=5 with mod=0 means disp32 only
	  auto disp = read_u32();
	  if ( !disp ) return false;
	  instruction.set_memory_displacement64( static_cast<int32_t>( *disp ) );
	  instruction.set_memory_displ_size( 4 );
	} else {
	  instruction.set_memory_base( static_cast<Register>(
	    static_cast<uint32_t>( base_reg ) + base ) );
	}

	return true;
}

void Decoder::read_op_mem_16( Instruction& instruction, uint32_t operand_index ) noexcept {
	// 16-bit addressing mode lookup table
	static constexpr struct { Register base; Register index; } mem_regs_16[] = {
	  { Register::BX, Register::SI },  // rm=0: [BX+SI]
	  { Register::BX, Register::DI },  // rm=1: [BX+DI]
	  { Register::BP, Register::SI },  // rm=2: [BP+SI]
	  { Register::BP, Register::DI },  // rm=3: [BP+DI]
	  { Register::SI, Register::NONE },// rm=4: [SI]
	  { Register::DI, Register::NONE },// rm=5: [DI]
	  { Register::BP, Register::NONE },// rm=6: [BP] or disp16 if mod=0
	  { Register::BX, Register::NONE } // rm=7: [BX]
	};

	if ( state_.mod_ == 0 && state_.rm == 6 ) {
	  // disp16 only
	  auto disp = read_u16();
	  if ( !disp ) return;
	  instruction.set_memory_displacement64( *disp );
	  instruction.set_memory_displ_size( 2 );
	} else {
	  auto& regs = mem_regs_16[state_.rm];
	  instruction.set_memory_base( regs.base );
	  if ( regs.index != Register::NONE ) {
	    instruction.set_memory_index( regs.index );
	  }

	  if ( state_.mod_ == 1 ) {
	    auto disp = read_byte();
	    if ( !disp ) return;
	    instruction.set_memory_displacement64( static_cast<int8_t>( *disp ) );
	    instruction.set_memory_displ_size( 1 );
	  } else if ( state_.mod_ == 2 ) {
	    auto disp = read_u16();
	    if ( !disp ) return;
	    instruction.set_memory_displacement64( *disp );
	    instruction.set_memory_displ_size( 2 );
	  }
	}

	// Set operand kind
	switch ( operand_index ) {
	  case 0: instruction.set_op0_kind( OpKind::MEMORY ); break;
	  case 1: instruction.set_op1_kind( OpKind::MEMORY ); break;
	  case 2: instruction.set_op2_kind( OpKind::MEMORY ); break;
	  case 3: instruction.set_op3_kind( OpKind::MEMORY ); break;
	}
}

void Decoder::read_op_mem_vsib( Instruction& instruction, uint32_t operand_index, Register vsib_index, uint32_t tuple_type ) noexcept {
	// VSIB addressing always requires a SIB byte (mod != 3, rm == 4)
	// The index register comes from VSIB, not from SIB.index

	if ( state_.address_size == OpSize::SIZE16 ) {
	  // 16-bit addressing doesn't support VSIB
	  set_invalid_instruction();
	  return;
	}

	// Read the SIB byte
	auto sib_opt = read_byte();
	if ( !sib_opt ) {
	  set_invalid_instruction();
	  return;
	}
	uint32_t sib = *sib_opt;

	// Extract SIB fields
	uint32_t scale = 1u << ( sib >> 6 );
	uint32_t index = ( ( sib >> 3 ) & 7 ) + state_.extra_index_register_base + state_.extra_index_register_base_vsib;
	uint32_t base = ( sib & 7 ) + state_.extra_base_register_base;

	// Set scale
	instruction.set_memory_index_scale( scale );

	// Set VSIB index register
	instruction.set_memory_index( static_cast<Register>( static_cast<uint32_t>( vsib_index ) + index ) );

	// Base register (64-bit or 32-bit addressing)
	Register base_reg = ( state_.address_size == OpSize::SIZE64 ) ? Register::RAX : Register::EAX;

	// Handle displacement based on mod
	if ( state_.mod_ == 0 ) {
	  if ( ( sib & 7 ) == 5 ) {
	    // No base register, just disp32
	    auto disp = read_u32();
	    if ( !disp ) return;
	    instruction.set_memory_displacement64( static_cast<int32_t>( *disp ) );
	    instruction.set_memory_displ_size( 4 );
	  } else {
	    instruction.set_memory_base( static_cast<Register>( static_cast<uint32_t>( base_reg ) + base ) );
	  }
	} else if ( state_.mod_ == 1 ) {
	  // 8-bit displacement (scaled by tuple_type for EVEX)
	  instruction.set_memory_base( static_cast<Register>( static_cast<uint32_t>( base_reg ) + base ) );
	  auto disp = read_byte();
	  if ( !disp ) return;
	  int32_t scaled_disp = static_cast<int8_t>( *disp );
	  if ( tuple_type != 0 ) {
	    scaled_disp *= static_cast<int32_t>( tuple_type );
	  }
	  instruction.set_memory_displacement64( scaled_disp );
	  instruction.set_memory_displ_size( 1 );
	} else if ( state_.mod_ == 2 ) {
	  // 32-bit displacement
	  instruction.set_memory_base( static_cast<Register>( static_cast<uint32_t>( base_reg ) + base ) );
	  auto disp = read_u32();
	  if ( !disp ) return;
	  instruction.set_memory_displacement64( static_cast<int32_t>( *disp ) );
	  instruction.set_memory_displ_size( 4 );
	}

	// Set operand kind
	switch ( operand_index ) {
	  case 0: instruction.set_op0_kind( OpKind::MEMORY ); break;
	  case 1: instruction.set_op1_kind( OpKind::MEMORY ); break;
	  case 2: instruction.set_op2_kind( OpKind::MEMORY ); break;
	  case 3: instruction.set_op3_kind( OpKind::MEMORY ); break;
	}
}

void Decoder::decode_vex2( Instruction& instruction ) noexcept {
	// Validate: no REX prefix and no mandatory prefix already set
	if ( ( ( ( state_.flags & StateFlags::HAS_REX ) |
	        static_cast<uint32_t>( state_.mandatory_prefix ) ) & invalid_check_mask_ ) != 0 ) {
	  set_invalid_instruction();
	  return;
	}

	// Clear W flag and reset REX extension bits
	state_.flags &= ~StateFlags::W;
	state_.extra_index_register_base = 0;
	state_.extra_base_register_base = 0;
	state_.extra_register_base_evex = 0;
	state_.extra_base_register_base_evex = 0;

	// state_.modrm contains the VEX byte2 (already read)
	uint32_t b2 = state_.modrm;

	// Read opcode byte
	auto opcode_opt = read_byte();
	if ( !opcode_opt ) {
	  set_invalid_instruction();
	  return;
	}
	uint32_t opcode = *opcode_opt;

	// Extract VEX fields from b2:
	// Bit 7: ~R (inverted REX.R)
	// Bits 6-3: ~vvvv (inverted register specifier)
	// Bit 2: L (vector length: 0=128, 1=256)
	// Bits 1-0: pp (implied mandatory prefix)
	state_.vector_length = static_cast<VectorLength>( ( b2 >> 2 ) & 1 );
	state_.mandatory_prefix = static_cast<DecoderMandatoryPrefix>( b2 & 3 );

	uint32_t b2_inv = ~b2;
	state_.extra_register_base = ( b2_inv >> 4 ) & 8;  // R bit -> bit 3

	uint32_t vvvv = ( b2_inv >> 3 ) & 0x0F;
	state_.vvvv_invalid_check = vvvv;
	state_.vvvv = vvvv & reg15_mask();

	// VEX2 implies map 0F (map_index = 0)
	auto table = get_vex_table( 0 );
	if ( table.empty() || opcode >= table.size() ) {
	  set_invalid_instruction();
	  return;
	}

	// Reset modrm_read so the instruction handler can read the actual ModRM
	state_.modrm_read = false;
	decode_table( table[opcode], instruction );
}

void Decoder::decode_vex3( Instruction& instruction ) noexcept {
	// Validate: no REX prefix and no mandatory prefix already set
	if ( ( ( ( state_.flags & StateFlags::HAS_REX ) |
	        static_cast<uint32_t>( state_.mandatory_prefix ) ) & invalid_check_mask_ ) != 0 ) {
	  set_invalid_instruction();
	  return;
	}

	// Clear W flag
	state_.flags &= ~StateFlags::W;
	state_.extra_register_base_evex = 0;
	state_.extra_base_register_base_evex = 0;

	// state_.modrm contains VEX byte2 (P0: RXBmmmmm)
	uint32_t p0 = state_.modrm;

	// Read VEX byte3 (P1: WvvvvLpp) and opcode
	auto p1_opt = read_byte();
	if ( !p1_opt ) {
	  set_invalid_instruction();
	  return;
	}
	uint32_t p1 = *p1_opt;

	auto opcode_opt = read_byte();
	if ( !opcode_opt ) {
	  set_invalid_instruction();
	  return;
	}
	uint32_t opcode = *opcode_opt;

	// Extract P1 fields:
	// Bit 7: W (REX.W equivalent)
	// Bits 6-3: ~vvvv (inverted register specifier)
	// Bit 2: L (vector length)
	// Bits 1-0: pp (implied mandatory prefix)
	if ( ( p1 & 0x80 ) != 0 ) {
	  state_.flags |= StateFlags::W;
	}
	state_.vector_length = static_cast<VectorLength>( ( p1 >> 2 ) & 1 );
	state_.mandatory_prefix = static_cast<DecoderMandatoryPrefix>( p1 & 3 );

	uint32_t vvvv = ( ~p1 >> 3 ) & 0x0F;
	state_.vvvv_invalid_check = vvvv;
	state_.vvvv = vvvv & reg15_mask();

	// Extract P0 fields (inverted R, X, B bits):
	// Bit 7: ~R, Bit 6: ~X, Bit 5: ~B
	// Bits 4-0: mmmmm (map select)
	uint32_t p0_inv = ~p0 & mask_e0_;
	state_.extra_register_base = ( p0_inv >> 4 ) & 8;
	state_.extra_index_register_base = ( p0_inv >> 3 ) & 8;
	state_.extra_base_register_base = ( p0_inv >> 2 ) & 8;

	// Map select: mmmmm field (1=0F, 2=0F38, 3=0F3A)
	uint32_t map = ( p0 & 0x1F );
	if ( map == 0 || map > 3 ) {
	  set_invalid_instruction();
	  return;
	}
	uint32_t map_index = map - 1;  // Convert to 0-based index

	auto table = get_vex_table( map_index );
	if ( table.empty() || opcode >= table.size() ) {
	  set_invalid_instruction();
	  return;
	}

	// Reset modrm_read so the instruction handler can read the actual ModRM
	state_.modrm_read = false;
	decode_table( table[opcode], instruction );
}

void Decoder::decode_evex( Instruction& instruction ) noexcept {
	// Validate: no REX prefix and no mandatory prefix already set
	if ( ( ( ( state_.flags & StateFlags::HAS_REX ) |
	        static_cast<uint32_t>( state_.mandatory_prefix ) ) & invalid_check_mask_ ) != 0 ) {
	  set_invalid_instruction();
	  return;
	}

	// state_.modrm contains P0 (first EVEX payload byte)
	uint32_t p0 = state_.modrm;

	// Read P1, P2, and opcode
	auto p1_opt = read_byte();
	if ( !p1_opt ) {
	  set_invalid_instruction();
	  return;
	}
	uint32_t p1 = *p1_opt;

	// Validate EVEX: P1 bit 2 must be 1
	if ( ( p1 & 0x04 ) == 0 ) {
	  set_invalid_instruction();
	  return;
	}

	auto p2_opt = read_byte();
	if ( !p2_opt ) {
	  set_invalid_instruction();
	  return;
	}
	uint32_t p2 = *p2_opt;

	auto opcode_opt = read_byte();
	if ( !opcode_opt ) {
	  set_invalid_instruction();
	  return;
	}
	uint32_t opcode = *opcode_opt;

	// Extract P1 fields:
	// Bit 7: W
	// Bits 6-3: ~vvvv
	// Bit 2: must be 1 (already checked)
	// Bits 1-0: pp
	state_.mandatory_prefix = static_cast<DecoderMandatoryPrefix>( p1 & 3 );
	if ( ( p1 & 0x80 ) != 0 ) {
	  state_.flags |= StateFlags::W;
	} else {
	  state_.flags &= ~StateFlags::W;
	}

	// Extract P2 fields:
	// Bit 7: z (zeroing-masking)
	// Bits 6-5: LL' (vector length)
	// Bit 4: b (broadcast/rounding)
	// Bit 3: V' (vvvv extension)
	// Bits 2-0: aaa (opmask register)
	state_.aaa = p2 & 7;
	instruction.set_op_mask( static_cast<Register>(
	  static_cast<uint32_t>( Register::K0 ) + state_.aaa ) );

	if ( ( p2 & 0x80 ) != 0 ) {
	  state_.flags |= StateFlags::Z;
	  instruction.set_zeroing_masking( true );
	} else {
	  state_.flags &= ~StateFlags::Z;
	}

	if ( ( p2 & 0x10 ) != 0 ) {
	  state_.flags |= StateFlags::B;
	} else {
	  state_.flags &= ~StateFlags::B;
	}

	state_.vector_length = static_cast<VectorLength>( ( p2 >> 5 ) & 3 );

	// vvvv from P1 and V' from P2
	uint32_t vvvv_low = ( ~p1 >> 3 ) & 0x0F;
	if ( bitness_ == 64 ) {
	  uint32_t v_prime = ( ~p2 & 8 ) << 1;  // V' bit -> bit 4
	  state_.extra_index_register_base_vsib = v_prime;
	  state_.vvvv = v_prime + vvvv_low;
	  state_.vvvv_invalid_check = state_.vvvv;
	} else {
	  state_.vvvv = vvvv_low & 0x7;
	  state_.vvvv_invalid_check = vvvv_low;
	}

	// Extract P0 fields (EVEX-specific R', X', B' extensions):
	// Bit 7: ~R, Bit 6: ~X, Bit 5: ~B, Bit 4: ~R'
	// Bit 3: 0=EVEX, 1=MVEX
	// Bits 2-0: mm (map select)
	if ( ( p0 & 0x08 ) != 0 ) {
	  // MVEX: switch to MVEX decoding
	  decode_mvex( p0, p1, p2, opcode, instruction );
	  return;
	}

	if ( bitness_ == 64 ) {
	  uint32_t p0_inv = ~p0;
	  state_.extra_register_base = ( p0_inv >> 4 ) & 8;       // R -> bit 3
	  state_.extra_index_register_base = ( p0_inv >> 3 ) & 8; // X -> bit 3
	  state_.extra_register_base_evex = p0_inv & 0x10;        // R' -> bit 4
	  state_.extra_base_register_base_evex = ( p0_inv >> 2 ) & 0x18; // X' and B'
	  state_.extra_base_register_base = ( p0_inv >> 2 ) & 8; // B -> bit 3
	} else {
	  state_.extra_register_base = 0;
	  state_.extra_index_register_base = 0;
	  state_.extra_register_base_evex = 0;
	  state_.extra_base_register_base_evex = 0;
	  state_.extra_base_register_base = 0;
	}

	// Map select: mm field (1=0F, 2=0F38, 3=0F3A, 5=MAP5, 6=MAP6)
	uint32_t map = ( p0 & 0x07 );
	uint32_t map_index;
	switch ( map ) {
	  case 1: map_index = 0; break;  // 0F
	  case 2: map_index = 1; break;  // 0F38
	  case 3: map_index = 2; break;  // 0F3A
	  case 5: map_index = 4; break;  // MAP5
	  case 6: map_index = 5; break;  // MAP6
	  default:
	    set_invalid_instruction();
	    return;
	}

	auto table = get_mvex_table( map_index );
	if ( table.empty() || opcode >= table.size() ) {
	  set_invalid_instruction();
	  return;
	}

	// Invalid if LL=3 (Unknown vector length) and no embedded rounding (B=0)
	// Rust uses B=0x10 so (flags & B) | LL == 3 works. We use a direct check instead.
	if ( ( state_.vector_length == VectorLength::UNKNOWN ) && 
	     ( ( state_.flags & StateFlags::B ) == 0 ) &&
	     ( invalid_check_mask_ != 0 ) ) {
	    set_invalid_instruction();
	}

	// Reset modrm_read so the instruction handler can read the actual ModRM
	state_.modrm_read = false;
	decode_table( table[opcode], instruction );
}

void Decoder::decode_mvex( uint32_t p0, uint32_t p1, uint32_t p2, uint32_t opcode, Instruction& instruction ) noexcept {
	// MVEX prefix (0x62 with bit 3 set in P0)
	// MVEX format: 62 [P0] [P1] [P2] [opcode] [modrm if handler needs it]

	// Validate MVEX: P1 bit 2 must be 1 (same as EVEX)
	if ( ( p1 & 0x04 ) == 0 ) {
	  set_invalid_instruction();
	  return;
	}

	// Extract P1 fields (same as EVEX):
	// Bit 7: W
	// Bits 6-3: ~vvvv
	// Bit 2: must be 1 (already checked)
	// Bits 1-0: pp
	state_.mandatory_prefix = static_cast<DecoderMandatoryPrefix>( p1 & 3 );
	if ( ( p1 & 0x80 ) != 0 ) {
	  state_.flags |= StateFlags::W;
	} else {
	  state_.flags &= ~StateFlags::W;
	}

	// Extract P2 fields (MVEX-specific):
	// Bit 7: ~E (eviction hint)
	// Bits 6-4: SSS (swizzle/SAE/conversion)
	// Bit 3: V' (vvvv extension)
	// Bits 2-0: kkk (opmask register)
	uint32_t sss = ( p2 >> 4 ) & 7;
	state_.flags |= sss << StateFlags::MVEX_SSS_SHIFT;
	if ( ( p2 & 0x80 ) == 0 ) {
	  state_.flags |= StateFlags::MVEX_EH;
	  instruction.set_is_mvex_eviction_hint( true );
	}
	state_.aaa = p2 & 7;
	instruction.set_op_mask( static_cast<Register>(
	  static_cast<uint32_t>( Register::K0 ) + state_.aaa ) );

	// vvvv from P1 and V' from P2
	uint32_t vvvv_low = ( ~p1 >> 3 ) & 0x0F;
	if ( bitness_ == 64 ) {
	  uint32_t v_prime = ( ~p2 & 8 ) << 1;  // V' bit -> bit 4
	  state_.extra_index_register_base_vsib = v_prime;
	  state_.vvvv = v_prime + vvvv_low;
	  state_.vvvv_invalid_check = state_.vvvv;
	} else {
	  state_.vvvv = vvvv_low & 0x7;
	  state_.vvvv_invalid_check = vvvv_low;
	}

	// Extract P0 fields (MVEX R', X', B' extensions):
	// Bit 7: ~R, Bit 6: ~X, Bit 5: ~B, Bit 4: ~R'
	// Bit 3: must be 1 for MVEX (already checked)
	// Bits 2-0: mm (map select)
	if ( bitness_ == 64 ) {
	  uint32_t p0_inv = ~p0;
	  state_.extra_register_base = ( p0_inv >> 4 ) & 8;       // R -> bit 3
	  state_.extra_index_register_base = ( p0_inv >> 3 ) & 8; // X -> bit 3
	  state_.extra_register_base_evex = p0_inv & 0x10;        // R' -> bit 4
	  state_.extra_base_register_base_evex = ( p0_inv >> 2 ) & 0x18; // X' and B'
	  state_.extra_base_register_base = ( p0_inv >> 2 ) & 8; // B -> bit 3
	} else {
	  state_.extra_register_base = 0;
	  state_.extra_index_register_base = 0;
	  state_.extra_register_base_evex = 0;
	  state_.extra_base_register_base_evex = 0;
	  state_.extra_base_register_base = 0;
	}

	// Map select: mm field (1=0F, 2=0F38, 3=0F3A)
	uint32_t map = ( p0 & 0x07 );
	uint32_t map_index;
	switch ( map ) {
	  case 1: map_index = 0; break;  // 0F
	  case 2: map_index = 1; break;  // 0F38
	  case 3: map_index = 2; break;  // 0F3A
	  default:
	    set_invalid_instruction();
	    return;
	}

	auto table = get_mvex_table( map_index );
	if ( table.empty() || opcode >= table.size() ) {
	  set_invalid_instruction();
	  return;
	}

	// Reset modrm_read so the instruction handler can read the actual ModRM
	state_.modrm_read = false;
	decode_table( table[opcode], instruction );
}

void Decoder::decode_xop( Instruction& instruction ) noexcept {
	// XOP prefix (0x8F followed by XOP-specific bytes)
	// XOP uses same basic structure as VEX3 but different map values
	// XOP format: 8F [modrm=P0 already read] [P1=XOP2] [opcode] [modrm if handler needs it]

	// Read XOP2 + opcode (2 bytes) like Rust does
	if ( !can_read( 2 ) ) {
	  set_invalid_instruction();
	  return;
	}
	data_ptr_ += 2;  // Skip XOP2 and opcode bytes

	// Calculate XOP map index from modrm (P0) that was already read
	// XOP maps: map8=0, map9=1, mapA=2
	// Rust: handlers_xop.get(((b1 & 0x1F) as usize).wrapping_sub(8))
	uint32_t p0 = state_.modrm;
	uint32_t map_idx = ( p0 & 0x1F ) - 8;

	// Only read modrm if XOP map is valid (index 0, 1, or 2)
	// If map is invalid, don't read extra bytes
	if ( map_idx < 3 && can_read( 1 ) ) {
	  // Valid XOP map - would need modrm for handler
	}
}

void Decoder::decode_3dnow( Instruction& instruction ) noexcept {
	// 3DNow! instructions (0x0F 0x0F ... suffix)
	// These are legacy AMD instructions
	// For now, mark as invalid - 3DNow! is deprecated
	set_invalid_instruction();
}

void Decoder::read_op_mem_evex( Instruction& instruction, uint32_t operand_index, uint32_t tuple_type ) noexcept {
	// EVEX memory operand with tuple type scaling for compressed displacement
	if ( state_.address_size == OpSize::SIZE16 ) {
	  read_op_mem_16( instruction, operand_index );
	  return;
	}

	// Base register for 32 vs 64-bit addressing
	Register base_reg = ( state_.address_size == OpSize::SIZE64 ) ? Register::RAX : Register::EAX;

	if ( state_.mod_ == 0 ) {
	  // No displacement (except special cases)
	  if ( state_.rm == 4 ) {
	    // SIB byte
	    read_sib( instruction );
	  } else if ( state_.rm == 5 ) {
	    // RIP/EIP-relative or disp32
	    auto disp = read_u32();
	    if ( !disp ) return;
	    instruction.set_memory_displacement64( static_cast<int32_t>( *disp ) );
	    instruction.set_memory_displ_size( 4 );
	    if ( bitness_ == 64 ) {
	      instruction.set_memory_base( Register::RIP );
	      state_.flags |= StateFlags::IP_REL64;
	    } else if ( state_.address_size == OpSize::SIZE64 ) {
	      instruction.set_memory_base( Register::EIP );
	      state_.flags |= StateFlags::IP_REL32;
	    }
	  } else {
	    // Simple base register
	    instruction.set_memory_base( static_cast<Register>(
	      static_cast<uint32_t>( base_reg ) + state_.rm + state_.extra_base_register_base + state_.extra_base_register_base_evex ) );
	  }
	} else if ( state_.mod_ == 1 ) {
	  // 8-bit displacement with EVEX compressed displacement scaling
	  if ( state_.rm == 4 ) {
	    read_sib( instruction );
	  } else {
	    instruction.set_memory_base( static_cast<Register>(
	      static_cast<uint32_t>( base_reg ) + state_.rm + state_.extra_base_register_base + state_.extra_base_register_base_evex ) );
	  }
	  auto disp = read_byte();
	  if ( !disp ) return;
	  int32_t scaled_disp = static_cast<int8_t>( *disp );
	  if ( tuple_type != 0 ) {
	    scaled_disp *= static_cast<int32_t>( tuple_type );
	  }
	  instruction.set_memory_displacement64( scaled_disp );
	  instruction.set_memory_displ_size( 1 );
	} else if ( state_.mod_ == 2 ) {
	  // 32-bit displacement (no scaling)
	  if ( state_.rm == 4 ) {
	    read_sib( instruction );
	  } else {
	    instruction.set_memory_base( static_cast<Register>(
	      static_cast<uint32_t>( base_reg ) + state_.rm + state_.extra_base_register_base + state_.extra_base_register_base_evex ) );
	  }
	  auto disp = read_u32();
	  if ( !disp ) return;
	  instruction.set_memory_displacement64( static_cast<int32_t>( *disp ) );
	  instruction.set_memory_displ_size( 4 );
	}

	// Set operand kind based on operand_index
	switch ( operand_index ) {
	  case 0: instruction.set_op0_kind( OpKind::MEMORY ); break;
	  case 1: instruction.set_op1_kind( OpKind::MEMORY ); break;
	  case 2: instruction.set_op2_kind( OpKind::MEMORY ); break;
	  case 3: instruction.set_op3_kind( OpKind::MEMORY ); break;
	}
}
std::span<const internal::HandlerEntry> Decoder::get_vex_table( uint32_t map_index ) const noexcept {
	switch ( map_index ) {
	  case 0: return handlers_vex_0f_;
	  case 1: return handlers_vex_0f38_;
	  case 2: return handlers_vex_0f3a_;
	  default: return {};
	}
}

std::span<const internal::HandlerEntry> Decoder::get_evex_table( uint32_t map_index ) const noexcept {
	switch ( map_index ) {
	  case 0: return handlers_evex_0f_;
	  case 1: return handlers_evex_0f38_;
	  case 2: return handlers_evex_0f3a_;
	  case 4: return handlers_evex_map5_;
	  case 5: return handlers_evex_map6_;
	  default: return {};
	}
}

std::span<const internal::HandlerEntry> Decoder::get_mvex_table( uint32_t map_index ) const noexcept {
	switch ( map_index ) {
	  case 0: return handlers_mvex_0f;
	  case 1: return handlers_mvex_0f38;
	  case 2: return handlers_mvex_0f3a;
	  default: return {};
	}
}

} // namespace iced_x86
