// SPDX-License-Identifier: MIT
// Copyright (C) 2018-present iced project and contributors

// ‚ö†Ô∏èThis file was generated by GENERATOR!ü¶π‚Äç‚ôÇÔ∏è

#include "iced_x86/decoder.hpp"
#include "iced_x86/internal/table_deserializer.hpp"

#include <algorithm>

namespace iced_x86 {

Decoder::Decoder(
  uint32_t bitness,
  std::span< const uint8_t > data,
  uint64_t ip,
  DecoderOptions::Value options
) noexcept
  : data_( data )
  , position_( 0 )
  , instr_start_position_( 0 )
  , max_instr_position_( 0 )
  , ip_( ip )
  , bitness_( bitness )
  , options_( options )
{
	// Set default sizes based on bitness
	switch ( bitness ) {
	  case 64:
	    default_operand_size_ = OpSize::SIZE32;
	    default_inverted_operand_size_ = OpSize::SIZE16;
	    default_address_size_ = OpSize::SIZE64;
	    default_inverted_address_size_ = OpSize::SIZE32;
	    default_code_size_ = CodeSize::CODE64;
	    break;
	  case 32:
	    default_operand_size_ = OpSize::SIZE32;
	    default_inverted_operand_size_ = OpSize::SIZE16;
	    default_address_size_ = OpSize::SIZE32;
	    default_inverted_address_size_ = OpSize::SIZE16;
	    default_code_size_ = CodeSize::CODE32;
	    break;
	  case 16:
	  default:
	    default_operand_size_ = OpSize::SIZE16;
	    default_inverted_operand_size_ = OpSize::SIZE32;
	    default_address_size_ = OpSize::SIZE16;
	    default_inverted_address_size_ = OpSize::SIZE32;
	    default_code_size_ = CodeSize::CODE16;
	    break;
	}

	// Initialize handler tables
	handlers_map0_ = internal::read_legacy_tables();

	// Initialize VEX/EVEX tables
	auto vex_tables = internal::read_vex_tables();
	if ( vex_tables.size() >= 3 ) {
	  handlers_vex_0f_ = std::move( vex_tables[0] );
	  handlers_vex_0f38_ = std::move( vex_tables[1] );
	  handlers_vex_0f3a_ = std::move( vex_tables[2] );
	}

	auto evex_tables = internal::read_evex_tables();
	if ( evex_tables.size() >= 5 ) {
	  handlers_evex_0f_ = std::move( evex_tables[0] );
	  handlers_evex_0f38_ = std::move( evex_tables[1] );
	  handlers_evex_0f3a_ = std::move( evex_tables[2] );
	  handlers_evex_map5_ = std::move( evex_tables[3] );
	  handlers_evex_map6_ = std::move( evex_tables[4] );
	}

	// Set up masks for bitness-dependent behavior
	mask_e0_ = ( bitness == 64 ) ? 0xE0u : 0u;
	// invalid_check_mask is based on NO_INVALID_CHECK option, not bitness (matches Rust)
	invalid_check_mask_ = ( ( options & DecoderOptions::NO_INVALID_CHECK ) == 0 ) ? 0xFFFFFFFFu : 0u;
}

std::expected< Instruction, DecodeError > Decoder::decode() noexcept {
	DecoderError error = DecoderError::NONE;
	Instruction instr = decode_out( error );
	if ( error != DecoderError::NONE ) {
	  return std::unexpected( DecodeError{ error, ip_ } );
	}
	return instr;
}

Instruction Decoder::decode_out( DecoderError& error ) noexcept {
	Instruction instr{};
	error = DecoderError::NONE;

	if ( position_ >= data_.size() ) {
	  error = DecoderError::NO_MORE_BYTES;
	  return instr;
	}

	decode_internal( instr );

	// Check for errors
	if ( ( state_.flags & StateFlags::NO_MORE_BYTES ) != 0 ) {
	  error = DecoderError::NO_MORE_BYTES;
	} else if ( ( state_.flags & StateFlags::IS_INVALID ) != 0 ) {
	  error = DecoderError::INVALID_INSTRUCTION;
	}

	return instr;
}

void Decoder::decode_internal( Instruction& instruction ) noexcept {
	// Reset state (matches Rust decoder.rs line ~1372-1381)
	state_.extra_register_base = 0;
	state_.extra_index_register_base = 0;
	state_.extra_base_register_base = 0;
	state_.extra_index_register_base_vsib = 0;  // EVEX.V' for VSIB - must be reset!
	state_.flags = 0;
	state_.mandatory_prefix = DecoderMandatoryPrefix::PNP;
	state_.vvvv = 0;
	state_.vvvv_invalid_check = 0;
	state_.address_size = default_address_size_;
	state_.operand_size = default_operand_size_;
	state_.segment_prio = 0;

	instr_start_position_ = position_;
	max_instr_position_ = std::min( position_ + MAX_INSTRUCTION_LENGTH, data_.size() );

	// Read first byte
	auto b_opt = read_byte();
	if ( !b_opt ) {
	  state_.flags |= StateFlags::IS_INVALID | StateFlags::NO_MORE_BYTES;
	  return;
	}
	auto b = static_cast<std::size_t>( *b_opt );

	// Check for REX prefix in 64-bit mode
	if ( bitness_ == 64 && ( b & 0xF0 ) == 0x40 ) {
	  // REX prefix
	  auto next_opt = read_byte();
	  if ( !next_opt ) {
	    state_.flags |= StateFlags::IS_INVALID | StateFlags::NO_MORE_BYTES;
	    return;
	  }

	  uint32_t flags = state_.flags | StateFlags::HAS_REX;
	  if ( ( b & 8 ) != 0 ) {
	    flags |= StateFlags::W;
	    state_.operand_size = OpSize::SIZE64;
	  }
	  state_.flags = flags;
	  state_.extra_register_base = ( static_cast<uint32_t>( b ) & 4 ) << 1;
	  state_.extra_index_register_base = ( static_cast<uint32_t>( b ) & 2 ) << 2;
	  state_.extra_base_register_base = ( static_cast<uint32_t>( b ) & 1 ) << 3;

	  b = static_cast<std::size_t>( *next_opt );
	}

	// Look up handler
	if ( b < handlers_map0_.size() ) {
	  auto& handler = handlers_map0_[b];
	  decode_table( handler, instruction );
	} else {
	  set_invalid_instruction();
	}

	// Calculate instruction length
	auto instr_len = static_cast<uint32_t>( position_ - instr_start_position_ );
	instruction.set_length( instr_len );

	// Update IP
	auto orig_ip = ip_;
	ip_ += instr_len;
	instruction.set_next_ip( ip_ );
	instruction.set_code_size( default_code_size_ );

	// Post-process RIP/EIP-relative addressing: convert displacement to absolute address
	auto flags = state_.flags;
	if ( ( flags & ( StateFlags::IP_REL64 | StateFlags::IP_REL32 | StateFlags::IS_INVALID ) ) != 0 ) {
	  if ( ( flags & StateFlags::IP_REL64 ) != 0 ) {
	    // RIP-relative: target = next_ip + displacement
	    auto addr = ip_ + instruction.memory_displacement64();
	    instruction.set_memory_displacement64( addr );
	  } else if ( ( flags & StateFlags::IP_REL32 ) != 0 ) {
	    // EIP-relative: target = next_ip + displacement (32-bit)
	    auto addr = static_cast<uint32_t>( ip_ ) + static_cast<uint32_t>( instruction.memory_displacement64() );
	    instruction.set_memory_displacement64( addr );
	  }
	}

	// Handle invalid instructions and LOCK prefix validation (matches Rust decoder.rs line ~1442-1443)
	// Invalid if: IS_INVALID flag is set, OR LOCK prefix used without ALLOW_LOCK (when invalid checking is enabled)
	bool is_invalid = ( state_.flags & StateFlags::IS_INVALID ) != 0;
	if ( !is_invalid ) {
	  // Check LOCK prefix validation: LOCK set but ALLOW_LOCK not set
	  is_invalid = ( ( ( state_.flags & ( StateFlags::LOCK | StateFlags::ALLOW_LOCK ) ) & invalid_check_mask_ ) == StateFlags::LOCK );
	}
	if ( is_invalid ) {
	  instruction = Instruction{};
	  instruction.set_code( Code::INVALID );

	  instr_len = static_cast<uint32_t>( position_ - instr_start_position_ );
	  instruction.set_length( instr_len );
	  ip_ = orig_ip + instr_len;
	  instruction.set_next_ip( ip_ );
	  instruction.set_code_size( default_code_size_ );
	  state_.flags |= StateFlags::IS_INVALID;
	}
}

void Decoder::decode_table( internal::HandlerEntry handler, Instruction& instruction ) noexcept {
	if ( handler.handler->has_modrm ) {
	  auto m_opt = read_byte();
	  if ( !m_opt ) {
	    set_invalid_instruction();
	    return;
	  }
	  auto m = static_cast<uint32_t>( *m_opt );
	  state_.modrm = m;
	  state_.reg = ( m >> 3 ) & 7;
	  state_.mod_ = m >> 6;
	  state_.rm = m & 7;
	  state_.mem_index = ( state_.mod_ << 3 ) | state_.rm;
	}

	handler.decode( handler.handler, *this, instruction );
}

bool Decoder::can_decode() const noexcept {
	return position_ < data_.size();
}

void Decoder::set_position( std::size_t pos ) noexcept {
	if ( pos <= data_.size() ) {
	  int64_t diff = static_cast<int64_t>( pos ) - static_cast<int64_t>( position_ );
	  position_ = pos;
	  ip_ = static_cast<uint64_t>( static_cast<int64_t>( ip_ ) + diff );
	}
}

std::optional<uint8_t> Decoder::read_byte() noexcept {
	if ( position_ >= max_instr_position_ ) {
	  state_.flags |= StateFlags::IS_INVALID | StateFlags::NO_MORE_BYTES;
	  return std::nullopt;
	}
	return data_[position_++];
}

std::optional<uint16_t> Decoder::read_u16() noexcept {
	if ( position_ + 2 > max_instr_position_ ) {
	  state_.flags |= StateFlags::IS_INVALID | StateFlags::NO_MORE_BYTES;
	  return std::nullopt;
	}
	uint16_t result = static_cast<uint16_t>( data_[position_] ) |
	                  ( static_cast<uint16_t>( data_[position_ + 1] ) << 8 );
	position_ += 2;
	return result;
}

std::optional<uint32_t> Decoder::read_u32() noexcept {
	if ( position_ + 4 > max_instr_position_ ) {
	  state_.flags |= StateFlags::IS_INVALID | StateFlags::NO_MORE_BYTES;
	  return std::nullopt;
	}
	uint32_t result = static_cast<uint32_t>( data_[position_] ) |
	                  ( static_cast<uint32_t>( data_[position_ + 1] ) << 8 ) |
	                  ( static_cast<uint32_t>( data_[position_ + 2] ) << 16 ) |
	                  ( static_cast<uint32_t>( data_[position_ + 3] ) << 24 );
	position_ += 4;
	return result;
}

std::optional<uint64_t> Decoder::read_u64() noexcept {
	if ( position_ + 8 > max_instr_position_ ) {
	  state_.flags |= StateFlags::IS_INVALID | StateFlags::NO_MORE_BYTES;
	  return std::nullopt;
	}
	uint64_t result = static_cast<uint64_t>( data_[position_] ) |
	                  ( static_cast<uint64_t>( data_[position_ + 1] ) << 8 ) |
	                  ( static_cast<uint64_t>( data_[position_ + 2] ) << 16 ) |
	                  ( static_cast<uint64_t>( data_[position_ + 3] ) << 24 ) |
	                  ( static_cast<uint64_t>( data_[position_ + 4] ) << 32 ) |
	                  ( static_cast<uint64_t>( data_[position_ + 5] ) << 40 ) |
	                  ( static_cast<uint64_t>( data_[position_ + 6] ) << 48 ) |
	                  ( static_cast<uint64_t>( data_[position_ + 7] ) << 56 );
	position_ += 8;
	return result;
}

void Decoder::set_invalid_instruction() noexcept {
	state_.flags |= StateFlags::IS_INVALID;
}

void Decoder::reset_rex_prefix_state() noexcept {
	state_.flags &= ~( StateFlags::HAS_REX | StateFlags::W );
	if ( ( state_.flags & StateFlags::HAS66 ) == 0 ) {
	  state_.operand_size = default_operand_size_;
	} else {
	  state_.operand_size = default_inverted_operand_size_;
	}
	state_.extra_register_base = 0;
	state_.extra_index_register_base = 0;
	state_.extra_base_register_base = 0;
}

void Decoder::call_opcode_handlers_map0_table( Instruction& instruction ) noexcept {
	auto b_opt = read_byte();
	if ( !b_opt ) {
	  set_invalid_instruction();
	  return;
	}
	auto b = static_cast<std::size_t>( *b_opt );
	if ( b < handlers_map0_.size() ) {
	  decode_table( handlers_map0_[b], instruction );
	} else {
	  set_invalid_instruction();
	}
}

void Decoder::read_op_mem( Instruction& instruction, uint32_t operand_index ) noexcept {
	if ( state_.address_size == OpSize::SIZE16 ) {
	  read_op_mem_16( instruction, operand_index );
	} else {
	  read_op_mem_32_or_64( instruction, operand_index );
	}
}

void Decoder::read_op_mem_32_or_64( Instruction& instruction, uint32_t operand_index ) noexcept {
	// Base register for 32 vs 64-bit addressing
	Register base_reg = ( state_.address_size == OpSize::SIZE64 ) ? Register::RAX : Register::EAX;

	if ( state_.mod_ == 0 ) {
	  // No displacement (except special cases)
	  if ( state_.rm == 4 ) {
	    // SIB byte
	    read_sib( instruction );
	  } else if ( state_.rm == 5 ) {
	    // RIP/EIP-relative or disp32
	    auto disp = read_u32();
	    if ( !disp ) return;
	    instruction.set_memory_displacement64( static_cast<int32_t>( *disp ) );
	    instruction.set_memory_displ_size( 4 );
	    if ( bitness_ == 64 ) {
	      instruction.set_memory_base( Register::RIP );
	      state_.flags |= StateFlags::IP_REL64;
	    } else if ( state_.address_size == OpSize::SIZE64 ) {
	      instruction.set_memory_base( Register::EIP );
	      state_.flags |= StateFlags::IP_REL32;
	    }
	  } else {
	    // Simple base register
	    instruction.set_memory_base( static_cast<Register>(
	      static_cast<uint32_t>( base_reg ) + state_.rm + state_.extra_base_register_base ) );
	  }
	} else if ( state_.mod_ == 1 ) {
	  // 8-bit displacement
	  if ( state_.rm == 4 ) {
	    read_sib( instruction );
	  } else {
	    instruction.set_memory_base( static_cast<Register>(
	      static_cast<uint32_t>( base_reg ) + state_.rm + state_.extra_base_register_base ) );
	  }
	  auto disp = read_byte();
	  if ( !disp ) return;
	  instruction.set_memory_displacement64( static_cast<int8_t>( *disp ) );
	  instruction.set_memory_displ_size( 1 );
	} else if ( state_.mod_ == 2 ) {
	  // 32-bit displacement
	  if ( state_.rm == 4 ) {
	    read_sib( instruction );
	  } else {
	    instruction.set_memory_base( static_cast<Register>(
	      static_cast<uint32_t>( base_reg ) + state_.rm + state_.extra_base_register_base ) );
	  }
	  auto disp = read_u32();
	  if ( !disp ) return;
	  instruction.set_memory_displacement64( static_cast<int32_t>( *disp ) );
	  instruction.set_memory_displ_size( 4 );
	}

	// Set operand kind based on operand_index
	switch ( operand_index ) {
	  case 0: instruction.set_op0_kind( OpKind::MEMORY ); break;
	  case 1: instruction.set_op1_kind( OpKind::MEMORY ); break;
	  case 2: instruction.set_op2_kind( OpKind::MEMORY ); break;
	  case 3: instruction.set_op3_kind( OpKind::MEMORY ); break;
	}
}

bool Decoder::read_sib( Instruction& instruction ) noexcept {
	auto sib_opt = read_byte();
	if ( !sib_opt ) return false;
	auto sib = static_cast<uint32_t>( *sib_opt );

	// Scale: bits 7-6 (0-3 maps to 1, 2, 4, 8)
	instruction.set_memory_index_scale( 1u << ( sib >> 6 ) );

	// Base register for 32 vs 64-bit addressing
	Register base_reg = ( state_.address_size == OpSize::SIZE64 ) ? Register::RAX : Register::EAX;

	// Index: bits 5-3 + REX.X extension
	uint32_t index = ( ( sib >> 3 ) & 7 ) + state_.extra_index_register_base;
	if ( index != 4 ) {  // index=4 means no index register
	  instruction.set_memory_index( static_cast<Register>(
	    static_cast<uint32_t>( base_reg ) + index ) );
	}

	// Base: bits 2-0 + REX.B extension
	uint32_t base = ( sib & 7 ) + state_.extra_base_register_base;
	if ( ( sib & 7 ) == 5 && state_.mod_ == 0 ) {
	  // Special case: base=5 with mod=0 means disp32 only
	  auto disp = read_u32();
	  if ( !disp ) return false;
	  instruction.set_memory_displacement64( static_cast<int32_t>( *disp ) );
	  instruction.set_memory_displ_size( 4 );
	} else {
	  instruction.set_memory_base( static_cast<Register>(
	    static_cast<uint32_t>( base_reg ) + base ) );
	}

	return true;
}

void Decoder::read_op_mem_16( Instruction& instruction, uint32_t operand_index ) noexcept {
	// 16-bit addressing mode lookup table
	static constexpr struct { Register base; Register index; } mem_regs_16[] = {
	  { Register::BX, Register::SI },  // rm=0: [BX+SI]
	  { Register::BX, Register::DI },  // rm=1: [BX+DI]
	  { Register::BP, Register::SI },  // rm=2: [BP+SI]
	  { Register::BP, Register::DI },  // rm=3: [BP+DI]
	  { Register::SI, Register::NONE },// rm=4: [SI]
	  { Register::DI, Register::NONE },// rm=5: [DI]
	  { Register::BP, Register::NONE },// rm=6: [BP] or disp16 if mod=0
	  { Register::BX, Register::NONE } // rm=7: [BX]
	};

	if ( state_.mod_ == 0 && state_.rm == 6 ) {
	  // disp16 only
	  auto disp = read_u16();
	  if ( !disp ) return;
	  instruction.set_memory_displacement64( *disp );
	  instruction.set_memory_displ_size( 2 );
	} else {
	  auto& regs = mem_regs_16[state_.rm];
	  instruction.set_memory_base( regs.base );
	  if ( regs.index != Register::NONE ) {
	    instruction.set_memory_index( regs.index );
	  }

	  if ( state_.mod_ == 1 ) {
	    auto disp = read_byte();
	    if ( !disp ) return;
	    instruction.set_memory_displacement64( static_cast<int8_t>( *disp ) );
	    instruction.set_memory_displ_size( 1 );
	  } else if ( state_.mod_ == 2 ) {
	    auto disp = read_u16();
	    if ( !disp ) return;
	    instruction.set_memory_displacement64( *disp );
	    instruction.set_memory_displ_size( 2 );
	  }
	}

	// Set operand kind
	switch ( operand_index ) {
	  case 0: instruction.set_op0_kind( OpKind::MEMORY ); break;
	  case 1: instruction.set_op1_kind( OpKind::MEMORY ); break;
	  case 2: instruction.set_op2_kind( OpKind::MEMORY ); break;
	  case 3: instruction.set_op3_kind( OpKind::MEMORY ); break;
	}
}

void Decoder::read_op_mem_vsib( Instruction& instruction, uint32_t operand_index, Register vsib_index, uint32_t tuple_type ) noexcept {
	// VSIB addressing always requires a SIB byte (mod != 3, rm == 4)
	// The index register comes from VSIB, not from SIB.index

	if ( state_.address_size == OpSize::SIZE16 ) {
	  // 16-bit addressing doesn't support VSIB
	  set_invalid_instruction();
	  return;
	}

	// Read the SIB byte
	auto sib_opt = read_byte();
	if ( !sib_opt ) {
	  set_invalid_instruction();
	  return;
	}
	uint32_t sib = *sib_opt;

	// Extract SIB fields
	uint32_t scale = 1u << ( sib >> 6 );
	uint32_t index = ( ( sib >> 3 ) & 7 ) + state_.extra_index_register_base + state_.extra_index_register_base_vsib;
	uint32_t base = ( sib & 7 ) + state_.extra_base_register_base;

	// Set scale
	instruction.set_memory_index_scale( scale );

	// Set VSIB index register
	instruction.set_memory_index( static_cast<Register>( static_cast<uint32_t>( vsib_index ) + index ) );

	// Base register (64-bit or 32-bit addressing)
	Register base_reg = ( state_.address_size == OpSize::SIZE64 ) ? Register::RAX : Register::EAX;

	// Handle displacement based on mod
	if ( state_.mod_ == 0 ) {
	  if ( ( sib & 7 ) == 5 ) {
	    // No base register, just disp32
	    auto disp = read_u32();
	    if ( !disp ) return;
	    instruction.set_memory_displacement64( static_cast<int32_t>( *disp ) );
	    instruction.set_memory_displ_size( 4 );
	  } else {
	    instruction.set_memory_base( static_cast<Register>( static_cast<uint32_t>( base_reg ) + base ) );
	  }
	} else if ( state_.mod_ == 1 ) {
	  // 8-bit displacement (scaled by tuple_type for EVEX)
	  instruction.set_memory_base( static_cast<Register>( static_cast<uint32_t>( base_reg ) + base ) );
	  auto disp = read_byte();
	  if ( !disp ) return;
	  int32_t scaled_disp = static_cast<int8_t>( *disp );
	  if ( tuple_type != 0 ) {
	    scaled_disp *= static_cast<int32_t>( tuple_type );
	  }
	  instruction.set_memory_displacement64( scaled_disp );
	  instruction.set_memory_displ_size( 1 );
	} else if ( state_.mod_ == 2 ) {
	  // 32-bit displacement
	  instruction.set_memory_base( static_cast<Register>( static_cast<uint32_t>( base_reg ) + base ) );
	  auto disp = read_u32();
	  if ( !disp ) return;
	  instruction.set_memory_displacement64( static_cast<int32_t>( *disp ) );
	  instruction.set_memory_displ_size( 4 );
	}

	// Set operand kind
	switch ( operand_index ) {
	  case 0: instruction.set_op0_kind( OpKind::MEMORY ); break;
	  case 1: instruction.set_op1_kind( OpKind::MEMORY ); break;
	  case 2: instruction.set_op2_kind( OpKind::MEMORY ); break;
	  case 3: instruction.set_op3_kind( OpKind::MEMORY ); break;
	}
}

void Decoder::decode_vex2( Instruction& instruction ) noexcept {
	// Validate: no REX prefix and no mandatory prefix already set
	if ( ( ( ( state_.flags & StateFlags::HAS_REX ) |
	        static_cast<uint32_t>( state_.mandatory_prefix ) ) & invalid_check_mask_ ) != 0 ) {
	  set_invalid_instruction();
	  return;
	}

	// Clear W flag and reset REX extension bits
	state_.flags &= ~StateFlags::W;
	state_.extra_index_register_base = 0;
	state_.extra_base_register_base = 0;
	state_.extra_register_base_evex = 0;
	state_.extra_base_register_base_evex = 0;

	// state_.modrm contains the VEX byte2 (already read)
	uint32_t b2 = state_.modrm;

	// Read opcode byte
	auto opcode_opt = read_byte();
	if ( !opcode_opt ) {
	  set_invalid_instruction();
	  return;
	}
	uint32_t opcode = *opcode_opt;

	// Extract VEX fields from b2:
	// Bit 7: ~R (inverted REX.R)
	// Bits 6-3: ~vvvv (inverted register specifier)
	// Bit 2: L (vector length: 0=128, 1=256)
	// Bits 1-0: pp (implied mandatory prefix)
	state_.vector_length = static_cast<VectorLength>( ( b2 >> 2 ) & 1 );
	state_.mandatory_prefix = static_cast<DecoderMandatoryPrefix>( b2 & 3 );

	uint32_t b2_inv = ~b2;
	state_.extra_register_base = ( b2_inv >> 4 ) & 8;  // R bit -> bit 3

	uint32_t vvvv = ( b2_inv >> 3 ) & 0x0F;
	state_.vvvv_invalid_check = vvvv;
	state_.vvvv = vvvv & reg15_mask();

	// VEX2 implies map 0F (map_index = 0)
	auto* table = get_vex_table( 0 );
	if ( !table || opcode >= table->size() ) {
	  set_invalid_instruction();
	  return;
	}

	decode_table( (*table)[opcode], instruction );
}

void Decoder::decode_vex3( Instruction& instruction ) noexcept {
	// Validate: no REX prefix and no mandatory prefix already set
	if ( ( ( ( state_.flags & StateFlags::HAS_REX ) |
	        static_cast<uint32_t>( state_.mandatory_prefix ) ) & invalid_check_mask_ ) != 0 ) {
	  set_invalid_instruction();
	  return;
	}

	// Clear W flag
	state_.flags &= ~StateFlags::W;
	state_.extra_register_base_evex = 0;
	state_.extra_base_register_base_evex = 0;

	// state_.modrm contains VEX byte2 (P0: RXBmmmmm)
	uint32_t p0 = state_.modrm;

	// Read VEX byte3 (P1: WvvvvLpp) and opcode
	auto p1_opt = read_byte();
	if ( !p1_opt ) {
	  set_invalid_instruction();
	  return;
	}
	uint32_t p1 = *p1_opt;

	auto opcode_opt = read_byte();
	if ( !opcode_opt ) {
	  set_invalid_instruction();
	  return;
	}
	uint32_t opcode = *opcode_opt;

	// Extract P1 fields:
	// Bit 7: W (REX.W equivalent)
	// Bits 6-3: ~vvvv (inverted register specifier)
	// Bit 2: L (vector length)
	// Bits 1-0: pp (implied mandatory prefix)
	if ( ( p1 & 0x80 ) != 0 ) {
	  state_.flags |= StateFlags::W;
	}
	state_.vector_length = static_cast<VectorLength>( ( p1 >> 2 ) & 1 );
	state_.mandatory_prefix = static_cast<DecoderMandatoryPrefix>( p1 & 3 );

	uint32_t vvvv = ( ~p1 >> 3 ) & 0x0F;
	state_.vvvv_invalid_check = vvvv;
	state_.vvvv = vvvv & reg15_mask();

	// Extract P0 fields (inverted R, X, B bits):
	// Bit 7: ~R, Bit 6: ~X, Bit 5: ~B
	// Bits 4-0: mmmmm (map select)
	uint32_t p0_inv = ~p0 & mask_e0_;
	state_.extra_register_base = ( p0_inv >> 4 ) & 8;
	state_.extra_index_register_base = ( p0_inv >> 3 ) & 8;
	state_.extra_base_register_base = ( p0_inv >> 2 ) & 8;

	// Map select: mmmmm field (1=0F, 2=0F38, 3=0F3A)
	uint32_t map = ( p0 & 0x1F );
	if ( map == 0 || map > 3 ) {
	  set_invalid_instruction();
	  return;
	}
	uint32_t map_index = map - 1;  // Convert to 0-based index

	auto* table = get_vex_table( map_index );
	if ( !table || opcode >= table->size() ) {
	  set_invalid_instruction();
	  return;
	}

	decode_table( (*table)[opcode], instruction );
}

void Decoder::decode_evex( Instruction& instruction ) noexcept {
	// Validate: no REX prefix and no mandatory prefix already set
	if ( ( ( ( state_.flags & StateFlags::HAS_REX ) |
	        static_cast<uint32_t>( state_.mandatory_prefix ) ) & invalid_check_mask_ ) != 0 ) {
	  set_invalid_instruction();
	  return;
	}

	// state_.modrm contains P0 (first EVEX payload byte)
	uint32_t p0 = state_.modrm;

	// Read P1, P2, and opcode
	auto p1_opt = read_byte();
	if ( !p1_opt ) {
	  set_invalid_instruction();
	  return;
	}
	uint32_t p1 = *p1_opt;

	// Validate EVEX: P1 bit 2 must be 1
	if ( ( p1 & 0x04 ) == 0 ) {
	  set_invalid_instruction();
	  return;
	}

	auto p2_opt = read_byte();
	if ( !p2_opt ) {
	  set_invalid_instruction();
	  return;
	}
	uint32_t p2 = *p2_opt;

	auto opcode_opt = read_byte();
	if ( !opcode_opt ) {
	  set_invalid_instruction();
	  return;
	}
	uint32_t opcode = *opcode_opt;

	// Extract P1 fields:
	// Bit 7: W
	// Bits 6-3: ~vvvv
	// Bit 2: must be 1 (already checked)
	// Bits 1-0: pp
	state_.mandatory_prefix = static_cast<DecoderMandatoryPrefix>( p1 & 3 );
	if ( ( p1 & 0x80 ) != 0 ) {
	  state_.flags |= StateFlags::W;
	} else {
	  state_.flags &= ~StateFlags::W;
	}

	// Extract P2 fields:
	// Bit 7: z (zeroing-masking)
	// Bits 6-5: LL' (vector length)
	// Bit 4: b (broadcast/rounding)
	// Bit 3: V' (vvvv extension)
	// Bits 2-0: aaa (opmask register)
	state_.aaa = p2 & 7;
	instruction.set_op_mask( static_cast<Register>(
	  static_cast<uint32_t>( Register::K0 ) + state_.aaa ) );

	if ( ( p2 & 0x80 ) != 0 ) {
	  state_.flags |= StateFlags::Z;
	  instruction.set_zeroing_masking( true );
	} else {
	  state_.flags &= ~StateFlags::Z;
	}

	if ( ( p2 & 0x10 ) != 0 ) {
	  state_.flags |= StateFlags::B;
	} else {
	  state_.flags &= ~StateFlags::B;
	}

	state_.vector_length = static_cast<VectorLength>( ( p2 >> 5 ) & 3 );

	// vvvv from P1 and V' from P2
	uint32_t vvvv_low = ( ~p1 >> 3 ) & 0x0F;
	if ( bitness_ == 64 ) {
	  uint32_t v_prime = ( ~p2 & 8 ) << 1;  // V' bit -> bit 4
	  state_.extra_index_register_base_vsib = v_prime;
	  state_.vvvv = v_prime + vvvv_low;
	  state_.vvvv_invalid_check = state_.vvvv;
	} else {
	  state_.vvvv = vvvv_low & 0x7;
	  state_.vvvv_invalid_check = vvvv_low;
	}

	// Extract P0 fields (EVEX-specific R', X', B' extensions):
	// Bit 7: ~R, Bit 6: ~X, Bit 5: ~B, Bit 4: ~R'
	// Bit 3: must be 0 for EVEX (vs MVEX)
	// Bits 2-0: mm (map select)
	if ( ( p0 & 0x08 ) != 0 ) {
	  // Bit 3 must be 0 for EVEX
	  set_invalid_instruction();
	  return;
	}

	if ( bitness_ == 64 ) {
	  uint32_t p0_inv = ~p0;
	  state_.extra_register_base = ( p0_inv >> 4 ) & 8;       // R -> bit 3
	  state_.extra_index_register_base = ( p0_inv >> 3 ) & 8; // X -> bit 3
	  state_.extra_register_base_evex = p0_inv & 0x10;        // R' -> bit 4
	  state_.extra_base_register_base_evex = ( p0_inv >> 2 ) & 0x18; // X' and B'
	  state_.extra_base_register_base = ( p0_inv >> 2 ) & 8; // B -> bit 3
	} else {
	  state_.extra_register_base = 0;
	  state_.extra_index_register_base = 0;
	  state_.extra_register_base_evex = 0;
	  state_.extra_base_register_base_evex = 0;
	  state_.extra_base_register_base = 0;
	}

	// Map select: mm field (1=0F, 2=0F38, 3=0F3A, 5=MAP5, 6=MAP6)
	uint32_t map = ( p0 & 0x07 );
	uint32_t map_index;
	switch ( map ) {
	  case 1: map_index = 0; break;  // 0F
	  case 2: map_index = 1; break;  // 0F38
	  case 3: map_index = 2; break;  // 0F3A
	  case 5: map_index = 4; break;  // MAP5
	  case 6: map_index = 5; break;  // MAP6
	  default:
	    set_invalid_instruction();
	    return;
	}

	auto* table = get_evex_table( map_index );
	if ( !table || opcode >= table->size() ) {
	  set_invalid_instruction();
	  return;
	}

	decode_table( (*table)[opcode], instruction );
}

void Decoder::decode_xop( Instruction& instruction ) noexcept {
	// XOP prefix (0x8F followed by XOP-specific bytes)
	// XOP uses same basic structure as VEX3 but different map values
	// For now, mark as invalid - XOP is AMD-specific and rarely used
	set_invalid_instruction();
}

void Decoder::decode_3dnow( Instruction& instruction ) noexcept {
	// 3DNow! instructions (0x0F 0x0F ... suffix)
	// These are legacy AMD instructions
	// For now, mark as invalid - 3DNow! is deprecated
	set_invalid_instruction();
}

void Decoder::read_op_mem_evex( Instruction& instruction, uint32_t operand_index, uint32_t tuple_type ) noexcept {
	// EVEX memory operand with tuple type scaling for compressed displacement
	if ( state_.address_size == OpSize::SIZE16 ) {
	  read_op_mem_16( instruction, operand_index );
	  return;
	}

	// Base register for 32 vs 64-bit addressing
	Register base_reg = ( state_.address_size == OpSize::SIZE64 ) ? Register::RAX : Register::EAX;

	if ( state_.mod_ == 0 ) {
	  // No displacement (except special cases)
	  if ( state_.rm == 4 ) {
	    // SIB byte
	    read_sib( instruction );
	  } else if ( state_.rm == 5 ) {
	    // RIP/EIP-relative or disp32
	    auto disp = read_u32();
	    if ( !disp ) return;
	    instruction.set_memory_displacement64( static_cast<int32_t>( *disp ) );
	    instruction.set_memory_displ_size( 4 );
	    if ( bitness_ == 64 ) {
	      instruction.set_memory_base( Register::RIP );
	      state_.flags |= StateFlags::IP_REL64;
	    } else if ( state_.address_size == OpSize::SIZE64 ) {
	      instruction.set_memory_base( Register::EIP );
	      state_.flags |= StateFlags::IP_REL32;
	    }
	  } else {
	    // Simple base register
	    instruction.set_memory_base( static_cast<Register>(
	      static_cast<uint32_t>( base_reg ) + state_.rm + state_.extra_base_register_base + state_.extra_base_register_base_evex ) );
	  }
	} else if ( state_.mod_ == 1 ) {
	  // 8-bit displacement with EVEX compressed displacement scaling
	  if ( state_.rm == 4 ) {
	    read_sib( instruction );
	  } else {
	    instruction.set_memory_base( static_cast<Register>(
	      static_cast<uint32_t>( base_reg ) + state_.rm + state_.extra_base_register_base + state_.extra_base_register_base_evex ) );
	  }
	  auto disp = read_byte();
	  if ( !disp ) return;
	  int32_t scaled_disp = static_cast<int8_t>( *disp );
	  if ( tuple_type != 0 ) {
	    scaled_disp *= static_cast<int32_t>( tuple_type );
	  }
	  instruction.set_memory_displacement64( scaled_disp );
	  instruction.set_memory_displ_size( 1 );
	} else if ( state_.mod_ == 2 ) {
	  // 32-bit displacement (no scaling)
	  if ( state_.rm == 4 ) {
	    read_sib( instruction );
	  } else {
	    instruction.set_memory_base( static_cast<Register>(
	      static_cast<uint32_t>( base_reg ) + state_.rm + state_.extra_base_register_base + state_.extra_base_register_base_evex ) );
	  }
	  auto disp = read_u32();
	  if ( !disp ) return;
	  instruction.set_memory_displacement64( static_cast<int32_t>( *disp ) );
	  instruction.set_memory_displ_size( 4 );
	}

	// Set operand kind based on operand_index
	switch ( operand_index ) {
	  case 0: instruction.set_op0_kind( OpKind::MEMORY ); break;
	  case 1: instruction.set_op1_kind( OpKind::MEMORY ); break;
	  case 2: instruction.set_op2_kind( OpKind::MEMORY ); break;
	  case 3: instruction.set_op3_kind( OpKind::MEMORY ); break;
	}
}
const std::vector<internal::HandlerEntry>* Decoder::get_vex_table( uint32_t map_index ) const noexcept {
	switch ( map_index ) {
	  case 0: return &handlers_vex_0f_;
	  case 1: return &handlers_vex_0f38_;
	  case 2: return &handlers_vex_0f3a_;
	  default: return nullptr;
	}
}

const std::vector<internal::HandlerEntry>* Decoder::get_evex_table( uint32_t map_index ) const noexcept {
	switch ( map_index ) {
	  case 0: return &handlers_evex_0f_;
	  case 1: return &handlers_evex_0f38_;
	  case 2: return &handlers_evex_0f3a_;
	  case 4: return &handlers_evex_map5_;
	  case 5: return &handlers_evex_map6_;
	  default: return nullptr;
	}
}

} // namespace iced_x86
