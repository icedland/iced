# SPDX-License-Identifier: MIT
# Copyright (C) 2018-present iced project and contributors

# Code: INVALID
INSTRUCTION: <invalid> | <invalid> | INTEL8086
	mnemonic: INVALID
	flags: no-instr cflow=ex asm-ig
	fast: mnemonic=(bad)
	gas: mnemonic=(bad)
	intel: mnemonic=(bad)
	masm: mnemonic=(bad)
	nasm: mnemonic=(bad)
END

# Code: DeclareByte
INSTRUCTION: <db> | <db> | INTEL8086
	mnemonic: db
	code-mnemonic: DeclareByte
	flags: no-instr cflow=ex asm-ig
	gas: mnemonic=.byte decl
	intel: decl
	masm: decl
	nasm: decl
END

# Code: DeclareWord
INSTRUCTION: <dw> | <dw> | INTEL8086
	mnemonic: dw
	code-mnemonic: DeclareWord
	flags: no-instr cflow=ex asm-ig
	gas: mnemonic=.word decl
	intel: decl
	masm: decl
	nasm: decl
END

# Code: DeclareDword
INSTRUCTION: <dd> | <dd> | INTEL8086
	mnemonic: dd
	code-mnemonic: DeclareDword
	flags: no-instr cflow=ex asm-ig
	gas: mnemonic=.int decl
	intel: decl
	masm: decl
	nasm: decl
END

# Code: DeclareQword
INSTRUCTION: <dq> | <dq> | INTEL8086
	mnemonic: dq
	code-mnemonic: DeclareQword
	flags: no-instr cflow=ex asm-ig
	gas: mnemonic=.quad decl
	intel: decl
	masm: decl
	nasm: decl
END

# Code: Zero_bytes
INSTRUCTION: <zero_bytes> | ZERO_BYTES | INTEL8086
	flags: no-instr
END

# Code: Add_rm8_r8
INSTRUCTION: 00 /r | ADD r/m8, r8 | INTEL8086
	ops: rw=rm r=reg | UInt8
	rflags: w=oszacp
	flags: lock xacquire xrelease
	gas: suffix=b
END

# Code: Add_rm16_r16
INSTRUCTION: o16 01 /r | ADD r/m16, r16 | INTEL8086
	ops: rw=rm r=reg | UInt16
	rflags: w=oszacp
	flags: lock xacquire xrelease
	gas: suffix=w
END

# Code: Add_rm32_r32
INSTRUCTION: o32 01 /r | ADD r/m32, r32 | INTEL386
	ops: rw=rm r=reg | UInt32
	rflags: w=oszacp
	flags: lock xacquire xrelease
	gas: suffix=l
END

# Code: Add_rm64_r64
INSTRUCTION: o64 01 /r | ADD r/m64, r64 | X64
	ops: rw=rm r=reg | UInt64
	rflags: w=oszacp
	flags: 64 lock xacquire xrelease
	gas: suffix=q
END

# Code: Add_r8_rm8
INSTRUCTION: 02 /r | ADD r8, r/m8 | INTEL8086
	ops: rw=reg r=rm | UInt8
	rflags: w=oszacp
	gas: suffix=b
END

# Code: Add_r16_rm16
INSTRUCTION: o16 03 /r | ADD r16, r/m16 | INTEL8086
	ops: rw=reg r=rm | UInt16
	rflags: w=oszacp
	gas: suffix=w
END

# Code: Add_r32_rm32
INSTRUCTION: o32 03 /r | ADD r32, r/m32 | INTEL386
	ops: rw=reg r=rm | UInt32
	rflags: w=oszacp
	gas: suffix=l
END

# Code: Add_r64_rm64
INSTRUCTION: o64 03 /r | ADD r64, r/m64 | X64
	ops: rw=reg r=rm | UInt64
	rflags: w=oszacp
	flags: 64
	gas: suffix=q
END

# Code: Add_AL_imm8
INSTRUCTION: 04 ib | ADD AL, imm8 | INTEL8086
	ops: rw=r:al r=imm
	rflags: w=oszacp
	gas: suffix=b
END

# Code: Add_AX_imm16
INSTRUCTION: o16 05 iw | ADD AX, imm16 | INTEL8086
	ops: rw=r:ax r=imm
	rflags: w=oszacp
	gas: suffix=w
END

# Code: Add_EAX_imm32
INSTRUCTION: o32 05 id | ADD EAX, imm32 | INTEL386
	ops: rw=r:eax r=imm
	rflags: w=oszacp
	gas: suffix=l
END

# Code: Add_RAX_imm32
INSTRUCTION: o64 05 id | ADD RAX, imm32 | X64
	ops: rw=r:rax r=imm;64
	rflags: w=oszacp
	flags: 64
	gas: suffix=q
	nasm: sx
END

# Code: Pushw_ES
INSTRUCTION: o16 06 | PUSH ES | INTEL8086
	ops: r=r:es
	implied: push=1x2
	code-mnemonic: pushw
	flags: 16 32 sp=push;2
	gas: suffix=w osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Pushd_ES
INSTRUCTION: o32 06 | PUSH ES | INTEL386
	ops: r=r:es
	implied: push=1x4
	code-mnemonic: pushd
	flags: 16 32 sp=push;4
	gas: suffix=l osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Popw_ES
INSTRUCTION: o16 07 | POP ES | INTEL8086
	ops: w=r:es
	implied: pop=1x2
	code-mnemonic: popw
	flags: 16 32 sp=pop;2 no-in-sgx tsx-impl-abort
	gas: suffix=w osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Popd_ES
INSTRUCTION: o32 07 | POP ES | INTEL386
	ops: w=r:es
	implied: pop=1x4
	code-mnemonic: popd
	flags: 16 32 sp=pop;4 no-in-sgx tsx-impl-abort
	gas: suffix=l osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Or_rm8_r8
INSTRUCTION: 08 /r | OR r/m8, r8 | INTEL8086
	ops: rw=rm r=reg | UInt8
	rflags: u=a w=szp 0=oc
	flags: lock xacquire xrelease
	gas: suffix=b
END

# Code: Or_rm16_r16
INSTRUCTION: o16 09 /r | OR r/m16, r16 | INTEL8086
	ops: rw=rm r=reg | UInt16
	rflags: u=a w=szp 0=oc
	flags: lock xacquire xrelease
	gas: suffix=w
END

# Code: Or_rm32_r32
INSTRUCTION: o32 09 /r | OR r/m32, r32 | INTEL386
	ops: rw=rm r=reg | UInt32
	rflags: u=a w=szp 0=oc
	flags: lock xacquire xrelease
	gas: suffix=l
END

# Code: Or_rm64_r64
INSTRUCTION: o64 09 /r | OR r/m64, r64 | X64
	ops: rw=rm r=reg | UInt64
	rflags: u=a w=szp 0=oc
	flags: 64 lock xacquire xrelease
	gas: suffix=q
END

# Code: Or_r8_rm8
INSTRUCTION: 0A /r | OR r8, r/m8 | INTEL8086
	ops: rw=reg r=rm | UInt8
	rflags: u=a w=szp 0=oc
	gas: suffix=b
END

# Code: Or_r16_rm16
INSTRUCTION: o16 0B /r | OR r16, r/m16 | INTEL8086
	ops: rw=reg r=rm | UInt16
	rflags: u=a w=szp 0=oc
	gas: suffix=w
END

# Code: Or_r32_rm32
INSTRUCTION: o32 0B /r | OR r32, r/m32 | INTEL386
	ops: rw=reg r=rm | UInt32
	rflags: u=a w=szp 0=oc
	gas: suffix=l
END

# Code: Or_r64_rm64
INSTRUCTION: o64 0B /r | OR r64, r/m64 | X64
	ops: rw=reg r=rm | UInt64
	rflags: u=a w=szp 0=oc
	flags: 64
	gas: suffix=q
END

# Code: Or_AL_imm8
INSTRUCTION: 0C ib | OR AL, imm8 | INTEL8086
	ops: rw=r:al r=imm
	rflags: u=a w=szp 0=oc
	gas: suffix=b
END

# Code: Or_AX_imm16
INSTRUCTION: o16 0D iw | OR AX, imm16 | INTEL8086
	ops: rw=r:ax r=imm
	rflags: u=a w=szp 0=oc
	gas: suffix=w
END

# Code: Or_EAX_imm32
INSTRUCTION: o32 0D id | OR EAX, imm32 | INTEL386
	ops: rw=r:eax r=imm
	rflags: u=a w=szp 0=oc
	gas: suffix=l
END

# Code: Or_RAX_imm32
INSTRUCTION: o64 0D id | OR RAX, imm32 | X64
	ops: rw=r:rax r=imm;64
	rflags: u=a w=szp 0=oc
	flags: 64
	gas: suffix=q
	nasm: sx
END

# Code: Pushw_CS
INSTRUCTION: o16 0E | PUSH CS | INTEL8086
	ops: r=r:cs
	implied: push=1x2
	code-mnemonic: pushw
	flags: 16 32 sp=push;2
	gas: suffix=w osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Pushd_CS
INSTRUCTION: o32 0E | PUSH CS | INTEL386
	ops: r=r:cs
	implied: push=1x4
	code-mnemonic: pushd
	flags: 16 32 sp=push;4
	gas: suffix=l osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Popw_CS
INSTRUCTION: o16 0F | POP CS | INTEL8086_ONLY
	ops: w=r:cs
	implied: pop=1x2
	code-mnemonic: popw
	flags: 16 sp=pop;2 asm-ig
	gas: suffix=w
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Adc_rm8_r8
INSTRUCTION: 10 /r | ADC r/m8, r8 | INTEL8086
	ops: rw=rm r=reg | UInt8
	rflags: r=c w=oszacp
	flags: lock xacquire xrelease
	gas: suffix=b
END

# Code: Adc_rm16_r16
INSTRUCTION: o16 11 /r | ADC r/m16, r16 | INTEL8086
	ops: rw=rm r=reg | UInt16
	rflags: r=c w=oszacp
	flags: lock xacquire xrelease
	gas: suffix=w
END

# Code: Adc_rm32_r32
INSTRUCTION: o32 11 /r | ADC r/m32, r32 | INTEL386
	ops: rw=rm r=reg | UInt32
	rflags: r=c w=oszacp
	flags: lock xacquire xrelease
	gas: suffix=l
END

# Code: Adc_rm64_r64
INSTRUCTION: o64 11 /r | ADC r/m64, r64 | X64
	ops: rw=rm r=reg | UInt64
	rflags: r=c w=oszacp
	flags: 64 lock xacquire xrelease
	gas: suffix=q
END

# Code: Adc_r8_rm8
INSTRUCTION: 12 /r | ADC r8, r/m8 | INTEL8086
	ops: rw=reg r=rm | UInt8
	rflags: r=c w=oszacp
	gas: suffix=b
END

# Code: Adc_r16_rm16
INSTRUCTION: o16 13 /r | ADC r16, r/m16 | INTEL8086
	ops: rw=reg r=rm | UInt16
	rflags: r=c w=oszacp
	gas: suffix=w
END

# Code: Adc_r32_rm32
INSTRUCTION: o32 13 /r | ADC r32, r/m32 | INTEL386
	ops: rw=reg r=rm | UInt32
	rflags: r=c w=oszacp
	gas: suffix=l
END

# Code: Adc_r64_rm64
INSTRUCTION: o64 13 /r | ADC r64, r/m64 | X64
	ops: rw=reg r=rm | UInt64
	rflags: r=c w=oszacp
	flags: 64
	gas: suffix=q
END

# Code: Adc_AL_imm8
INSTRUCTION: 14 ib | ADC AL, imm8 | INTEL8086
	ops: rw=r:al r=imm
	rflags: r=c w=oszacp
	gas: suffix=b
END

# Code: Adc_AX_imm16
INSTRUCTION: o16 15 iw | ADC AX, imm16 | INTEL8086
	ops: rw=r:ax r=imm
	rflags: r=c w=oszacp
	gas: suffix=w
END

# Code: Adc_EAX_imm32
INSTRUCTION: o32 15 id | ADC EAX, imm32 | INTEL386
	ops: rw=r:eax r=imm
	rflags: r=c w=oszacp
	gas: suffix=l
END

# Code: Adc_RAX_imm32
INSTRUCTION: o64 15 id | ADC RAX, imm32 | X64
	ops: rw=r:rax r=imm;64
	rflags: r=c w=oszacp
	flags: 64
	gas: suffix=q
	nasm: sx
END

# Code: Pushw_SS
INSTRUCTION: o16 16 | PUSH SS | INTEL8086
	ops: r=r:ss
	implied: push=1x2
	code-mnemonic: pushw
	flags: 16 32 sp=push;2
	gas: suffix=w osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Pushd_SS
INSTRUCTION: o32 16 | PUSH SS | INTEL386
	ops: r=r:ss
	implied: push=1x4
	code-mnemonic: pushd
	flags: 16 32 sp=push;4
	gas: suffix=l osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Popw_SS
INSTRUCTION: o16 17 | POP SS | INTEL8086
	ops: w=r:ss
	implied: pop=1x2
	code-mnemonic: popw
	flags: 16 32 sp=pop;2 no-in-sgx tsx-impl-abort
	gas: suffix=w osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Popd_SS
INSTRUCTION: o32 17 | POP SS | INTEL386
	ops: w=r:ss
	implied: pop=1x4
	code-mnemonic: popd
	flags: 16 32 sp=pop;4 no-in-sgx tsx-impl-abort
	gas: suffix=l osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Sbb_rm8_r8
INSTRUCTION: 18 /r | SBB r/m8, r8 | INTEL8086
	ops: rw=rm r=reg | UInt8
	rflags: r=c w=oszacp
	flags: lock xacquire xrelease
	gas: suffix=b
END

# Code: Sbb_rm16_r16
INSTRUCTION: o16 19 /r | SBB r/m16, r16 | INTEL8086
	ops: rw=rm r=reg | UInt16
	rflags: r=c w=oszacp
	flags: lock xacquire xrelease
	gas: suffix=w
END

# Code: Sbb_rm32_r32
INSTRUCTION: o32 19 /r | SBB r/m32, r32 | INTEL386
	ops: rw=rm r=reg | UInt32
	rflags: r=c w=oszacp
	flags: lock xacquire xrelease
	gas: suffix=l
END

# Code: Sbb_rm64_r64
INSTRUCTION: o64 19 /r | SBB r/m64, r64 | X64
	ops: rw=rm r=reg | UInt64
	rflags: r=c w=oszacp
	flags: 64 lock xacquire xrelease
	gas: suffix=q
END

# Code: Sbb_r8_rm8
INSTRUCTION: 1A /r | SBB r8, r/m8 | INTEL8086
	ops: rw=reg r=rm | UInt8
	rflags: r=c w=oszacp
	gas: suffix=b
END

# Code: Sbb_r16_rm16
INSTRUCTION: o16 1B /r | SBB r16, r/m16 | INTEL8086
	ops: rw=reg r=rm | UInt16
	rflags: r=c w=oszacp
	gas: suffix=w
END

# Code: Sbb_r32_rm32
INSTRUCTION: o32 1B /r | SBB r32, r/m32 | INTEL386
	ops: rw=reg r=rm | UInt32
	rflags: r=c w=oszacp
	gas: suffix=l
END

# Code: Sbb_r64_rm64
INSTRUCTION: o64 1B /r | SBB r64, r/m64 | X64
	ops: rw=reg r=rm | UInt64
	rflags: r=c w=oszacp
	flags: 64
	gas: suffix=q
END

# Code: Sbb_AL_imm8
INSTRUCTION: 1C ib | SBB AL, imm8 | INTEL8086
	ops: rw=r:al r=imm
	rflags: r=c w=oszacp
	gas: suffix=b
END

# Code: Sbb_AX_imm16
INSTRUCTION: o16 1D iw | SBB AX, imm16 | INTEL8086
	ops: rw=r:ax r=imm
	rflags: r=c w=oszacp
	gas: suffix=w
END

# Code: Sbb_EAX_imm32
INSTRUCTION: o32 1D id | SBB EAX, imm32 | INTEL386
	ops: rw=r:eax r=imm
	rflags: r=c w=oszacp
	gas: suffix=l
END

# Code: Sbb_RAX_imm32
INSTRUCTION: o64 1D id | SBB RAX, imm32 | X64
	ops: rw=r:rax r=imm;64
	rflags: r=c w=oszacp
	flags: 64
	gas: suffix=q
	nasm: sx
END

# Code: Pushw_DS
INSTRUCTION: o16 1E | PUSH DS | INTEL8086
	ops: r=r:ds
	implied: push=1x2
	code-mnemonic: pushw
	flags: 16 32 sp=push;2
	gas: suffix=w osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Pushd_DS
INSTRUCTION: o32 1E | PUSH DS | INTEL386
	ops: r=r:ds
	implied: push=1x4
	code-mnemonic: pushd
	flags: 16 32 sp=push;4
	gas: suffix=l osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Popw_DS
INSTRUCTION: o16 1F | POP DS | INTEL8086
	ops: w=r:ds
	implied: pop=1x2
	code-mnemonic: popw
	flags: 16 32 sp=pop;2 no-in-sgx tsx-impl-abort
	gas: suffix=w osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Popd_DS
INSTRUCTION: o32 1F | POP DS | INTEL386
	ops: w=r:ds
	implied: pop=1x4
	code-mnemonic: popd
	flags: 16 32 sp=pop;4 no-in-sgx tsx-impl-abort
	gas: suffix=l osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: And_rm8_r8
INSTRUCTION: 20 /r | AND r/m8, r8 | INTEL8086
	ops: rw=rm r=reg | UInt8
	rflags: u=a w=szp 0=oc
	flags: lock xacquire xrelease
	gas: suffix=b
END

# Code: And_rm16_r16
INSTRUCTION: o16 21 /r | AND r/m16, r16 | INTEL8086
	ops: rw=rm r=reg | UInt16
	rflags: u=a w=szp 0=oc
	flags: lock xacquire xrelease
	gas: suffix=w
END

# Code: And_rm32_r32
INSTRUCTION: o32 21 /r | AND r/m32, r32 | INTEL386
	ops: rw=rm r=reg | UInt32
	rflags: u=a w=szp 0=oc
	flags: lock xacquire xrelease
	gas: suffix=l
END

# Code: And_rm64_r64
INSTRUCTION: o64 21 /r | AND r/m64, r64 | X64
	ops: rw=rm r=reg | UInt64
	rflags: u=a w=szp 0=oc
	flags: 64 lock xacquire xrelease
	gas: suffix=q
END

# Code: And_r8_rm8
INSTRUCTION: 22 /r | AND r8, r/m8 | INTEL8086
	ops: rw=reg r=rm | UInt8
	rflags: u=a w=szp 0=oc
	gas: suffix=b
END

# Code: And_r16_rm16
INSTRUCTION: o16 23 /r | AND r16, r/m16 | INTEL8086
	ops: rw=reg r=rm | UInt16
	rflags: u=a w=szp 0=oc
	gas: suffix=w
END

# Code: And_r32_rm32
INSTRUCTION: o32 23 /r | AND r32, r/m32 | INTEL386
	ops: rw=reg r=rm | UInt32
	rflags: u=a w=szp 0=oc
	gas: suffix=l
END

# Code: And_r64_rm64
INSTRUCTION: o64 23 /r | AND r64, r/m64 | X64
	ops: rw=reg r=rm | UInt64
	rflags: u=a w=szp 0=oc
	flags: 64
	gas: suffix=q
END

# Code: And_AL_imm8
INSTRUCTION: 24 ib | AND AL, imm8 | INTEL8086
	ops: rw=r:al r=imm
	rflags: u=a w=szp 0=oc
	gas: suffix=b
END

# Code: And_AX_imm16
INSTRUCTION: o16 25 iw | AND AX, imm16 | INTEL8086
	ops: rw=r:ax r=imm
	rflags: u=a w=szp 0=oc
	gas: suffix=w
END

# Code: And_EAX_imm32
INSTRUCTION: o32 25 id | AND EAX, imm32 | INTEL386
	ops: rw=r:eax r=imm
	rflags: u=a w=szp 0=oc
	gas: suffix=l
END

# Code: And_RAX_imm32
INSTRUCTION: o64 25 id | AND RAX, imm32 | X64
	ops: rw=r:rax r=imm;64
	rflags: u=a w=szp 0=oc
	flags: 64
	gas: suffix=q
	nasm: sx
END

# Code: Daa
INSTRUCTION: 27 | DAA | INTEL8086
	implied: rw=al
	rflags: r=ac u=o w=szacp
	flags: 16 32
END

# Code: Sub_rm8_r8
INSTRUCTION: 28 /r | SUB r/m8, r8 | INTEL8086
	ops: rw=rm r=reg | UInt8
	implied: zero-reg-rflags
	rflags: w=oszacp
	flags: lock xacquire xrelease
	gas: suffix=b
END

# Code: Sub_rm16_r16
INSTRUCTION: o16 29 /r | SUB r/m16, r16 | INTEL8086
	ops: rw=rm r=reg | UInt16
	implied: zero-reg-rflags
	rflags: w=oszacp
	flags: lock xacquire xrelease
	gas: suffix=w
END

# Code: Sub_rm32_r32
INSTRUCTION: o32 29 /r | SUB r/m32, r32 | INTEL386
	ops: rw=rm r=reg | UInt32
	implied: zero-reg-rflags
	rflags: w=oszacp
	flags: lock xacquire xrelease
	gas: suffix=l
END

# Code: Sub_rm64_r64
INSTRUCTION: o64 29 /r | SUB r/m64, r64 | X64
	ops: rw=rm r=reg | UInt64
	implied: zero-reg-rflags
	rflags: w=oszacp
	flags: 64 lock xacquire xrelease
	gas: suffix=q
END

# Code: Sub_r8_rm8
INSTRUCTION: 2A /r | SUB r8, r/m8 | INTEL8086
	ops: rw=reg r=rm | UInt8
	implied: zero-reg-rflags
	rflags: w=oszacp
	gas: suffix=b
END

# Code: Sub_r16_rm16
INSTRUCTION: o16 2B /r | SUB r16, r/m16 | INTEL8086
	ops: rw=reg r=rm | UInt16
	implied: zero-reg-rflags
	rflags: w=oszacp
	gas: suffix=w
END

# Code: Sub_r32_rm32
INSTRUCTION: o32 2B /r | SUB r32, r/m32 | INTEL386
	ops: rw=reg r=rm | UInt32
	implied: zero-reg-rflags
	rflags: w=oszacp
	gas: suffix=l
END

# Code: Sub_r64_rm64
INSTRUCTION: o64 2B /r | SUB r64, r/m64 | X64
	ops: rw=reg r=rm | UInt64
	implied: zero-reg-rflags
	rflags: w=oszacp
	flags: 64
	gas: suffix=q
END

# Code: Sub_AL_imm8
INSTRUCTION: 2C ib | SUB AL, imm8 | INTEL8086
	ops: rw=r:al r=imm
	rflags: w=oszacp
	gas: suffix=b
END

# Code: Sub_AX_imm16
INSTRUCTION: o16 2D iw | SUB AX, imm16 | INTEL8086
	ops: rw=r:ax r=imm
	rflags: w=oszacp
	gas: suffix=w
END

# Code: Sub_EAX_imm32
INSTRUCTION: o32 2D id | SUB EAX, imm32 | INTEL386
	ops: rw=r:eax r=imm
	rflags: w=oszacp
	gas: suffix=l
END

# Code: Sub_RAX_imm32
INSTRUCTION: o64 2D id | SUB RAX, imm32 | X64
	ops: rw=r:rax r=imm;64
	rflags: w=oszacp
	flags: 64
	gas: suffix=q
	nasm: sx
END

# Code: Das
INSTRUCTION: 2F | DAS | INTEL8086
	implied: rw=al
	rflags: r=ac u=o w=szacp
	flags: 16 32
END

# Code: Xor_rm8_r8
INSTRUCTION: 30 /r | XOR r/m8, r8 | INTEL8086
	ops: rw=rm r=reg | UInt8
	implied: zero-reg-rflags
	rflags: u=a w=szp 0=oc
	flags: lock xacquire xrelease
	gas: suffix=b
END

# Code: Xor_rm16_r16
INSTRUCTION: o16 31 /r | XOR r/m16, r16 | INTEL8086
	ops: rw=rm r=reg | UInt16
	implied: zero-reg-rflags
	rflags: u=a w=szp 0=oc
	flags: lock xacquire xrelease
	gas: suffix=w
END

# Code: Xor_rm32_r32
INSTRUCTION: o32 31 /r | XOR r/m32, r32 | INTEL386
	ops: rw=rm r=reg | UInt32
	implied: zero-reg-rflags
	rflags: u=a w=szp 0=oc
	flags: lock xacquire xrelease
	gas: suffix=l
END

# Code: Xor_rm64_r64
INSTRUCTION: o64 31 /r | XOR r/m64, r64 | X64
	ops: rw=rm r=reg | UInt64
	implied: zero-reg-rflags
	rflags: u=a w=szp 0=oc
	flags: 64 lock xacquire xrelease
	gas: suffix=q
END

# Code: Xor_r8_rm8
INSTRUCTION: 32 /r | XOR r8, r/m8 | INTEL8086
	ops: rw=reg r=rm | UInt8
	implied: zero-reg-rflags
	rflags: u=a w=szp 0=oc
	gas: suffix=b
END

# Code: Xor_r16_rm16
INSTRUCTION: o16 33 /r | XOR r16, r/m16 | INTEL8086
	ops: rw=reg r=rm | UInt16
	implied: zero-reg-rflags
	rflags: u=a w=szp 0=oc
	gas: suffix=w
END

# Code: Xor_r32_rm32
INSTRUCTION: o32 33 /r | XOR r32, r/m32 | INTEL386
	ops: rw=reg r=rm | UInt32
	implied: zero-reg-rflags
	rflags: u=a w=szp 0=oc
	gas: suffix=l
END

# Code: Xor_r64_rm64
INSTRUCTION: o64 33 /r | XOR r64, r/m64 | X64
	ops: rw=reg r=rm | UInt64
	implied: zero-reg-rflags
	rflags: u=a w=szp 0=oc
	flags: 64
	gas: suffix=q
END

# Code: Xor_AL_imm8
INSTRUCTION: 34 ib | XOR AL, imm8 | INTEL8086
	ops: rw=r:al r=imm
	rflags: u=a w=szp 0=oc
	gas: suffix=b
END

# Code: Xor_AX_imm16
INSTRUCTION: o16 35 iw | XOR AX, imm16 | INTEL8086
	ops: rw=r:ax r=imm
	rflags: u=a w=szp 0=oc
	gas: suffix=w
END

# Code: Xor_EAX_imm32
INSTRUCTION: o32 35 id | XOR EAX, imm32 | INTEL386
	ops: rw=r:eax r=imm
	rflags: u=a w=szp 0=oc
	gas: suffix=l
END

# Code: Xor_RAX_imm32
INSTRUCTION: o64 35 id | XOR RAX, imm32 | X64
	ops: rw=r:rax r=imm;64
	rflags: u=a w=szp 0=oc
	flags: 64
	gas: suffix=q
	nasm: sx
END

# Code: Aaa
INSTRUCTION: 37 | AAA | INTEL8086
	implied: rw=ax
	rflags: r=a u=oszp w=ac
	flags: 16 32
END

# Code: Cmp_rm8_r8
INSTRUCTION: 38 /r | CMP r/m8, r8 | INTEL8086
	ops: r=rm r=reg | UInt8
	rflags: w=oszacp
	gas: suffix=b
END

# Code: Cmp_rm16_r16
INSTRUCTION: o16 39 /r | CMP r/m16, r16 | INTEL8086
	ops: r=rm r=reg | UInt16
	rflags: w=oszacp
	gas: suffix=w
END

# Code: Cmp_rm32_r32
INSTRUCTION: o32 39 /r | CMP r/m32, r32 | INTEL386
	ops: r=rm r=reg | UInt32
	rflags: w=oszacp
	gas: suffix=l
END

# Code: Cmp_rm64_r64
INSTRUCTION: o64 39 /r | CMP r/m64, r64 | X64
	ops: r=rm r=reg | UInt64
	rflags: w=oszacp
	flags: 64
	gas: suffix=q
END

# Code: Cmp_r8_rm8
INSTRUCTION: 3A /r | CMP r8, r/m8 | INTEL8086
	ops: r=reg r=rm | UInt8
	rflags: w=oszacp
	gas: suffix=b
END

# Code: Cmp_r16_rm16
INSTRUCTION: o16 3B /r | CMP r16, r/m16 | INTEL8086
	ops: r=reg r=rm | UInt16
	rflags: w=oszacp
	gas: suffix=w
END

# Code: Cmp_r32_rm32
INSTRUCTION: o32 3B /r | CMP r32, r/m32 | INTEL386
	ops: r=reg r=rm | UInt32
	rflags: w=oszacp
	gas: suffix=l
END

# Code: Cmp_r64_rm64
INSTRUCTION: o64 3B /r | CMP r64, r/m64 | X64
	ops: r=reg r=rm | UInt64
	rflags: w=oszacp
	flags: 64
	gas: suffix=q
END

# Code: Cmp_AL_imm8
INSTRUCTION: 3C ib | CMP AL, imm8 | INTEL8086
	ops: r=r:al r=imm
	rflags: w=oszacp
	gas: suffix=b
END

# Code: Cmp_AX_imm16
INSTRUCTION: o16 3D iw | CMP AX, imm16 | INTEL8086
	ops: r=r:ax r=imm
	rflags: w=oszacp
	gas: suffix=w
END

# Code: Cmp_EAX_imm32
INSTRUCTION: o32 3D id | CMP EAX, imm32 | INTEL386
	ops: r=r:eax r=imm
	rflags: w=oszacp
	gas: suffix=l
END

# Code: Cmp_RAX_imm32
INSTRUCTION: o64 3D id | CMP RAX, imm32 | X64
	ops: r=r:rax r=imm;64
	rflags: w=oszacp
	flags: 64
	gas: suffix=q
	nasm: sx
END

# Code: Aas
INSTRUCTION: 3F | AAS | INTEL8086
	implied: rw=ax
	rflags: r=a u=oszp w=ac
	flags: 16 32
END

# Code: Inc_r16
INSTRUCTION: o16 40+rw | INC r16 | INTEL8086
	ops: rw=opcode
	rflags: w=oszap
	flags: 16 32
	gas: suffix=w
END

# Code: Inc_r32
INSTRUCTION: o32 40+rd | INC r32 | INTEL386
	ops: rw=opcode
	rflags: w=oszap
	flags: 16 32
	gas: suffix=l
END

# Code: Dec_r16
INSTRUCTION: o16 48+rw | DEC r16 | INTEL8086
	ops: rw=opcode
	rflags: w=oszap
	flags: 16 32
	gas: suffix=w
END

# Code: Dec_r32
INSTRUCTION: o32 48+rd | DEC r32 | INTEL386
	ops: rw=opcode
	rflags: w=oszap
	flags: 16 32
	gas: suffix=l
END

# Code: Push_r16
INSTRUCTION: o16 50+rw | PUSH r16 | INTEL8086
	ops: r=opcode
	implied: push=1x2
	flags: sp=push;2
	gas: suffix=w
END

# Code: Push_r32
INSTRUCTION: o32 50+rd | PUSH r32 | INTEL386
	ops: r=opcode
	implied: push=1x4
	flags: 16 32 sp=push;4
	gas: suffix=l
END

# Code: Push_r64
INSTRUCTION: o64 50+ro | PUSH r64 | X64
	ops: r=opcode
	implied: push=1x8
	flags: 64 sp=push;8 do64
	gas: suffix=q
END

# Code: Pop_r16
INSTRUCTION: o16 58+rw | POP r16 | INTEL8086
	ops: w=opcode
	implied: pop=1x2
	flags: sp=pop;2
	gas: suffix=w
END

# Code: Pop_r32
INSTRUCTION: o32 58+rd | POP r32 | INTEL386
	ops: w=opcode
	implied: pop=1x4
	flags: 16 32 sp=pop;4
	gas: suffix=l
END

# Code: Pop_r64
INSTRUCTION: o64 58+ro | POP r64 | X64
	ops: w=opcode
	implied: pop=1x8
	flags: 64 sp=pop;8 do64
	gas: suffix=q
END

# Code: Pushaw
INSTRUCTION: o16 60 | PUSHA | INTEL186
	implied: pusha=2
	code-mnemonic: pushaw
	flags: 16 32 sp=push;16 asm=pusha
	gas: osz-suffix-1
	masm: osz-suffix-1
	nasm: osz-suffix-1
END

# Code: Pushad
INSTRUCTION: o32 60 | PUSHAD | INTEL386
	implied: pusha=4
	flags: 16 32 sp=push;32 asm=pushad
	gas: mnemonic=pusha osz-suffix-1
	masm: mnemonic=pusha osz-suffix-1
	nasm: mnemonic=pusha osz-suffix-1
END

# Code: Popaw
INSTRUCTION: o16 61 | POPA | INTEL186
	implied: popa=2
	code-mnemonic: popaw
	flags: 16 32 sp=pop;16 asm=popa
	gas: osz-suffix-1
	masm: osz-suffix-1
	nasm: osz-suffix-1
END

# Code: Popad
INSTRUCTION: o32 61 | POPAD | INTEL386
	implied: popa=4
	flags: 16 32 sp=pop;32 asm=popad
	gas: mnemonic=popa osz-suffix-1
	masm: mnemonic=popa osz-suffix-1
	nasm: mnemonic=popa osz-suffix-1
END

# Code: Bound_r16_m1616
INSTRUCTION: o16 62 /r | BOUND r16, m16&16 | INTEL186
	ops: r=reg r=rm | Bound16_WordWord
	code-memory-size: 1616
	# VM exit if #BR
	# May cause a TSX abort if VM exit or #BR
	flags: 16 32 intel-may-vm-exit amd-may-vm-exit tsx-impl-abort
	gas: flags=keep-op-order suffix=w
	intel: flags=force-size=default
	masm: flags=force-size=default
END

# Code: Bound_r32_m3232
INSTRUCTION: o32 62 /r | BOUND r32, m32&32 | INTEL386
	ops: r=reg r=rm | Bound32_DwordDword
	code-memory-size: 3232
	# VM exit if #BR
	# May cause a TSX abort if VM exit or #BR
	flags: 16 32 intel-may-vm-exit amd-may-vm-exit tsx-impl-abort
	gas: flags=keep-op-order suffix=l
	intel: flags=force-size=default
	masm: flags=force-size=default
END

# Code: Arpl_rm16_r16
INSTRUCTION: o16 63 /r | ARPL r/m16, r16 | INTEL286
	ops: rcw=rm r=reg | UInt16
	implied: arpl
	rflags: w=z
	flags: 16 32 no-rm no-v86
	gas: reg16
	intel: reg16
	masm: reg16
	nasm: reg16
END

# Code: Arpl_r32m16_r32
INSTRUCTION: o32 63 /r | ARPL r32/m16, r32 | INTEL386
	ops: rcw=rm r=reg | UInt16
	implied: arpl
	rflags: w=z
	flags: 16 32 no-rm no-v86
	gas: reg16
	intel: reg16
	masm: reg16
	nasm: reg16
END

# Code: Movsxd_r16_rm16
INSTRUCTION: o16 63 /r | MOVSXD r16, r/m16 | X64
	ops: w=reg r=rm | Int16
	flags: 64
	masm: flags=force-size=default
END

# Code: Movsxd_r32_rm32
INSTRUCTION: o32 63 /r | MOVSXD r32, r/m32 | X64
	ops: w=reg r=rm | Int32
	flags: 64
	masm: flags=force-size=default
END

# Code: Movsxd_r64_rm32
INSTRUCTION: o64 63 /r | MOVSXD r64, r/m32 | X64
	ops: w=reg r=rm | Int32
	flags: 64
	gas: mnemonic=movslq
	masm: flags=force-size=default
END

# Code: Push_imm16
INSTRUCTION: o16 68 iw | PUSH imm16 | INTEL186
	ops: r=imm
	implied: push=1x2
	flags: sp=push;2
	gas: suffix=w osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: sx-push-imm
END

# Code: Pushd_imm32
INSTRUCTION: o32 68 id | PUSH imm32 | INTEL386
	ops: r=imm
	implied: push=1x4
	code-mnemonic: pushd
	flags: 16 32 sp=push;4
	gas: suffix=l osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: sx-push-imm
END

# Code: Pushq_imm32
INSTRUCTION: o64 68 id | PUSH imm32 | X64
	ops: r=imm;64
	implied: push=1x8
	code-mnemonic: pushq
	flags: 64 sp=push;8 do64
	gas: suffix=q osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: sx-push-imm
END

# Code: Imul_r16_rm16_imm16
INSTRUCTION: o16 69 /r iw | IMUL r16, r/m16, imm16 | INTEL186
	ops: w=reg r=rm r=imm | Int16
	rflags: u=szap w=oc
	gas: suffix=w imul
	intel: imul
	masm: imul
	nasm: imul
END

# Code: Imul_r32_rm32_imm32
INSTRUCTION: o32 69 /r id | IMUL r32, r/m32, imm32 | INTEL386
	ops: w=reg r=rm r=imm | Int32
	rflags: u=szap w=oc
	gas: suffix=l imul
	intel: imul
	masm: imul
	nasm: imul
END

# Code: Imul_r64_rm64_imm32
INSTRUCTION: o64 69 /r id | IMUL r64, r/m64, imm32 | X64
	ops: w=reg r=rm r=imm;64 | Int64
	rflags: u=szap w=oc
	flags: 64
	gas: suffix=q imul
	intel: imul
	masm: imul
	nasm: imul
END

# Code: Pushw_imm8
INSTRUCTION: o16 6A ib | PUSH imm8 | INTEL186
	ops: r=imm;16
	implied: push=1x2
	code-mnemonic: pushw
	flags: sp=push;2
	gas: suffix=w osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: sx-push-imm8
END

# Code: Pushd_imm8
INSTRUCTION: o32 6A ib | PUSH imm8 | INTEL386
	ops: r=imm;32
	implied: push=1x4
	code-mnemonic: pushd
	flags: 16 32 sp=push;4
	gas: suffix=l osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: sx-push-imm8
END

# Code: Pushq_imm8
INSTRUCTION: o64 6A ib | PUSH imm8 | X64
	ops: r=imm;64
	implied: push=1x8
	code-mnemonic: pushq
	flags: 64 sp=push;8 do64
	gas: suffix=q osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: sx-push-imm8
END

# Code: Imul_r16_rm16_imm8
INSTRUCTION: o16 6B /r ib | IMUL r16, r/m16, imm8 | INTEL186
	ops: w=reg r=rm r=imm;16 | Int16
	rflags: u=szap w=oc
	gas: suffix=w imul
	intel: imul
	masm: imul
	nasm: imul
END

# Code: Imul_r32_rm32_imm8
INSTRUCTION: o32 6B /r ib | IMUL r32, r/m32, imm8 | INTEL386
	ops: w=reg r=rm r=imm;32 | Int32
	rflags: u=szap w=oc
	gas: suffix=l imul
	intel: imul
	masm: imul
	nasm: imul
END

# Code: Imul_r64_rm64_imm8
INSTRUCTION: o64 6B /r ib | IMUL r64, r/m64, imm8 | X64
	ops: w=reg r=rm r=imm;64 | Int64
	rflags: u=szap w=oc
	flags: 64
	gas: suffix=q imul
	intel: imul
	masm: imul
	nasm: imul
END

# Code: Insb_m8_DX
INSTRUCTION: 6C | INSB [m8], [DX] | INTEL186
	ops: w=es-rdi r=r:dx | UInt8
	implied: ins
	rflags: r=d
	flags: io privileged rep intel-may-vm-exit no-in-sgx tdx-non-root-ve amd-may-vm-exit tsx-impl-abort is-string-op
	gas: mnemonic=ins flags=force-suffix suffix=b
	masm: mnemonic=ins asz-string-yd b
	nasm: asz-string
END

# Code: Insw_m16_DX
INSTRUCTION: o16 6D | INSW [m16], [DX] | INTEL186
	ops: w=es-rdi r=r:dx | UInt16
	implied: ins
	rflags: r=d
	flags: io privileged rep intel-may-vm-exit no-in-sgx tdx-non-root-ve amd-may-vm-exit tsx-impl-abort is-string-op
	gas: mnemonic=ins flags=force-suffix suffix=w
	masm: mnemonic=ins asz-string-yd w
	nasm: asz-string
END

# Code: Insd_m32_DX
INSTRUCTION: o32 6D | INSD [m32], [DX] | INTEL386
	ops: w=es-rdi r=r:dx | UInt32
	implied: ins
	rflags: r=d
	flags: io privileged rep intel-may-vm-exit no-in-sgx tdx-non-root-ve amd-may-vm-exit tsx-impl-abort is-string-op
	gas: mnemonic=ins flags=force-suffix suffix=l
	masm: mnemonic=ins asz-string-yd d
	nasm: asz-string
END

# Code: Outsb_DX_m8
INSTRUCTION: 6E | OUTSB [DX], [m8] | INTEL186
	ops: r=r:dx r=seg-rsi | UInt8
	implied: outs
	rflags: r=d
	flags: io privileged rep intel-may-vm-exit no-in-sgx tdx-non-root-ve amd-may-vm-exit tsx-impl-abort is-string-op
	gas: mnemonic=outs flags=force-suffix suffix=b
	masm: mnemonic=outs asz-string-dx b
	nasm: asz-string
END

# Code: Outsw_DX_m16
INSTRUCTION: o16 6F | OUTSW [DX], [m16] | INTEL186
	ops: r=r:dx r=seg-rsi | UInt16
	implied: outs
	rflags: r=d
	flags: io privileged rep intel-may-vm-exit no-in-sgx tdx-non-root-ve amd-may-vm-exit tsx-impl-abort is-string-op
	gas: mnemonic=outs flags=force-suffix suffix=w
	masm: mnemonic=outs asz-string-dx w
	nasm: asz-string
END

# Code: Outsd_DX_m32
INSTRUCTION: o32 6F | OUTSD [DX], [m32] | INTEL386
	ops: r=r:dx r=seg-rsi | UInt32
	implied: outs
	rflags: r=d
	flags: io privileged rep intel-may-vm-exit no-in-sgx tdx-non-root-ve amd-may-vm-exit tsx-impl-abort is-string-op
	gas: mnemonic=outs flags=force-suffix suffix=l
	masm: mnemonic=outs asz-string-dx d
	nasm: asz-string
END

# Code: Jo_rel8_16
INSTRUCTION: o16 70 cb | JO rel8 | INTEL8086
	ops: r=br
	code-suffix: 16
	rflags: r=o
	flags: bnd ht cc=j;o; br=jcc-short cflow=br-cond no-intel-dec64
END

# Code: Jo_rel8_32
INSTRUCTION: o32 70 cb | JO rel8 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=o
	flags: 16 32 bnd ht cc=j;o; br=jcc-short cflow=br-cond
END

# Code: Jo_rel8_64
INSTRUCTION: o64 70 cb | JO rel8 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=o
	flags: 64 bnd ht cc=j;o; br=jcc-short cflow=br-cond intel-fo64 do64
END

# Code: Jno_rel8_16
INSTRUCTION: o16 71 cb | JNO rel8 | INTEL8086
	ops: r=br
	code-suffix: 16
	rflags: r=o
	flags: bnd ht cc=j;no; br=jcc-short cflow=br-cond no-intel-dec64
END

# Code: Jno_rel8_32
INSTRUCTION: o32 71 cb | JNO rel8 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=o
	flags: 16 32 bnd ht cc=j;no; br=jcc-short cflow=br-cond
END

# Code: Jno_rel8_64
INSTRUCTION: o64 71 cb | JNO rel8 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=o
	flags: 64 bnd ht cc=j;no; br=jcc-short cflow=br-cond intel-fo64 do64
END

# Code: Jb_rel8_16
INSTRUCTION: o16 72 cb | JB rel8 | INTEL8086
	ops: r=br
	code-suffix: 16
	rflags: r=c
	flags: bnd ht cc=j;b; br=jcc-short cflow=br-cond no-intel-dec64
END

# Code: Jb_rel8_32
INSTRUCTION: o32 72 cb | JB rel8 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=c
	flags: 16 32 bnd ht cc=j;b; br=jcc-short cflow=br-cond
END

# Code: Jb_rel8_64
INSTRUCTION: o64 72 cb | JB rel8 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=c
	flags: 64 bnd ht cc=j;b; br=jcc-short cflow=br-cond intel-fo64 do64
END

# Code: Jae_rel8_16
INSTRUCTION: o16 73 cb | JAE rel8 | INTEL8086
	ops: r=br
	code-suffix: 16
	rflags: r=c
	flags: bnd ht cc=j;ae; br=jcc-short cflow=br-cond no-intel-dec64
END

# Code: Jae_rel8_32
INSTRUCTION: o32 73 cb | JAE rel8 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=c
	flags: 16 32 bnd ht cc=j;ae; br=jcc-short cflow=br-cond
END

# Code: Jae_rel8_64
INSTRUCTION: o64 73 cb | JAE rel8 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=c
	flags: 64 bnd ht cc=j;ae; br=jcc-short cflow=br-cond intel-fo64 do64
END

# Code: Je_rel8_16
INSTRUCTION: o16 74 cb | JE rel8 | INTEL8086
	ops: r=br
	code-suffix: 16
	rflags: r=z
	flags: bnd ht cc=j;e; br=jcc-short cflow=br-cond no-intel-dec64
END

# Code: Je_rel8_32
INSTRUCTION: o32 74 cb | JE rel8 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=z
	flags: 16 32 bnd ht cc=j;e; br=jcc-short cflow=br-cond
END

# Code: Je_rel8_64
INSTRUCTION: o64 74 cb | JE rel8 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=z
	flags: 64 bnd ht cc=j;e; br=jcc-short cflow=br-cond intel-fo64 do64
END

# Code: Jne_rel8_16
INSTRUCTION: o16 75 cb | JNE rel8 | INTEL8086
	ops: r=br
	code-suffix: 16
	rflags: r=z
	flags: bnd ht cc=j;ne; br=jcc-short cflow=br-cond no-intel-dec64
END

# Code: Jne_rel8_32
INSTRUCTION: o32 75 cb | JNE rel8 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=z
	flags: 16 32 bnd ht cc=j;ne; br=jcc-short cflow=br-cond
END

# Code: Jne_rel8_64
INSTRUCTION: o64 75 cb | JNE rel8 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=z
	flags: 64 bnd ht cc=j;ne; br=jcc-short cflow=br-cond intel-fo64 do64
END

# Code: Jbe_rel8_16
INSTRUCTION: o16 76 cb | JBE rel8 | INTEL8086
	ops: r=br
	code-suffix: 16
	rflags: r=zc
	flags: bnd ht cc=j;be; br=jcc-short cflow=br-cond no-intel-dec64
END

# Code: Jbe_rel8_32
INSTRUCTION: o32 76 cb | JBE rel8 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=zc
	flags: 16 32 bnd ht cc=j;be; br=jcc-short cflow=br-cond
END

# Code: Jbe_rel8_64
INSTRUCTION: o64 76 cb | JBE rel8 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=zc
	flags: 64 bnd ht cc=j;be; br=jcc-short cflow=br-cond intel-fo64 do64
END

# Code: Ja_rel8_16
INSTRUCTION: o16 77 cb | JA rel8 | INTEL8086
	ops: r=br
	code-suffix: 16
	rflags: r=zc
	flags: bnd ht cc=j;a; br=jcc-short cflow=br-cond no-intel-dec64
END

# Code: Ja_rel8_32
INSTRUCTION: o32 77 cb | JA rel8 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=zc
	flags: 16 32 bnd ht cc=j;a; br=jcc-short cflow=br-cond
END

# Code: Ja_rel8_64
INSTRUCTION: o64 77 cb | JA rel8 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=zc
	flags: 64 bnd ht cc=j;a; br=jcc-short cflow=br-cond intel-fo64 do64
END

# Code: Js_rel8_16
INSTRUCTION: o16 78 cb | JS rel8 | INTEL8086
	ops: r=br
	code-suffix: 16
	rflags: r=s
	flags: bnd ht cc=j;s; br=jcc-short cflow=br-cond no-intel-dec64
END

# Code: Js_rel8_32
INSTRUCTION: o32 78 cb | JS rel8 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=s
	flags: 16 32 bnd ht cc=j;s; br=jcc-short cflow=br-cond
END

# Code: Js_rel8_64
INSTRUCTION: o64 78 cb | JS rel8 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=s
	flags: 64 bnd ht cc=j;s; br=jcc-short cflow=br-cond intel-fo64 do64
END

# Code: Jns_rel8_16
INSTRUCTION: o16 79 cb | JNS rel8 | INTEL8086
	ops: r=br
	code-suffix: 16
	rflags: r=s
	flags: bnd ht cc=j;ns; br=jcc-short cflow=br-cond no-intel-dec64
END

# Code: Jns_rel8_32
INSTRUCTION: o32 79 cb | JNS rel8 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=s
	flags: 16 32 bnd ht cc=j;ns; br=jcc-short cflow=br-cond
END

# Code: Jns_rel8_64
INSTRUCTION: o64 79 cb | JNS rel8 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=s
	flags: 64 bnd ht cc=j;ns; br=jcc-short cflow=br-cond intel-fo64 do64
END

# Code: Jp_rel8_16
INSTRUCTION: o16 7A cb | JP rel8 | INTEL8086
	ops: r=br
	code-suffix: 16
	rflags: r=p
	flags: bnd ht cc=j;p; br=jcc-short cflow=br-cond no-intel-dec64
END

# Code: Jp_rel8_32
INSTRUCTION: o32 7A cb | JP rel8 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=p
	flags: 16 32 bnd ht cc=j;p; br=jcc-short cflow=br-cond
END

# Code: Jp_rel8_64
INSTRUCTION: o64 7A cb | JP rel8 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=p
	flags: 64 bnd ht cc=j;p; br=jcc-short cflow=br-cond intel-fo64 do64
END

# Code: Jnp_rel8_16
INSTRUCTION: o16 7B cb | JNP rel8 | INTEL8086
	ops: r=br
	code-suffix: 16
	rflags: r=p
	flags: bnd ht cc=j;np; br=jcc-short cflow=br-cond no-intel-dec64
END

# Code: Jnp_rel8_32
INSTRUCTION: o32 7B cb | JNP rel8 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=p
	flags: 16 32 bnd ht cc=j;np; br=jcc-short cflow=br-cond
END

# Code: Jnp_rel8_64
INSTRUCTION: o64 7B cb | JNP rel8 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=p
	flags: 64 bnd ht cc=j;np; br=jcc-short cflow=br-cond intel-fo64 do64
END

# Code: Jl_rel8_16
INSTRUCTION: o16 7C cb | JL rel8 | INTEL8086
	ops: r=br
	code-suffix: 16
	rflags: r=os
	flags: bnd ht cc=j;l; br=jcc-short cflow=br-cond no-intel-dec64
END

# Code: Jl_rel8_32
INSTRUCTION: o32 7C cb | JL rel8 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=os
	flags: 16 32 bnd ht cc=j;l; br=jcc-short cflow=br-cond
END

# Code: Jl_rel8_64
INSTRUCTION: o64 7C cb | JL rel8 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=os
	flags: 64 bnd ht cc=j;l; br=jcc-short cflow=br-cond intel-fo64 do64
END

# Code: Jge_rel8_16
INSTRUCTION: o16 7D cb | JGE rel8 | INTEL8086
	ops: r=br
	code-suffix: 16
	rflags: r=os
	flags: bnd ht cc=j;ge; br=jcc-short cflow=br-cond no-intel-dec64
END

# Code: Jge_rel8_32
INSTRUCTION: o32 7D cb | JGE rel8 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=os
	flags: 16 32 bnd ht cc=j;ge; br=jcc-short cflow=br-cond
END

# Code: Jge_rel8_64
INSTRUCTION: o64 7D cb | JGE rel8 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=os
	flags: 64 bnd ht cc=j;ge; br=jcc-short cflow=br-cond intel-fo64 do64
END

# Code: Jle_rel8_16
INSTRUCTION: o16 7E cb | JLE rel8 | INTEL8086
	ops: r=br
	code-suffix: 16
	rflags: r=osz
	flags: bnd ht cc=j;le; br=jcc-short cflow=br-cond no-intel-dec64
END

# Code: Jle_rel8_32
INSTRUCTION: o32 7E cb | JLE rel8 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=osz
	flags: 16 32 bnd ht cc=j;le; br=jcc-short cflow=br-cond
END

# Code: Jle_rel8_64
INSTRUCTION: o64 7E cb | JLE rel8 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=osz
	flags: 64 bnd ht cc=j;le; br=jcc-short cflow=br-cond intel-fo64 do64
END

# Code: Jg_rel8_16
INSTRUCTION: o16 7F cb | JG rel8 | INTEL8086
	ops: r=br
	code-suffix: 16
	rflags: r=osz
	flags: bnd ht cc=j;g; br=jcc-short cflow=br-cond no-intel-dec64
END

# Code: Jg_rel8_32
INSTRUCTION: o32 7F cb | JG rel8 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=osz
	flags: 16 32 bnd ht cc=j;g; br=jcc-short cflow=br-cond
END

# Code: Jg_rel8_64
INSTRUCTION: o64 7F cb | JG rel8 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=osz
	flags: 64 bnd ht cc=j;g; br=jcc-short cflow=br-cond intel-fo64 do64
END

# Code: Add_rm8_imm8
INSTRUCTION: 80 /0 ib | ADD r/m8, imm8 | INTEL8086
	ops: rw=rm r=imm | UInt8
	rflags: w=oszacp
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Or_rm8_imm8
INSTRUCTION: 80 /1 ib | OR r/m8, imm8 | INTEL8086
	ops: rw=rm r=imm | UInt8
	rflags: u=a w=szp 0=oc
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Adc_rm8_imm8
INSTRUCTION: 80 /2 ib | ADC r/m8, imm8 | INTEL8086
	ops: rw=rm r=imm | UInt8
	rflags: r=c w=oszacp
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sbb_rm8_imm8
INSTRUCTION: 80 /3 ib | SBB r/m8, imm8 | INTEL8086
	ops: rw=rm r=imm | UInt8
	rflags: r=c w=oszacp
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: And_rm8_imm8
INSTRUCTION: 80 /4 ib | AND r/m8, imm8 | INTEL8086
	ops: rw=rm r=imm | UInt8
	rflags: u=a w=szp 0=oc
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sub_rm8_imm8
INSTRUCTION: 80 /5 ib | SUB r/m8, imm8 | INTEL8086
	ops: rw=rm r=imm | UInt8
	rflags: w=oszacp
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Xor_rm8_imm8
INSTRUCTION: 80 /6 ib | XOR r/m8, imm8 | INTEL8086
	ops: rw=rm r=imm | UInt8
	rflags: u=a w=szp 0=oc
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Cmp_rm8_imm8
INSTRUCTION: 80 /7 ib | CMP r/m8, imm8 | INTEL8086
	ops: r=rm r=imm | UInt8
	rflags: w=oszacp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Add_rm16_imm16
INSTRUCTION: o16 81 /0 iw | ADD r/m16, imm16 | INTEL8086
	ops: rw=rm r=imm | UInt16
	rflags: w=oszacp
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Add_rm32_imm32
INSTRUCTION: o32 81 /0 id | ADD r/m32, imm32 | INTEL386
	ops: rw=rm r=imm | UInt32
	rflags: w=oszacp
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Add_rm64_imm32
INSTRUCTION: o64 81 /0 id | ADD r/m64, imm32 | X64
	ops: rw=rm r=imm;64 | UInt64
	rflags: w=oszacp
	flags: 64 lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: Or_rm16_imm16
INSTRUCTION: o16 81 /1 iw | OR r/m16, imm16 | INTEL8086
	ops: rw=rm r=imm | UInt16
	rflags: u=a w=szp 0=oc
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Or_rm32_imm32
INSTRUCTION: o32 81 /1 id | OR r/m32, imm32 | INTEL386
	ops: rw=rm r=imm | UInt32
	rflags: u=a w=szp 0=oc
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Or_rm64_imm32
INSTRUCTION: o64 81 /1 id | OR r/m64, imm32 | X64
	ops: rw=rm r=imm;64 | UInt64
	rflags: u=a w=szp 0=oc
	flags: 64 lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: Adc_rm16_imm16
INSTRUCTION: o16 81 /2 iw | ADC r/m16, imm16 | INTEL8086
	ops: rw=rm r=imm | UInt16
	rflags: r=c w=oszacp
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Adc_rm32_imm32
INSTRUCTION: o32 81 /2 id | ADC r/m32, imm32 | INTEL386
	ops: rw=rm r=imm | UInt32
	rflags: r=c w=oszacp
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Adc_rm64_imm32
INSTRUCTION: o64 81 /2 id | ADC r/m64, imm32 | X64
	ops: rw=rm r=imm;64 | UInt64
	rflags: r=c w=oszacp
	flags: 64 lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: Sbb_rm16_imm16
INSTRUCTION: o16 81 /3 iw | SBB r/m16, imm16 | INTEL8086
	ops: rw=rm r=imm | UInt16
	rflags: r=c w=oszacp
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sbb_rm32_imm32
INSTRUCTION: o32 81 /3 id | SBB r/m32, imm32 | INTEL386
	ops: rw=rm r=imm | UInt32
	rflags: r=c w=oszacp
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sbb_rm64_imm32
INSTRUCTION: o64 81 /3 id | SBB r/m64, imm32 | X64
	ops: rw=rm r=imm;64 | UInt64
	rflags: r=c w=oszacp
	flags: 64 lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: And_rm16_imm16
INSTRUCTION: o16 81 /4 iw | AND r/m16, imm16 | INTEL8086
	ops: rw=rm r=imm | UInt16
	rflags: u=a w=szp 0=oc
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: And_rm32_imm32
INSTRUCTION: o32 81 /4 id | AND r/m32, imm32 | INTEL386
	ops: rw=rm r=imm | UInt32
	rflags: u=a w=szp 0=oc
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: And_rm64_imm32
INSTRUCTION: o64 81 /4 id | AND r/m64, imm32 | X64
	ops: rw=rm r=imm;64 | UInt64
	rflags: u=a w=szp 0=oc
	flags: 64 lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: Sub_rm16_imm16
INSTRUCTION: o16 81 /5 iw | SUB r/m16, imm16 | INTEL8086
	ops: rw=rm r=imm | UInt16
	rflags: w=oszacp
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sub_rm32_imm32
INSTRUCTION: o32 81 /5 id | SUB r/m32, imm32 | INTEL386
	ops: rw=rm r=imm | UInt32
	rflags: w=oszacp
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sub_rm64_imm32
INSTRUCTION: o64 81 /5 id | SUB r/m64, imm32 | X64
	ops: rw=rm r=imm;64 | UInt64
	rflags: w=oszacp
	flags: 64 lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: Xor_rm16_imm16
INSTRUCTION: o16 81 /6 iw | XOR r/m16, imm16 | INTEL8086
	ops: rw=rm r=imm | UInt16
	rflags: u=a w=szp 0=oc
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Xor_rm32_imm32
INSTRUCTION: o32 81 /6 id | XOR r/m32, imm32 | INTEL386
	ops: rw=rm r=imm | UInt32
	rflags: u=a w=szp 0=oc
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Xor_rm64_imm32
INSTRUCTION: o64 81 /6 id | XOR r/m64, imm32 | X64
	ops: rw=rm r=imm;64 | UInt64
	rflags: u=a w=szp 0=oc
	flags: 64 lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: Cmp_rm16_imm16
INSTRUCTION: o16 81 /7 iw | CMP r/m16, imm16 | INTEL8086
	ops: r=rm r=imm | UInt16
	rflags: w=oszacp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Cmp_rm32_imm32
INSTRUCTION: o32 81 /7 id | CMP r/m32, imm32 | INTEL386
	ops: r=rm r=imm | UInt32
	rflags: w=oszacp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Cmp_rm64_imm32
INSTRUCTION: o64 81 /7 id | CMP r/m64, imm32 | X64
	ops: r=rm r=imm;64 | UInt64
	rflags: w=oszacp
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: Add_rm8_imm8_82
INSTRUCTION: 82 /0 ib | ADD r/m8, imm8 | INTEL8086
	ops: rw=rm r=imm | UInt8
	code-suffix: 82
	rflags: w=oszacp
	flags: 16 32 lock xacquire xrelease asm-ig
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Or_rm8_imm8_82
INSTRUCTION: 82 /1 ib | OR r/m8, imm8 | INTEL8086
	ops: rw=rm r=imm | UInt8
	code-suffix: 82
	rflags: u=a w=szp 0=oc
	flags: 16 32 lock xacquire xrelease asm-ig
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Adc_rm8_imm8_82
INSTRUCTION: 82 /2 ib | ADC r/m8, imm8 | INTEL8086
	ops: rw=rm r=imm | UInt8
	code-suffix: 82
	rflags: r=c w=oszacp
	flags: 16 32 lock xacquire xrelease asm-ig
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sbb_rm8_imm8_82
INSTRUCTION: 82 /3 ib | SBB r/m8, imm8 | INTEL8086
	ops: rw=rm r=imm | UInt8
	code-suffix: 82
	rflags: r=c w=oszacp
	flags: 16 32 lock xacquire xrelease asm-ig
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: And_rm8_imm8_82
INSTRUCTION: 82 /4 ib | AND r/m8, imm8 | INTEL8086
	ops: rw=rm r=imm | UInt8
	code-suffix: 82
	rflags: u=a w=szp 0=oc
	flags: 16 32 lock xacquire xrelease asm-ig
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sub_rm8_imm8_82
INSTRUCTION: 82 /5 ib | SUB r/m8, imm8 | INTEL8086
	ops: rw=rm r=imm | UInt8
	code-suffix: 82
	rflags: w=oszacp
	flags: 16 32 lock xacquire xrelease asm-ig
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Xor_rm8_imm8_82
INSTRUCTION: 82 /6 ib | XOR r/m8, imm8 | INTEL8086
	ops: rw=rm r=imm | UInt8
	code-suffix: 82
	rflags: u=a w=szp 0=oc
	flags: 16 32 lock xacquire xrelease asm-ig
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Cmp_rm8_imm8_82
INSTRUCTION: 82 /7 ib | CMP r/m8, imm8 | INTEL8086
	ops: r=rm r=imm | UInt8
	code-suffix: 82
	rflags: w=oszacp
	flags: 16 32 asm-ig
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Add_rm16_imm8
INSTRUCTION: o16 83 /0 ib | ADD r/m16, imm8 | INTEL8086
	ops: rw=rm r=imm;16 | UInt16
	rflags: w=oszacp
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: Add_rm32_imm8
INSTRUCTION: o32 83 /0 ib | ADD r/m32, imm8 | INTEL386
	ops: rw=rm r=imm;32 | UInt32
	rflags: w=oszacp
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: Add_rm64_imm8
INSTRUCTION: o64 83 /0 ib | ADD r/m64, imm8 | X64
	ops: rw=rm r=imm;64 | UInt64
	rflags: w=oszacp
	flags: 64 lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: Or_rm16_imm8
INSTRUCTION: o16 83 /1 ib | OR r/m16, imm8 | INTEL8086
	ops: rw=rm r=imm;16 | UInt16
	rflags: u=a w=szp 0=oc
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: Or_rm32_imm8
INSTRUCTION: o32 83 /1 ib | OR r/m32, imm8 | INTEL386
	ops: rw=rm r=imm;32 | UInt32
	rflags: u=a w=szp 0=oc
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: Or_rm64_imm8
INSTRUCTION: o64 83 /1 ib | OR r/m64, imm8 | X64
	ops: rw=rm r=imm;64 | UInt64
	rflags: u=a w=szp 0=oc
	flags: 64 lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: Adc_rm16_imm8
INSTRUCTION: o16 83 /2 ib | ADC r/m16, imm8 | INTEL8086
	ops: rw=rm r=imm;16 | UInt16
	rflags: r=c w=oszacp
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: Adc_rm32_imm8
INSTRUCTION: o32 83 /2 ib | ADC r/m32, imm8 | INTEL386
	ops: rw=rm r=imm;32 | UInt32
	rflags: r=c w=oszacp
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: Adc_rm64_imm8
INSTRUCTION: o64 83 /2 ib | ADC r/m64, imm8 | X64
	ops: rw=rm r=imm;64 | UInt64
	rflags: r=c w=oszacp
	flags: 64 lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: Sbb_rm16_imm8
INSTRUCTION: o16 83 /3 ib | SBB r/m16, imm8 | INTEL8086
	ops: rw=rm r=imm;16 | UInt16
	rflags: r=c w=oszacp
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: Sbb_rm32_imm8
INSTRUCTION: o32 83 /3 ib | SBB r/m32, imm8 | INTEL386
	ops: rw=rm r=imm;32 | UInt32
	rflags: r=c w=oszacp
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: Sbb_rm64_imm8
INSTRUCTION: o64 83 /3 ib | SBB r/m64, imm8 | X64
	ops: rw=rm r=imm;64 | UInt64
	rflags: r=c w=oszacp
	flags: 64 lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: And_rm16_imm8
INSTRUCTION: o16 83 /4 ib | AND r/m16, imm8 | INTEL8086
	ops: rw=rm r=imm;16 | UInt16
	rflags: u=a w=szp 0=oc
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: And_rm32_imm8
INSTRUCTION: o32 83 /4 ib | AND r/m32, imm8 | INTEL386
	ops: rw=rm r=imm;32 | UInt32
	rflags: u=a w=szp 0=oc
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: And_rm64_imm8
INSTRUCTION: o64 83 /4 ib | AND r/m64, imm8 | X64
	ops: rw=rm r=imm;64 | UInt64
	rflags: u=a w=szp 0=oc
	flags: 64 lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: Sub_rm16_imm8
INSTRUCTION: o16 83 /5 ib | SUB r/m16, imm8 | INTEL8086
	ops: rw=rm r=imm;16 | UInt16
	rflags: w=oszacp
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: Sub_rm32_imm8
INSTRUCTION: o32 83 /5 ib | SUB r/m32, imm8 | INTEL386
	ops: rw=rm r=imm;32 | UInt32
	rflags: w=oszacp
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: Sub_rm64_imm8
INSTRUCTION: o64 83 /5 ib | SUB r/m64, imm8 | X64
	ops: rw=rm r=imm;64 | UInt64
	rflags: w=oszacp
	flags: 64 lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: Xor_rm16_imm8
INSTRUCTION: o16 83 /6 ib | XOR r/m16, imm8 | INTEL8086
	ops: rw=rm r=imm;16 | UInt16
	rflags: u=a w=szp 0=oc
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: Xor_rm32_imm8
INSTRUCTION: o32 83 /6 ib | XOR r/m32, imm8 | INTEL386
	ops: rw=rm r=imm;32 | UInt32
	rflags: u=a w=szp 0=oc
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: Xor_rm64_imm8
INSTRUCTION: o64 83 /6 ib | XOR r/m64, imm8 | X64
	ops: rw=rm r=imm;64 | UInt64
	rflags: u=a w=szp 0=oc
	flags: 64 lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: Cmp_rm16_imm8
INSTRUCTION: o16 83 /7 ib | CMP r/m16, imm8 | INTEL8086
	ops: r=rm r=imm;16 | UInt16
	rflags: w=oszacp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: Cmp_rm32_imm8
INSTRUCTION: o32 83 /7 ib | CMP r/m32, imm8 | INTEL386
	ops: r=rm r=imm;32 | UInt32
	rflags: w=oszacp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: Cmp_rm64_imm8
INSTRUCTION: o64 83 /7 ib | CMP r/m64, imm8 | X64
	ops: r=rm r=imm;64 | UInt64
	rflags: w=oszacp
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx
END

# Code: Test_rm8_r8
INSTRUCTION: 84 /r | TEST r/m8, r8 | INTEL8086
	ops: r=rm r=reg | UInt8
	rflags: u=a w=szp 0=oc
	gas: suffix=b
END

# Code: Test_rm16_r16
INSTRUCTION: o16 85 /r | TEST r/m16, r16 | INTEL8086
	ops: r=rm r=reg | UInt16
	rflags: u=a w=szp 0=oc
	gas: suffix=w
END

# Code: Test_rm32_r32
INSTRUCTION: o32 85 /r | TEST r/m32, r32 | INTEL386
	ops: r=rm r=reg | UInt32
	rflags: u=a w=szp 0=oc
	gas: suffix=l
END

# Code: Test_rm64_r64
INSTRUCTION: o64 85 /r | TEST r/m64, r64 | X64
	ops: r=rm r=reg | UInt64
	rflags: u=a w=szp 0=oc
	flags: 64
	gas: suffix=q
END

# Code: Xchg_rm8_r8
INSTRUCTION: 86 /r | XCHG r/m8, r8 | INTEL8086
	ops: rw=rm rw=reg | UInt8
	flags: lock xacquire xrelease atomic
	gas: suffix=b
	masm: reverse
	nasm: reverse
END

# Code: Xchg_rm16_r16
INSTRUCTION: o16 87 /r | XCHG r/m16, r16 | INTEL8086
	ops: rw=rm rw=reg | UInt16
	flags: lock xacquire xrelease atomic
	gas: suffix=w
	masm: reverse
	nasm: reverse
END

# Code: Xchg_rm32_r32
INSTRUCTION: o32 87 /r | XCHG r/m32, r32 | INTEL386
	ops: rw=rm rw=reg | UInt32
	flags: lock xacquire xrelease atomic
	gas: suffix=l
	masm: reverse
	nasm: reverse
END

# Code: Xchg_rm64_r64
INSTRUCTION: o64 87 /r | XCHG r/m64, r64 | X64
	ops: rw=rm rw=reg | UInt64
	flags: 64 lock xacquire xrelease atomic
	gas: suffix=q
	masm: reverse
	nasm: reverse
END

# Code: Mov_rm8_r8
INSTRUCTION: 88 /r | MOV r/m8, r8 | INTEL8086
	ops: w=rm r=reg | UInt8
	flags: xrelease
	gas: suffix=b
END

# Code: Mov_rm16_r16
INSTRUCTION: o16 89 /r | MOV r/m16, r16 | INTEL8086
	ops: w=rm r=reg | UInt16
	flags: xrelease
	gas: suffix=w
END

# Code: Mov_rm32_r32
INSTRUCTION: o32 89 /r | MOV r/m32, r32 | INTEL386
	ops: w=rm r=reg | UInt32
	flags: xrelease
	gas: suffix=l
END

# Code: Mov_rm64_r64
INSTRUCTION: o64 89 /r | MOV r/m64, r64 | X64
	ops: w=rm r=reg | UInt64
	flags: 64 xrelease
	gas: suffix=q
END

# Code: Mov_r8_rm8
INSTRUCTION: 8A /r | MOV r8, r/m8 | INTEL8086
	ops: w=reg r=rm | UInt8
	gas: suffix=b
END

# Code: Mov_r16_rm16
INSTRUCTION: o16 8B /r | MOV r16, r/m16 | INTEL8086
	ops: w=reg r=rm | UInt16
	gas: suffix=w
END

# Code: Mov_r32_rm32
INSTRUCTION: o32 8B /r | MOV r32, r/m32 | INTEL386
	ops: w=reg r=rm | UInt32
	gas: suffix=l
END

# Code: Mov_r64_rm64
INSTRUCTION: o64 8B /r | MOV r64, r/m64 | X64
	ops: w=reg r=rm | UInt64
	flags: 64
	gas: suffix=q
END

# Code: Mov_rm16_Sreg
INSTRUCTION: o16 8C /r | MOV r/m16, Sreg | INTEL8086
	ops: w=rm r=reg | UInt16
	gas: suffix=w mem16
	nasm: osz-mem-1
END

# Code: Mov_r32m16_Sreg
INSTRUCTION: o32 8C /r | MOV r32/m16, Sreg | INTEL386
	ops: w=rm r=reg | UInt16
	gas: suffix=l mem16
	nasm: osz-mem-1
END

# Code: Mov_r64m16_Sreg
INSTRUCTION: o64 8C /r | MOV r64/m16, Sreg | X64
	ops: w=rm r=reg | UInt16
	flags: 64
	gas: suffix=q mem16
	nasm: osz-mem-1
END

# Code: Lea_r16_m
INSTRUCTION: o16 8D /r | LEA r16, m | INTEL8086
	ops: w=reg nma=rm
	implied: lea
	flags: ignores-seg
	gas: suffix=w
END

# Code: Lea_r32_m
INSTRUCTION: o32 8D /r | LEA r32, m | INTEL386
	ops: w=reg nma=rm
	implied: lea
	flags: ignores-seg
	gas: suffix=l
END

# Code: Lea_r64_m
INSTRUCTION: o64 8D /r | LEA r64, m | X64
	ops: w=reg nma=rm
	implied: lea
	flags: 64 ignores-seg
	gas: suffix=q
END

# Code: Mov_Sreg_rm16
INSTRUCTION: o16 8E /r | MOV Sreg, r/m16 | INTEL8086
	ops: w=reg r=rm | UInt16
	flags: no-in-sgx tsx-impl-abort
	gas: suffix=w mem16
	nasm: osz-mem-1
END

# Code: Mov_Sreg_r32m16
INSTRUCTION: o32 8E /r | MOV Sreg, r32/m16 | INTEL386
	ops: w=reg r=rm | UInt16
	implied: last-gpr-16
	flags: no-in-sgx tsx-impl-abort
	gas: suffix=l mem16
	intel: reg16
	nasm: osz-mem-1
END

# Code: Mov_Sreg_r64m16
INSTRUCTION: o64 8E /r | MOV Sreg, r64/m16 | X64
	ops: w=reg r=rm | UInt16
	implied: last-gpr-16
	flags: 64 no-in-sgx tsx-impl-abort
	gas: suffix=q mem16
	intel: reg16
	nasm: osz-mem-1
END

# Code: Pop_rm16
INSTRUCTION: o16 8F /0 | POP r/m16 | INTEL8086
	ops: w=rm | UInt16
	implied: pop-rm=2
	flags: sp=pop;2
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Pop_rm32
INSTRUCTION: o32 8F /0 | POP r/m32 | INTEL386
	ops: w=rm | UInt32
	implied: pop-rm=4
	flags: 16 32 sp=pop;4
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Pop_rm64
INSTRUCTION: o64 8F /0 | POP r/m64 | X64
	ops: w=rm | UInt64
	implied: pop-rm=8
	flags: 64 sp=pop;8 do64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Nopw
INSTRUCTION: o16 90 | NOP | INTEL8086
	code-mnemonic: nopw
	flags: nop
	gas: nop
	intel: nop
	masm: nop
	nasm: nop
END

# Code: Nopd
INSTRUCTION: o32 90 | NOP | INTEL8086
	code-mnemonic: nopd
	flags: nop
	gas: nop
	intel: nop
	masm: nop
	nasm: nop
END

# Code: Nopq
INSTRUCTION: o64 90 | NOP | INTEL8086
	code-mnemonic: nopq
	flags: 64 nop asm-ig
	gas: nop
	intel: nop
	masm: nop
	nasm: nop
END

# Code: Xchg_r16_AX
INSTRUCTION: o16 90+rw | XCHG r16, AX | INTEL8086
	ops: rw=opcode rw=r:ax
	gas: suffix=w
END

# Code: Xchg_r32_EAX
INSTRUCTION: o32 90+rd | XCHG r32, EAX | INTEL386
	ops: rw=opcode rw=r:eax
	gas: suffix=l
END

# Code: Xchg_r64_RAX
INSTRUCTION: o64 90+ro | XCHG r64, RAX | X64
	ops: rw=opcode rw=r:rax
	flags: 64
	gas: suffix=q
END

# Code: Pause
INSTRUCTION: F3 90 | PAUSE | PAUSE
	flags: intel-may-vm-exit amd-may-vm-exit tsx-abort
END

# Code: Cbw
INSTRUCTION: o16 98 | CBW | INTEL8086
	implied: r=al w=ah
	gas: mnemonic=cbtw
END

# Code: Cwde
INSTRUCTION: o32 98 | CWDE | INTEL386
	implied: r=ax w=eax
	gas: mnemonic=cwtl
END

# Code: Cdqe
INSTRUCTION: o64 98 | CDQE | X64
	# It will be converted to r=eax w=rax
	implied: rw=eax
	flags: 64
	gas: mnemonic=cltq
END

# Code: Cwd
INSTRUCTION: o16 99 | CWD | INTEL8086
	implied: r=ax w=dx
	gas: mnemonic=cwtd
END

# Code: Cdq
INSTRUCTION: o32 99 | CDQ | INTEL386
	implied: r=eax w=edx
	gas: mnemonic=cltd
END

# Code: Cqo
INSTRUCTION: o64 99 | CQO | X64
	implied: r=rax w=rdx
	flags: 64
	gas: mnemonic=cqto
END

# Code: Call_ptr1616
INSTRUCTION: o16 9A cd | CALL ptr16:16 | INTEL8086
	ops: r=br-far
	implied: push=2x2
	# VM exit if task switch
	flags: 16 32 sp=push;4 br=call-far cflow=call intel-may-vm-exit no-in-sgx amd-may-vm-exit tsx-impl-abort asm-ig
	gas: mnemonic=lcall suffix=w osz-suffix-4
	intel: flags=far osz
	nasm: far
END

# Code: Call_ptr1632
INSTRUCTION: o32 9A cp | CALL ptr16:32 | INTEL386
	ops: r=br-far
	implied: push=2x4
	# VM exit if task switch
	flags: 16 32 sp=push;8 br=call-far cflow=call intel-may-vm-exit no-in-sgx amd-may-vm-exit tsx-impl-abort asm-ig
	gas: mnemonic=lcall suffix=l osz-suffix-4
	intel: flags=far osz
	nasm: far
END

# Code: Wait
INSTRUCTION: 9B | WAIT | INTEL8086
	flags: tsx-impl-abort
	gas: mnemonic=fwait
	intel: mnemonic=fwait
END

# Code: Pushfw
INSTRUCTION: o16 9C | PUSHF | INTEL8086
	implied: push=1x2
	code-mnemonic: pushfw
	rflags: r=oszacpdi
	flags: sp=push;2 amd-may-vm-exit asm=pushf
	gas: osz-suffix-1
	nasm: osz-suffix-1
END

# Code: Pushfd
INSTRUCTION: o32 9C | PUSHFD | INTEL386
	implied: push=1x4
	rflags: r=oszacpdiA
	flags: 16 32 sp=push;4 amd-may-vm-exit asm=pushfd
	gas: mnemonic=pushf osz-suffix-1
	nasm: mnemonic=pushf osz-suffix-1
END

# Code: Pushfq
INSTRUCTION: o64 9C | PUSHFQ | X64
	implied: push=1x8
	rflags: r=oszacpdiA
	flags: 64 sp=push;8 do64 amd-may-vm-exit asm=pushfq
	gas: mnemonic=pushf osz-suffix-1
	nasm: mnemonic=pushf osz-suffix-1
END

# Code: Popfw
INSTRUCTION: o16 9D | POPF | INTEL8086
	implied: pop=1x2
	code-mnemonic: popfw
	rflags: w=oszacpdi
	flags: sp=pop;2 amd-may-vm-exit tsx-impl-abort asm=popf
	gas: osz-suffix-1
	nasm: osz-suffix-1
END

# Code: Popfd
INSTRUCTION: o32 9D | POPFD | INTEL386
	implied: pop=1x4
	rflags: w=oszacpdiA
	flags: 16 32 sp=pop;4 amd-may-vm-exit tsx-impl-abort asm=popfd
	gas: mnemonic=popf osz-suffix-1
	nasm: mnemonic=popf osz-suffix-1
END

# Code: Popfq
INSTRUCTION: o64 9D | POPFQ | X64
	implied: pop=1x8
	rflags: w=oszacpdiA
	flags: 64 sp=pop;8 do64 amd-may-vm-exit tsx-impl-abort asm=popfq
	gas: mnemonic=popf osz-suffix-1
	nasm: mnemonic=popf osz-suffix-1
END

# Code: Sahf
INSTRUCTION: 9E | SAHF | INTEL8086
	implied: r=ah
	rflags: w=szacp
END

# Code: Lahf
INSTRUCTION: 9F | LAHF | INTEL8086
	implied: w=ah
	rflags: r=szacp
END

# Code: Mov_AL_moffs8
INSTRUCTION: A0 mo | MOV AL, moffs8 | INTEL8086
	ops: w=r:al r=moffs | UInt8
	gas: suffix=b movabs
	intel: movabs
	nasm: movabs
END

# Code: Mov_AX_moffs16
INSTRUCTION: o16 A1 mo | MOV AX, moffs16 | INTEL8086
	ops: w=r:ax r=moffs | UInt16
	gas: suffix=w movabs
	intel: movabs
	nasm: movabs
END

# Code: Mov_EAX_moffs32
INSTRUCTION: o32 A1 mo | MOV EAX, moffs32 | INTEL386
	ops: w=r:eax r=moffs | UInt32
	gas: suffix=l movabs
	intel: movabs
	nasm: movabs
END

# Code: Mov_RAX_moffs64
INSTRUCTION: o64 A1 mo | MOV RAX, moffs64 | X64
	ops: w=r:rax r=moffs | UInt64
	flags: 64
	gas: suffix=q movabs
	intel: movabs
	nasm: movabs
END

# Code: Mov_moffs8_AL
INSTRUCTION: A2 mo | MOV moffs8, AL | INTEL8086
	ops: w=moffs r=r:al | UInt8
	gas: suffix=b movabs
	intel: movabs
	nasm: movabs
END

# Code: Mov_moffs16_AX
INSTRUCTION: o16 A3 mo | MOV moffs16, AX | INTEL8086
	ops: w=moffs r=r:ax | UInt16
	gas: suffix=w movabs
	intel: movabs
	nasm: movabs
END

# Code: Mov_moffs32_EAX
INSTRUCTION: o32 A3 mo | MOV moffs32, EAX | INTEL386
	ops: w=moffs r=r:eax | UInt32
	gas: suffix=l movabs
	intel: movabs
	nasm: movabs
END

# Code: Mov_moffs64_RAX
INSTRUCTION: o64 A3 mo | MOV moffs64, RAX | X64
	ops: w=moffs r=r:rax | UInt64
	flags: 64
	gas: suffix=q movabs
	intel: movabs
	nasm: movabs
END

# Code: Movsb_m8_m8
INSTRUCTION: A4 | MOVSB [m8], [m8] | INTEL8086
	ops: w=es-rdi r=seg-rsi | UInt8
	implied: movs
	rflags: r=d
	flags: rep is-string-op
	gas: mnemonic=movs flags=force-suffix suffix=b
	masm: mnemonic=movs asz-string-yx b
	nasm: asz-string
END

# Code: Movsw_m16_m16
INSTRUCTION: o16 A5 | MOVSW [m16], [m16] | INTEL8086
	ops: w=es-rdi r=seg-rsi | UInt16
	implied: movs
	rflags: r=d
	flags: rep is-string-op
	gas: mnemonic=movs flags=force-suffix suffix=w
	masm: mnemonic=movs asz-string-yx w
	nasm: asz-string
END

# Code: Movsd_m32_m32
INSTRUCTION: o32 A5 | MOVSD [m32], [m32] | INTEL386
	ops: w=es-rdi r=seg-rsi | UInt32
	implied: movs
	rflags: r=d
	flags: rep is-string-op
	gas: mnemonic=movs flags=force-suffix suffix=l
	masm: mnemonic=movs asz-string-yx d
	nasm: asz-string
END

# Code: Movsq_m64_m64
INSTRUCTION: o64 A5 | MOVSQ [m64], [m64] | X64
	ops: w=es-rdi r=seg-rsi | UInt64
	implied: movs
	rflags: r=d
	flags: 64 rep is-string-op
	gas: mnemonic=movs flags=force-suffix suffix=q
	masm: mnemonic=movs asz-string-yx q
	nasm: asz-string
END

# Code: Cmpsb_m8_m8
INSTRUCTION: A6 | CMPSB [m8], [m8] | INTEL8086
	ops: r=seg-rsi r=es-rdi | UInt8
	implied: cmps
	rflags: r=d w=oszacp
	flags: repe repne is-string-op
	gas: mnemonic=cmps flags=force-suffix suffix=b
	masm: mnemonic=cmps asz-string-xy b
	nasm: asz-string
END

# Code: Cmpsw_m16_m16
INSTRUCTION: o16 A7 | CMPSW [m16], [m16] | INTEL8086
	ops: r=seg-rsi r=es-rdi | UInt16
	implied: cmps
	rflags: r=d w=oszacp
	flags: repe repne is-string-op
	gas: mnemonic=cmps flags=force-suffix suffix=w
	masm: mnemonic=cmps asz-string-xy w
	nasm: asz-string
END

# Code: Cmpsd_m32_m32
INSTRUCTION: o32 A7 | CMPSD [m32], [m32] | INTEL386
	ops: r=seg-rsi r=es-rdi | UInt32
	implied: cmps
	rflags: r=d w=oszacp
	flags: repe repne is-string-op
	gas: mnemonic=cmps flags=force-suffix suffix=l
	masm: mnemonic=cmps asz-string-xy d
	nasm: asz-string
END

# Code: Cmpsq_m64_m64
INSTRUCTION: o64 A7 | CMPSQ [m64], [m64] | X64
	ops: r=seg-rsi r=es-rdi | UInt64
	implied: cmps
	rflags: r=d w=oszacp
	flags: 64 repe repne is-string-op
	gas: mnemonic=cmps flags=force-suffix suffix=q
	masm: mnemonic=cmps asz-string-xy q
	nasm: asz-string
END

# Code: Test_AL_imm8
INSTRUCTION: A8 ib | TEST AL, imm8 | INTEL8086
	ops: r=r:al r=imm
	rflags: u=a w=szp 0=oc
	gas: suffix=b
END

# Code: Test_AX_imm16
INSTRUCTION: o16 A9 iw | TEST AX, imm16 | INTEL8086
	ops: r=r:ax r=imm
	rflags: u=a w=szp 0=oc
	gas: suffix=w
END

# Code: Test_EAX_imm32
INSTRUCTION: o32 A9 id | TEST EAX, imm32 | INTEL386
	ops: r=r:eax r=imm
	rflags: u=a w=szp 0=oc
	gas: suffix=l
END

# Code: Test_RAX_imm32
INSTRUCTION: o64 A9 id | TEST RAX, imm32 | X64
	ops: r=r:rax r=imm;64
	rflags: u=a w=szp 0=oc
	flags: 64
	gas: suffix=q
	nasm: flags=no-sx sx
END

# Code: Stosb_m8_AL
INSTRUCTION: AA | STOSB [m8], [AL] | INTEL8086
	ops: w=es-rdi r=r:al | UInt8
	implied: stos
	rflags: r=d
	flags: rep is-string-op
	gas: mnemonic=stos suffix=b
	intel: ignore-last
	masm: mnemonic=stos asz-string-ya b
	nasm: asz-string
END

# Code: Stosw_m16_AX
INSTRUCTION: o16 AB | STOSW [m16], [AX] | INTEL8086
	ops: w=es-rdi r=r:ax | UInt16
	implied: stos
	rflags: r=d
	flags: rep is-string-op
	gas: mnemonic=stos suffix=w
	intel: ignore-last
	masm: mnemonic=stos asz-string-ya w
	nasm: asz-string
END

# Code: Stosd_m32_EAX
INSTRUCTION: o32 AB | STOSD [m32], [EAX] | INTEL386
	ops: w=es-rdi r=r:eax | UInt32
	implied: stos
	rflags: r=d
	flags: rep is-string-op
	gas: mnemonic=stos suffix=l
	intel: ignore-last
	masm: mnemonic=stos asz-string-ya d
	nasm: asz-string
END

# Code: Stosq_m64_RAX
INSTRUCTION: o64 AB | STOSQ [m64], [RAX] | X64
	ops: w=es-rdi r=r:rax | UInt64
	implied: stos
	rflags: r=d
	flags: 64 rep is-string-op
	gas: mnemonic=stos suffix=q
	intel: ignore-last
	masm: mnemonic=stos asz-string-ya q
	nasm: asz-string
END

# Code: Lodsb_AL_m8
INSTRUCTION: AC | LODSB [AL], [m8] | INTEL8086
	ops: w=r:al r=seg-rsi | UInt8
	implied: lods
	rflags: r=d
	flags: rep is-string-op
	gas: mnemonic=lods suffix=b
	intel: ignore-first
	masm: mnemonic=lods asz-string-ax b
	nasm: asz-string
END

# Code: Lodsw_AX_m16
INSTRUCTION: o16 AD | LODSW [AX], [m16] | INTEL8086
	ops: w=r:ax r=seg-rsi | UInt16
	implied: lods
	rflags: r=d
	flags: rep is-string-op
	gas: mnemonic=lods suffix=w
	intel: ignore-first
	masm: mnemonic=lods asz-string-ax w
	nasm: asz-string
END

# Code: Lodsd_EAX_m32
INSTRUCTION: o32 AD | LODSD [EAX], [m32] | INTEL386
	ops: w=r:eax r=seg-rsi | UInt32
	implied: lods
	rflags: r=d
	flags: rep is-string-op
	gas: mnemonic=lods suffix=l
	intel: ignore-first
	masm: mnemonic=lods asz-string-ax d
	nasm: asz-string
END

# Code: Lodsq_RAX_m64
INSTRUCTION: o64 AD | LODSQ [RAX], [m64] | X64
	ops: w=r:rax r=seg-rsi | UInt64
	implied: lods
	rflags: r=d
	flags: 64 rep is-string-op
	gas: mnemonic=lods suffix=q
	intel: ignore-first
	masm: mnemonic=lods asz-string-ax q
	nasm: asz-string
END

# Code: Scasb_AL_m8
INSTRUCTION: AE | SCASB [AL], [m8] | INTEL8086
	ops: r=r:al r=es-rdi | UInt8
	implied: scas
	rflags: r=d w=oszacp
	flags: repe repne is-string-op
	gas: mnemonic=scas suffix=b
	intel: ignore-first
	masm: mnemonic=scas asz-string-ay b
	nasm: asz-string
END

# Code: Scasw_AX_m16
INSTRUCTION: o16 AF | SCASW [AX], [m16] | INTEL8086
	ops: r=r:ax r=es-rdi | UInt16
	implied: scas
	rflags: r=d w=oszacp
	flags: repe repne is-string-op
	gas: mnemonic=scas suffix=w
	intel: ignore-first
	masm: mnemonic=scas asz-string-ay w
	nasm: asz-string
END

# Code: Scasd_EAX_m32
INSTRUCTION: o32 AF | SCASD [EAX], [m32] | INTEL386
	ops: r=r:eax r=es-rdi | UInt32
	implied: scas
	rflags: r=d w=oszacp
	flags: repe repne is-string-op
	gas: mnemonic=scas suffix=l
	intel: ignore-first
	masm: mnemonic=scas asz-string-ay d
	nasm: asz-string
END

# Code: Scasq_RAX_m64
INSTRUCTION: o64 AF | SCASQ [RAX], [m64] | X64
	ops: r=r:rax r=es-rdi | UInt64
	implied: scas
	rflags: r=d w=oszacp
	flags: 64 repe repne is-string-op
	gas: mnemonic=scas suffix=q
	intel: ignore-first
	masm: mnemonic=scas asz-string-ay q
	nasm: asz-string
END

# Code: Mov_r8_imm8
INSTRUCTION: B0+rb ib | MOV r8, imm8 | INTEL8086
	ops: w=opcode r=imm
	gas: suffix=b
END

# Code: Mov_r16_imm16
INSTRUCTION: o16 B8+rw iw | MOV r16, imm16 | INTEL8086
	ops: w=opcode r=imm
	gas: suffix=w
END

# Code: Mov_r32_imm32
INSTRUCTION: o32 B8+rd id | MOV r32, imm32 | INTEL386
	ops: w=opcode r=imm
	gas: suffix=l
END

# Code: Mov_r64_imm64
INSTRUCTION: o64 B8+ro io | MOV r64, imm64 | X64
	ops: w=opcode r=imm
	flags: 64
	gas: mnemonic=movabs suffix=q
END

# Code: Rol_rm8_imm8
INSTRUCTION: C0 /0 ib | ROL r/m8, imm8 | INTEL186
	ops: rw=rm r=imm | UInt8
	implied: shift-mask=0x1F
	rflags: u=o w=c
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Ror_rm8_imm8
INSTRUCTION: C0 /1 ib | ROR r/m8, imm8 | INTEL186
	ops: rw=rm r=imm | UInt8
	implied: shift-mask=0x1F
	rflags: u=o w=c
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rcl_rm8_imm8
INSTRUCTION: C0 /2 ib | RCL r/m8, imm8 | INTEL186
	ops: rw=rm r=imm | UInt8
	implied: shift-mask-1F-mod=9
	rflags: r=c u=o w=c
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rcr_rm8_imm8
INSTRUCTION: C0 /3 ib | RCR r/m8, imm8 | INTEL186
	ops: rw=rm r=imm | UInt8
	implied: shift-mask-1F-mod=9
	rflags: r=c u=o w=c
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Shl_rm8_imm8
INSTRUCTION: C0 /4 ib | SHL r/m8, imm8 | INTEL186
	ops: rw=rm r=imm | UInt8
	implied: shift-mask=0x1F
	rflags: u=oa w=szcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Shr_rm8_imm8
INSTRUCTION: C0 /5 ib | SHR r/m8, imm8 | INTEL186
	ops: rw=rm r=imm | UInt8
	implied: shift-mask=0x1F
	rflags: u=oa w=szcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sal_rm8_imm8
INSTRUCTION: C0 /6 ib | SAL r/m8, imm8 | INTEL186
	ops: rw=rm r=imm | UInt8
	implied: shift-mask=0x1F
	rflags: u=oa w=szcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: mnemonic=shl flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sar_rm8_imm8
INSTRUCTION: C0 /7 ib | SAR r/m8, imm8 | INTEL186
	ops: rw=rm r=imm | Int8
	implied: shift-mask=0x1F
	rflags: u=oa w=szcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rol_rm16_imm8
INSTRUCTION: o16 C1 /0 ib | ROL r/m16, imm8 | INTEL186
	ops: rw=rm r=imm | UInt16
	implied: shift-mask=0x1F
	rflags: u=o w=c
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rol_rm32_imm8
INSTRUCTION: o32 C1 /0 ib | ROL r/m32, imm8 | INTEL386
	ops: rw=rm r=imm | UInt32
	implied: shift-mask=0x1F
	rflags: u=o w=c
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rol_rm64_imm8
INSTRUCTION: o64 C1 /0 ib | ROL r/m64, imm8 | X64
	ops: rw=rm r=imm | UInt64
	implied: shift-mask=0x3F
	rflags: u=o w=c
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Ror_rm16_imm8
INSTRUCTION: o16 C1 /1 ib | ROR r/m16, imm8 | INTEL186
	ops: rw=rm r=imm | UInt16
	implied: shift-mask=0x1F
	rflags: u=o w=c
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Ror_rm32_imm8
INSTRUCTION: o32 C1 /1 ib | ROR r/m32, imm8 | INTEL386
	ops: rw=rm r=imm | UInt32
	implied: shift-mask=0x1F
	rflags: u=o w=c
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Ror_rm64_imm8
INSTRUCTION: o64 C1 /1 ib | ROR r/m64, imm8 | X64
	ops: rw=rm r=imm | UInt64
	implied: shift-mask=0x3F
	rflags: u=o w=c
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rcl_rm16_imm8
INSTRUCTION: o16 C1 /2 ib | RCL r/m16, imm8 | INTEL186
	ops: rw=rm r=imm | UInt16
	implied: shift-mask-1F-mod=17
	rflags: r=c u=o w=c
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rcl_rm32_imm8
INSTRUCTION: o32 C1 /2 ib | RCL r/m32, imm8 | INTEL386
	ops: rw=rm r=imm | UInt32
	implied: shift-mask=0x1F
	rflags: r=c u=o w=c
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rcl_rm64_imm8
INSTRUCTION: o64 C1 /2 ib | RCL r/m64, imm8 | X64
	ops: rw=rm r=imm | UInt64
	implied: shift-mask=0x3F
	rflags: r=c u=o w=c
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rcr_rm16_imm8
INSTRUCTION: o16 C1 /3 ib | RCR r/m16, imm8 | INTEL186
	ops: rw=rm r=imm | UInt16
	implied: shift-mask-1F-mod=17
	rflags: r=c u=o w=c
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rcr_rm32_imm8
INSTRUCTION: o32 C1 /3 ib | RCR r/m32, imm8 | INTEL386
	ops: rw=rm r=imm | UInt32
	implied: shift-mask=0x1F
	rflags: r=c u=o w=c
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rcr_rm64_imm8
INSTRUCTION: o64 C1 /3 ib | RCR r/m64, imm8 | X64
	ops: rw=rm r=imm | UInt64
	implied: shift-mask=0x3F
	rflags: r=c u=o w=c
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Shl_rm16_imm8
INSTRUCTION: o16 C1 /4 ib | SHL r/m16, imm8 | INTEL186
	ops: rw=rm r=imm | UInt16
	implied: shift-mask=0x1F
	rflags: u=oa w=szcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Shl_rm32_imm8
INSTRUCTION: o32 C1 /4 ib | SHL r/m32, imm8 | INTEL386
	ops: rw=rm r=imm | UInt32
	implied: shift-mask=0x1F
	rflags: u=oa w=szcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Shl_rm64_imm8
INSTRUCTION: o64 C1 /4 ib | SHL r/m64, imm8 | X64
	ops: rw=rm r=imm | UInt64
	implied: shift-mask=0x3F
	rflags: u=oa w=szcp
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Shr_rm16_imm8
INSTRUCTION: o16 C1 /5 ib | SHR r/m16, imm8 | INTEL186
	ops: rw=rm r=imm | UInt16
	implied: shift-mask=0x1F
	rflags: u=oa w=szcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Shr_rm32_imm8
INSTRUCTION: o32 C1 /5 ib | SHR r/m32, imm8 | INTEL386
	ops: rw=rm r=imm | UInt32
	implied: shift-mask=0x1F
	rflags: u=oa w=szcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Shr_rm64_imm8
INSTRUCTION: o64 C1 /5 ib | SHR r/m64, imm8 | X64
	ops: rw=rm r=imm | UInt64
	implied: shift-mask=0x3F
	rflags: u=oa w=szcp
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sal_rm16_imm8
INSTRUCTION: o16 C1 /6 ib | SAL r/m16, imm8 | INTEL186
	ops: rw=rm r=imm | UInt16
	implied: shift-mask=0x1F
	rflags: u=oa w=szcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: mnemonic=shl flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sal_rm32_imm8
INSTRUCTION: o32 C1 /6 ib | SAL r/m32, imm8 | INTEL386
	ops: rw=rm r=imm | UInt32
	implied: shift-mask=0x1F
	rflags: u=oa w=szcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: mnemonic=shl flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sal_rm64_imm8
INSTRUCTION: o64 C1 /6 ib | SAL r/m64, imm8 | X64
	ops: rw=rm r=imm | UInt64
	implied: shift-mask=0x3F
	rflags: u=oa w=szcp
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: mnemonic=shl flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sar_rm16_imm8
INSTRUCTION: o16 C1 /7 ib | SAR r/m16, imm8 | INTEL186
	ops: rw=rm r=imm | Int16
	implied: shift-mask=0x1F
	rflags: u=oa w=szcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sar_rm32_imm8
INSTRUCTION: o32 C1 /7 ib | SAR r/m32, imm8 | INTEL386
	ops: rw=rm r=imm | Int32
	implied: shift-mask=0x1F
	rflags: u=oa w=szcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sar_rm64_imm8
INSTRUCTION: o64 C1 /7 ib | SAR r/m64, imm8 | X64
	ops: rw=rm r=imm | Int64
	implied: shift-mask=0x3F
	rflags: u=oa w=szcp
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Retnw_imm16
INSTRUCTION: o16 C2 iw | RET imm16 | INTEL8086
	ops: r=imm
	implied: pop=1x2
	code-mnemonic: retnw
	flags: sp=pop_imm16;2 bnd cflow=ret no-intel-dec64
	gas: osz-suffix-2 ret retw retw
	intel: osz-bnd
	masm: osz-suffix-2 ret retw retw
	nasm: osz-suffix-2 ret retw retw
END

# Code: Retnd_imm16
INSTRUCTION: o32 C2 iw | RET imm16 | INTEL386
	ops: r=imm
	implied: pop=1x4
	code-mnemonic: retnd
	flags: 16 32 sp=pop_imm16;4 bnd cflow=ret
	gas: osz-suffix-2 retl ret retl
	intel: osz-bnd
	masm: osz-suffix-2 retnd ret retnd
	nasm: osz-suffix-2 retd ret retd
END

# Code: Retnq_imm16
INSTRUCTION: o64 C2 iw | RET imm16 | X64
	ops: r=imm
	implied: pop=1x8
	code-mnemonic: retnq
	flags: 64 sp=pop_imm16;8 bnd cflow=ret intel-fo64 do64
	gas: suffix=q bnd
	intel: bnd
	masm: bnd
	nasm: bnd
END

# Code: Retnw
INSTRUCTION: o16 C3 | RET | INTEL8086
	implied: pop=1x2
	code-mnemonic: retnw
	flags: sp=pop;2 bnd cflow=ret no-intel-dec64
	gas: osz-suffix-2 ret retw retw
	intel: osz-bnd
	masm: osz-suffix-2 ret retw retw
	nasm: osz-suffix-2 ret retw retw
END

# Code: Retnd
INSTRUCTION: o32 C3 | RET | INTEL386
	implied: pop=1x4
	code-mnemonic: retnd
	flags: 16 32 sp=pop;4 bnd cflow=ret
	gas: osz-suffix-2 retl ret retl
	intel: osz-bnd
	masm: osz-suffix-2 retnd ret retnd
	nasm: osz-suffix-2 retd ret retd
END

# Code: Retnq
INSTRUCTION: o64 C3 | RET | X64
	implied: pop=1x8
	code-mnemonic: retnq
	flags: 64 sp=pop;8 bnd cflow=ret intel-fo64 do64
	gas: suffix=q bnd
	intel: bnd
	masm: bnd
	nasm: bnd
END

# Code: Les_r16_m1616
INSTRUCTION: o16 C4 /r | LES r16, m16:16 | INTEL8086
	ops: w=reg r=rm | SegPtr16
	implied: w=es
	code-memory-size: 1616
	flags: 16 32 no-in-sgx tsx-impl-abort
	gas: suffix=w
	nasm: flags=mem-size=ignore
END

# Code: Les_r32_m1632
INSTRUCTION: o32 C4 /r | LES r32, m16:32 | INTEL386
	ops: w=reg r=rm | SegPtr32
	implied: w=es
	code-memory-size: 1632
	flags: 16 32 no-in-sgx tsx-impl-abort
	gas: suffix=l
	nasm: flags=mem-size=ignore
END

# Code: Lds_r16_m1616
INSTRUCTION: o16 C5 /r | LDS r16, m16:16 | INTEL8086
	ops: w=reg r=rm | SegPtr16
	implied: w=ds
	code-memory-size: 1616
	flags: 16 32 no-in-sgx tsx-impl-abort
	gas: suffix=w
	nasm: flags=mem-size=ignore
END

# Code: Lds_r32_m1632
INSTRUCTION: o32 C5 /r | LDS r32, m16:32 | INTEL386
	ops: w=reg r=rm | SegPtr32
	implied: w=ds
	code-memory-size: 1632
	flags: 16 32 no-in-sgx tsx-impl-abort
	gas: suffix=l
	nasm: flags=mem-size=ignore
END

# Code: Mov_rm8_imm8
INSTRUCTION: C6 /0 ib | MOV r/m8, imm8 | INTEL8086
	ops: w=rm r=imm | UInt8
	flags: xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Xabort_imm8
INSTRUCTION: C6 F8 ib | XABORT imm8 | RTM
	ops: r=imm
	flags: save-restore tsx-abort
END

# Code: Mov_rm16_imm16
INSTRUCTION: o16 C7 /0 iw | MOV r/m16, imm16 | INTEL8086
	ops: w=rm r=imm | UInt16
	flags: xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Mov_rm32_imm32
INSTRUCTION: o32 C7 /0 id | MOV r/m32, imm32 | INTEL386
	ops: w=rm r=imm | UInt32
	flags: xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Mov_rm64_imm32
INSTRUCTION: o64 C7 /0 id | MOV r/m64, imm32 | X64
	ops: w=rm r=imm;64 | UInt64
	flags: 64 xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always sx2
END

# Code: Xbegin_rel16
INSTRUCTION: o16 C7 F8 cw | XBEGIN rel16 | RTM
	ops: r=br-x
	implied: cw=eax
	flags: br=xbegin cflow=tsx tsx-may-abort
END

# Code: Xbegin_rel32
INSTRUCTION: o32 C7 F8 cd | XBEGIN rel32 | RTM
	ops: r=br-x
	implied: cw=eax
	flags: br=xbegin cflow=tsx tsx-may-abort
END

# Code: Enterw_imm16_imm8
INSTRUCTION: o16 C8 iw ib | ENTER imm16, imm8 | INTEL186
	ops: r=imm r=imm
	implied: enter=2
	code-mnemonic: enterw
	flags: sp=enter;2
	gas: flags=keep-op-order suffix=w osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Enterd_imm16_imm8
INSTRUCTION: o32 C8 iw ib | ENTER imm16, imm8 | INTEL386
	ops: r=imm r=imm
	implied: enter=4
	code-mnemonic: enterd
	flags: 16 32 sp=enter;4
	gas: flags=keep-op-order suffix=l osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Enterq_imm16_imm8
INSTRUCTION: o64 C8 iw ib | ENTER imm16, imm8 | X64
	ops: r=imm r=imm
	implied: enter=8
	code-mnemonic: enterq
	flags: 64 sp=enter;8 do64
	gas: flags=keep-op-order suffix=q osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Leavew
INSTRUCTION: o16 C9 | LEAVE | INTEL186
	implied: leave=2
	code-mnemonic: leavew
	flags: stack
	gas: suffix=w osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Leaved
INSTRUCTION: o32 C9 | LEAVE | INTEL386
	implied: leave=4
	code-mnemonic: leaved
	flags: 16 32 stack
	gas: suffix=l osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Leaveq
INSTRUCTION: o64 C9 | LEAVE | X64
	implied: leave=8
	code-mnemonic: leaveq
	flags: 64 stack do64
	gas: suffix=q osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Retfw_imm16
INSTRUCTION: o16 CA iw | RETF imm16 | INTEL8086
	ops: r=imm
	implied: pop=2x2
	code-mnemonic: retfw
	flags: sp=pop_imm16;4 cflow=ret no-in-sgx tsx-impl-abort
	gas: mnemonic=lret suffix=w osz-suffix-3 16
	intel: mnemonic=ret flags=far osz
	masm: osz-suffix-2 retf retfw retfw
	nasm: osz-suffix-3
END

# Code: Retfd_imm16
INSTRUCTION: o32 CA iw | RETF imm16 | INTEL386
	ops: r=imm
	implied: pop=2x4
	code-mnemonic: retfd
	flags: sp=pop_imm16;8 cflow=ret no-in-sgx tsx-impl-abort
	gas: mnemonic=lret suffix=l osz-suffix-3 32
	intel: mnemonic=ret flags=far osz
	masm: osz-suffix-2 retfd retf retf
	nasm: osz-suffix-3
END

# Code: Retfq_imm16
INSTRUCTION: o64 CA iw | RETF imm16 | X64
	ops: r=imm
	implied: pop=2x8
	code-mnemonic: retfq
	flags: 64 sp=pop_imm16;16 cflow=ret no-in-sgx tsx-impl-abort
	fast: mnemonic=retfq
	gas: mnemonic=lret suffix=q osz-suffix-3 0
	intel: mnemonic=ret flags=far;o64
	masm: mnemonic=retfq osz-suffix-2 retf retf retfq
	nasm: osz-suffix-3
END

# Code: Retfw
INSTRUCTION: o16 CB | RETF | INTEL8086
	implied: pop=2x2
	code-mnemonic: retfw
	flags: sp=pop;4 cflow=ret no-in-sgx tsx-impl-abort
	gas: mnemonic=lret suffix=w osz-suffix-3 16
	intel: mnemonic=ret flags=far osz
	masm: osz-suffix-2 retf retfw retfw
	nasm: osz-suffix-3
END

# Code: Retfd
INSTRUCTION: o32 CB | RETF | INTEL386
	implied: pop=2x4
	code-mnemonic: retfd
	flags: sp=pop;8 cflow=ret no-in-sgx tsx-impl-abort
	gas: mnemonic=lret suffix=l osz-suffix-3 32
	intel: mnemonic=ret flags=far osz
	masm: osz-suffix-2 retfd retf retf
	nasm: osz-suffix-3
END

# Code: Retfq
INSTRUCTION: o64 CB | RETF | X64
	implied: pop=2x8
	code-mnemonic: retfq
	flags: 64 sp=pop;16 cflow=ret no-in-sgx tsx-impl-abort
	fast: mnemonic=retfq
	gas: mnemonic=lret suffix=q osz-suffix-3 0
	intel: mnemonic=ret flags=far;o64
	masm: mnemonic=retfq osz-suffix-2 retf retf retfq
	nasm: osz-suffix-3
END

# Code: Int3
INSTRUCTION: CC | INT3 | INTEL8086
	# #BP always causes transactional aborts
	flags: cflow=int intel-vm-exit amd-may-vm-exit tsx-abort asm=int3
	masm: mnemonic=int int3
END

# Code: Int_imm8
INSTRUCTION: CD ib | INT imm8 | INTEL8086
	ops: r=imm
	# VM exit if task switch
	flags: cflow=int intel-may-vm-exit no-in-sgx amd-may-vm-exit tsx-impl-abort
END

# Code: Into
INSTRUCTION: CE | INTO | INTEL8086
	rflags: r=o
	# VM exit if OF=1
	flags: 16 32 cflow=int intel-may-vm-exit no-in-sgx amd-may-vm-exit tsx-impl-abort
END

# Code: Iretw
INSTRUCTION: o16 CF | IRET | INTEL8086
	implied: pop;!64=3x2 pop;64=5x2 w;64=ss
	code-mnemonic: iretw
	rflags: w=oszacpdi
	# VM exit if task switch
	flags: sp=iret;2 cflow=ret serialize-intel serialize-amd intel-may-vm-exit no-in-sgx amd-may-vm-exit tsx-impl-abort asm=iret
	gas: suffix=w osz-suffix-3 16
	nasm: osz-suffix-3
END

# Code: Iretd
INSTRUCTION: o32 CF | IRETD | INTEL386
	implied: pop;!64=3x4 pop;64=5x4 w;64=ss
	rflags: w=oszacpdiA
	# VM exit if task switch
	flags: sp=iret;4 cflow=ret serialize-intel serialize-amd intel-may-vm-exit no-in-sgx amd-may-vm-exit tsx-impl-abort asm=iretd
	gas: mnemonic=iret suffix=l osz-suffix-3 32
	nasm: mnemonic=iret osz-suffix-3
END

# Code: Iretq
INSTRUCTION: o64 CF | IRETQ | X64
	implied: pop=5x8 w=ss
	rflags: w=oszacpdiA
	# VM exit if task switch
	flags: 64 sp=pop;40 cflow=ret serialize-intel serialize-amd intel-may-vm-exit no-in-sgx amd-may-vm-exit tsx-impl-abort asm=iretq
	gas: mnemonic=iret suffix=q osz-suffix-3 0
	nasm: mnemonic=iret osz-suffix-3
END

# Code: Rol_rm8_1
INSTRUCTION: D0 /0 | ROL r/m8, 1 | INTEL8086
	ops: rw=rm r=c:1 | UInt8
	rflags: w=oc
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Ror_rm8_1
INSTRUCTION: D0 /1 | ROR r/m8, 1 | INTEL8086
	ops: rw=rm r=c:1 | UInt8
	rflags: w=oc
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rcl_rm8_1
INSTRUCTION: D0 /2 | RCL r/m8, 1 | INTEL8086
	ops: rw=rm r=c:1 | UInt8
	rflags: r=c w=oc
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rcr_rm8_1
INSTRUCTION: D0 /3 | RCR r/m8, 1 | INTEL8086
	ops: rw=rm r=c:1 | UInt8
	rflags: r=c w=oc
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Shl_rm8_1
INSTRUCTION: D0 /4 | SHL r/m8, 1 | INTEL8086
	ops: rw=rm r=c:1 | UInt8
	rflags: u=a w=oszcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Shr_rm8_1
INSTRUCTION: D0 /5 | SHR r/m8, 1 | INTEL8086
	ops: rw=rm r=c:1 | UInt8
	rflags: u=a w=oszcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sal_rm8_1
INSTRUCTION: D0 /6 | SAL r/m8, 1 | INTEL8086
	ops: rw=rm r=c:1 | UInt8
	rflags: u=a w=oszcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: mnemonic=shl flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sar_rm8_1
INSTRUCTION: D0 /7 | SAR r/m8, 1 | INTEL8086
	ops: rw=rm r=c:1 | Int8
	rflags: u=a w=oszcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rol_rm16_1
INSTRUCTION: o16 D1 /0 | ROL r/m16, 1 | INTEL8086
	ops: rw=rm r=c:1 | UInt16
	rflags: w=oc
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rol_rm32_1
INSTRUCTION: o32 D1 /0 | ROL r/m32, 1 | INTEL386
	ops: rw=rm r=c:1 | UInt32
	rflags: w=oc
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rol_rm64_1
INSTRUCTION: o64 D1 /0 | ROL r/m64, 1 | X64
	ops: rw=rm r=c:1 | UInt64
	rflags: w=oc
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Ror_rm16_1
INSTRUCTION: o16 D1 /1 | ROR r/m16, 1 | INTEL8086
	ops: rw=rm r=c:1 | UInt16
	rflags: w=oc
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Ror_rm32_1
INSTRUCTION: o32 D1 /1 | ROR r/m32, 1 | INTEL386
	ops: rw=rm r=c:1 | UInt32
	rflags: w=oc
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Ror_rm64_1
INSTRUCTION: o64 D1 /1 | ROR r/m64, 1 | X64
	ops: rw=rm r=c:1 | UInt64
	rflags: w=oc
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rcl_rm16_1
INSTRUCTION: o16 D1 /2 | RCL r/m16, 1 | INTEL8086
	ops: rw=rm r=c:1 | UInt16
	rflags: r=c w=oc
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rcl_rm32_1
INSTRUCTION: o32 D1 /2 | RCL r/m32, 1 | INTEL386
	ops: rw=rm r=c:1 | UInt32
	rflags: r=c w=oc
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rcl_rm64_1
INSTRUCTION: o64 D1 /2 | RCL r/m64, 1 | X64
	ops: rw=rm r=c:1 | UInt64
	rflags: r=c w=oc
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rcr_rm16_1
INSTRUCTION: o16 D1 /3 | RCR r/m16, 1 | INTEL8086
	ops: rw=rm r=c:1 | UInt16
	rflags: r=c w=oc
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rcr_rm32_1
INSTRUCTION: o32 D1 /3 | RCR r/m32, 1 | INTEL386
	ops: rw=rm r=c:1 | UInt32
	rflags: r=c w=oc
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rcr_rm64_1
INSTRUCTION: o64 D1 /3 | RCR r/m64, 1 | X64
	ops: rw=rm r=c:1 | UInt64
	rflags: r=c w=oc
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Shl_rm16_1
INSTRUCTION: o16 D1 /4 | SHL r/m16, 1 | INTEL8086
	ops: rw=rm r=c:1 | UInt16
	rflags: u=a w=oszcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Shl_rm32_1
INSTRUCTION: o32 D1 /4 | SHL r/m32, 1 | INTEL386
	ops: rw=rm r=c:1 | UInt32
	rflags: u=a w=oszcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Shl_rm64_1
INSTRUCTION: o64 D1 /4 | SHL r/m64, 1 | X64
	ops: rw=rm r=c:1 | UInt64
	rflags: u=a w=oszcp
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Shr_rm16_1
INSTRUCTION: o16 D1 /5 | SHR r/m16, 1 | INTEL8086
	ops: rw=rm r=c:1 | UInt16
	rflags: u=a w=oszcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Shr_rm32_1
INSTRUCTION: o32 D1 /5 | SHR r/m32, 1 | INTEL386
	ops: rw=rm r=c:1 | UInt32
	rflags: u=a w=oszcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Shr_rm64_1
INSTRUCTION: o64 D1 /5 | SHR r/m64, 1 | X64
	ops: rw=rm r=c:1 | UInt64
	rflags: u=a w=oszcp
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sal_rm16_1
INSTRUCTION: o16 D1 /6 | SAL r/m16, 1 | INTEL8086
	ops: rw=rm r=c:1 | UInt16
	rflags: u=a w=oszcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: mnemonic=shl flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sal_rm32_1
INSTRUCTION: o32 D1 /6 | SAL r/m32, 1 | INTEL386
	ops: rw=rm r=c:1 | UInt32
	rflags: u=a w=oszcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: mnemonic=shl flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sal_rm64_1
INSTRUCTION: o64 D1 /6 | SAL r/m64, 1 | X64
	ops: rw=rm r=c:1 | UInt64
	rflags: u=a w=oszcp
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: mnemonic=shl flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sar_rm16_1
INSTRUCTION: o16 D1 /7 | SAR r/m16, 1 | INTEL8086
	ops: rw=rm r=c:1 | Int16
	rflags: u=a w=oszcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sar_rm32_1
INSTRUCTION: o32 D1 /7 | SAR r/m32, 1 | INTEL386
	ops: rw=rm r=c:1 | Int32
	rflags: u=a w=oszcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sar_rm64_1
INSTRUCTION: o64 D1 /7 | SAR r/m64, 1 | X64
	ops: rw=rm r=c:1 | Int64
	rflags: u=a w=oszcp
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rol_rm8_CL
INSTRUCTION: D2 /0 | ROL r/m8, CL | INTEL8086
	ops: rw=rm r=r:cl | UInt8
	rflags: u=o w=c
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Ror_rm8_CL
INSTRUCTION: D2 /1 | ROR r/m8, CL | INTEL8086
	ops: rw=rm r=r:cl | UInt8
	rflags: u=o w=c
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rcl_rm8_CL
INSTRUCTION: D2 /2 | RCL r/m8, CL | INTEL8086
	ops: rw=rm r=r:cl | UInt8
	rflags: r=c u=o w=c
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rcr_rm8_CL
INSTRUCTION: D2 /3 | RCR r/m8, CL | INTEL8086
	ops: rw=rm r=r:cl | UInt8
	rflags: r=c u=o w=c
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Shl_rm8_CL
INSTRUCTION: D2 /4 | SHL r/m8, CL | INTEL8086
	ops: rw=rm r=r:cl | UInt8
	rflags: u=oa w=szcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Shr_rm8_CL
INSTRUCTION: D2 /5 | SHR r/m8, CL | INTEL8086
	ops: rw=rm r=r:cl | UInt8
	rflags: u=oa w=szcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sal_rm8_CL
INSTRUCTION: D2 /6 | SAL r/m8, CL | INTEL8086
	ops: rw=rm r=r:cl | UInt8
	rflags: u=oa w=szcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: mnemonic=shl flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sar_rm8_CL
INSTRUCTION: D2 /7 | SAR r/m8, CL | INTEL8086
	ops: rw=rm r=r:cl | Int8
	rflags: u=oa w=szcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rol_rm16_CL
INSTRUCTION: o16 D3 /0 | ROL r/m16, CL | INTEL8086
	ops: rw=rm r=r:cl | UInt16
	rflags: u=o w=c
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rol_rm32_CL
INSTRUCTION: o32 D3 /0 | ROL r/m32, CL | INTEL386
	ops: rw=rm r=r:cl | UInt32
	rflags: u=o w=c
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rol_rm64_CL
INSTRUCTION: o64 D3 /0 | ROL r/m64, CL | X64
	ops: rw=rm r=r:cl | UInt64
	rflags: u=o w=c
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Ror_rm16_CL
INSTRUCTION: o16 D3 /1 | ROR r/m16, CL | INTEL8086
	ops: rw=rm r=r:cl | UInt16
	rflags: u=o w=c
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Ror_rm32_CL
INSTRUCTION: o32 D3 /1 | ROR r/m32, CL | INTEL386
	ops: rw=rm r=r:cl | UInt32
	rflags: u=o w=c
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Ror_rm64_CL
INSTRUCTION: o64 D3 /1 | ROR r/m64, CL | X64
	ops: rw=rm r=r:cl | UInt64
	rflags: u=o w=c
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rcl_rm16_CL
INSTRUCTION: o16 D3 /2 | RCL r/m16, CL | INTEL8086
	ops: rw=rm r=r:cl | UInt16
	rflags: r=c u=o w=c
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rcl_rm32_CL
INSTRUCTION: o32 D3 /2 | RCL r/m32, CL | INTEL386
	ops: rw=rm r=r:cl | UInt32
	rflags: r=c u=o w=c
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rcl_rm64_CL
INSTRUCTION: o64 D3 /2 | RCL r/m64, CL | X64
	ops: rw=rm r=r:cl | UInt64
	rflags: r=c u=o w=c
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rcr_rm16_CL
INSTRUCTION: o16 D3 /3 | RCR r/m16, CL | INTEL8086
	ops: rw=rm r=r:cl | UInt16
	rflags: r=c u=o w=c
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rcr_rm32_CL
INSTRUCTION: o32 D3 /3 | RCR r/m32, CL | INTEL386
	ops: rw=rm r=r:cl | UInt32
	rflags: r=c u=o w=c
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Rcr_rm64_CL
INSTRUCTION: o64 D3 /3 | RCR r/m64, CL | X64
	ops: rw=rm r=r:cl | UInt64
	rflags: r=c u=o w=c
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Shl_rm16_CL
INSTRUCTION: o16 D3 /4 | SHL r/m16, CL | INTEL8086
	ops: rw=rm r=r:cl | UInt16
	rflags: u=oa w=szcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Shl_rm32_CL
INSTRUCTION: o32 D3 /4 | SHL r/m32, CL | INTEL386
	ops: rw=rm r=r:cl | UInt32
	rflags: u=oa w=szcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Shl_rm64_CL
INSTRUCTION: o64 D3 /4 | SHL r/m64, CL | X64
	ops: rw=rm r=r:cl | UInt64
	rflags: u=oa w=szcp
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Shr_rm16_CL
INSTRUCTION: o16 D3 /5 | SHR r/m16, CL | INTEL8086
	ops: rw=rm r=r:cl | UInt16
	rflags: u=oa w=szcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Shr_rm32_CL
INSTRUCTION: o32 D3 /5 | SHR r/m32, CL | INTEL386
	ops: rw=rm r=r:cl | UInt32
	rflags: u=oa w=szcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Shr_rm64_CL
INSTRUCTION: o64 D3 /5 | SHR r/m64, CL | X64
	ops: rw=rm r=r:cl | UInt64
	rflags: u=oa w=szcp
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sal_rm16_CL
INSTRUCTION: o16 D3 /6 | SAL r/m16, CL | INTEL8086
	ops: rw=rm r=r:cl | UInt16
	rflags: u=oa w=szcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: mnemonic=shl flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sal_rm32_CL
INSTRUCTION: o32 D3 /6 | SAL r/m32, CL | INTEL386
	ops: rw=rm r=r:cl | UInt32
	rflags: u=oa w=szcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: mnemonic=shl flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sal_rm64_CL
INSTRUCTION: o64 D3 /6 | SAL r/m64, CL | X64
	ops: rw=rm r=r:cl | UInt64
	rflags: u=oa w=szcp
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: mnemonic=shl flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sar_rm16_CL
INSTRUCTION: o16 D3 /7 | SAR r/m16, CL | INTEL8086
	ops: rw=rm r=r:cl | Int16
	rflags: u=oa w=szcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sar_rm32_CL
INSTRUCTION: o32 D3 /7 | SAR r/m32, CL | INTEL386
	ops: rw=rm r=r:cl | Int32
	rflags: u=oa w=szcp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sar_rm64_CL
INSTRUCTION: o64 D3 /7 | SAR r/m64, CL | X64
	ops: rw=rm r=r:cl | Int64
	rflags: u=oa w=szcp
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Aam_imm8
INSTRUCTION: D4 ib | AAM imm8 | INTEL8086
	ops: r=imm
	implied: r=al w=ax
	rflags: u=oac w=szp
	flags: 16 32
	gas: ignore-const10
	masm: ignore-const10
	nasm: ignore-const10
END

# Code: Aad_imm8
INSTRUCTION: D5 ib | AAD imm8 | INTEL8086
	ops: r=imm
	implied: rw=ax
	rflags: u=oac w=szp
	flags: 16 32
	gas: ignore-const10
	masm: ignore-const10
	nasm: ignore-const10
END

# Code: Salc
INSTRUCTION: D6 | SALC | INTEL8086
	implied: w=al
	rflags: r=c
	flags: 16 32
END

# Code: Xlat_m8
INSTRUCTION: D7 | XLATB [m8] | INTEL8086
	ops: r=seg-rbx-al | UInt8
	implied: rw=al
	code-mnemonic: xlat
	flags: asm-ig
	fast: mnemonic=xlat
	gas: mnemonic=xlat flags=ignore-index suffix=b
	intel: mnemonic=xlat flags=ignore-index
	masm: mnemonic=xlat xlat
	nasm: xlat
END

# Code: Fadd_m32fp
INSTRUCTION: D8 /0 | FADD m32fp | FPU
	ops: r=rm | Float32
	implied: rw=st0
	code-memory-size-suffix: fp
	rflags: w=1 u=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=s
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fmul_m32fp
INSTRUCTION: D8 /1 | FMUL m32fp | FPU
	ops: r=rm | Float32
	implied: rw=st0
	code-memory-size-suffix: fp
	rflags: w=1 u=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=s
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fcom_m32fp
INSTRUCTION: D8 /2 | FCOM m32fp | FPU
	ops: r=rm | Float32
	implied: r=st0
	code-memory-size-suffix: fp
	rflags: 0=1 w=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=s
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fcomp_m32fp
INSTRUCTION: D8 /3 | FCOMP m32fp | FPU
	ops: r=rm | Float32
	implied: r=st0
	code-memory-size-suffix: fp
	rflags: 0=1 w=023
	flags: fpu-pop=1 tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=s
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fsub_m32fp
INSTRUCTION: D8 /4 | FSUB m32fp | FPU
	ops: r=rm | Float32
	implied: rw=st0
	code-memory-size-suffix: fp
	rflags: w=1 u=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=s
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fsubr_m32fp
INSTRUCTION: D8 /5 | FSUBR m32fp | FPU
	ops: r=rm | Float32
	implied: rw=st0
	code-memory-size-suffix: fp
	rflags: w=1 u=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=s
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fdiv_m32fp
INSTRUCTION: D8 /6 | FDIV m32fp | FPU
	ops: r=rm | Float32
	implied: rw=st0
	code-memory-size-suffix: fp
	rflags: w=1 u=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=s
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fdivr_m32fp
INSTRUCTION: D8 /7 | FDIVR m32fp | FPU
	ops: r=rm | Float32
	implied: rw=st0
	code-memory-size-suffix: fp
	rflags: w=1 u=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=s
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fadd_st0_sti
INSTRUCTION: D8 C0+i | FADD ST(0), ST(i) | FPU
	ops: rw=r:st0 r=opcode
	rflags: w=1 u=023
	flags: tsx-impl-abort
	gas: st1
	intel: st1
	masm: st1
	nasm: st1
END

# Code: Fmul_st0_sti
INSTRUCTION: D8 C8+i | FMUL ST(0), ST(i) | FPU
	ops: rw=r:st0 r=opcode
	rflags: w=1 u=023
	flags: tsx-impl-abort
	gas: st1
	intel: st1
	masm: st1
	nasm: st1
END

# Code: Fcom_st0_sti
INSTRUCTION: D8 D0+i | FCOM [ST(0)], ST(i) | FPU
	ops: r=r:st0 r=opcode
	rflags: 0=1 w=023
	flags: tsx-impl-abort
	gas: st1-ignore-st1 pseudo
	intel: st1 pseudo
	masm: st1-ignore-st1 pseudo
	nasm: st1 pseudo
END

# Code: Fcomp_st0_sti
INSTRUCTION: D8 D8+i | FCOMP [ST(0)], ST(i) | FPU
	ops: r=r:st0 r=opcode
	rflags: 0=1 w=023
	flags: fpu-pop=1 tsx-impl-abort
	gas: st1-ignore-st1 pseudo
	intel: st1 pseudo
	masm: st1-ignore-st1 pseudo
	nasm: st1 pseudo
END

# Code: Fsub_st0_sti
INSTRUCTION: D8 E0+i | FSUB ST(0), ST(i) | FPU
	ops: rw=r:st0 r=opcode
	rflags: w=1 u=023
	flags: tsx-impl-abort
	gas: st1
	intel: st1
	masm: st1
	nasm: st1
END

# Code: Fsubr_st0_sti
INSTRUCTION: D8 E8+i | FSUBR ST(0), ST(i) | FPU
	ops: rw=r:st0 r=opcode
	rflags: w=1 u=023
	flags: tsx-impl-abort
	gas: st1
	intel: st1
	masm: st1
	nasm: st1
END

# Code: Fdiv_st0_sti
INSTRUCTION: D8 F0+i | FDIV ST(0), ST(i) | FPU
	ops: rw=r:st0 r=opcode
	rflags: w=1 u=023
	flags: tsx-impl-abort
	gas: st1
	intel: st1
	masm: st1
	nasm: st1
END

# Code: Fdivr_st0_sti
INSTRUCTION: D8 F8+i | FDIVR ST(0), ST(i) | FPU
	ops: rw=r:st0 r=opcode
	rflags: w=1 u=023
	flags: tsx-impl-abort
	gas: st1
	intel: st1
	masm: st1
	nasm: st1
END

# Code: Fld_m32fp
INSTRUCTION: D9 /0 | FLD m32fp | FPU
	ops: r=rm | Float32
	code-memory-size-suffix: fp
	rflags: w=1 u=023
	flags: fpu-push=1 tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=s
	intel: flags=force-size=always add-st1 load
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fst_m32fp
INSTRUCTION: D9 /2 | FST m32fp | FPU
	ops: w=rm | Float32
	implied: r=st0
	code-memory-size-suffix: fp
	rflags: w=1 u=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=s
	intel: flags=force-size=always add-st2
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fstp_m32fp
INSTRUCTION: D9 /3 | FSTP m32fp | FPU
	ops: w=rm | Float32
	implied: r=st0
	code-memory-size-suffix: fp
	rflags: w=1 u=023
	flags: fpu-pop=1 tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=s
	intel: flags=force-size=always add-st2
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fldenv_m14byte
INSTRUCTION: o16 D9 /4 | FLDENV m14byte | FPU
	ops: r=rm | FpuEnv14
	code-memory-size: 14byte
	rflags: w=0123
	flags: writes-fpu-top tsx-impl-abort
	fast: flags=force-size=always
	gas: suffix=s osz-mem-2
	intel: osz-mem-2 16
	masm: osz-mem-2 16
	nasm: flags=mem-size=ignore osz-mem-2
END

# Code: Fldenv_m28byte
INSTRUCTION: o32 D9 /4 | FLDENV m28byte | FPU387
	ops: r=rm | FpuEnv28
	code-memory-size: 28byte
	rflags: w=0123
	flags: writes-fpu-top tsx-impl-abort
	fast: flags=force-size=always
	gas: suffix=l osz-mem-2
	intel: osz-mem-2
	masm: osz-mem-2
	nasm: flags=mem-size=ignore osz-mem-2
END

# Code: Fldcw_m2byte
INSTRUCTION: D9 /5 | FLDCW m2byte | FPU
	ops: r=rm | UInt16
	code-memory-size: 2byte
	rflags: u=0123
	flags: tsx-impl-abort
	gas: suffix=w
END

# Code: Fnstenv_m14byte
INSTRUCTION: o16 D9 /6 | FNSTENV m14byte | FPU
	ops: w=rm | FpuEnv14
	code-memory-size: 14byte
	rflags: r=0123 u=0123
	flags: tsx-impl-abort no-wait
	fast: flags=force-size=always
	gas: suffix=s osz-mem-2
	intel: osz-mem-2 16
	masm: osz-mem-2 16
	nasm: flags=mem-size=ignore osz-mem-2
END

# Code: Fstenv_m14byte
INSTRUCTION: 9B o16 D9 /6 | FSTENV m14byte | FPU
	ops: w=rm | FpuEnv14
	code-memory-size: 14byte
	rflags: r=0123 u=0123
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: suffix=s osz-mem-2
	intel: osz-mem-2 16
	masm: osz-mem-2 16
	nasm: flags=mem-size=ignore osz-mem-2
END

# Code: Fnstenv_m28byte
INSTRUCTION: o32 D9 /6 | FNSTENV m28byte | FPU387
	ops: w=rm | FpuEnv28
	code-memory-size: 28byte
	rflags: r=0123 u=0123
	flags: tsx-impl-abort no-wait
	fast: flags=force-size=always
	gas: suffix=l osz-mem-2
	intel: osz-mem-2
	masm: osz-mem-2
	nasm: flags=mem-size=ignore osz-mem-2
END

# Code: Fstenv_m28byte
INSTRUCTION: 9B o32 D9 /6 | FSTENV m28byte | FPU387
	ops: w=rm | FpuEnv28
	code-memory-size: 28byte
	rflags: r=0123 u=0123
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: suffix=l osz-mem-2
	intel: osz-mem-2
	masm: osz-mem-2
	nasm: flags=mem-size=ignore osz-mem-2
END

# Code: Fnstcw_m2byte
INSTRUCTION: D9 /7 | FNSTCW m2byte | FPU
	ops: w=rm | UInt16
	code-memory-size: 2byte
	rflags: u=0123
	flags: tsx-impl-abort no-wait
	gas: suffix=w
END

# Code: Fstcw_m2byte
INSTRUCTION: 9B D9 /7 | FSTCW m2byte | FPU
	ops: w=rm | UInt16
	code-memory-size: 2byte
	rflags: u=0123
	flags: tsx-impl-abort
	gas: suffix=w
END

# Code: Fld_sti
INSTRUCTION: D9 C0+i | FLD ST(i) | FPU
	ops: r=opcode
	rflags: w=1 u=023
	flags: fpu-push=1 tsx-impl-abort
	intel: add-st1 load
END

# Code: Fxch_st0_sti
INSTRUCTION: D9 C8+i | FXCH [ST(0)], ST(i) | FPU
	ops: rw=r:st0 rw=opcode
	rflags: 0=1 u=023
	flags: tsx-impl-abort
	gas: st1-ignore-st1 pseudo
	intel: st1 pseudo
	masm: st1-ignore-st1 pseudo
	nasm: st1 pseudo
END

# Code: Fnop
INSTRUCTION: D9 D0 | FNOP | FPU
	# c0,c1,c2,c3 == not updated

	# Intel documents that all x87 instructions may cause a TSX abort
	# (it's not really a NOP, it can generate #NM/#MF)
	flags: tsx-impl-abort
END

# Code: Fstpnce_sti
INSTRUCTION: D9 D8+i | FSTPNCE ST(i) | FPU
	ops: w=opcode
	implied: r=st0
	rflags: w=1 u=023
	flags: fpu-pop=1 tsx-impl-abort
	fast: mnemonic=fstp
	gas: mnemonic=fstp
	intel: add-st2
	masm: mnemonic=fstp
END

# Code: Fchs
INSTRUCTION: D9 E0 | FCHS | FPU
	implied: rw=st0
	rflags: 0=1 u=023
	flags: tsx-impl-abort
END

# Code: Fabs
INSTRUCTION: D9 E1 | FABS | FPU
	implied: rw=st0
	rflags: 0=1 u=023
	flags: tsx-impl-abort
END

# Code: Ftst
INSTRUCTION: D9 E4 | FTST | FPU
	implied: r=st0
	rflags: 0=1 w=023
	flags: tsx-impl-abort
END

# Code: Fxam
INSTRUCTION: D9 E5 | FXAM | FPU
	implied: r=st0
	rflags: w=0123
	flags: tsx-impl-abort
END

# Code: Fld1
INSTRUCTION: D9 E8 | FLD1 | FPU
	rflags: w=1 u=023
	flags: fpu-push=1 tsx-impl-abort
END

# Code: Fldl2t
INSTRUCTION: D9 E9 | FLDL2T | FPU
	rflags: w=1 u=023
	flags: fpu-push=1 tsx-impl-abort
END

# Code: Fldl2e
INSTRUCTION: D9 EA | FLDL2E | FPU
	rflags: w=1 u=023
	flags: fpu-push=1 tsx-impl-abort
END

# Code: Fldpi
INSTRUCTION: D9 EB | FLDPI | FPU
	rflags: w=1 u=023
	flags: fpu-push=1 tsx-impl-abort
END

# Code: Fldlg2
INSTRUCTION: D9 EC | FLDLG2 | FPU
	rflags: w=1 u=023
	flags: fpu-push=1 tsx-impl-abort
END

# Code: Fldln2
INSTRUCTION: D9 ED | FLDLN2 | FPU
	rflags: w=1 u=023
	flags: fpu-push=1 tsx-impl-abort
END

# Code: Fldz
INSTRUCTION: D9 EE | FLDZ | FPU
	rflags: w=1 u=023
	flags: fpu-push=1 tsx-impl-abort
END

# Code: F2xm1
INSTRUCTION: D9 F0 | F2XM1 | FPU
	implied: rw=st0
	rflags: w=1 u=023
	flags: tsx-impl-abort
END

# Code: Fyl2x
INSTRUCTION: D9 F1 | FYL2X | FPU
	implied: r=st0 rw=st1
	rflags: w=1 u=023
	flags: fpu-pop=1 tsx-impl-abort
END

# Code: Fptan
INSTRUCTION: D9 F2 | FPTAN | FPU
	implied: rcw=st0
	rflags: w=12 u=03
	flags: fpu-cond-push=1 tsx-impl-abort
END

# Code: Fpatan
INSTRUCTION: D9 F3 | FPATAN | FPU
	implied: r=st0 rw=st1
	rflags: w=1 u=023
	flags: fpu-pop=1 tsx-impl-abort
END

# Code: Fxtract
INSTRUCTION: D9 F4 | FXTRACT | FPU
	implied: rw=st0
	rflags: w=1 u=023
	flags: fpu-push=1 tsx-impl-abort
END

# Code: Fprem1
INSTRUCTION: D9 F5 | FPREM1 | FPU387
	implied: rw=st0 r=st1
	rflags: w=0123
	flags: tsx-impl-abort
END

# Code: Fdecstp
INSTRUCTION: D9 F6 | FDECSTP | FPU
	rflags: 0=1 u=023
	flags: fpu-stack=-1 tsx-impl-abort
END

# Code: Fincstp
INSTRUCTION: D9 F7 | FINCSTP | FPU
	rflags: 0=1 u=023
	flags: fpu-stack=1 tsx-impl-abort
END

# Code: Fprem
INSTRUCTION: D9 F8 | FPREM | FPU
	implied: rw=st0 r=st1
	rflags: w=0123
	flags: tsx-impl-abort
END

# Code: Fyl2xp1
INSTRUCTION: D9 F9 | FYL2XP1 | FPU
	implied: r=st0 rw=st1
	rflags: w=1 u=023
	flags: fpu-pop=1 tsx-impl-abort
END

# Code: Fsqrt
INSTRUCTION: D9 FA | FSQRT | FPU
	implied: rw=st0
	rflags: w=1 u=023
	flags: tsx-impl-abort
END

# Code: Fsincos
INSTRUCTION: D9 FB | FSINCOS | FPU387
	implied: rcw=st0
	rflags: w=12 u=03
	flags: fpu-cond-push=1 tsx-impl-abort
END

# Code: Frndint
INSTRUCTION: D9 FC | FRNDINT | FPU
	implied: rw=st0
	rflags: w=1 u=023
	flags: tsx-impl-abort
END

# Code: Fscale
INSTRUCTION: D9 FD | FSCALE | FPU
	implied: rw=st0 r=st1
	rflags: w=1 u=023
	flags: tsx-impl-abort
END

# Code: Fsin
INSTRUCTION: D9 FE | FSIN | FPU387
	implied: rcw=st0
	rflags: w=12 u=03
	flags: tsx-impl-abort
END

# Code: Fcos
INSTRUCTION: D9 FF | FCOS | FPU387
	implied: rcw=st0
	rflags: w=12 u=03
	flags: tsx-impl-abort
END

# Code: Fiadd_m32int
INSTRUCTION: DA /0 | FIADD m32int | FPU
	ops: r=rm | Int32
	implied: rw=st0
	code-memory-size-suffix: int
	rflags: w=1 u=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=l
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fimul_m32int
INSTRUCTION: DA /1 | FIMUL m32int | FPU
	ops: r=rm | Int32
	implied: rw=st0
	code-memory-size-suffix: int
	rflags: w=1 u=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=l
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Ficom_m32int
INSTRUCTION: DA /2 | FICOM m32int | FPU
	ops: r=rm | Int32
	implied: r=st0
	code-memory-size-suffix: int
	rflags: 0=1 w=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=l
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Ficomp_m32int
INSTRUCTION: DA /3 | FICOMP m32int | FPU
	ops: r=rm | Int32
	implied: r=st0
	code-memory-size-suffix: int
	rflags: 0=1 w=023
	flags: fpu-pop=1 tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=l
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fisub_m32int
INSTRUCTION: DA /4 | FISUB m32int | FPU
	ops: r=rm | Int32
	implied: rw=st0
	code-memory-size-suffix: int
	rflags: w=1 u=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=l
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fisubr_m32int
INSTRUCTION: DA /5 | FISUBR m32int | FPU
	ops: r=rm | Int32
	implied: rw=st0
	code-memory-size-suffix: int
	rflags: w=1 u=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=l
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fidiv_m32int
INSTRUCTION: DA /6 | FIDIV m32int | FPU
	ops: r=rm | Int32
	implied: rw=st0
	code-memory-size-suffix: int
	rflags: w=1 u=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=l
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fidivr_m32int
INSTRUCTION: DA /7 | FIDIVR m32int | FPU
	ops: r=rm | Int32
	implied: rw=st0
	code-memory-size-suffix: int
	rflags: w=1 u=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=l
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fcmovb_st0_sti
INSTRUCTION: DA C0+i | FCMOVB ST(0), ST(i) | FPU CMOV
	ops: cw=r:st0 cr=opcode
	rflags: r=c 0=1 u=023
	flags: tsx-impl-abort
	gas: st1
	intel: st1
	masm: st1
	nasm: st1
END

# Code: Fcmove_st0_sti
INSTRUCTION: DA C8+i | FCMOVE ST(0), ST(i) | FPU CMOV
	ops: cw=r:st0 cr=opcode
	rflags: r=z 0=1 u=023
	flags: tsx-impl-abort
	gas: st1
	intel: st1
	masm: st1
	nasm: st1
END

# Code: Fcmovbe_st0_sti
INSTRUCTION: DA D0+i | FCMOVBE ST(0), ST(i) | FPU CMOV
	ops: cw=r:st0 cr=opcode
	rflags: r=zc 0=1 u=023
	flags: tsx-impl-abort
	gas: st1
	intel: st1
	masm: st1
	nasm: st1
END

# Code: Fcmovu_st0_sti
INSTRUCTION: DA D8+i | FCMOVU ST(0), ST(i) | FPU CMOV
	ops: cw=r:st0 cr=opcode
	rflags: r=p 0=1 u=023
	flags: tsx-impl-abort
	gas: st1
	intel: st1
	masm: st1
	nasm: st1
END

# Code: Fucompp
INSTRUCTION: DA E9 | FUCOMPP | FPU387
	implied: r=st0;st1
	rflags: 0=1 w=023
	flags: fpu-pop=2 tsx-impl-abort
END

# Code: Fild_m32int
INSTRUCTION: DB /0 | FILD m32int | FPU
	ops: r=rm | Int32
	code-memory-size-suffix: int
	rflags: w=1 u=023
	flags: fpu-push=1 tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=l
	intel: flags=force-size=always add-st1 load
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fisttp_m32int
INSTRUCTION: DB /1 | FISTTP m32int | FPU SSE3
	ops: w=rm | Int32
	implied: r=st0
	code-memory-size-suffix: int
	rflags: 0=1 u=023
	flags: fpu-pop=1 tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=l
	intel: flags=force-size=always add-st2
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fist_m32int
INSTRUCTION: DB /2 | FIST m32int | FPU
	ops: w=rm | Int32
	implied: r=st0
	code-memory-size-suffix: int
	rflags: w=1 u=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=l
	intel: flags=force-size=always add-st2
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fistp_m32int
INSTRUCTION: DB /3 | FISTP m32int | FPU
	ops: w=rm | Int32
	implied: r=st0
	code-memory-size-suffix: int
	rflags: w=1 u=023
	flags: fpu-pop=1 tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=l
	intel: flags=force-size=always add-st2
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fld_m80fp
INSTRUCTION: DB /5 | FLD m80fp | FPU
	ops: r=rm | Float80
	code-memory-size-suffix: fp
	rflags: w=1 u=023
	flags: fpu-push=1 tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=t
	intel: flags=force-size=always add-st1 load
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fstp_m80fp
INSTRUCTION: DB /7 | FSTP m80fp | FPU
	ops: w=rm | Float80
	implied: r=st0
	code-memory-size-suffix: fp
	rflags: w=1 u=023
	flags: fpu-pop=1 tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=t
	intel: flags=force-size=always add-st2
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fcmovnb_st0_sti
INSTRUCTION: DB C0+i | FCMOVNB ST(0), ST(i) | FPU CMOV
	ops: cw=r:st0 cr=opcode
	rflags: r=c 0=1 u=023
	flags: tsx-impl-abort
	gas: st1
	intel: st1
	masm: st1
	nasm: st1
END

# Code: Fcmovne_st0_sti
INSTRUCTION: DB C8+i | FCMOVNE ST(0), ST(i) | FPU CMOV
	ops: cw=r:st0 cr=opcode
	rflags: r=z 0=1 u=023
	flags: tsx-impl-abort
	gas: st1
	intel: st1
	masm: st1
	nasm: st1
END

# Code: Fcmovnbe_st0_sti
INSTRUCTION: DB D0+i | FCMOVNBE ST(0), ST(i) | FPU CMOV
	ops: cw=r:st0 cr=opcode
	rflags: r=zc 0=1 u=023
	flags: tsx-impl-abort
	gas: st1
	intel: st1
	masm: st1
	nasm: st1
END

# Code: Fcmovnu_st0_sti
INSTRUCTION: DB D8+i | FCMOVNU ST(0), ST(i) | FPU CMOV
	ops: cw=r:st0 cr=opcode
	rflags: r=p 0=1 u=023
	flags: tsx-impl-abort
	gas: st1
	intel: st1
	masm: st1
	nasm: st1
END

# Code: Fneni
INSTRUCTION: DB E0 | FNENI | FPU
	# c0,c1,c2,c3 == not updated
	flags: tsx-impl-abort no-wait
END

# Code: Feni
INSTRUCTION: 9B DB E0 | FENI | FPU
	# c0,c1,c2,c3 == not updated
	flags: tsx-impl-abort
END

# Code: Fndisi
INSTRUCTION: DB E1 | FNDISI | FPU
	# c0,c1,c2,c3 == not updated
	flags: tsx-impl-abort no-wait
END

# Code: Fdisi
INSTRUCTION: 9B DB E1 | FDISI | FPU
	# c0,c1,c2,c3 == not updated
	flags: tsx-impl-abort
END

# Code: Fnclex
INSTRUCTION: DB E2 | FNCLEX | FPU
	rflags: u=0123
	flags: tsx-impl-abort no-wait
END

# Code: Fclex
INSTRUCTION: 9B DB E2 | FCLEX | FPU
	rflags: u=0123
	flags: tsx-impl-abort
END

# Code: Fninit
INSTRUCTION: DB E3 | FNINIT | FPU
	rflags: 0=0123
	flags: writes-fpu-top tsx-impl-abort no-wait
END

# Code: Finit
INSTRUCTION: 9B DB E3 | FINIT | FPU
	rflags: 0=0123
	flags: writes-fpu-top tsx-impl-abort
END

# Code: Fnsetpm
INSTRUCTION: DB E4 | FNSETPM | FPU287
	# c0,c1,c2,c3 == not updated
	flags: tsx-impl-abort no-wait
END

# Code: Fsetpm
INSTRUCTION: 9B DB E4 | FSETPM | FPU287
	# c0,c1,c2,c3 == not updated
	flags: tsx-impl-abort
END

# Code: Frstpm
INSTRUCTION: DB E5 | FRSTPM | FPU287XL_ONLY
	#TODO: assume c0,c1,c2,c3 == undefined
	rflags: u=0123
	flags: 16 32 dec-opt=OldFpu tsx-impl-abort
END

# Code: Fucomi_st0_sti
INSTRUCTION: DB E8+i | FUCOMI ST, ST(i) | FPU CMOV
	ops: r=r:st0 r=opcode
	rflags: w=zcp 0=osa 0=1
	flags: tsx-impl-abort
	gas: st1
	intel: st1
	masm: st1
	nasm: st1
END

# Code: Fcomi_st0_sti
INSTRUCTION: DB F0+i | FCOMI ST, ST(i) | FPU CMOV
	ops: r=r:st0 r=opcode
	rflags: w=zcp 0=osa 0=1
	flags: tsx-impl-abort
	gas: st1
	intel: st1
	masm: st1
	nasm: st1
END

# Code: Fadd_m64fp
INSTRUCTION: DC /0 | FADD m64fp | FPU
	ops: r=rm | Float64
	implied: rw=st0
	code-memory-size-suffix: fp
	rflags: w=1 u=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=l
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fmul_m64fp
INSTRUCTION: DC /1 | FMUL m64fp | FPU
	ops: r=rm | Float64
	implied: rw=st0
	code-memory-size-suffix: fp
	rflags: w=1 u=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=l
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fcom_m64fp
INSTRUCTION: DC /2 | FCOM m64fp | FPU
	ops: r=rm | Float64
	implied: r=st0
	code-memory-size-suffix: fp
	rflags: 0=1 w=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=l
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fcomp_m64fp
INSTRUCTION: DC /3 | FCOMP m64fp | FPU
	ops: r=rm | Float64
	implied: r=st0
	code-memory-size-suffix: fp
	rflags: 0=1 w=023
	flags: fpu-pop=1 tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=l
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fsub_m64fp
INSTRUCTION: DC /4 | FSUB m64fp | FPU
	ops: r=rm | Float64
	implied: rw=st0
	code-memory-size-suffix: fp
	rflags: w=1 u=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=l
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fsubr_m64fp
INSTRUCTION: DC /5 | FSUBR m64fp | FPU
	ops: r=rm | Float64
	implied: rw=st0
	code-memory-size-suffix: fp
	rflags: w=1 u=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=l
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fdiv_m64fp
INSTRUCTION: DC /6 | FDIV m64fp | FPU
	ops: r=rm | Float64
	implied: rw=st0
	code-memory-size-suffix: fp
	rflags: w=1 u=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=l
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fdivr_m64fp
INSTRUCTION: DC /7 | FDIVR m64fp | FPU
	ops: r=rm | Float64
	implied: rw=st0
	code-memory-size-suffix: fp
	rflags: w=1 u=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=l
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fadd_sti_st0
INSTRUCTION: DC C0+i | FADD ST(i), ST(0) | FPU
	ops: rw=opcode r=r:st0
	rflags: w=1 u=023
	flags: tsx-impl-abort
	gas: st2
	intel: st2
	masm: st2
	nasm: st2 to
END

# Code: Fmul_sti_st0
INSTRUCTION: DC C8+i | FMUL ST(i), ST(0) | FPU
	ops: rw=opcode r=r:st0
	rflags: w=1 u=023
	flags: tsx-impl-abort
	gas: st2
	intel: st2
	masm: st2
	nasm: st2 to
END

# Code: Fcom_st0_sti_DCD0
INSTRUCTION: DC D0+i | FCOM [ST(0)], ST(i) | FPU
	ops: r=r:st0 r=opcode
	code-suffix: DCD0
	rflags: 0=1 w=023
	flags: tsx-impl-abort asm-ig
	gas: st1-ignore-st1 pseudo
	intel: st1 pseudo
	masm: st1-ignore-st1 pseudo
	nasm: st1 pseudo
END

# Code: Fcomp_st0_sti_DCD8
INSTRUCTION: DC D8+i | FCOMP [ST(0)], ST(i) | FPU
	ops: r=r:st0 r=opcode
	code-suffix: DCD8
	rflags: 0=1 w=023
	flags: fpu-pop=1 tsx-impl-abort asm-ig
	gas: st1-ignore-st1 pseudo
	intel: st1 pseudo
	masm: st1-ignore-st1 pseudo
	nasm: st1 pseudo
END

# Code: Fsubr_sti_st0
INSTRUCTION: DC E0+i | FSUBR ST(i), ST(0) | FPU
	ops: rw=opcode r=r:st0
	gas: mnemonic=fsub st2
	rflags: w=1 u=023
	flags: tsx-impl-abort
	intel: st2
	masm: st2
	nasm: st2 to
END

# Code: Fsub_sti_st0
INSTRUCTION: DC E8+i | FSUB ST(i), ST(0) | FPU
	ops: rw=opcode r=r:st0
	gas: mnemonic=fsubr st2
	rflags: w=1 u=023
	flags: tsx-impl-abort
	intel: st2
	masm: st2
	nasm: st2 to
END

# Code: Fdivr_sti_st0
INSTRUCTION: DC F0+i | FDIVR ST(i), ST(0) | FPU
	ops: rw=opcode r=r:st0
	gas: mnemonic=fdiv st2
	rflags: w=1 u=023
	flags: tsx-impl-abort
	intel: st2
	masm: st2
	nasm: st2 to
END

# Code: Fdiv_sti_st0
INSTRUCTION: DC F8+i | FDIV ST(i), ST(0) | FPU
	ops: rw=opcode r=r:st0
	rflags: w=1 u=023
	flags: tsx-impl-abort
	gas: mnemonic=fdivr st2
	intel: st2
	masm: st2
	nasm: st2 to
END

# Code: Fld_m64fp
INSTRUCTION: DD /0 | FLD m64fp | FPU
	ops: r=rm | Float64
	code-memory-size-suffix: fp
	rflags: w=1 u=023
	flags: fpu-push=1 tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=l
	intel: flags=force-size=always add-st1 load
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fisttp_m64int
INSTRUCTION: DD /1 | FISTTP m64int | FPU SSE3
	ops: w=rm | Int64
	implied: r=st0
	code-memory-size-suffix: int
	rflags: 0=1 u=023
	flags: fpu-pop=1 tsx-impl-abort
	fast: flags=force-size=always
	gas: mnemonic=fisttpll
	intel: flags=force-size=always add-st2
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fst_m64fp
INSTRUCTION: DD /2 | FST m64fp | FPU
	ops: w=rm | Float64
	implied: r=st0
	code-memory-size-suffix: fp
	rflags: w=1 u=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=l
	intel: flags=force-size=always add-st2
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fstp_m64fp
INSTRUCTION: DD /3 | FSTP m64fp | FPU
	ops: w=rm | Float64
	implied: r=st0
	code-memory-size-suffix: fp
	rflags: w=1 u=023
	flags: fpu-pop=1 tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=l
	intel: flags=force-size=always add-st2
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Frstor_m94byte
INSTRUCTION: o16 DD /4 | FRSTOR m94byte | FPU
	ops: r=rm | FpuState94
	implied: w=st0-st7;mm0-mm7
	code-memory-size: 94byte
	rflags: w=0123
	flags: writes-fpu-top tsx-impl-abort
	fast: flags=force-size=always
	gas: suffix=s osz-mem-2
	intel: osz-mem-2 16
	masm: osz-mem-2 16
	nasm: flags=mem-size=ignore osz-mem-2
END

# Code: Frstor_m108byte
INSTRUCTION: o32 DD /4 | FRSTOR m108byte | FPU387
	ops: r=rm | FpuState108
	implied: w=st0-st7;mm0-mm7
	code-memory-size: 108byte
	rflags: w=0123
	flags: writes-fpu-top tsx-impl-abort
	fast: flags=force-size=always
	gas: suffix=l osz-mem-2
	intel: osz-mem-2
	masm: osz-mem-2
	nasm: flags=mem-size=ignore osz-mem-2
END

# Code: Fnsave_m94byte
INSTRUCTION: o16 DD /6 | FNSAVE m94byte | FPU
	ops: w=rm | FpuState94
	implied: r=st0-st7;mm0-mm7
	code-memory-size: 94byte
	rflags: r=0123 0=0123
	flags: writes-fpu-top tsx-impl-abort no-wait
	fast: flags=force-size=always
	gas: suffix=s osz-mem-2
	intel: osz-mem-2 16
	masm: osz-mem-2 16
	nasm: flags=mem-size=ignore osz-mem-2
END

# Code: Fsave_m94byte
INSTRUCTION: 9B o16 DD /6 | FSAVE m94byte | FPU
	ops: w=rm | FpuState94
	implied: r=st0-st7;mm0-mm7
	code-memory-size: 94byte
	rflags: r=0123 0=0123
	flags: writes-fpu-top tsx-impl-abort
	fast: flags=force-size=always
	gas: suffix=s osz-mem-2
	intel: osz-mem-2 16
	masm: osz-mem-2 16
	nasm: flags=mem-size=ignore osz-mem-2
END

# Code: Fnsave_m108byte
INSTRUCTION: o32 DD /6 | FNSAVE m108byte | FPU387
	ops: w=rm | FpuState108
	implied: r=st0-st7;mm0-mm7
	code-memory-size: 108byte
	rflags: r=0123 0=0123
	flags: writes-fpu-top tsx-impl-abort no-wait
	fast: flags=force-size=always
	gas: suffix=l osz-mem-2
	intel: osz-mem-2
	masm: osz-mem-2
	nasm: flags=mem-size=ignore osz-mem-2
END

# Code: Fsave_m108byte
INSTRUCTION: 9B o32 DD /6 | FSAVE m108byte | FPU387
	ops: w=rm | FpuState108
	implied: r=st0-st7;mm0-mm7
	code-memory-size: 108byte
	rflags: r=0123 0=0123
	flags: writes-fpu-top tsx-impl-abort
	fast: flags=force-size=always
	gas: suffix=l osz-mem-2
	intel: osz-mem-2
	masm: osz-mem-2
	nasm: flags=mem-size=ignore osz-mem-2
END

# Code: Fnstsw_m2byte
INSTRUCTION: DD /7 | FNSTSW m2byte | FPU
	ops: w=rm | UInt16
	code-memory-size: 2byte
	rflags: r=0123 u=0123
	flags: tsx-impl-abort no-wait
	gas: suffix=w
END

# Code: Fstsw_m2byte
INSTRUCTION: 9B DD /7 | FSTSW m2byte | FPU
	ops: w=rm | UInt16
	code-memory-size: 2byte
	rflags: r=0123 u=0123
	flags: tsx-impl-abort
	gas: suffix=w
END

# Code: Ffree_sti
INSTRUCTION: DD C0+i | FFREE ST(i) | FPU
	ops: n=opcode
	rflags: u=0123
	flags: tsx-impl-abort
END

# Code: Fxch_st0_sti_DDC8
INSTRUCTION: DD C8+i | FXCH [ST(0)], ST(i) | FPU
	ops: rw=r:st0 rw=opcode
	code-suffix: DDC8
	rflags: 0=1 u=023
	flags: tsx-impl-abort asm-ig
	gas: st1-ignore-st1 pseudo
	intel: st1 pseudo
	masm: st1-ignore-st1 pseudo
	nasm: st1 pseudo
END

# Code: Fst_sti
INSTRUCTION: DD D0+i | FST ST(i) | FPU
	ops: w=opcode
	implied: r=st0
	rflags: w=1 u=023
	flags: tsx-impl-abort
	intel: add-st2
END

# Code: Fstp_sti
INSTRUCTION: DD D8+i | FSTP ST(i) | FPU
	ops: w=opcode
	implied: r=st0
	rflags: w=1 u=023
	flags: fpu-pop=1 tsx-impl-abort
	intel: add-st2
END

# Code: Fucom_st0_sti
INSTRUCTION: DD E0+i | FUCOM [ST(0)], ST(i) | FPU
	ops: r=r:st0 r=opcode
	rflags: 0=1 w=023
	flags: tsx-impl-abort
	gas: st1-ignore-st1 pseudo
	intel: st1 pseudo
	masm: st1-ignore-st1 pseudo
	nasm: st1 pseudo
END

# Code: Fucomp_st0_sti
INSTRUCTION: DD E8+i | FUCOMP [ST(0)], ST(i) | FPU
	ops: r=r:st0 r=opcode
	rflags: 0=1 w=023
	flags: fpu-pop=1 tsx-impl-abort
	gas: st1-ignore-st1 pseudo
	intel: st1 pseudo
	masm: st1-ignore-st1 pseudo
	nasm: st1 pseudo
END

# Code: Fiadd_m16int
INSTRUCTION: DE /0 | FIADD m16int | FPU
	ops: r=rm | Int16
	implied: rw=st0
	code-memory-size-suffix: int
	rflags: w=1 u=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=s
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fimul_m16int
INSTRUCTION: DE /1 | FIMUL m16int | FPU
	ops: r=rm | Int16
	implied: rw=st0
	code-memory-size-suffix: int
	rflags: w=1 u=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=s
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Ficom_m16int
INSTRUCTION: DE /2 | FICOM m16int | FPU
	ops: r=rm | Int16
	implied: r=st0
	code-memory-size-suffix: int
	rflags: 0=1 w=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=s
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Ficomp_m16int
INSTRUCTION: DE /3 | FICOMP m16int | FPU
	ops: r=rm | Int16
	implied: r=st0
	code-memory-size-suffix: int
	rflags: 0=1 w=023
	flags: fpu-pop=1 tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=s
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fisub_m16int
INSTRUCTION: DE /4 | FISUB m16int | FPU
	ops: r=rm | Int16
	implied: rw=st0
	code-memory-size-suffix: int
	rflags: w=1 u=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=s
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fisubr_m16int
INSTRUCTION: DE /5 | FISUBR m16int | FPU
	ops: r=rm | Int16
	implied: rw=st0
	code-memory-size-suffix: int
	rflags: w=1 u=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=s
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fidiv_m16int
INSTRUCTION: DE /6 | FIDIV m16int | FPU
	ops: r=rm | Int16
	implied: rw=st0
	code-memory-size-suffix: int
	rflags: w=1 u=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=s
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fidivr_m16int
INSTRUCTION: DE /7 | FIDIVR m16int | FPU
	ops: r=rm | Int16
	implied: rw=st0
	code-memory-size-suffix: int
	rflags: w=1 u=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=s
	intel: flags=force-size=always add-st1
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Faddp_sti_st0
INSTRUCTION: DE C0+i | FADDP ST(i), ST(0) | FPU
	ops: rw=opcode r=r:st0
	rflags: w=1 u=023
	flags: fpu-pop=1 tsx-impl-abort
	gas: st2 pseudo
	intel: st2 pseudo
	masm: st2 pseudo
	nasm: st2 pseudo
END

# Code: Fmulp_sti_st0
INSTRUCTION: DE C8+i | FMULP ST(i), ST(0) | FPU
	ops: rw=opcode r=r:st0
	rflags: w=1 u=023
	flags: fpu-pop=1 tsx-impl-abort
	gas: st2 pseudo
	intel: st2 pseudo
	masm: st2 pseudo
	nasm: st2 pseudo
END

# Code: Fcomp_st0_sti_DED0
INSTRUCTION: DE D0+i | FCOMP [ST(0)], ST(i) | FPU
	ops: r=r:st0 r=opcode
	code-suffix: DED0
	rflags: 0=1 w=023
	flags: fpu-pop=1 tsx-impl-abort asm-ig
	gas: st1-ignore-st1 pseudo
	intel: st1 pseudo
	masm: st1-ignore-st1 pseudo
	nasm: st1 pseudo
END

# Code: Fcompp
INSTRUCTION: DE D9 | FCOMPP | FPU
	implied: r=st0;st1
	rflags: 0=1 w=023
	flags: fpu-pop=2 tsx-impl-abort
END

# Code: Fsubrp_sti_st0
INSTRUCTION: DE E0+i | FSUBRP ST(i), ST(0) | FPU
	ops: rw=opcode r=r:st0
	rflags: w=1 u=023
	flags: fpu-pop=1 tsx-impl-abort
	gas: mnemonic=fsubp st2 pseudo
	intel: st2 pseudo
	masm: st2 pseudo
	nasm: st2 pseudo
END

# Code: Fsubp_sti_st0
INSTRUCTION: DE E8+i | FSUBP ST(i), ST(0) | FPU
	ops: rw=opcode r=r:st0
	rflags: w=1 u=023
	flags: fpu-pop=1 tsx-impl-abort
	gas: mnemonic=fsubrp st2 pseudo
	intel: st2 pseudo
	masm: st2 pseudo
	nasm: st2 pseudo
END

# Code: Fdivrp_sti_st0
INSTRUCTION: DE F0+i | FDIVRP ST(i), ST(0) | FPU
	ops: rw=opcode r=r:st0
	rflags: w=1 u=023
	flags: fpu-pop=1 tsx-impl-abort
	gas: mnemonic=fdivp st2 pseudo
	intel: st2 pseudo
	masm: st2 pseudo
	nasm: st2 pseudo
END

# Code: Fdivp_sti_st0
INSTRUCTION: DE F8+i | FDIVP ST(i), ST(0) | FPU
	ops: rw=opcode r=r:st0
	rflags: w=1 u=023
	flags: fpu-pop=1 tsx-impl-abort
	gas: mnemonic=fdivrp st2 pseudo
	intel: st2 pseudo
	masm: st2 pseudo
	nasm: st2 pseudo
END

# Code: Fild_m16int
INSTRUCTION: DF /0 | FILD m16int | FPU
	ops: r=rm | Int16
	code-memory-size-suffix: int
	rflags: w=1 u=023
	flags: fpu-push=1 tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=s
	intel: flags=force-size=always add-st1 load
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fisttp_m16int
INSTRUCTION: DF /1 | FISTTP m16int | FPU SSE3
	ops: w=rm | Int16
	implied: r=st0
	code-memory-size-suffix: int
	rflags: 0=1 u=023
	flags: fpu-pop=1 tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=s
	intel: flags=force-size=always add-st2
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fist_m16int
INSTRUCTION: DF /2 | FIST m16int | FPU
	ops: w=rm | Int16
	implied: r=st0
	code-memory-size-suffix: int
	rflags: w=1 u=023
	flags: tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=s
	intel: flags=force-size=always add-st2
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fistp_m16int
INSTRUCTION: DF /3 | FISTP m16int | FPU
	ops: w=rm | Int16
	implied: r=st0
	code-memory-size-suffix: int
	rflags: w=1 u=023
	flags: fpu-pop=1 tsx-impl-abort
	fast: flags=force-size=always
	gas: flags=force-suffix suffix=s
	intel: flags=force-size=always add-st2
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fbld_m80bcd
INSTRUCTION: DF /4 | FBLD m80bcd | FPU
	ops: r=rm | Bcd
	code-memory-size-suffix: bcd
	rflags: w=1 u=023
	flags: fpu-push=1 tsx-impl-abort
	fast: flags=force-size=always
	intel: flags=force-size=default add-st1 load
	masm: flags=force-size=default
	nasm: flags=force-size=default
END

# Code: Fild_m64int
INSTRUCTION: DF /5 | FILD m64int | FPU
	ops: r=rm | Int64
	code-memory-size-suffix: int
	rflags: w=1 u=023
	flags: fpu-push=1 tsx-impl-abort
	fast: flags=force-size=always
	gas: mnemonic=fildll
	intel: flags=force-size=always add-st1 load
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Fbstp_m80bcd
INSTRUCTION: DF /6 | FBSTP m80bcd | FPU
	ops: w=rm | Bcd
	implied: r=st0
	code-memory-size-suffix: bcd
	rflags: w=1 u=023
	flags: fpu-pop=1 tsx-impl-abort
	fast: flags=force-size=always
	intel: flags=force-size=default add-st2
	masm: flags=force-size=default
	nasm: flags=force-size=default
END

# Code: Fistp_m64int
INSTRUCTION: DF /7 | FISTP m64int | FPU
	ops: w=rm | Int64
	implied: r=st0
	code-memory-size-suffix: int
	rflags: w=1 u=023
	flags: fpu-pop=1 tsx-impl-abort
	fast: flags=force-size=always
	gas: mnemonic=fistpll
	intel: flags=force-size=always add-st2
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Ffreep_sti
INSTRUCTION: DF C0+i | FFREEP ST(i) | FPU
	ops: n=opcode
	rflags: u=0123
	flags: fpu-pop=1 tsx-impl-abort
END

# Code: Fxch_st0_sti_DFC8
INSTRUCTION: DF C8+i | FXCH [ST(0)], ST(i) | FPU
	ops: rw=r:st0 rw=opcode
	code-suffix: DFC8
	rflags: 0=1 u=023
	flags: tsx-impl-abort asm-ig
	gas: st1-ignore-st1 pseudo
	intel: st1 pseudo
	masm: st1-ignore-st1 pseudo
	nasm: st1 pseudo
END

# Code: Fstp_sti_DFD0
INSTRUCTION: DF D0+i | FSTP ST(i) | FPU
	ops: w=opcode
	implied: r=st0
	code-suffix: DFD0
	rflags: w=1 u=023
	flags: fpu-pop=1 tsx-impl-abort asm-ig
	intel: add-st2
END

# Code: Fstp_sti_DFD8
INSTRUCTION: DF D8+i | FSTP ST(i) | FPU
	ops: w=opcode
	implied: r=st0
	code-suffix: DFD8
	rflags: w=1 u=023
	flags: fpu-pop=1 tsx-impl-abort asm-ig
	intel: add-st2
END

# Code: Fnstsw_AX
INSTRUCTION: DF E0 | FNSTSW AX | FPU287
	ops: w=r:ax
	rflags: r=0123 u=0123
	flags: tsx-impl-abort no-wait
END

# Code: Fstsw_AX
INSTRUCTION: 9B DF E0 | FSTSW AX | FPU287
	ops: w=r:ax
	rflags: r=0123 u=0123
	flags: tsx-impl-abort
END

# Code: Fstdw_AX
INSTRUCTION: 9B DF E1 | FSTDW AX | FPU387SL_ONLY
	ops: w=r:ax
	#TODO: assume c0,c1,c2,c3 == undefined
	rflags: u=0123
	flags: 16 32 dec-opt=OldFpu tsx-impl-abort
END

# Code: Fstsg_AX
INSTRUCTION: 9B DF E2 | FSTSG AX | FPU387SL_ONLY
	ops: w=r:ax
	#TODO: assume c0,c1,c2,c3 == undefined
	rflags: u=0123
	flags: 16 32 dec-opt=OldFpu tsx-impl-abort
END

# Code: Fucomip_st0_sti
INSTRUCTION: DF E8+i | FUCOMIP ST, ST(i) | FPU CMOV
	ops: r=r:st0 r=opcode
	rflags: w=zcp 0=osa 0=1
	flags: fpu-pop=1 tsx-impl-abort
	gas: st1
	intel: st1
	masm: st1
	nasm: st1
END

# Code: Fcomip_st0_sti
INSTRUCTION: DF F0+i | FCOMIP ST, ST(i) | FPU CMOV
	ops: r=r:st0 r=opcode
	rflags: w=zcp 0=osa 0=1
	flags: fpu-pop=1 tsx-impl-abort
	gas: st1
	intel: st1
	masm: st1
	nasm: st1
END

# Code: Loopne_rel8_16_CX
INSTRUCTION: a16 o16 E0 cb | LOOPNE rel8 | INTEL8086
	ops: r=br
	implied: rw=cx
	code-suffix: 16_CX
	rflags: r=z
	flags: 16 32 cc=loop;ne; br=loop cflow=br-cond
	gas: suffix=w loop
	intel: loop
	masm: loop2
	nasm: loop
END

# Code: Loopne_rel8_32_CX
INSTRUCTION: a16 o32 E0 cb | LOOPNE rel8 | INTEL386
	ops: r=br
	implied: rw=cx
	code-suffix: 32_CX
	rflags: r=z
	flags: 16 32 cc=loop;ne; br=loop cflow=br-cond asm-ig
	gas: suffix=w loop
	intel: loop
	masm: loop2
	nasm: loop
END

# Code: Loopne_rel8_16_ECX
INSTRUCTION: a32 o16 E0 cb | LOOPNE rel8 | INTEL386
	ops: r=br
	implied: rw=ecx
	code-suffix: 16_ECX
	rflags: r=z
	flags: cc=loop;ne; br=loop no-intel-dec64 cflow=br-cond asm-ig
	gas: suffix=l loop
	intel: loop
	masm: loop2
	nasm: loop
END

# Code: Loopne_rel8_32_ECX
INSTRUCTION: a32 o32 E0 cb | LOOPNE rel8 | INTEL386
	ops: r=br
	implied: rw=ecx
	code-suffix: 32_ECX
	rflags: r=z
	flags: 16 32 cc=loop;ne; br=loop cflow=br-cond
	gas: suffix=l loop
	intel: loop
	masm: loop2
	nasm: loop
END

# Code: Loopne_rel8_64_ECX
INSTRUCTION: a32 o64 E0 cb | LOOPNE rel8 | X64
	ops: r=br
	implied: rw=ecx
	code-suffix: 64_ECX
	rflags: r=z
	flags: 64 cc=loop;ne; br=loop cflow=br-cond intel-fo64 do64 asm-ig
	fast: mnemonic=loopned
	gas: suffix=l loop
	intel: loop
	masm: mnemonic=loopned loop1 d
	nasm: loop
END

# Code: Loopne_rel8_16_RCX
INSTRUCTION: a64 o16 E0 cb | LOOPNE rel8 | X64
	ops: r=br
	implied: rw=rcx
	code-suffix: 16_RCX
	rflags: r=z
	flags: 64 cc=loop;ne; br=loop cflow=br-cond no-intel-dec asm-ig
	gas: suffix=q loop
	intel: loop
	masm: loop1
	nasm: loop
END

# Code: Loopne_rel8_64_RCX
INSTRUCTION: a64 o64 E0 cb | LOOPNE rel8 | X64
	ops: r=br
	implied: rw=rcx
	code-suffix: 64_RCX
	rflags: r=z
	flags: 64 cc=loop;ne; br=loop cflow=br-cond intel-fo64 do64
	gas: suffix=q loop
	intel: loop
	masm: loop1
	nasm: loop
END

# Code: Loope_rel8_16_CX
INSTRUCTION: a16 o16 E1 cb | LOOPE rel8 | INTEL8086
	ops: r=br
	implied: rw=cx
	code-suffix: 16_CX
	rflags: r=z
	flags: 16 32 cc=loop;e; br=loop cflow=br-cond
	gas: suffix=w loop
	intel: loop
	masm: loop2
	nasm: loop
END

# Code: Loope_rel8_32_CX
INSTRUCTION: a16 o32 E1 cb | LOOPE rel8 | INTEL386
	ops: r=br
	implied: rw=cx
	code-suffix: 32_CX
	rflags: r=z
	flags: 16 32 cc=loop;e; br=loop cflow=br-cond asm-ig
	gas: suffix=w loop
	intel: loop
	masm: loop2
	nasm: loop
END

# Code: Loope_rel8_16_ECX
INSTRUCTION: a32 o16 E1 cb | LOOPE rel8 | INTEL386
	ops: r=br
	implied: rw=ecx
	code-suffix: 16_ECX
	rflags: r=z
	flags: cc=loop;e; br=loop cflow=br-cond no-intel-dec64 asm-ig
	gas: suffix=l loop
	intel: loop
	masm: loop2
	nasm: loop
END

# Code: Loope_rel8_32_ECX
INSTRUCTION: a32 o32 E1 cb | LOOPE rel8 | INTEL386
	ops: r=br
	implied: rw=ecx
	code-suffix: 32_ECX
	rflags: r=z
	flags: 16 32 cc=loop;e; br=loop cflow=br-cond
	gas: suffix=l loop
	intel: loop
	masm: loop2
	nasm: loop
END

# Code: Loope_rel8_64_ECX
INSTRUCTION: a32 o64 E1 cb | LOOPE rel8 | X64
	ops: r=br
	implied: rw=ecx
	code-suffix: 64_ECX
	rflags: r=z
	flags: 64 cc=loop;e; br=loop cflow=br-cond intel-fo64 do64 asm-ig
	fast: mnemonic=looped
	gas: suffix=l loop
	intel: loop
	masm: mnemonic=looped loop1 d
	nasm: loop
END

# Code: Loope_rel8_16_RCX
INSTRUCTION: a64 o16 E1 cb | LOOPE rel8 | X64
	ops: r=br
	implied: rw=rcx
	code-suffix: 16_RCX
	rflags: r=z
	flags: 64 cc=loop;e; br=loop cflow=br-cond no-intel-dec asm-ig
	gas: suffix=q loop
	intel: loop
	masm: loop1
	nasm: loop
END

# Code: Loope_rel8_64_RCX
INSTRUCTION: a64 o64 E1 cb | LOOPE rel8 | X64
	ops: r=br
	implied: rw=rcx
	code-suffix: 64_RCX
	rflags: r=z
	flags: 64 cc=loop;e; br=loop cflow=br-cond intel-fo64 do64
	gas: suffix=q loop
	intel: loop
	masm: loop1
	nasm: loop
END

# Code: Loop_rel8_16_CX
INSTRUCTION: a16 o16 E2 cb | LOOP rel8 | INTEL8086
	ops: r=br
	implied: rw=cx
	code-suffix: 16_CX
	flags: 16 32 br=loop cflow=br-cond
	gas: suffix=w loop
	intel: loop
	masm: osz-suffix-1-loop
	nasm: loop
END

# Code: Loop_rel8_32_CX
INSTRUCTION: a16 o32 E2 cb | LOOP rel8 | INTEL386
	ops: r=br
	implied: rw=cx
	code-suffix: 32_CX
	flags: 16 32 br=loop cflow=br-cond asm-ig
	gas: suffix=w loop
	intel: loop
	masm: osz-suffix-1-loop
	nasm: loop
END

# Code: Loop_rel8_16_ECX
INSTRUCTION: a32 o16 E2 cb | LOOP rel8 | INTEL386
	ops: r=br
	implied: rw=ecx
	code-suffix: 16_ECX
	flags: br=loop cflow=br-cond no-intel-dec64 asm-ig
	gas: suffix=l loop
	intel: loop
	masm: osz-suffix-1-loop
	nasm: loop
END

# Code: Loop_rel8_32_ECX
INSTRUCTION: a32 o32 E2 cb | LOOP rel8 | INTEL386
	ops: r=br
	implied: rw=ecx
	code-suffix: 32_ECX
	flags: 16 32 br=loop cflow=br-cond
	gas: suffix=l loop
	intel: loop
	masm: osz-suffix-1-loop
	nasm: loop
END

# Code: Loop_rel8_64_ECX
INSTRUCTION: a32 o64 E2 cb | LOOP rel8 | X64
	ops: r=br
	implied: rw=ecx
	code-suffix: 64_ECX
	flags: 64 br=loop cflow=br-cond intel-fo64 do64 asm-ig
	fast: mnemonic=loopd
	gas: suffix=l loop
	intel: loop
	masm: mnemonic=loopd
	nasm: loop
END

# Code: Loop_rel8_16_RCX
INSTRUCTION: a64 o16 E2 cb | LOOP rel8 | X64
	ops: r=br
	implied: rw=rcx
	code-suffix: 16_RCX
	flags: 64 br=loop cflow=br-cond no-intel-dec asm-ig
	gas: suffix=q loop
	intel: loop
	nasm: loop
END

# Code: Loop_rel8_64_RCX
INSTRUCTION: a64 o64 E2 cb | LOOP rel8 | X64
	ops: r=br
	implied: rw=rcx
	code-suffix: 64_RCX
	flags: 64 br=loop cflow=br-cond intel-fo64 do64
	gas: suffix=q loop
	intel: loop
	nasm: loop
END

# Code: Jcxz_rel8_16
INSTRUCTION: a16 o16 E3 cb | JCXZ rel8 | INTEL8086
	ops: r=br
	implied: r=cx
	code-suffix: 16
	flags: 16 32 br=jrcxz cflow=br-cond
	gas: flags=osz-is-byte-directive osz
	intel: osz
	nasm: osz
END

# Code: Jcxz_rel8_32
INSTRUCTION: a16 o32 E3 cb | JCXZ rel8 | INTEL386
	ops: r=br
	implied: r=cx
	code-suffix: 32
	flags: 16 32 br=jrcxz cflow=br-cond asm-ig
	gas: flags=osz-is-byte-directive osz
	intel: osz
	nasm: osz
END

# Code: Jecxz_rel8_16
INSTRUCTION: a32 o16 E3 cb | JECXZ rel8 | INTEL386
	ops: r=br
	implied: r=ecx
	code-suffix: 16
	flags: br=jrcxz cflow=br-cond no-intel-dec64 asm-ig
	gas: flags=osz-is-byte-directive osz
	intel: osz
	nasm: osz
END

# Code: Jecxz_rel8_32
INSTRUCTION: a32 o32 E3 cb | JECXZ rel8 | INTEL386
	ops: r=br
	implied: r=ecx
	code-suffix: 32
	flags: 16 32 br=jrcxz cflow=br-cond
	gas: flags=osz-is-byte-directive osz
	intel: osz
	nasm: osz
END

# Code: Jecxz_rel8_64
INSTRUCTION: a32 o64 E3 cb | JECXZ rel8 | X64
	ops: r=br
	implied: r=ecx
	code-suffix: 64
	flags: 64 br=jrcxz cflow=br-cond intel-fo64 do64 asm-ig
	gas: osz
	intel: osz
	nasm: osz
END

# Code: Jrcxz_rel8_16
INSTRUCTION: a64 o16 E3 cb | JRCXZ rel8 | X64
	ops: r=br
	implied: r=rcx
	code-suffix: 16
	flags: 64 br=jrcxz cflow=br-cond no-intel-dec asm-ig
	gas: flags=osz-is-byte-directive osz
	intel: osz
	nasm: osz
END

# Code: Jrcxz_rel8_64
INSTRUCTION: a64 o64 E3 cb | JRCXZ rel8 | X64
	ops: r=br
	implied: r=rcx
	code-suffix: 64
	flags: 64 br=jrcxz cflow=br-cond intel-fo64 do64
	gas: osz
	intel: osz
	nasm: osz
END

# Code: In_AL_imm8
INSTRUCTION: E4 ib | IN AL, imm8 | INTEL8086
	ops: w=r:al r=imm
	flags: io privileged intel-may-vm-exit no-in-sgx tdx-non-root-ve amd-may-vm-exit tsx-impl-abort
	gas: suffix=b
END

# Code: In_AX_imm8
INSTRUCTION: o16 E5 ib | IN AX, imm8 | INTEL8086
	ops: w=r:ax r=imm
	flags: io privileged intel-may-vm-exit no-in-sgx tdx-non-root-ve amd-may-vm-exit tsx-impl-abort
	gas: suffix=w
END

# Code: In_EAX_imm8
INSTRUCTION: o32 E5 ib | IN EAX, imm8 | INTEL386
	ops: w=r:eax r=imm
	flags: io privileged intel-may-vm-exit no-in-sgx tdx-non-root-ve amd-may-vm-exit tsx-impl-abort
	gas: suffix=l
END

# Code: Out_imm8_AL
INSTRUCTION: E6 ib | OUT imm8, AL | INTEL8086
	ops: r=imm r=r:al
	flags: io privileged intel-may-vm-exit no-in-sgx tdx-non-root-ve amd-may-vm-exit tsx-impl-abort
	gas: suffix=b
END

# Code: Out_imm8_AX
INSTRUCTION: o16 E7 ib | OUT imm8, AX | INTEL8086
	ops: r=imm r=r:ax
	flags: io privileged intel-may-vm-exit no-in-sgx tdx-non-root-ve amd-may-vm-exit tsx-impl-abort
	gas: suffix=w
END

# Code: Out_imm8_EAX
INSTRUCTION: o32 E7 ib | OUT imm8, EAX | INTEL386
	ops: r=imm r=r:eax
	flags: io privileged intel-may-vm-exit no-in-sgx tdx-non-root-ve amd-may-vm-exit tsx-impl-abort
	gas: suffix=l
END

# Code: Call_rel16
INSTRUCTION: o16 E8 cw | CALL rel16 | INTEL8086
	ops: r=br
	implied: push=1x2
	flags: sp=push;2 br=call-near cflow=call bnd no-intel-dec64
	gas: suffix=w osz-suffix-4
	intel: osz-bnd
	masm: bnd
	nasm: osz-call
END

# Code: Call_rel32_32
INSTRUCTION: o32 E8 cd | CALL rel32 | INTEL386
	ops: r=br
	implied: push=1x4
	code-suffix: 32
	flags: 16 32 sp=push;4 br=call-near cflow=call bnd
	gas: suffix=l osz-suffix-4
	intel: osz-bnd
	masm: bnd
	nasm: osz-call
END

# Code: Call_rel32_64
INSTRUCTION: o64 E8 cd | CALL rel32 | X64
	ops: r=br
	implied: push=1x8
	code-suffix: 64
	flags: 64 sp=push;8 br=call-near cflow=call bnd intel-fo64 do64
	gas: suffix=q osz-suffix-4
	intel: osz-bnd
	masm: bnd
	nasm: osz-call
END

# Code: Jmp_rel16
INSTRUCTION: o16 E9 cw | JMP rel16 | INTEL8086
	ops: r=br
	flags: br=jmp-near cflow=br bnd no-intel-dec64
	gas: osz
	intel: osz-bnd
	masm: bnd
	nasm: osz-call
END

# Code: Jmp_rel32_32
INSTRUCTION: o32 E9 cd | JMP rel32 | INTEL386
	ops: r=br
	code-suffix: 32
	flags: 16 32 br=jmp-near cflow=br bnd
	gas: osz
	intel: osz-bnd
	masm: bnd
	nasm: osz-call
END

# Code: Jmp_rel32_64
INSTRUCTION: o64 E9 cd | JMP rel32 | X64
	ops: r=br
	code-suffix: 64
	flags: 64 br=jmp-near cflow=br bnd intel-fo64 do64
	gas: osz
	intel: osz-bnd
	masm: bnd
	nasm: osz-call
END

# Code: Jmp_ptr1616
INSTRUCTION: o16 EA cd | JMP ptr16:16 | INTEL8086
	ops: r=br-far
	# VM exit if task switch
	flags: 16 32 br=jmp-far cflow=br intel-may-vm-exit no-in-sgx amd-may-vm-exit tsx-impl-abort asm-ig
	gas: mnemonic=ljmp suffix=w osz-suffix-4
	intel: flags=far osz
	nasm: far
END

# Code: Jmp_ptr1632
INSTRUCTION: o32 EA cp | JMP ptr16:32 | INTEL386
	ops: r=br-far
	# VM exit if task switch
	flags: 16 32 br=jmp-far cflow=br intel-may-vm-exit no-in-sgx amd-may-vm-exit tsx-impl-abort asm-ig
	gas: mnemonic=ljmp suffix=l osz-suffix-4
	intel: flags=far osz
	nasm: far
END

# Code: Jmp_rel8_16
INSTRUCTION: o16 EB cb | JMP rel8 | INTEL8086
	ops: r=br
	code-suffix: 16
	flags: br=jmp-short cflow=br no-intel-dec64
	gas: osz
	intel: flags=short osz
	nasm: flags=short osz
END

# Code: Jmp_rel8_32
INSTRUCTION: o32 EB cb | JMP rel8 | INTEL386
	ops: r=br
	code-suffix: 32
	flags: 16 32 br=jmp-short cflow=br
	gas: osz
	intel: flags=short osz
	nasm: flags=short osz
END

# Code: Jmp_rel8_64
INSTRUCTION: o64 EB cb | JMP rel8 | X64
	ops: r=br
	code-suffix: 64
	flags: 64 br=jmp-short cflow=br intel-fo64 do64
	gas: osz
	intel: flags=short osz
	nasm: flags=short osz
END

# Code: In_AL_DX
INSTRUCTION: EC | IN AL, DX | INTEL8086
	ops: w=r:al r=r:dx
	flags: io privileged intel-may-vm-exit no-in-sgx tdx-non-root-ve amd-may-vm-exit tsx-impl-abort
	gas: suffix=b
END

# Code: In_AX_DX
INSTRUCTION: o16 ED | IN AX, DX | INTEL8086
	ops: w=r:ax r=r:dx
	flags: io privileged intel-may-vm-exit no-in-sgx tdx-non-root-ve amd-may-vm-exit tsx-impl-abort
	gas: suffix=w
END

# Code: In_EAX_DX
INSTRUCTION: o32 ED | IN EAX, DX | INTEL386
	ops: w=r:eax r=r:dx
	flags: io privileged intel-may-vm-exit no-in-sgx tdx-non-root-ve amd-may-vm-exit tsx-impl-abort
	gas: suffix=l
END

# Code: Out_DX_AL
INSTRUCTION: EE | OUT DX, AL | INTEL8086
	ops: r=r:dx r=r:al
	flags: io privileged intel-may-vm-exit no-in-sgx tdx-non-root-ve amd-may-vm-exit tsx-impl-abort
	gas: suffix=b
END

# Code: Out_DX_AX
INSTRUCTION: o16 EF | OUT DX, AX | INTEL8086
	ops: r=r:dx r=r:ax
	flags: io privileged intel-may-vm-exit no-in-sgx tdx-non-root-ve amd-may-vm-exit tsx-impl-abort
	gas: suffix=w
END

# Code: Out_DX_EAX
INSTRUCTION: o32 EF | OUT DX, EAX | INTEL386
	ops: r=r:dx r=r:eax
	flags: io privileged intel-may-vm-exit no-in-sgx tdx-non-root-ve amd-may-vm-exit tsx-impl-abort
	gas: suffix=l
END

# Code: Int1
INSTRUCTION: F1 | INT1 | INTEL386
	# #DB always causes transactional aborts
	flags: cflow=int intel-vm-exit amd-may-vm-exit tsx-abort
END

# Code: Hlt
INSTRUCTION: F4 | HLT | INTEL8086
	flags: cpl0 intel-may-vm-exit tdx-non-root-ve amd-may-vm-exit tsx-impl-abort
END

# Code: Cmc
INSTRUCTION: F5 | CMC | INTEL8086
	rflags: r=c w=c
END

# Code: Test_rm8_imm8
INSTRUCTION: F6 /0 ib | TEST r/m8, imm8 | INTEL8086
	ops: r=rm r=imm | UInt8
	rflags: u=a w=szp 0=oc
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Test_rm8_imm8_F6r1
INSTRUCTION: F6 /1 ib | TEST r/m8, imm8 | INTEL8086
	ops: r=rm r=imm | UInt8
	code-suffix: F6r1
	rflags: u=a w=szp 0=oc
	flags: asm-ig
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Not_rm8
INSTRUCTION: F6 /2 | NOT r/m8 | INTEL8086
	ops: rw=rm | UInt8
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Neg_rm8
INSTRUCTION: F6 /3 | NEG r/m8 | INTEL8086
	ops: rw=rm | Int8
	rflags: w=oszacp
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Mul_rm8
INSTRUCTION: F6 /4 | MUL r/m8 | INTEL8086
	ops: r=rm | UInt8
	implied: r=al w=ax
	rflags: u=szap w=oc
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Imul_rm8
INSTRUCTION: F6 /5 | IMUL r/m8 | INTEL8086
	ops: r=rm | Int8
	implied: r=al w=ax
	rflags: u=szap w=oc
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Div_rm8
INSTRUCTION: F6 /6 | DIV r/m8 | INTEL8086
	ops: r=rm | UInt8
	implied: rw=ax
	rflags: u=oszacp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Idiv_rm8
INSTRUCTION: F6 /7 | IDIV r/m8 | INTEL8086
	ops: r=rm | Int8
	implied: rw=ax
	rflags: u=oszacp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Test_rm16_imm16
INSTRUCTION: o16 F7 /0 iw | TEST r/m16, imm16 | INTEL8086
	ops: r=rm r=imm | UInt16
	rflags: u=a w=szp 0=oc
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Test_rm32_imm32
INSTRUCTION: o32 F7 /0 id | TEST r/m32, imm32 | INTEL386
	ops: r=rm r=imm | UInt32
	rflags: u=a w=szp 0=oc
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Test_rm64_imm32
INSTRUCTION: o64 F7 /0 id | TEST r/m64, imm32 | X64
	ops: r=rm r=imm;64 | UInt64
	rflags: u=a w=szp 0=oc
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always;no-sx sx
END

# Code: Test_rm16_imm16_F7r1
INSTRUCTION: o16 F7 /1 iw | TEST r/m16, imm16 | INTEL8086
	ops: r=rm r=imm | UInt16
	code-suffix: F7r1
	rflags: u=a w=szp 0=oc
	flags: asm-ig
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Test_rm32_imm32_F7r1
INSTRUCTION: o32 F7 /1 id | TEST r/m32, imm32 | INTEL386
	ops: r=rm r=imm | UInt32
	code-suffix: F7r1
	rflags: u=a w=szp 0=oc
	flags: asm-ig
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Test_rm64_imm32_F7r1
INSTRUCTION: o64 F7 /1 id | TEST r/m64, imm32 | X64
	ops: r=rm r=imm;64 | UInt64
	code-suffix: F7r1
	rflags: u=a w=szp 0=oc
	flags: 64 asm-ig
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always;no-sx sx
END

# Code: Not_rm16
INSTRUCTION: o16 F7 /2 | NOT r/m16 | INTEL8086
	ops: rw=rm | UInt16
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Not_rm32
INSTRUCTION: o32 F7 /2 | NOT r/m32 | INTEL386
	ops: rw=rm | UInt32
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Not_rm64
INSTRUCTION: o64 F7 /2 | NOT r/m64 | X64
	ops: rw=rm | UInt64
	flags: 64 lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Neg_rm16
INSTRUCTION: o16 F7 /3 | NEG r/m16 | INTEL8086
	ops: rw=rm | Int16
	rflags: w=oszacp
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Neg_rm32
INSTRUCTION: o32 F7 /3 | NEG r/m32 | INTEL386
	ops: rw=rm | Int32
	rflags: w=oszacp
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Neg_rm64
INSTRUCTION: o64 F7 /3 | NEG r/m64 | X64
	ops: rw=rm | Int64
	rflags: w=oszacp
	flags: 64 lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Mul_rm16
INSTRUCTION: o16 F7 /4 | MUL r/m16 | INTEL8086
	ops: r=rm | UInt16
	implied: rw=ax w=dx
	rflags: u=szap w=oc
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Mul_rm32
INSTRUCTION: o32 F7 /4 | MUL r/m32 | INTEL386
	ops: r=rm | UInt32
	implied: rw=eax w=edx
	rflags: u=szap w=oc
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Mul_rm64
INSTRUCTION: o64 F7 /4 | MUL r/m64 | X64
	ops: r=rm | UInt64
	implied: rw=rax w=rdx
	rflags: u=szap w=oc
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Imul_rm16
INSTRUCTION: o16 F7 /5 | IMUL r/m16 | INTEL8086
	ops: r=rm | Int16
	implied: rw=ax w=dx
	rflags: u=szap w=oc
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Imul_rm32
INSTRUCTION: o32 F7 /5 | IMUL r/m32 | INTEL386
	ops: r=rm | Int32
	implied: rw=eax w=edx
	rflags: u=szap w=oc
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Imul_rm64
INSTRUCTION: o64 F7 /5 | IMUL r/m64 | X64
	ops: r=rm | Int64
	implied: rw=rax w=rdx
	rflags: u=szap w=oc
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Div_rm16
INSTRUCTION: o16 F7 /6 | DIV r/m16 | INTEL8086
	ops: r=rm | UInt16
	implied: rw=ax;dx
	rflags: u=oszacp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Div_rm32
INSTRUCTION: o32 F7 /6 | DIV r/m32 | INTEL386
	ops: r=rm | UInt32
	implied: rw=eax;edx
	rflags: u=oszacp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Div_rm64
INSTRUCTION: o64 F7 /6 | DIV r/m64 | X64
	ops: r=rm | UInt64
	implied: rw=rax;rdx
	rflags: u=oszacp
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Idiv_rm16
INSTRUCTION: o16 F7 /7 | IDIV r/m16 | INTEL8086
	ops: r=rm | Int16
	implied: rw=ax;dx
	rflags: u=oszacp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Idiv_rm32
INSTRUCTION: o32 F7 /7 | IDIV r/m32 | INTEL386
	ops: r=rm | Int32
	implied: rw=eax;edx
	rflags: u=oszacp
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Idiv_rm64
INSTRUCTION: o64 F7 /7 | IDIV r/m64 | X64
	ops: r=rm | Int64
	implied: rw=rax;rdx
	rflags: u=oszacp
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Clc
INSTRUCTION: F8 | CLC | INTEL8086
	rflags: 0=c
END

# Code: Stc
INSTRUCTION: F9 | STC | INTEL8086
	rflags: 1=c
END

# Code: Cli
INSTRUCTION: FA | CLI | INTEL8086
	rflags: 0=i
	flags: privileged tsx-impl-abort
END

# Code: Sti
INSTRUCTION: FB | STI | INTEL8086
	rflags: 1=i
	flags: privileged tsx-impl-abort
END

# Code: Cld
INSTRUCTION: FC | CLD | INTEL8086
	rflags: 0=d
	flags: tsx-impl-abort
END

# Code: Std
INSTRUCTION: FD | STD | INTEL8086
	rflags: 1=d
	flags: tsx-impl-abort
END

# Code: Inc_rm8
INSTRUCTION: FE /0 | INC r/m8 | INTEL8086
	ops: rw=rm | UInt8
	rflags: w=oszap
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Dec_rm8
INSTRUCTION: FE /1 | DEC r/m8 | INTEL8086
	ops: rw=rm | UInt8
	rflags: w=oszap
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Inc_rm16
INSTRUCTION: o16 FF /0 | INC r/m16 | INTEL8086
	ops: rw=rm | UInt16
	rflags: w=oszap
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Inc_rm32
INSTRUCTION: o32 FF /0 | INC r/m32 | INTEL386
	ops: rw=rm | UInt32
	rflags: w=oszap
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Inc_rm64
INSTRUCTION: o64 FF /0 | INC r/m64 | X64
	ops: rw=rm | UInt64
	rflags: w=oszap
	flags: 64 lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Dec_rm16
INSTRUCTION: o16 FF /1 | DEC r/m16 | INTEL8086
	ops: rw=rm | UInt16
	rflags: w=oszap
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Dec_rm32
INSTRUCTION: o32 FF /1 | DEC r/m32 | INTEL386
	ops: rw=rm | UInt32
	rflags: w=oszap
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Dec_rm64
INSTRUCTION: o64 FF /1 | DEC r/m64 | X64
	ops: rw=rm | UInt64
	rflags: w=oszap
	flags: 64 lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Call_rm16
INSTRUCTION: o16 FF /2 | CALL r/m16 | INTEL8086
	ops: r=rm | WordOffset
	implied: push=1x2
	flags: sp=push;2 br=call-near-indirect cflow=call-ind bnd notrack cet-tracked no-intel-dec64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix;indirect suffix=w bnd
	intel: flags=force-size=always bnd
	masm: flags=force-size=always bnd
	nasm: flags=force-size=always bnd
END

# Code: Call_rm32
INSTRUCTION: o32 FF /2 | CALL r/m32 | INTEL386
	ops: r=rm | DwordOffset
	implied: push=1x4
	flags: 16 32 sp=push;4 br=call-near-indirect cflow=call-ind bnd notrack cet-tracked
	fast: flags=force-size=always
	gas: flags=force-mem-suffix;indirect suffix=l bnd
	intel: flags=force-size=always bnd
	masm: flags=force-size=always bnd
	nasm: flags=force-size=always bnd
END

# Code: Call_rm64
INSTRUCTION: o64 FF /2 | CALL r/m64 | X64
	ops: r=rm | QwordOffset
	implied: push=1x8
	flags: 64 sp=push;8 br=call-near-indirect cflow=call-ind bnd notrack cet-tracked intel-fo64 do64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix;indirect suffix=q bnd
	intel: flags=force-size=always bnd
	masm: flags=force-size=always bnd
	nasm: flags=force-size=always bnd
END

# Code: Call_m1616
INSTRUCTION: o16 FF /3 | CALL m16:16 | INTEL8086
	ops: r=rm | SegPtr16
	implied: push=2x2
	code-memory-size: 1616
	# VM exit if task switch
	flags: sp=push;4 br=call-far-indirect cflow=call-ind cet-tracked intel-may-vm-exit no-in-sgx amd-may-vm-exit tsx-impl-abort
	fast: mnemonic=callf flags=force-size=always
	gas: mnemonic=lcall suffix=w far
	intel: flags=force-size=always;far
	masm: flags=force-size=always
	nasm: far-mem
END

# Code: Call_m1632
INSTRUCTION: o32 FF /3 | CALL m16:32 | INTEL386
	ops: r=rm | SegPtr32
	implied: push=2x4
	code-memory-size: 1632
	# VM exit if task switch
	flags: sp=push;8 br=call-far-indirect cflow=call-ind cet-tracked intel-may-vm-exit no-in-sgx amd-may-vm-exit tsx-impl-abort
	fast: mnemonic=callf flags=force-size=always
	gas: mnemonic=lcall suffix=l far
	intel: flags=force-size=always;far
	masm: flags=force-size=always
	nasm: far-mem
END

# Code: Call_m1664
INSTRUCTION: o64 FF /3 | CALL m16:64 | X64
	ops: r=rm | SegPtr64
	implied: push=2x8
	code-memory-size: 1664
	# VM exit if task switch
	flags: 64 sp=push;16 br=call-far-indirect cflow=call-ind cet-tracked no-amd-dec intel-may-vm-exit no-in-sgx tsx-impl-abort
	fast: mnemonic=callf flags=force-size=always
	gas: mnemonic=lcall far
	intel: flags=force-size=always;far
	masm: flags=force-size=always
	nasm: far-mem
END

# Code: Jmp_rm16
INSTRUCTION: o16 FF /4 | JMP r/m16 | INTEL8086
	ops: r=rm | WordOffset
	flags: bnd notrack br=jmp-near-indirect cflow=br-ind cet-tracked no-intel-dec64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix;indirect suffix=w bnd
	intel: flags=force-size=always bnd
	masm: flags=force-size=always bnd
	nasm: flags=force-size=always bnd
END

# Code: Jmp_rm32
INSTRUCTION: o32 FF /4 | JMP r/m32 | INTEL386
	ops: r=rm | DwordOffset
	flags: 16 32 br=jmp-near-indirect cflow=br-ind bnd notrack cet-tracked
	fast: flags=force-size=always
	gas: flags=force-mem-suffix;indirect suffix=l bnd
	intel: flags=force-size=always bnd
	masm: flags=force-size=always bnd
	nasm: flags=force-size=always bnd
END

# Code: Jmp_rm64
INSTRUCTION: o64 FF /4 | JMP r/m64 | X64
	ops: r=rm | QwordOffset
	flags: 64 br=jmp-near-indirect cflow=br-ind bnd notrack cet-tracked intel-fo64 do64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix;indirect suffix=q bnd
	intel: flags=force-size=always bnd
	masm: flags=force-size=always bnd
	nasm: flags=force-size=always bnd
END

# Code: Jmp_m1616
INSTRUCTION: o16 FF /5 | JMP m16:16 | INTEL8086
	ops: r=rm | SegPtr16
	code-memory-size: 1616
	# VM exit if task switch
	flags: br=jmp-far-indirect cflow=br-ind cet-tracked intel-may-vm-exit no-in-sgx amd-may-vm-exit tsx-impl-abort
	fast: mnemonic=jmpf flags=force-size=always
	gas: mnemonic=ljmp suffix=w far
	intel: flags=force-size=always;far
	masm: flags=force-size=always
	nasm: far-mem
END

# Code: Jmp_m1632
INSTRUCTION: o32 FF /5 | JMP m16:32 | INTEL386
	ops: r=rm | SegPtr32
	code-memory-size: 1632
	# VM exit if task switch
	flags: br=jmp-far-indirect cflow=br-ind cet-tracked intel-may-vm-exit no-in-sgx amd-may-vm-exit tsx-impl-abort
	fast: mnemonic=jmpf flags=force-size=always
	gas: mnemonic=ljmp suffix=l far
	intel: flags=force-size=always;far
	masm: flags=force-size=always
	nasm: far-mem
END

# Code: Jmp_m1664
INSTRUCTION: o64 FF /5 | JMP m16:64 | X64
	ops: r=rm | SegPtr64
	code-memory-size: 1664
	# VM exit if task switch
	flags: 64 br=jmp-far-indirect cflow=br-ind no-amd-dec cet-tracked intel-may-vm-exit no-in-sgx tsx-impl-abort
	fast: mnemonic=jmpf flags=force-size=always
	gas: mnemonic=ljmp far
	intel: flags=force-size=always;far
	masm: flags=force-size=always
	nasm: far-mem
END

# Code: Push_rm16
INSTRUCTION: o16 FF /6 | PUSH r/m16 | INTEL8086
	ops: r=rm | UInt16
	implied: push=1x2
	flags: sp=push;2
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Push_rm32
INSTRUCTION: o32 FF /6 | PUSH r/m32 | INTEL386
	ops: r=rm | UInt32
	implied: push=1x4
	flags: 16 32 sp=push;4
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Push_rm64
INSTRUCTION: o64 FF /6 | PUSH r/m64 | X64
	ops: r=rm | UInt64
	implied: push=1x8
	flags: 64 sp=push;8 do64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sldt_rm16
INSTRUCTION: o16 0F 00 /0 | SLDT r/m16 | INTEL286
	ops: w=rm | UInt16
	# If CR4.UMIP=1, CPL=0 is required
	flags: no-rm no-v86 may-require-cpl0 intel-may-vm-exit no-in-sgx amd-may-vm-exit tsx-impl-abort
	gas: suffix=w mem16
	masm: flags=force-size=default
	nasm: osz-mem-1
END

# Code: Sldt_r32m16
INSTRUCTION: o32 0F 00 /0 | SLDT r32/m16 | INTEL386
	ops: w=rm | UInt16
	# If CR4.UMIP=1, CPL=0 is required
	flags: no-rm no-v86 may-require-cpl0 intel-may-vm-exit no-in-sgx amd-may-vm-exit tsx-impl-abort
	gas: suffix=l mem16
	masm: flags=force-size=default
	nasm: osz-mem-1
END

# Code: Sldt_r64m16
INSTRUCTION: o64 0F 00 /0 | SLDT r64/m16 | X64
	ops: w=rm | UInt16
	# If CR4.UMIP=1, CPL=0 is required
	flags: 64 no-rm no-v86 may-require-cpl0 intel-may-vm-exit no-in-sgx amd-may-vm-exit tsx-impl-abort
	gas: suffix=q mem16
	masm: flags=force-size=default
	nasm: osz-mem-1
END

# Code: Str_rm16
INSTRUCTION: o16 0F 00 /1 | STR r/m16 | INTEL286
	ops: w=rm | UInt16
	# If CR4.UMIP=1, CPL=0 is required
	flags: no-rm no-v86 may-require-cpl0 intel-may-vm-exit no-in-sgx amd-may-vm-exit tsx-impl-abort
	gas: suffix=w mem16
	masm: flags=force-size=default
	nasm: osz-mem-1
END

# Code: Str_r32m16
INSTRUCTION: o32 0F 00 /1 | STR r32/m16 | INTEL386
	ops: w=rm | UInt16
	# If CR4.UMIP=1, CPL=0 is required
	flags: no-rm no-v86 may-require-cpl0 intel-may-vm-exit no-in-sgx amd-may-vm-exit tsx-impl-abort
	gas: suffix=l mem16
	masm: flags=force-size=default
	nasm: osz-mem-1
END

# Code: Str_r64m16
INSTRUCTION: o64 0F 00 /1 | STR r64/m16 | X64
	ops: w=rm | UInt16
	# If CR4.UMIP=1, CPL=0 is required
	flags: 64 no-rm no-v86 may-require-cpl0 intel-may-vm-exit no-in-sgx amd-may-vm-exit tsx-impl-abort
	gas: suffix=q mem16
	masm: flags=force-size=default
	nasm: osz-mem-1
END

# Code: Lldt_rm16
INSTRUCTION: o16 0F 00 /2 | LLDT r/m16 | INTEL286
	ops: r=rm | UInt16
	flags: cpl0 no-rm no-v86 serialize-intel serialize-amd intel-may-vm-exit amd-may-vm-exit tsx-impl-abort
	gas: reg16
	masm: flags=force-size=default
	nasm: osz-reg16
END

# Code: Lldt_r32m16
INSTRUCTION: o32 0F 00 /2 | LLDT r32/m16 | INTEL386
	ops: r=rm | UInt16
	implied: last-gpr-16
	flags: cpl0 no-rm no-v86 serialize-intel serialize-amd intel-may-vm-exit amd-may-vm-exit tsx-impl-abort
	gas: reg16
	intel: reg16
	masm: flags=force-size=default reg16
	nasm: osz-reg16
END

# Code: Lldt_r64m16
INSTRUCTION: o64 0F 00 /2 | LLDT r64/m16 | X64
	ops: r=rm | UInt16
	implied: last-gpr-16
	flags: 64 cpl0 no-rm no-v86 serialize-intel serialize-amd intel-may-vm-exit amd-may-vm-exit tsx-impl-abort
	gas: reg16
	intel: reg16
	masm: flags=force-size=default reg16
	nasm: osz-reg16
END

# Code: Ltr_rm16
INSTRUCTION: o16 0F 00 /3 | LTR r/m16 | INTEL286
	ops: r=rm | UInt16
	flags: cpl0 no-rm no-v86 serialize-intel serialize-amd intel-may-vm-exit amd-may-vm-exit tsx-impl-abort
	gas: reg16
	masm: flags=force-size=default
	nasm: osz-reg16
END

# Code: Ltr_r32m16
INSTRUCTION: o32 0F 00 /3 | LTR r32/m16 | INTEL386
	ops: r=rm | UInt16
	implied: last-gpr-16
	flags: cpl0 no-rm no-v86 serialize-intel serialize-amd intel-may-vm-exit amd-may-vm-exit tsx-impl-abort
	gas: reg16
	intel: reg16
	masm: flags=force-size=default reg16
	nasm: osz-reg16
END

# Code: Ltr_r64m16
INSTRUCTION: o64 0F 00 /3 | LTR r64/m16 | X64
	ops: r=rm | UInt16
	implied: last-gpr-16
	flags: 64 cpl0 no-rm no-v86 serialize-intel serialize-amd intel-may-vm-exit amd-may-vm-exit tsx-impl-abort
	gas: reg16
	intel: reg16
	masm: flags=force-size=default reg16
	nasm: osz-reg16
END

# Code: Verr_rm16
INSTRUCTION: o16 0F 00 /4 | VERR r/m16 | INTEL286
	ops: r=rm | UInt16
	rflags: w=z
	flags: no-rm no-v86
	gas: reg16
	masm: flags=force-size=default
	nasm: osz-reg16
END

# Code: Verr_r32m16
INSTRUCTION: o32 0F 00 /4 | VERR r32/m16 | INTEL386
	ops: r=rm | UInt16
	implied: last-gpr-16
	rflags: w=z
	flags: no-rm no-v86
	gas: reg16
	intel: reg16
	masm: flags=force-size=default reg16
	nasm: osz-reg16
END

# Code: Verr_r64m16
INSTRUCTION: o64 0F 00 /4 | VERR r64/m16 | X64
	ops: r=rm | UInt16
	implied: last-gpr-16
	rflags: w=z
	flags: 64 no-rm no-v86
	gas: reg16
	intel: reg16
	masm: flags=force-size=default reg16
	nasm: osz-reg16
END

# Code: Verw_rm16
INSTRUCTION: o16 0F 00 /5 | VERW r/m16 | INTEL286
	ops: r=rm | UInt16
	rflags: w=z
	flags: no-rm no-v86
	gas: reg16
	masm: flags=force-size=default
	nasm: osz-reg16
END

# Code: Verw_r32m16
INSTRUCTION: o32 0F 00 /5 | VERW r32/m16 | INTEL386
	ops: r=rm | UInt16
	implied: last-gpr-16
	rflags: w=z
	flags: no-rm no-v86
	gas: reg16
	intel: reg16
	masm: flags=force-size=default reg16
	nasm: osz-reg16
END

# Code: Verw_r64m16
INSTRUCTION: o64 0F 00 /5 | VERW r64/m16 | X64
	ops: r=rm | UInt16
	implied: last-gpr-16
	rflags: w=z
	flags: 64 no-rm no-v86
	gas: reg16
	intel: reg16
	masm: flags=force-size=default reg16
	nasm: osz-reg16
END

# Code: Jmpe_rm16
INSTRUCTION: o16 0F 00 /6 | JMPE r/m16 | IA64
	ops: r=rm | WordOffset
	flags: 16 32 dec-opt=Jmpe br=jmpe-near-indirect cflow=br-ind
	fast: flags=force-size=always
	gas: flags=indirect suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Jmpe_rm32
INSTRUCTION: o32 0F 00 /6 | JMPE r/m32 | IA64
	ops: r=rm | DwordOffset
	flags: 16 32 dec-opt=Jmpe br=jmpe-near-indirect cflow=br-ind
	fast: flags=force-size=always
	gas: flags=indirect suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Sgdt_m1632_16
INSTRUCTION: o16 0F 01 /0 | SGDT m | INTEL286
	ops: w=rm | Fword6
	code-memory-size: 1632
	code-suffix: 16
	# If CR4.UMIP=1, CPL=0 is required
	flags: 16 32 may-require-cpl0 intel-may-vm-exit no-in-sgx amd-may-vm-exit tsx-impl-abort
	gas: suffix=w osz-suffix-4
	masm: gidt
	nasm: osz-mem-1
END

# Code: Sgdt_m1632
INSTRUCTION: o32 0F 01 /0 | SGDT m | INTEL386
	ops: w=rm | Fword6
	code-memory-size: 1632
	# If CR4.UMIP=1, CPL=0 is required
	flags: 16 32 may-require-cpl0 intel-may-vm-exit no-in-sgx amd-may-vm-exit tsx-impl-abort
	gas: suffix=l osz-suffix-4
	masm: gidt
	nasm: osz-mem-1
END

# Code: Sgdt_m1664
INSTRUCTION: 0F 01 /0 | SGDT m | X64
	ops: w=rm | Fword10
	code-memory-size: 1664
	# If CR4.UMIP=1, CPL=0 is required
	flags: 64 fo64 may-require-cpl0 intel-may-vm-exit no-in-sgx amd-may-vm-exit tsx-impl-abort
	gas: suffix=q osz-suffix-4
	masm: gidt
END

# Code: Sidt_m1632_16
INSTRUCTION: o16 0F 01 /1 | SIDT m | INTEL286
	ops: w=rm | Fword6
	code-memory-size: 1632
	code-suffix: 16
	# If CR4.UMIP=1, CPL=0 is required
	flags: 16 32 may-require-cpl0 intel-may-vm-exit no-in-sgx amd-may-vm-exit tsx-impl-abort
	gas: suffix=w osz-suffix-4
	masm: gidt
	nasm: osz-mem-1
END

# Code: Sidt_m1632
INSTRUCTION: o32 0F 01 /1 | SIDT m | INTEL386
	ops: w=rm | Fword6
	code-memory-size: 1632
	# If CR4.UMIP=1, CPL=0 is required
	flags: 16 32 may-require-cpl0 intel-may-vm-exit no-in-sgx amd-may-vm-exit tsx-impl-abort
	gas: suffix=l osz-suffix-4
	masm: gidt
	nasm: osz-mem-1
END

# Code: Sidt_m1664
INSTRUCTION: 0F 01 /1 | SIDT m | X64
	ops: w=rm | Fword10
	code-memory-size: 1664
	# If CR4.UMIP=1, CPL=0 is required
	flags: 64 fo64 may-require-cpl0 intel-may-vm-exit no-in-sgx amd-may-vm-exit tsx-impl-abort
	gas: suffix=q osz-suffix-4
	masm: gidt
END

# Code: Lgdt_m1632_16
INSTRUCTION: o16 0F 01 /2 | LGDT m16&32 | INTEL286
	ops: r=rm | Fword6
	code-memory-size: 1632
	code-suffix: 16
	flags: 16 32 cpl0 serialize-intel serialize-amd intel-may-vm-exit amd-may-vm-exit tsx-impl-abort
	gas: suffix=w osz-suffix-4
	masm: flags=force-size=default gidt
	nasm: osz-mem-1
END

# Code: Lgdt_m1632
INSTRUCTION: o32 0F 01 /2 | LGDT m16&32 | INTEL386
	ops: r=rm | Fword6
	code-memory-size: 1632
	flags: 16 32 cpl0 serialize-intel serialize-amd intel-may-vm-exit amd-may-vm-exit tsx-impl-abort
	gas: suffix=l osz-suffix-4
	masm: flags=force-size=default gidt
	nasm: osz-mem-1
END

# Code: Lgdt_m1664
INSTRUCTION: 0F 01 /2 | LGDT m16&64 | X64
	ops: r=rm | Fword10
	code-memory-size: 1664
	flags: 64 cpl0 fo64 serialize-intel serialize-amd intel-may-vm-exit amd-may-vm-exit tsx-impl-abort
	gas: suffix=q osz-suffix-4
	masm: flags=force-size=default gidt
END

# Code: Lidt_m1632_16
INSTRUCTION: o16 0F 01 /3 | LIDT m16&32 | INTEL286
	ops: r=rm | Fword6
	code-memory-size: 1632
	code-suffix: 16
	flags: 16 32 cpl0 serialize-intel serialize-amd intel-may-vm-exit amd-may-vm-exit tsx-impl-abort
	gas: suffix=w osz-suffix-4
	masm: flags=force-size=default gidt
	nasm: osz-mem-1
END

# Code: Lidt_m1632
INSTRUCTION: o32 0F 01 /3 | LIDT m16&32 | INTEL386
	ops: r=rm | Fword6
	code-memory-size: 1632
	flags: 16 32 cpl0 serialize-intel serialize-amd intel-may-vm-exit amd-may-vm-exit tsx-impl-abort
	gas: suffix=l osz-suffix-4
	masm: flags=force-size=default gidt
	nasm: osz-mem-1
END

# Code: Lidt_m1664
INSTRUCTION: 0F 01 /3 | LIDT m16&64 | X64
	ops: r=rm | Fword10
	code-memory-size: 1664
	flags: 64 cpl0 fo64 serialize-intel serialize-amd intel-may-vm-exit amd-may-vm-exit tsx-impl-abort
	gas: suffix=q osz-suffix-4
	masm: flags=force-size=default gidt
END

# Code: Smsw_rm16
INSTRUCTION: o16 0F 01 /4 | SMSW r/m16 | INTEL286
	ops: w=rm | UInt16
	implied: r=cr0
	# If CR4.UMIP=1, CPL=0 is required
	# May cause a TSX abort if VM exit
	flags: may-require-cpl0 intel-may-vm-exit no-in-sgx amd-may-vm-exit tsx-impl-abort
	gas: suffix=w mem16
	masm: flags=force-size=default
	nasm: osz-mem-1
END

# Code: Smsw_r32m16
INSTRUCTION: o32 0F 01 /4 | SMSW r32/m16 | INTEL386
	ops: w=rm | UInt16
	implied: r=cr0
	# If CR4.UMIP=1, CPL=0 is required
	# May cause a TSX abort if VM exit
	flags: may-require-cpl0 intel-may-vm-exit no-in-sgx amd-may-vm-exit tsx-impl-abort
	gas: suffix=l mem16
	masm: flags=force-size=default
	nasm: osz-mem-1
END

# Code: Smsw_r64m16
INSTRUCTION: o64 0F 01 /4 | SMSW r64/m16 | X64
	ops: w=rm | UInt16
	implied: r=cr0
	# If CR4.UMIP=1, CPL=0 is required
	# May cause a TSX abort if VM exit
	flags: 64 may-require-cpl0 intel-may-vm-exit no-in-sgx amd-may-vm-exit tsx-impl-abort
	gas: suffix=q mem16
	masm: flags=force-size=default
	nasm: osz-mem-1
END

# Code: Rstorssp_m64
INSTRUCTION: F3 0F 01 /5 | RSTORSSP m64 | CET_SS
	ops: rw=rm | UInt64
	rflags: w=c 0=oszap
	flags: no-rm no-v86
	masm: flags=force-size=default
END

# Code: Lmsw_rm16
INSTRUCTION: o16 0F 01 /6 | LMSW r/m16 | INTEL286
	ops: r=rm | UInt16
	implied: rw=cr0
	flags: cpl0 serialize-intel intel-may-vm-exit amd-may-vm-exit tsx-impl-abort
	gas: reg16
	masm: flags=force-size=default
	nasm: osz-reg16
END

# Code: Lmsw_r32m16
INSTRUCTION: o32 0F 01 /6 | LMSW r32/m16 | INTEL386
	ops: r=rm | UInt16
	implied: rw=cr0 last-gpr-16
	flags: cpl0 serialize-intel intel-may-vm-exit amd-may-vm-exit tsx-impl-abort
	gas: reg16
	intel: reg16
	masm: flags=force-size=default reg16
	nasm: osz-reg16
END

# Code: Lmsw_r64m16
INSTRUCTION: o64 0F 01 /6 | LMSW r64/m16 | X64
	ops: r=rm | UInt16
	implied: rw=cr0 last-gpr-16
	flags: 64 cpl0 serialize-intel intel-may-vm-exit amd-may-vm-exit tsx-impl-abort
	gas: reg16
	intel: reg16
	masm: flags=force-size=default reg16
	nasm: osz-reg16
END

# Code: Invlpg_m
INSTRUCTION: 0F 01 /7 | INVLPG m | INTEL486
	ops: nma=rm
	flags: cpl0 serialize-intel serialize-amd intel-may-vm-exit amd-may-vm-exit tsx-impl-abort
	intel: flags=mem-size=ignore
END

# Code: Enclv
INSTRUCTION: NP 0F 01 C0 | ENCLV | OSS
	implied: rcw=eax crcw;!64=ecx;edx;ebx crcw;64=rcx;rdx;rbx cr;!64=ds
	rflags: w=oszacp
	flags: cpl0 no-rm no-v86 no-in-smm vmx=op intel-may-vm-exit tdx-non-root-ud tsx-abort
END

# This instruction is NP, the SDM is wrong
# Code: Vmcall
INSTRUCTION: NP 0F 01 C1 | VMCALL | VMX
	rflags: w=zc 0=osap
	# It has CPL=0 but it can VM exit and the VMM doesn't need to require CPL=0, so shouldn't be marked privileged
	#TODO: #UD if (v86 or compat) && VMX root operation
	flags: cpl0 no-privileged cflow=call vmx=op intel-vm-exit intel-smm-vm-exit no-in-sgx tdx-non-root-ve tsx-impl-abort
END

# This instruction is NP, the SDM is wrong
# Code: Vmlaunch
INSTRUCTION: NP 0F 01 C2 | VMLAUNCH | VMX
	rflags: w=zc 0=osap
	# Continues from the next instruction on failure
	flags: cpl0 no-rm no-v86 no-cm cflow=call vmx=op intel-vm-exit tdx-non-root-ud tsx-impl-abort
END

# This instruction is NP, the SDM is wrong
# Code: Vmresume
INSTRUCTION: NP 0F 01 C3 | VMRESUME | VMX
	rflags: w=zc 0=osap
	# Continues from the next instruction on failure
	flags: cpl0 no-rm no-v86 no-cm cflow=call vmx=op intel-vm-exit tdx-non-root-ud tsx-impl-abort
END

# This instruction is NP, the SDM is wrong
# Code: Vmxoff
INSTRUCTION: NP 0F 01 C4 | VMXOFF | VMX
	rflags: w=zc 0=osap
	flags: cpl0 no-rm no-v86 no-cm vmx=op intel-vm-exit tdx-non-root-ud tsx-impl-abort
END

# Code: Pconfig
INSTRUCTION: NP 0F 01 C5 | PCONFIG | PCONFIG
	implied: rw=eax cr;!64=ecx;edx;ebx cr;64=rcx;rdx;rbx cw=ecx;edx;ebx cr;!64=ds
	rflags: w=z 0=osacp
	# May cause a TSX abort if VM exit
	# TDX #UD or #VE depending on feature enabling
	flags: cpl0 no-v86 intel-may-vm-exit tdx-non-root-ud tdx-non-root-ve tsx-impl-abort
END

# This instruction is NP, the SDM is wrong
# Code: Monitorw
INSTRUCTION: a16 NP 0F 01 C8 | MONITOR | MONITOR
	# Memory isn't read but it performs the same mem checks as a 1-byte read
	implied: r=seg;ax;ecx;edx
	code-mnemonic: monitorw
	# Intel: MISC_FEATURES_ENABLES[1]=1 (MSR=140h) enables it in CPL0-3 and v86 mode (Knights Landing CPUs only)
	# AMD: C001_0015h[MonMwaitUserEn]=1 enables it in CPL0-3 and v86 mode
	flags: 16 32 may-require-cpl0 intel-may-vm-exit tdx-non-root-ve amd-may-vm-exit tsx-impl-abort
	gas: asz
	intel: asz
	masm: monitor
	nasm: asz
END

# This instruction is NP, the SDM is wrong
# Code: Monitord
INSTRUCTION: a32 NP 0F 01 C8 | MONITOR | MONITOR
	# Memory isn't read but it performs the same mem checks as a 1-byte read
	implied: r=seg;eax;ecx;edx
	code-mnemonic: monitord
	# Intel: MISC_FEATURES_ENABLES[1]=1 (MSR=140h) enables it in CPL0-3 and v86 mode (Knights Landing CPUs only)
	# AMD: C001_0015h[MonMwaitUserEn]=1 enables it in CPL0-3 and v86 mode
	flags: may-require-cpl0 intel-may-vm-exit tdx-non-root-ve amd-may-vm-exit tsx-impl-abort
	gas: asz
	intel: asz
	masm: monitor
	nasm: asz
END

# This instruction is NP, the SDM is wrong
# Code: Monitorq
INSTRUCTION: a64 NP 0F 01 C8 | MONITOR | MONITOR
	# Memory isn't read but it performs the same mem checks as a 1-byte read
	implied: r=seg;rax;ecx;edx
	code-mnemonic: monitorq
	# Intel: MISC_FEATURES_ENABLES[1]=1 (MSR=140h) enables it in CPL0-3 and v86 mode (Knights Landing CPUs only)
	# AMD: C001_0015h[MonMwaitUserEn]=1 enables it in CPL0-3 and v86 mode
	flags: 64 may-require-cpl0 intel-may-vm-exit tdx-non-root-ve amd-may-vm-exit tsx-impl-abort
	gas: asz
	intel: asz
	masm: monitor
	nasm: asz
END

# This instruction is NP, the SDM is wrong
# Code: Mwait
INSTRUCTION: NP 0F 01 C9 | MWAIT | MONITOR
	implied: r=eax;ecx
	# Intel: MISC_FEATURES_ENABLES[1]=1 (MSR=140h) enables it in CPL0-3 and v86 mode (Knights Landing CPUs only)
	# AMD: C001_0015h[MonMwaitUserEn]=1 enables it in CPL0-3 and v86 mode
	flags: may-require-cpl0 intel-may-vm-exit tdx-non-root-ve amd-may-vm-exit tsx-impl-abort
	masm: mwait
END

# Code: Clac
INSTRUCTION: NP 0F 01 CA | CLAC | SMAP
	rflags: 0=A
	flags: cpl0 no-v86 tsx-impl-abort
END

# Code: Stac
INSTRUCTION: NP 0F 01 CB | STAC | SMAP
	rflags: 1=A
	flags: cpl0 no-v86 tsx-impl-abort
END

# Code: Encls
INSTRUCTION: NP 0F 01 CF | ENCLS | SGX1
	implied: rcw=eax crcw;!64=ecx;edx;ebx crcw;64=rcx;rdx;rbx cr;!64=ds
	rflags: w=oszacp
	flags: cpl0 no-rm no-v86 no-in-smm intel-may-vm-exit tdx-non-root-ud tsx-abort
END

# Code: Xgetbv
INSTRUCTION: NP 0F 01 D0 | XGETBV | XSAVE
	implied: r=ecx w=eax;edx
END

# Code: Xsetbv
INSTRUCTION: NP 0F 01 D1 | XSETBV | XSAVE
	implied: r=eax;ecx;edx
	flags: cpl0 intel-vm-exit amd-may-vm-exit tsx-impl-abort
END

# Code: Vmfunc
INSTRUCTION: NP 0F 01 D4 | VMFUNC | VMX
	implied: r=eax;ecx
	#TODO: should be cond-write
	rflags: w=oszacp
	# VM exit if func EAX is disabled or if func EAX causes a VM exit
	flags: vmx=non-root intel-may-vm-exit no-in-sgx tdx-non-root-ud tsx-impl-abort
END

# Code: Xend
INSTRUCTION: NP 0F 01 D5 | XEND | RTM
	flags: tsx-may-abort
END

# Code: Xtest
INSTRUCTION: NP 0F 01 D6 | XTEST | HLE_or_RTM
	rflags: w=z 0=osacp
END

# Code: Enclu
INSTRUCTION: NP 0F 01 D7 | ENCLU | SGX1
	implied: rcw=eax crcw;!64=ecx;edx;ebx crcw;64=rcx;rdx;rbx cr;!64=ds
	rflags: w=oszacp
	# The only instruction that requires CPL=3 (will #UD if CPL<3).
	# ENCLU[EENTER] is a serializing instruction.
	flags: cpl3 no-rm no-v86 no-in-smm tsx-abort
END

# Code: Vmrunw
INSTRUCTION: a16 0F 01 D8 | VMRUN | SVM
	implied: r=ax
	code-mnemonic: vmrunw
	rflags: r=oszacpdiA
	# Not supported in SMM: undefined behavior
	# Continues from the next instruction
	flags: 16 32 cpl0 save-restore no-rm no-v86 cflow=call amd-may-vm-exit
	gas: asz
	intel: reg ax
	masm: reg ax
	nasm: asz
END

# Code: Vmrund
INSTRUCTION: a32 0F 01 D8 | VMRUN | SVM
	implied: r=eax
	code-mnemonic: vmrund
	rflags: r=oszacpdiA
	# Not supported in SMM: undefined behavior
	# Continues from the next instruction
	flags: cpl0 save-restore no-rm no-v86 cflow=call amd-may-vm-exit
	gas: asz
	intel: reg eax
	masm: reg eax
	nasm: asz
END

# Code: Vmrunq
INSTRUCTION: a64 0F 01 D8 | VMRUN | SVM
	implied: r=rax
	code-mnemonic: vmrunq
	rflags: r=oszacpdiA
	# Not supported in SMM: undefined behavior
	# Continues from the next instruction
	flags: 64 cpl0 save-restore no-rm no-v86 cflow=call amd-may-vm-exit
	gas: asz
	intel: reg rax
	masm: reg rax
	nasm: asz
END

# Code: Vmmcall
INSTRUCTION: 0F 01 D9 | VMMCALL | SVM
	# #UD if not intercepted
	flags: cflow=call amd-may-vm-exit
END

# Code: Vmloadw
INSTRUCTION: a16 0F 01 DA | VMLOAD | SVM
	implied: r=ax w=fs;gs
	code-mnemonic: vmloadw
	flags: 16 32 cpl0 no-rm no-v86 amd-may-vm-exit
	gas: asz
	intel: reg ax
	masm: reg ax
	nasm: asz
END

# Code: Vmloadd
INSTRUCTION: a32 0F 01 DA | VMLOAD | SVM
	implied: r=eax w=fs;gs
	code-mnemonic: vmloadd
	flags: cpl0 no-rm no-v86 amd-may-vm-exit
	gas: asz
	intel: reg eax
	masm: reg eax
	nasm: asz
END

# Code: Vmloadq
INSTRUCTION: a64 0F 01 DA | VMLOAD | SVM
	implied: r=rax w=fs;gs
	code-mnemonic: vmloadq
	flags: 64 cpl0 no-rm no-v86 amd-may-vm-exit
	gas: asz
	intel: reg rax
	masm: reg rax
	nasm: asz
END

# Code: Vmsavew
INSTRUCTION: a16 0F 01 DB | VMSAVE | SVM
	implied: r=ax;fs;gs
	code-mnemonic: vmsavew
	flags: 16 32 cpl0 no-rm no-v86 amd-may-vm-exit
	gas: asz
	intel: reg ax
	masm: reg ax
	nasm: asz
END

# Code: Vmsaved
INSTRUCTION: a32 0F 01 DB | VMSAVE | SVM
	implied: r=eax;fs;gs
	code-mnemonic: vmsaved
	flags: cpl0 no-rm no-v86 amd-may-vm-exit
	gas: asz
	intel: reg eax
	masm: reg eax
	nasm: asz
END

# Code: Vmsaveq
INSTRUCTION: a64 0F 01 DB | VMSAVE | SVM
	implied: r=rax;fs;gs
	code-mnemonic: vmsaveq
	flags: 64 cpl0 no-rm no-v86 amd-may-vm-exit
	gas: asz
	intel: reg rax
	masm: reg rax
	nasm: asz
END

# Code: Stgi
INSTRUCTION: 0F 01 DC | STGI | SKINIT_or_SVM
	flags: cpl0 no-rm no-v86 amd-may-vm-exit
END

# Code: Clgi
INSTRUCTION: 0F 01 DD | CLGI | SVM
	flags: cpl0 no-rm no-v86 amd-may-vm-exit
END

# Code: Skinit
INSTRUCTION: 0F 01 DE | SKINIT | SKINIT_or_SVM
	# It also causes an INIT which clears various regs
	implied: w=cr0;cr2-cr4 w=dr0-dr3;dr6;dr7 w=es-gs r=eax w;!64=eax-edi w;64=rax-r15
	rflags: 0=oszacpdiA
	flags: cpl0 no-rm no-v86 cflow=ret amd-may-vm-exit
	intel: reg eax
	masm: reg eax
END

# Code: Invlpgaw
INSTRUCTION: a16 0F 01 DF | INVLPGA | SVM
	implied: r=ax;ecx
	code-mnemonic: invlpgaw
	flags: 16 32 cpl0 no-rm no-v86 serialize-amd amd-may-vm-exit
	gas: asz
	intel: invlpga
	masm: invlpga
	nasm: invlpga
END

# Code: Invlpgad
INSTRUCTION: a32 0F 01 DF | INVLPGA | SVM
	implied: r=eax;ecx
	code-mnemonic: invlpgad
	flags: cpl0 no-rm no-v86 serialize-amd amd-may-vm-exit
	gas: asz
	intel: invlpga
	masm: invlpga
	nasm: invlpga
END

# Code: Invlpgaq
INSTRUCTION: a64 0F 01 DF | INVLPGA | SVM
	implied: r=rax;ecx
	code-mnemonic: invlpgaq
	flags: 64 cpl0 no-rm no-v86 serialize-amd amd-may-vm-exit
	gas: asz
	intel: invlpga
	masm: invlpga
	nasm: invlpga
END

# Code: Setssbsy
INSTRUCTION: F3 0F 01 E8 | SETSSBSY | CET_SS
	flags: cpl0 no-rm no-v86
END

# Code: Saveprevssp
INSTRUCTION: F3 0F 01 EA | SAVEPREVSSP | CET_SS
	rflags: r=c
	flags: no-rm no-v86
END

# Code: Rdpkru
INSTRUCTION: NP 0F 01 EE | RDPKRU | PKU
	implied: r=ecx w=eax;edx
END

# Code: Wrpkru
INSTRUCTION: NP 0F 01 EF | WRPKRU | PKU
	implied: r=eax;ecx;edx
	flags: tsx-impl-abort
END

# Code: Swapgs
INSTRUCTION: 0F 01 F8 | SWAPGS | X64
	# #UD if CR4.FRED=1
	flags: 64 cpl0 serialize-amd tsx-impl-abort
END

# Code: Rdtscp
INSTRUCTION: 0F 01 F9 | RDTSCP | RDTSCP
	implied: w=eax;ecx;edx
	# If CR4.TSD=1, CPL=0 is required
	# May cause a TSX abort if VM exit
	flags: may-require-cpl0 intel-may-vm-exit no-in-sgx1 amd-may-vm-exit tsx-impl-abort
END

# Code: Monitorxw
INSTRUCTION: a16 NP 0F 01 FA | MONITORX | MONITORX
	# Memory isn't read but it performs the same mem checks as a 1-byte read
	implied: r=seg;ax;ecx;edx
	code-mnemonic: monitorxw
	flags: 16 32 amd-may-vm-exit
	gas: asz
	intel: asz
	masm: monitor
	nasm: asz
END

# Code: Monitorxd
INSTRUCTION: a32 NP 0F 01 FA | MONITORX | MONITORX
	# Memory isn't read but it performs the same mem checks as a 1-byte read
	implied: r=seg;eax;ecx;edx
	code-mnemonic: monitorxd
	flags: amd-may-vm-exit
	gas: asz
	intel: asz
	masm: monitor
	nasm: asz
END

# Code: Monitorxq
INSTRUCTION: a64 NP 0F 01 FA | MONITORX | MONITORX
	# Memory isn't read but it performs the same mem checks as a 1-byte read
	implied: r=seg;rax;ecx;edx
	code-mnemonic: monitorxq
	flags: 64 amd-may-vm-exit
	gas: asz
	intel: asz
	masm: monitor
	nasm: asz
END

# Code: Mcommit
INSTRUCTION: F3 0F 01 FA | MCOMMIT | MCOMMIT
	rflags: w=c 0=oszap
	flags: amd-may-vm-exit
END

# Code: Mwaitx
INSTRUCTION: NP 0F 01 FB | MWAITX | MONITORX
	implied: r=eax;ecx cr=ebx
	flags: amd-may-vm-exit
	masm: mwaitx
END

# Code: Clzerow
INSTRUCTION: a16 0F 01 FC | CLZERO | CLZERO
	implied: r=seg r=ax
	code-mnemonic: clzerow
	flags: 16 32 non-temporal
	gas: asz
	intel: reg ax
	nasm: asz
END

# Code: Clzerod
INSTRUCTION: a32 0F 01 FC | CLZERO | CLZERO
	implied: r=seg r=eax
	code-mnemonic: clzerod
	flags: non-temporal
	gas: asz
	intel: reg eax
	nasm: asz
END

# Code: Clzeroq
INSTRUCTION: a64 0F 01 FC | CLZERO | CLZERO
	implied: r=seg r=rax
	code-mnemonic: clzeroq
	flags: 64 non-temporal
	gas: asz
	intel: reg rax
	nasm: asz
END

# Code: Rdpru
INSTRUCTION: NP 0F 01 FD | RDPRU | RDPRU
	implied: r=ecx w=eax;edx
	rflags: w=c 0=oszap
	# If CR4.TSD=1, CPL=0 is required
	flags: may-require-cpl0 amd-may-vm-exit
END

# Code: Lar_r16_rm16
INSTRUCTION: o16 0F 02 /r | LAR r16, r/m16 | INTEL286
	ops: cw=reg r=rm | UInt16
	rflags: w=z
	flags: no-rm no-v86
	gas: suffix=w
	masm: flags=force-size=default
END

# Code: Lar_r32_r32m16
INSTRUCTION: o32 0F 02 /r | LAR r32, r32/m16 | INTEL386
	ops: cw=reg r=rm | UInt16
	implied: last-gpr-16
	rflags: w=z
	flags: no-rm no-v86
	gas: suffix=l
	masm: flags=force-size=default
END

# Code: Lar_r64_r64m16
INSTRUCTION: o64 0F 02 /r | LAR r64, r64/m16 | X64
	ops: cw=reg r=rm | UInt16
	implied: last-gpr-16
	rflags: w=z
	flags: 64 no-rm no-v86
	gas: suffix=q
	masm: flags=force-size=default
END

# Code: Lsl_r16_rm16
INSTRUCTION: o16 0F 03 /r | LSL r16, r/m16 | INTEL286
	ops: cw=reg r=rm | UInt16
	rflags: w=z
	flags: no-rm no-v86
	gas: suffix=w
	masm: flags=force-size=default
END

# Code: Lsl_r32_r32m16
INSTRUCTION: o32 0F 03 /r | LSL r32, r32/m16 | INTEL386
	ops: cw=reg r=rm | UInt16
	implied: last-gpr-16
	rflags: w=z
	flags: no-rm no-v86
	gas: suffix=l
	masm: flags=force-size=default
END

# Code: Lsl_r64_r64m16
INSTRUCTION: o64 0F 03 /r | LSL r64, r64/m16 | X64
	ops: cw=reg r=rm | UInt16
	implied: last-gpr-16
	rflags: w=z
	flags: 64 no-rm no-v86
	gas: suffix=q
	masm: flags=force-size=default
END

# Code: Storeall
INSTRUCTION: 0F 04 | STOREALL | INTEL286_ONLY
	# This one probably needs the F1h prefix (it was a prefix on 286)
	#	https://www.vcfed.org/forum/forum/technical-support/vintage-computer-programming/71519-i-found-the-saveall-opcode
	#	https://www.pcjs.org/documents/manuals/intel/80386/loadall/
	code-mnemonic: storeall
	flags: 16 32 dec-opt=Loadall286 cpl0 save-restore asm-ig
END

# Code: Loadall286
INSTRUCTION: 0F 05 | LOADALL | INTEL286_ONLY
	code-mnemonic: loadall286
	flags: 16 32 dec-opt=Loadall286 cpl0 save-restore asm-ig
	fast: mnemonic=loadall286
	gas: mnemonic=loadall286
	intel: mnemonic=loadall286
	masm: mnemonic=loadall286
	nasm: mnemonic=loadall286
END

# Code: Syscall
INSTRUCTION: 0F 05 | SYSCALL | SYSCALL
	implied: w=ecx w;64=r11
	rflags: r=oszacpdiA w=oszacpdiA
	# Not supported by Intel in 64-bit mode but the Intel decoder should still decode it.
	flags: cflow=call no-in-sgx tsx-impl-abort
END

# Code: Clts
INSTRUCTION: 0F 06 | CLTS | INTEL286
	implied: rw=cr0
	flags: cpl0 intel-may-vm-exit amd-may-vm-exit tsx-impl-abort
END

# Code: Loadall386
INSTRUCTION: 0F 07 | LOADALL | INTEL386_ONLY
	implied: r=es;edi
	code-mnemonic: loadall386
	flags: 16 32 dec-opt=Loadall386 cpl0 save-restore
	fast: mnemonic=loadall386
	gas: mnemonic=loadall386
	intel: mnemonic=loadall386
	masm: mnemonic=loadall386
END

# Code: Sysretd
INSTRUCTION: 0F 07 | SYSRET | SYSCALL
	implied: r=ecx r;64=r11d w=cs;ss
	code-mnemonic: sysretd
	rflags: w=oszacpdiA
	# Not supported by Intel in 64-bit mode but the Intel decoder should still decode it.
	# AMD: no-rm no-v86 or #GP(0)
	# #UD if CR4.FRED=1
	flags: cpl0 cflow=ret tsx-impl-abort asm=sysret
	gas: suffix=l osz-suffix-3 16 32
END

# Code: Sysretq
INSTRUCTION: o64 0F 07 | SYSRETQ | SYSCALL
	implied: r=rcx;r11d w=cs;ss
	rflags: w=oszacpdiA
	# Not supported by Intel in 64-bit mode but the Intel decoder should still decode it.
	# #UD if CR4.FRED=1
	flags: 64 cpl0 cflow=ret tsx-impl-abort asm=sysretq
	nasm: mnemonic=sysret flags=o64
END

# Code: Invd
INSTRUCTION: 0F 08 | INVD | INTEL486
	flags: cpl0 serialize-intel serialize-amd intel-vm-exit tdx-non-root-ve amd-may-vm-exit tsx-impl-abort
END

# Code: Wbinvd
INSTRUCTION: 0F 09 | WBINVD | INTEL486
	flags: cpl0 serialize-intel serialize-amd intel-may-vm-exit tdx-non-root-ve amd-may-vm-exit tsx-impl-abort
END

# Code: Wbnoinvd
INSTRUCTION: F3 0F 09 | WBNOINVD | WBNOINVD
	flags: cpl0 serialize-intel serialize-amd intel-may-vm-exit tdx-non-root-ve amd-may-vm-exit tsx-impl-abort
END

# Code: Cl1invmb
INSTRUCTION: 0F 0A | CL1INVMB | CL1INVMB
	flags: 16 32 dec-opt=Cl1invmb cpl0
END

# Code: Ud2
INSTRUCTION: 0F 0B | UD2 | INTEL286
	flags: cflow=ex intel-vm-exit tsx-impl-abort
END

# Code: Reservednop_rm16_r16_0F0D
INSTRUCTION: o16 0F 0D /r | RESERVEDNOP r/m16, r16 | MULTIBYTENOP
	ops: n=rm n=reg | UInt16
	code-suffix: 0F0D
	flags: nop res-nop asm=reservednop_0f0d
	fast: mnemonic=nop
	gas: mnemonic=nop suffix=w
	intel: mnemonic=nop
	masm: mnemonic=nop
	nasm: mnemonic=nop
END

# Code: Reservednop_rm32_r32_0F0D
INSTRUCTION: o32 0F 0D /r | RESERVEDNOP r/m32, r32 | MULTIBYTENOP
	ops: n=rm n=reg | UInt32
	code-suffix: 0F0D
	flags: nop res-nop asm=reservednop_0f0d
	fast: mnemonic=nop
	gas: mnemonic=nop suffix=l
	intel: mnemonic=nop
	masm: mnemonic=nop
	nasm: mnemonic=nop
END

# Code: Reservednop_rm64_r64_0F0D
INSTRUCTION: o64 0F 0D /r | RESERVEDNOP r/m64, r64 | MULTIBYTENOP
	ops: n=rm n=reg | UInt64
	code-suffix: 0F0D
	flags: 64 nop res-nop asm=reservednop_0f0d
	fast: mnemonic=nop
	gas: mnemonic=nop suffix=q
	intel: mnemonic=nop
	masm: mnemonic=nop
	nasm: mnemonic=nop
END

# Code: Prefetch_m8
INSTRUCTION: 0F 0D /0 | PREFETCH m8 | PREFETCHW
	ops: nma=rm | UInt8
	flags: prefetch
	intel: mnemonic=prefetch_exclusive
	nasm: flags=mem-size=ignore
END

# Code: Prefetchw_m8
INSTRUCTION: 0F 0D /1 | PREFETCHW m8 | PREFETCHW
	ops: nma=rm | UInt8
	flags: prefetch
	nasm: flags=mem-size=ignore
END

# Code: Prefetchwt1_m8
INSTRUCTION: 0F 0D /2 | PREFETCHWT1 m8 | PREFETCHWT1
	ops: nma=rm | UInt8
	flags: prefetch
END

# Code: Femms
INSTRUCTION: 0F 0E | FEMMS | D3NOW
END

# Code: Umov_rm8_r8
INSTRUCTION: 0F 10 /r | UMOV r/m8, r8 | UMOV
	ops: w=rm r=reg | UInt8
	flags: 16 32 dec-opt=Umov
	gas: suffix=b
END

# Code: Umov_rm16_r16
INSTRUCTION: o16 0F 11 /r | UMOV r/m16, r16 | UMOV
	ops: w=rm r=reg | UInt16
	flags: 16 32 dec-opt=Umov
	gas: suffix=w
END

# Code: Umov_rm32_r32
INSTRUCTION: o32 0F 11 /r | UMOV r/m32, r32 | UMOV
	ops: w=rm r=reg | UInt32
	flags: 16 32 dec-opt=Umov
	gas: suffix=l
END

# Code: Umov_r8_rm8
INSTRUCTION: 0F 12 /r | UMOV r8, r/m8 | UMOV
	ops: w=reg r=rm | UInt8
	flags: 16 32 dec-opt=Umov
	gas: suffix=b
END

# Code: Umov_r16_rm16
INSTRUCTION: o16 0F 13 /r | UMOV r16, r/m16 | UMOV
	ops: w=reg r=rm | UInt16
	flags: 16 32 dec-opt=Umov
	gas: suffix=w
END

# Code: Umov_r32_rm32
INSTRUCTION: o32 0F 13 /r | UMOV r32, r/m32 | UMOV
	ops: w=reg r=rm | UInt32
	flags: 16 32 dec-opt=Umov
	gas: suffix=l
END

# Code: Movups_xmm_xmmm128
INSTRUCTION: NP 0F 10 /r | MOVUPS xmm1, xmm2/m128 | SSE
	ops: w=reg r=rm | Packed128_Float32
END

# Code: VEX_Vmovups_xmm_xmmm128
INSTRUCTION: VEX.128.0F.WIG 10 /r | VMOVUPS xmm1, xmm2/m128 | AVX
	ops: w=reg r=rm | Packed128_Float32
END

# Code: VEX_Vmovups_ymm_ymmm256
INSTRUCTION: VEX.256.0F.WIG 10 /r | VMOVUPS ymm1, ymm2/m256 | AVX
	ops: w=reg r=rm | Packed256_Float32
END

# Code: EVEX_Vmovups_xmm_k1z_xmmm128
INSTRUCTION: EVEX.128.0F.W0 10 /r | VMOVUPS xmm1 {k1}{z}, xmm2/m128 | AVX512VL AVX512F | N16
	ops: w=reg r=rm | Packed128_Float32
END

# Code: EVEX_Vmovups_ymm_k1z_ymmm256
INSTRUCTION: EVEX.256.0F.W0 10 /r | VMOVUPS ymm1 {k1}{z}, ymm2/m256 | AVX512VL AVX512F | N32
	ops: w=reg r=rm | Packed256_Float32
END

# Code: EVEX_Vmovups_zmm_k1z_zmmm512
INSTRUCTION: EVEX.512.0F.W0 10 /r | VMOVUPS zmm1 {k1}{z}, zmm2/m512 | AVX512F | N64
	ops: wvmm=reg r=rm | Packed512_Float32
END

# Code: Movupd_xmm_xmmm128
INSTRUCTION: 66 0F 10 /r | MOVUPD xmm1, xmm2/m128 | SSE2
	ops: w=reg r=rm | Packed128_Float64
END

# Code: VEX_Vmovupd_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 10 /r | VMOVUPD xmm1, xmm2/m128 | AVX
	ops: w=reg r=rm | Packed128_Float64
END

# Code: VEX_Vmovupd_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 10 /r | VMOVUPD ymm1, ymm2/m256 | AVX
	ops: w=reg r=rm | Packed256_Float64
END

# Code: EVEX_Vmovupd_xmm_k1z_xmmm128
INSTRUCTION: EVEX.128.66.0F.W1 10 /r | VMOVUPD xmm1 {k1}{z}, xmm2/m128 | AVX512VL AVX512F | N16
	ops: w=reg r=rm | Packed128_Float64
END

# Code: EVEX_Vmovupd_ymm_k1z_ymmm256
INSTRUCTION: EVEX.256.66.0F.W1 10 /r | VMOVUPD ymm1 {k1}{z}, ymm2/m256 | AVX512VL AVX512F | N32
	ops: w=reg r=rm | Packed256_Float64
END

# Code: EVEX_Vmovupd_zmm_k1z_zmmm512
INSTRUCTION: EVEX.512.66.0F.W1 10 /r | VMOVUPD zmm1 {k1}{z}, zmm2/m512 | AVX512F | N64
	ops: wvmm=reg r=rm | Packed512_Float64
END

# Code: Movss_xmm_xmmm32
INSTRUCTION: F3 0F 10 /r | MOVSS xmm1, xmm2/m32 | SSE
	ops: wm_rwreg=reg r=rm | Float32
	masm: flags=force-size=default
END

# Code: VEX_Vmovss_xmm_xmm_xmm
INSTRUCTION: VEX.LIG.F3.0F.WIG 10 /r | VMOVSS xmm1, xmm2, xmm3 | AVX
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_Vmovss_xmm_m32
INSTRUCTION: VEX.LIG.F3.0F.WIG 10 /r | VMOVSS xmm1, m32 | AVX
	ops: w=reg r=rm | Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vmovss_xmm_k1z_xmm_xmm
INSTRUCTION: EVEX.LIG.F3.0F.W0 10 /r | VMOVSS xmm1 {k1}{z}, xmm2, xmm3 | AVX512F
	ops: w=reg r=vvvv r=rm
END

# Code: EVEX_Vmovss_xmm_k1z_m32
INSTRUCTION: EVEX.LIG.F3.0F.W0 10 /r | VMOVSS xmm1 {k1}{z}, m32 | AVX512F | N4
	ops: w=reg r=rm | Float32
	masm: flags=force-size=default
END

# Code: Movsd_xmm_xmmm64
INSTRUCTION: F2 0F 10 /r | MOVSD xmm1, xmm2/m64 | SSE2
	ops: wm_rwreg=reg r=rm | Float64
	masm: flags=force-size=default
END

# Code: VEX_Vmovsd_xmm_xmm_xmm
INSTRUCTION: VEX.LIG.F2.0F.WIG 10 /r | VMOVSD xmm1, xmm2, xmm3 | AVX
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_Vmovsd_xmm_m64
INSTRUCTION: VEX.LIG.F2.0F.WIG 10 /r | VMOVSD xmm1, m64 | AVX
	ops: w=reg r=rm | Float64
	masm: flags=force-size=default
END

# Code: EVEX_Vmovsd_xmm_k1z_xmm_xmm
INSTRUCTION: EVEX.LIG.F2.0F.W1 10 /r | VMOVSD xmm1 {k1}{z}, xmm2, xmm3 | AVX512F
	ops: w=reg r=vvvv r=rm
END

# Code: EVEX_Vmovsd_xmm_k1z_m64
INSTRUCTION: EVEX.LIG.F2.0F.W1 10 /r | VMOVSD xmm1 {k1}{z}, m64 | AVX512F | N8
	ops: w=reg r=rm | Float64
	masm: flags=force-size=default
END

# Code: Movups_xmmm128_xmm
INSTRUCTION: NP 0F 11 /r | MOVUPS xmm2/m128, xmm1 | SSE
	ops: w=rm r=reg | Packed128_Float32
END

# Code: VEX_Vmovups_xmmm128_xmm
INSTRUCTION: VEX.128.0F.WIG 11 /r | VMOVUPS xmm2/m128, xmm1 | AVX
	ops: w=rm r=reg | Packed128_Float32
END

# Code: VEX_Vmovups_ymmm256_ymm
INSTRUCTION: VEX.256.0F.WIG 11 /r | VMOVUPS ymm2/m256, ymm1 | AVX
	ops: w=rm r=reg | Packed256_Float32
END

# Code: EVEX_Vmovups_xmmm128_k1z_xmm
INSTRUCTION: EVEX.128.0F.W0 11 /r | VMOVUPS xmm2/m128 {k1}{z}, xmm1 | AVX512VL AVX512F | N16
	ops: w=rm r=reg | Packed128_Float32
END

# Code: EVEX_Vmovups_ymmm256_k1z_ymm
INSTRUCTION: EVEX.256.0F.W0 11 /r | VMOVUPS ymm2/m256 {k1}{z}, ymm1 | AVX512VL AVX512F | N32
	ops: w=rm r=reg | Packed256_Float32
END

# Code: EVEX_Vmovups_zmmm512_k1z_zmm
INSTRUCTION: EVEX.512.0F.W0 11 /r | VMOVUPS zmm2/m512 {k1}{z}, zmm1 | AVX512F | N64
	ops: wvmm=rm r=reg | Packed512_Float32
END

# Code: Movupd_xmmm128_xmm
INSTRUCTION: 66 0F 11 /r | MOVUPD xmm2/m128, xmm1 | SSE2
	ops: w=rm r=reg | Packed128_Float64
END

# Code: VEX_Vmovupd_xmmm128_xmm
INSTRUCTION: VEX.128.66.0F.WIG 11 /r | VMOVUPD xmm2/m128, xmm1 | AVX
	ops: w=rm r=reg | Packed128_Float64
END

# Code: VEX_Vmovupd_ymmm256_ymm
INSTRUCTION: VEX.256.66.0F.WIG 11 /r | VMOVUPD ymm2/m256, ymm1 | AVX
	ops: w=rm r=reg | Packed256_Float64
END

# Code: EVEX_Vmovupd_xmmm128_k1z_xmm
INSTRUCTION: EVEX.128.66.0F.W1 11 /r | VMOVUPD xmm2/m128 {k1}{z}, xmm1 | AVX512VL AVX512F | N16
	ops: w=rm r=reg | Packed128_Float64
END

# Code: EVEX_Vmovupd_ymmm256_k1z_ymm
INSTRUCTION: EVEX.256.66.0F.W1 11 /r | VMOVUPD ymm2/m256 {k1}{z}, ymm1 | AVX512VL AVX512F | N32
	ops: w=rm r=reg | Packed256_Float64
END

# Code: EVEX_Vmovupd_zmmm512_k1z_zmm
INSTRUCTION: EVEX.512.66.0F.W1 11 /r | VMOVUPD zmm2/m512 {k1}{z}, zmm1 | AVX512F | N64
	ops: wvmm=rm r=reg | Packed512_Float64
END

# Code: Movss_xmmm32_xmm
INSTRUCTION: F3 0F 11 /r | MOVSS xmm2/m32, xmm1 | SSE
	ops: wm_rwreg=rm r=reg | Float32
	masm: flags=force-size=default
END

# Code: VEX_Vmovss_xmm_xmm_xmm_0F11
INSTRUCTION: VEX.LIG.F3.0F.WIG 11 /r | VMOVSS xmm1, xmm2, xmm3 | AVX
	ops: w=rm r=vvvv r=reg
	code-suffix: 0F11
	flags: asm-ig
END

# Code: VEX_Vmovss_m32_xmm
INSTRUCTION: VEX.LIG.F3.0F.WIG 11 /r | VMOVSS m32, xmm1 | AVX
	ops: w=rm r=reg | Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vmovss_xmm_k1z_xmm_xmm_0F11
INSTRUCTION: EVEX.LIG.F3.0F.W0 11 /r | VMOVSS xmm1 {k1}{z}, xmm2, xmm3 | AVX512F
	ops: w=rm r=vvvv r=reg
	code-suffix: 0F11
	flags: asm-ig
END

# Code: EVEX_Vmovss_m32_k1_xmm
INSTRUCTION: EVEX.LIG.F3.0F.W0 11 /r | VMOVSS m32 {k1}, xmm1 | AVX512F | N4
	ops: w=rm r=reg | Float32
	masm: flags=force-size=default
END

# Code: Movsd_xmmm64_xmm
INSTRUCTION: F2 0F 11 /r | MOVSD xmm1/m64, xmm2 | SSE2
	ops: wm_rwreg=rm r=reg | Float64
	masm: flags=force-size=default
END

# Code: VEX_Vmovsd_xmm_xmm_xmm_0F11
INSTRUCTION: VEX.LIG.F2.0F.WIG 11 /r | VMOVSD xmm1, xmm2, xmm3 | AVX
	ops: w=rm r=vvvv r=reg
	code-suffix: 0F11
	flags: asm-ig
END

# Code: VEX_Vmovsd_m64_xmm
INSTRUCTION: VEX.LIG.F2.0F.WIG 11 /r | VMOVSD m64, xmm1 | AVX
	ops: w=rm r=reg | Float64
	masm: flags=force-size=default
END

# Code: EVEX_Vmovsd_xmm_k1z_xmm_xmm_0F11
INSTRUCTION: EVEX.LIG.F2.0F.W1 11 /r | VMOVSD xmm1 {k1}{z}, xmm2, xmm3 | AVX512F
	ops: w=rm r=vvvv r=reg
	code-suffix: 0F11
	flags: asm-ig
END

# Code: EVEX_Vmovsd_m64_k1_xmm
INSTRUCTION: EVEX.LIG.F2.0F.W1 11 /r | VMOVSD m64 {k1}, xmm1 | AVX512F | N8
	ops: w=rm r=reg | Float64
	masm: flags=force-size=default
END

# Code: Movhlps_xmm_xmm
INSTRUCTION: NP 0F 12 /r | MOVHLPS xmm1, xmm2 | SSE
	ops: rw=reg r=rm
END

# Code: Movlps_xmm_m64
INSTRUCTION: NP 0F 12 /r | MOVLPS xmm1, m64 | SSE
	ops: rw=reg r=rm | Packed64_Float32
	masm: flags=force-size=default
END

# Code: VEX_Vmovhlps_xmm_xmm_xmm
INSTRUCTION: VEX.128.0F.WIG 12 /r | VMOVHLPS xmm1, xmm2, xmm3 | AVX
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_Vmovlps_xmm_xmm_m64
INSTRUCTION: VEX.128.0F.WIG 12 /r | VMOVLPS xmm2, xmm1, m64 | AVX
	ops: w=reg r=vvvv r=rm | Packed64_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vmovhlps_xmm_xmm_xmm
INSTRUCTION: EVEX.128.0F.W0 12 /r | VMOVHLPS xmm1, xmm2, xmm3 | AVX512F
	ops: w=reg r=vvvv r=rm
END

# Code: EVEX_Vmovlps_xmm_xmm_m64
INSTRUCTION: EVEX.128.0F.W0 12 /r | VMOVLPS xmm2, xmm1, m64 | AVX512F | N8
	ops: w=reg r=vvvv r=rm | Packed64_Float32
	masm: flags=force-size=default
END

# Code: Movlpd_xmm_m64
INSTRUCTION: 66 0F 12 /r | MOVLPD xmm1, m64 | SSE2
	ops: rw=reg r=rm | Float64
	masm: flags=force-size=default
END

# Code: VEX_Vmovlpd_xmm_xmm_m64
INSTRUCTION: VEX.128.66.0F.WIG 12 /r | VMOVLPD xmm2, xmm1, m64 | AVX
	ops: w=reg r=vvvv r=rm | Float64
	masm: flags=force-size=default
END

# Code: EVEX_Vmovlpd_xmm_xmm_m64
INSTRUCTION: EVEX.128.66.0F.W1 12 /r | VMOVLPD xmm2, xmm1, m64 | AVX512F | N8
	ops: w=reg r=vvvv r=rm | Float64
	masm: flags=force-size=default
END

# Code: Movsldup_xmm_xmmm128
INSTRUCTION: F3 0F 12 /r | MOVSLDUP xmm1, xmm2/m128 | SSE3
	ops: w=reg r=rm | Packed128_Float32
END

# Code: VEX_Vmovsldup_xmm_xmmm128
INSTRUCTION: VEX.128.F3.0F.WIG 12 /r | VMOVSLDUP xmm1, xmm2/m128 | AVX
	ops: w=reg r=rm | Packed128_Float32
	masm: flags=force-size=default
END

# Code: VEX_Vmovsldup_ymm_ymmm256
INSTRUCTION: VEX.256.F3.0F.WIG 12 /r | VMOVSLDUP ymm1, ymm2/m256 | AVX
	ops: w=reg r=rm | Packed256_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vmovsldup_xmm_k1z_xmmm128
INSTRUCTION: EVEX.128.F3.0F.W0 12 /r | VMOVSLDUP xmm1 {k1}{z}, xmm2/m128 | AVX512VL AVX512F | N16
	ops: w=reg r=rm | Packed128_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vmovsldup_ymm_k1z_ymmm256
INSTRUCTION: EVEX.256.F3.0F.W0 12 /r | VMOVSLDUP ymm1 {k1}{z}, ymm2/m256 | AVX512VL AVX512F | N32
	ops: w=reg r=rm | Packed256_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vmovsldup_zmm_k1z_zmmm512
INSTRUCTION: EVEX.512.F3.0F.W0 12 /r | VMOVSLDUP zmm1 {k1}{z}, zmm2/m512 | AVX512F | N64
	ops: wvmm=reg r=rm | Packed512_Float32
	masm: flags=force-size=default
END

# Code: Movddup_xmm_xmmm64
INSTRUCTION: F2 0F 12 /r | MOVDDUP xmm1, xmm2/m64 | SSE3
	ops: w=reg r=rm | Float64
	masm: flags=force-size=default
END

# Code: VEX_Vmovddup_xmm_xmmm64
INSTRUCTION: VEX.128.F2.0F.WIG 12 /r | VMOVDDUP xmm1, xmm2/m64 | AVX
	ops: w=reg r=rm | Float64
	masm: flags=force-size=default
END

# Code: VEX_Vmovddup_ymm_ymmm256
INSTRUCTION: VEX.256.F2.0F.WIG 12 /r | VMOVDDUP ymm1, ymm2/m256 | AVX
	ops: w=reg r=rm | Packed256_Float64
	masm: flags=force-size=default
END

# Code: EVEX_Vmovddup_xmm_k1z_xmmm64
INSTRUCTION: EVEX.128.F2.0F.W1 12 /r | VMOVDDUP xmm1 {k1}{z}, xmm2/m64 | AVX512VL AVX512F | N8
	ops: w=reg r=rm | Float64
	masm: flags=force-size=default
END

# Code: EVEX_Vmovddup_ymm_k1z_ymmm256
INSTRUCTION: EVEX.256.F2.0F.W1 12 /r | VMOVDDUP ymm1 {k1}{z}, ymm2/m256 | AVX512VL AVX512F | N32
	ops: w=reg r=rm | Packed256_Float64
	masm: flags=force-size=default
END

# Code: EVEX_Vmovddup_zmm_k1z_zmmm512
INSTRUCTION: EVEX.512.F2.0F.W1 12 /r | VMOVDDUP zmm1 {k1}{z}, zmm2/m512 | AVX512F | N64
	ops: wvmm=reg r=rm | Packed512_Float64
	masm: flags=force-size=default
END

# Code: Movlps_m64_xmm
INSTRUCTION: NP 0F 13 /r | MOVLPS m64, xmm1 | SSE
	ops: w=rm r=reg | Packed64_Float32
	masm: flags=force-size=default
END

# Code: VEX_Vmovlps_m64_xmm
INSTRUCTION: VEX.128.0F.WIG 13 /r | VMOVLPS m64, xmm1 | AVX
	ops: w=rm r=reg | Packed64_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vmovlps_m64_xmm
INSTRUCTION: EVEX.128.0F.W0 13 /r | VMOVLPS m64, xmm1 | AVX512F | N8
	ops: w=rm r=reg | Packed64_Float32
	masm: flags=force-size=default
END

# Code: Movlpd_m64_xmm
INSTRUCTION: 66 0F 13 /r | MOVLPD m64, xmm1 | SSE2
	ops: w=rm r=reg | Float64
	masm: flags=force-size=default
END

# Code: VEX_Vmovlpd_m64_xmm
INSTRUCTION: VEX.128.66.0F.WIG 13 /r | VMOVLPD m64, xmm1 | AVX
	ops: w=rm r=reg | Float64
	masm: flags=force-size=default
END

# Code: EVEX_Vmovlpd_m64_xmm
INSTRUCTION: EVEX.128.66.0F.W1 13 /r | VMOVLPD m64, xmm1 | AVX512F | N8
	ops: w=rm r=reg | Float64
	masm: flags=force-size=default
END

# Code: Unpcklps_xmm_xmmm128
INSTRUCTION: NP 0F 14 /r | UNPCKLPS xmm1, xmm2/m128 | SSE
	ops: rw=reg r=rm | Packed128_Float32
END

# Code: VEX_Vunpcklps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.0F.WIG 14 /r | VUNPCKLPS xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vunpcklps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.0F.WIG 14 /r | VUNPCKLPS ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float32
END

# Code: EVEX_Vunpcklps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.0F.W0 14 /r | VUNPCKLPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vunpcklps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.0F.W0 14 /r | VUNPCKLPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vunpcklps_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.0F.W0 14 /r | VUNPCKLPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: Unpcklpd_xmm_xmmm128
INSTRUCTION: 66 0F 14 /r | UNPCKLPD xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_Float64
END

# Code: VEX_Vunpcklpd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 14 /r | VUNPCKLPD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vunpcklpd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 14 /r | VUNPCKLPD ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vunpcklpd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F.W1 14 /r | VUNPCKLPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vunpcklpd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F.W1 14 /r | VUNPCKLPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vunpcklpd_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F.W1 14 /r | VUNPCKLPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: Unpckhps_xmm_xmmm128
INSTRUCTION: NP 0F 15 /r | UNPCKHPS xmm1, xmm2/m128 | SSE
	ops: rw=reg r=rm | Packed128_Float32
END

# Code: VEX_Vunpckhps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.0F.WIG 15 /r | VUNPCKHPS xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vunpckhps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.0F.WIG 15 /r | VUNPCKHPS ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float32
END

# Code: EVEX_Vunpckhps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.0F.W0 15 /r | VUNPCKHPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vunpckhps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.0F.W0 15 /r | VUNPCKHPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vunpckhps_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.0F.W0 15 /r | VUNPCKHPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: Unpckhpd_xmm_xmmm128
INSTRUCTION: 66 0F 15 /r | UNPCKHPD xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_Float64
END

# Code: VEX_Vunpckhpd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 15 /r | VUNPCKHPD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vunpckhpd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 15 /r | VUNPCKHPD ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vunpckhpd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F.W1 15 /r | VUNPCKHPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vunpckhpd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F.W1 15 /r | VUNPCKHPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vunpckhpd_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F.W1 15 /r | VUNPCKHPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: Movlhps_xmm_xmm
INSTRUCTION: NP 0F 16 /r | MOVLHPS xmm1, xmm2 | SSE
	ops: rw=reg r=rm
END

# Code: VEX_Vmovlhps_xmm_xmm_xmm
INSTRUCTION: VEX.128.0F.WIG 16 /r | VMOVLHPS xmm1, xmm2, xmm3 | AVX
	ops: w=reg r=vvvv r=rm
END

# Code: EVEX_Vmovlhps_xmm_xmm_xmm
INSTRUCTION: EVEX.128.0F.W0 16 /r | VMOVLHPS xmm1, xmm2, xmm3 | AVX512F
	ops: w=reg r=vvvv r=rm
END

# Code: Movhps_xmm_m64
INSTRUCTION: NP 0F 16 /r | MOVHPS xmm1, m64 | SSE
	ops: rw=reg r=rm | Packed64_Float32
	masm: flags=force-size=default
END

# Code: VEX_Vmovhps_xmm_xmm_m64
INSTRUCTION: VEX.128.0F.WIG 16 /r | VMOVHPS xmm2, xmm1, m64 | AVX
	ops: w=reg r=vvvv r=rm | Packed64_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vmovhps_xmm_xmm_m64
INSTRUCTION: EVEX.128.0F.W0 16 /r | VMOVHPS xmm2, xmm1, m64 | AVX512F | N8
	ops: w=reg r=vvvv r=rm | Packed64_Float32
	masm: flags=force-size=default
END

# Code: Movhpd_xmm_m64
INSTRUCTION: 66 0F 16 /r | MOVHPD xmm1, m64 | SSE2
	ops: rw=reg r=rm | Float64
	masm: flags=force-size=default
END

# Code: VEX_Vmovhpd_xmm_xmm_m64
INSTRUCTION: VEX.128.66.0F.WIG 16 /r | VMOVHPD xmm2, xmm1, m64 | AVX
	ops: w=reg r=vvvv r=rm | Float64
	masm: flags=force-size=default
END

# Code: EVEX_Vmovhpd_xmm_xmm_m64
INSTRUCTION: EVEX.128.66.0F.W1 16 /r | VMOVHPD xmm2, xmm1, m64 | AVX512F | N8
	ops: w=reg r=vvvv r=rm | Float64
	masm: flags=force-size=default
END

# Code: Movshdup_xmm_xmmm128
INSTRUCTION: F3 0F 16 /r | MOVSHDUP xmm1, xmm2/m128 | SSE3
	ops: w=reg r=rm | Packed128_Float32
END

# Code: VEX_Vmovshdup_xmm_xmmm128
INSTRUCTION: VEX.128.F3.0F.WIG 16 /r | VMOVSHDUP xmm1, xmm2/m128 | AVX
	ops: w=reg r=rm | Packed128_Float32
	masm: flags=force-size=default
END

# Code: VEX_Vmovshdup_ymm_ymmm256
INSTRUCTION: VEX.256.F3.0F.WIG 16 /r | VMOVSHDUP ymm1, ymm2/m256 | AVX
	ops: w=reg r=rm | Packed256_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vmovshdup_xmm_k1z_xmmm128
INSTRUCTION: EVEX.128.F3.0F.W0 16 /r | VMOVSHDUP xmm1 {k1}{z}, xmm2/m128 | AVX512VL AVX512F | N16
	ops: w=reg r=rm | Packed128_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vmovshdup_ymm_k1z_ymmm256
INSTRUCTION: EVEX.256.F3.0F.W0 16 /r | VMOVSHDUP ymm1 {k1}{z}, ymm2/m256 | AVX512VL AVX512F | N32
	ops: w=reg r=rm | Packed256_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vmovshdup_zmm_k1z_zmmm512
INSTRUCTION: EVEX.512.F3.0F.W0 16 /r | VMOVSHDUP zmm1 {k1}{z}, zmm2/m512 | AVX512F | N64
	ops: wvmm=reg r=rm | Packed512_Float32
	masm: flags=force-size=default
END

# Code: Movhps_m64_xmm
INSTRUCTION: NP 0F 17 /r | MOVHPS m64, xmm1 | SSE
	ops: w=rm r=reg | Packed64_Float32
	masm: flags=force-size=default
END

# Code: VEX_Vmovhps_m64_xmm
INSTRUCTION: VEX.128.0F.WIG 17 /r | VMOVHPS m64, xmm1 | AVX
	ops: w=rm r=reg | Packed64_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vmovhps_m64_xmm
INSTRUCTION: EVEX.128.0F.W0 17 /r | VMOVHPS m64, xmm1 | AVX512F | N8
	ops: w=rm r=reg | Packed64_Float32
	masm: flags=force-size=default
END

# Code: Movhpd_m64_xmm
INSTRUCTION: 66 0F 17 /r | MOVHPD m64, xmm1 | SSE2
	ops: w=rm r=reg | Float64
	masm: flags=force-size=default
END

# Code: VEX_Vmovhpd_m64_xmm
INSTRUCTION: VEX.128.66.0F.WIG 17 /r | VMOVHPD m64, xmm1 | AVX
	ops: w=rm r=reg | Float64
	masm: flags=force-size=default
END

# Code: EVEX_Vmovhpd_m64_xmm
INSTRUCTION: EVEX.128.66.0F.W1 17 /r | VMOVHPD m64, xmm1 | AVX512F | N8
	ops: w=rm r=reg | Float64
	masm: flags=force-size=default
END

# Code: Reservednop_rm16_r16_0F18
INSTRUCTION: o16 0F 18 /r | RESERVEDNOP r/m16, r16 | MULTIBYTENOP
	ops: n=rm n=reg | UInt16
	code-suffix: 0F18
	flags: nop res-nop asm=reservednop_0f18
	fast: mnemonic=nop
	gas: mnemonic=nop suffix=w
	intel: mnemonic=nop
	masm: mnemonic=nop
	nasm: mnemonic=nop
END

# Code: Reservednop_rm32_r32_0F18
INSTRUCTION: o32 0F 18 /r | RESERVEDNOP r/m32, r32 | MULTIBYTENOP
	ops: n=rm n=reg | UInt32
	code-suffix: 0F18
	flags: nop res-nop asm=reservednop_0f18
	fast: mnemonic=nop
	gas: mnemonic=nop suffix=l
	intel: mnemonic=nop
	masm: mnemonic=nop
	nasm: mnemonic=nop
END

# Code: Reservednop_rm64_r64_0F18
INSTRUCTION: o64 0F 18 /r | RESERVEDNOP r/m64, r64 | MULTIBYTENOP
	ops: n=rm n=reg | UInt64
	code-suffix: 0F18
	flags: 64 nop res-nop asm=reservednop_0f18
	fast: mnemonic=nop
	gas: mnemonic=nop suffix=q
	intel: mnemonic=nop
	masm: mnemonic=nop
	nasm: mnemonic=nop
END

# Code: Reservednop_rm16_r16_0F19
INSTRUCTION: o16 0F 19 /r | RESERVEDNOP r/m16, r16 | MULTIBYTENOP
	ops: n=rm n=reg | UInt16
	code-suffix: 0F19
	flags: nop res-nop asm=reservednop_0f19
	fast: mnemonic=nop
	gas: mnemonic=nop suffix=w
	intel: mnemonic=nop
	masm: mnemonic=nop
	nasm: mnemonic=nop
END

# Code: Reservednop_rm32_r32_0F19
INSTRUCTION: o32 0F 19 /r | RESERVEDNOP r/m32, r32 | MULTIBYTENOP
	ops: n=rm n=reg | UInt32
	code-suffix: 0F19
	flags: nop res-nop asm=reservednop_0f19
	fast: mnemonic=nop
	gas: mnemonic=nop suffix=l
	intel: mnemonic=nop
	masm: mnemonic=nop
	nasm: mnemonic=nop
END

# Code: Reservednop_rm64_r64_0F19
INSTRUCTION: o64 0F 19 /r | RESERVEDNOP r/m64, r64 | MULTIBYTENOP
	ops: n=rm n=reg | UInt64
	code-suffix: 0F19
	flags: 64 nop res-nop asm=reservednop_0f19
	fast: mnemonic=nop
	gas: mnemonic=nop suffix=q
	intel: mnemonic=nop
	masm: mnemonic=nop
	nasm: mnemonic=nop
END

# Code: Reservednop_rm16_r16_0F1A
INSTRUCTION: o16 0F 1A /r | RESERVEDNOP r/m16, r16 | MULTIBYTENOP
	ops: n=rm n=reg | UInt16
	code-suffix: 0F1A
	flags: nop res-nop asm=reservednop_0f1a
	fast: mnemonic=nop
	gas: mnemonic=nop suffix=w
	intel: mnemonic=nop
	masm: mnemonic=nop
	nasm: mnemonic=nop
END

# Code: Reservednop_rm32_r32_0F1A
INSTRUCTION: o32 0F 1A /r | RESERVEDNOP r/m32, r32 | MULTIBYTENOP
	ops: n=rm n=reg | UInt32
	code-suffix: 0F1A
	flags: nop res-nop asm=reservednop_0f1a
	fast: mnemonic=nop
	gas: mnemonic=nop suffix=l
	intel: mnemonic=nop
	masm: mnemonic=nop
	nasm: mnemonic=nop
END

# Code: Reservednop_rm64_r64_0F1A
INSTRUCTION: o64 0F 1A /r | RESERVEDNOP r/m64, r64 | MULTIBYTENOP
	ops: n=rm n=reg | UInt64
	code-suffix: 0F1A
	flags: 64 nop res-nop asm=reservednop_0f1a
	fast: mnemonic=nop
	gas: mnemonic=nop suffix=q
	intel: mnemonic=nop
	masm: mnemonic=nop
	nasm: mnemonic=nop
END

# Code: Reservednop_rm16_r16_0F1B
INSTRUCTION: o16 0F 1B /r | RESERVEDNOP r/m16, r16 | MULTIBYTENOP
	ops: n=rm n=reg | UInt16
	code-suffix: 0F1B
	flags: nop res-nop asm=reservednop_0f1b
	fast: mnemonic=nop
	gas: mnemonic=nop suffix=w
	intel: mnemonic=nop
	masm: mnemonic=nop
	nasm: mnemonic=nop
END

# Code: Reservednop_rm32_r32_0F1B
INSTRUCTION: o32 0F 1B /r | RESERVEDNOP r/m32, r32 | MULTIBYTENOP
	ops: n=rm n=reg | UInt32
	code-suffix: 0F1B
	flags: nop res-nop asm=reservednop_0f1b
	fast: mnemonic=nop
	gas: mnemonic=nop suffix=l
	intel: mnemonic=nop
	masm: mnemonic=nop
	nasm: mnemonic=nop
END

# Code: Reservednop_rm64_r64_0F1B
INSTRUCTION: o64 0F 1B /r | RESERVEDNOP r/m64, r64 | MULTIBYTENOP
	ops: n=rm n=reg | UInt64
	code-suffix: 0F1B
	flags: 64 nop res-nop asm=reservednop_0f1b
	fast: mnemonic=nop
	gas: mnemonic=nop suffix=q
	intel: mnemonic=nop
	masm: mnemonic=nop
	nasm: mnemonic=nop
END

# Code: Reservednop_rm16_r16_0F1C
INSTRUCTION: o16 0F 1C /r | RESERVEDNOP r/m16, r16 | MULTIBYTENOP
	ops: n=rm n=reg | UInt16
	code-suffix: 0F1C
	flags: nop res-nop asm=reservednop_0f1c
	fast: mnemonic=nop
	gas: mnemonic=nop suffix=w
	intel: mnemonic=nop
	masm: mnemonic=nop
	nasm: mnemonic=nop
END

# Code: Reservednop_rm32_r32_0F1C
INSTRUCTION: o32 0F 1C /r | RESERVEDNOP r/m32, r32 | MULTIBYTENOP
	ops: n=rm n=reg | UInt32
	code-suffix: 0F1C
	flags: nop res-nop asm=reservednop_0f1c
	fast: mnemonic=nop
	gas: mnemonic=nop suffix=l
	intel: mnemonic=nop
	masm: mnemonic=nop
	nasm: mnemonic=nop
END

# Code: Reservednop_rm64_r64_0F1C
INSTRUCTION: o64 0F 1C /r | RESERVEDNOP r/m64, r64 | MULTIBYTENOP
	ops: n=rm n=reg | UInt64
	code-suffix: 0F1C
	flags: 64 nop res-nop asm=reservednop_0f1c
	fast: mnemonic=nop
	gas: mnemonic=nop suffix=q
	intel: mnemonic=nop
	masm: mnemonic=nop
	nasm: mnemonic=nop
END

# Code: Reservednop_rm16_r16_0F1D
INSTRUCTION: o16 0F 1D /r | RESERVEDNOP r/m16, r16 | MULTIBYTENOP
	ops: n=rm n=reg | UInt16
	code-suffix: 0F1D
	flags: nop res-nop asm=reservednop_0f1d
	fast: mnemonic=nop
	gas: mnemonic=nop suffix=w
	intel: mnemonic=nop
	masm: mnemonic=nop
	nasm: mnemonic=nop
END

# Code: Reservednop_rm32_r32_0F1D
INSTRUCTION: o32 0F 1D /r | RESERVEDNOP r/m32, r32 | MULTIBYTENOP
	ops: n=rm n=reg | UInt32
	code-suffix: 0F1D
	flags: nop res-nop asm=reservednop_0f1d
	fast: mnemonic=nop
	gas: mnemonic=nop suffix=l
	intel: mnemonic=nop
	masm: mnemonic=nop
	nasm: mnemonic=nop
END

# Code: Reservednop_rm64_r64_0F1D
INSTRUCTION: o64 0F 1D /r | RESERVEDNOP r/m64, r64 | MULTIBYTENOP
	ops: n=rm n=reg | UInt64
	code-suffix: 0F1D
	flags: 64 nop res-nop asm=reservednop_0f1d
	fast: mnemonic=nop
	gas: mnemonic=nop suffix=q
	intel: mnemonic=nop
	masm: mnemonic=nop
	nasm: mnemonic=nop
END

# Code: Reservednop_rm16_r16_0F1E
INSTRUCTION: o16 0F 1E /r | RESERVEDNOP r/m16, r16 | MULTIBYTENOP
	ops: n=rm n=reg | UInt16
	code-suffix: 0F1E
	flags: nop res-nop asm=reservednop_0f1e
	fast: mnemonic=nop
	gas: mnemonic=nop suffix=w
	intel: mnemonic=nop
	masm: mnemonic=nop
	nasm: mnemonic=nop
END

# Code: Reservednop_rm32_r32_0F1E
INSTRUCTION: o32 0F 1E /r | RESERVEDNOP r/m32, r32 | MULTIBYTENOP
	ops: n=rm n=reg | UInt32
	code-suffix: 0F1E
	flags: nop res-nop asm=reservednop_0f1e
	fast: mnemonic=nop
	gas: mnemonic=nop suffix=l
	intel: mnemonic=nop
	masm: mnemonic=nop
	nasm: mnemonic=nop
END

# Code: Reservednop_rm64_r64_0F1E
INSTRUCTION: o64 0F 1E /r | RESERVEDNOP r/m64, r64 | MULTIBYTENOP
	ops: n=rm n=reg | UInt64
	code-suffix: 0F1E
	flags: 64 nop res-nop asm=reservednop_0f1e
	fast: mnemonic=nop
	gas: mnemonic=nop suffix=q
	intel: mnemonic=nop
	masm: mnemonic=nop
	nasm: mnemonic=nop
END

# Code: Reservednop_rm16_r16_0F1F
INSTRUCTION: o16 0F 1F /r | RESERVEDNOP r/m16, r16 | MULTIBYTENOP
	ops: n=rm n=reg | UInt16
	code-suffix: 0F1F
	flags: nop res-nop asm=reservednop_0f1f
	fast: mnemonic=nop
	gas: mnemonic=nop suffix=w
	intel: mnemonic=nop
	masm: mnemonic=nop
	nasm: mnemonic=nop
END

# Code: Reservednop_rm32_r32_0F1F
INSTRUCTION: o32 0F 1F /r | RESERVEDNOP r/m32, r32 | MULTIBYTENOP
	ops: n=rm n=reg | UInt32
	code-suffix: 0F1F
	flags: nop res-nop asm=reservednop_0f1f
	fast: mnemonic=nop
	gas: mnemonic=nop suffix=l
	intel: mnemonic=nop
	masm: mnemonic=nop
	nasm: mnemonic=nop
END

# Code: Reservednop_rm64_r64_0F1F
INSTRUCTION: o64 0F 1F /r | RESERVEDNOP r/m64, r64 | MULTIBYTENOP
	ops: n=rm n=reg | UInt64
	code-suffix: 0F1F
	flags: 64 nop res-nop asm=reservednop_0f1f
	fast: mnemonic=nop
	gas: mnemonic=nop suffix=q
	intel: mnemonic=nop
	masm: mnemonic=nop
	nasm: mnemonic=nop
END

# Code: Prefetchnta_m8
INSTRUCTION: 0F 18 /0 | PREFETCHNTA m8 | SSE
	ops: nma=rm | UInt8
	# May cause TSX abort because of non-temporal hint
	flags: prefetch tsx-impl-abort non-temporal
END

# Code: Prefetcht0_m8
INSTRUCTION: 0F 18 /1 | PREFETCHT0 m8 | SSE
	ops: nma=rm | UInt8
	flags: prefetch
END

# Code: Prefetcht1_m8
INSTRUCTION: 0F 18 /2 | PREFETCHT1 m8 | SSE
	ops: nma=rm | UInt8
	flags: prefetch
END

# Code: Prefetcht2_m8
INSTRUCTION: 0F 18 /3 | PREFETCHT2 m8 | SSE
	ops: nma=rm | UInt8
	flags: prefetch
END

# Code: Bndldx_bnd_mib
INSTRUCTION: NP 0F 1A /r | BNDLDX bnd, mib | MPX
	ops: w=reg nma=rm
	# TSX abort if non-flat segment
	flags: dec-opt=MPX ignores-index tsx-impl-abort
	intel: flags=mem-size=ignore
	masm: flags=force-size=default;mem-size=dorq
	nasm: flags=mem-size=ignore
END

# Code: Bndmov_bnd_bndm64
INSTRUCTION: 66 0F 1A /r | BNDMOV bnd1, bnd2/m64 | MPX
	ops: w=reg r=rm;mpx | Bnd32
	flags: 16 32 dec-opt=MPX
	intel: flags=force-size=default
	masm: flags=force-size=default
	nasm: flags=mem-size=ignore
END

# Code: Bndmov_bnd_bndm128
INSTRUCTION: 66 0F 1A /r | BNDMOV bnd1, bnd2/m128 | MPX
	ops: w=reg r=rm;mpx | Bnd64
	flags: 64 dec-opt=MPX
	intel: flags=force-size=default
	masm: flags=force-size=default
	nasm: flags=mem-size=ignore
END

# Code: Bndcl_bnd_rm32
INSTRUCTION: F3 0F 1A /r | BNDCL bnd, r/m32 | MPX
	ops: r=reg nma=rm;mpx | UInt32
	flags: 16 32 dec-opt=MPX ignores-seg
	intel: flags=mem-size=ignore
	nasm: flags=mem-size=ignore
END

# Code: Bndcl_bnd_rm64
INSTRUCTION: F3 0F 1A /r | BNDCL bnd, r/m64 | MPX
	ops: r=reg nma=rm;mpx | UInt64
	flags: 64 dec-opt=MPX ignores-seg
	intel: flags=mem-size=ignore
	nasm: flags=mem-size=ignore
END

# Code: Bndcu_bnd_rm32
INSTRUCTION: F2 0F 1A /r | BNDCU bnd, r/m32 | MPX
	ops: r=reg nma=rm;mpx | UInt32
	flags: 16 32 dec-opt=MPX ignores-seg
	intel: flags=mem-size=ignore
	nasm: flags=mem-size=ignore
END

# Code: Bndcu_bnd_rm64
INSTRUCTION: F2 0F 1A /r | BNDCU bnd, r/m64 | MPX
	ops: r=reg nma=rm;mpx | UInt64
	flags: 64 dec-opt=MPX ignores-seg
	intel: flags=mem-size=ignore
	nasm: flags=mem-size=ignore
END

# Code: Bndstx_mib_bnd
INSTRUCTION: NP 0F 1B /r | BNDSTX mib, bnd | MPX
	ops: nma=rm r=reg
	# TSX abort if non-flat segment
	flags: dec-opt=MPX ignores-index tsx-impl-abort
	intel: flags=mem-size=ignore
	masm: flags=force-size=default;mem-size=dorq
	nasm: flags=mem-size=ignore
END

# Code: Bndmov_bndm64_bnd
INSTRUCTION: 66 0F 1B /r | BNDMOV bnd1/m64, bnd2 | MPX
	ops: w=rm;mpx r=reg | Bnd32
	flags: 16 32 dec-opt=MPX
	intel: flags=force-size=default
	masm: flags=force-size=default
	nasm: flags=mem-size=ignore
END

# Code: Bndmov_bndm128_bnd
INSTRUCTION: 66 0F 1B /r | BNDMOV bnd1/m128, bnd2 | MPX
	ops: w=rm;mpx r=reg | Bnd64
	flags: 64 dec-opt=MPX
	intel: flags=force-size=default
	masm: flags=force-size=default
	nasm: flags=mem-size=ignore
END

# Code: Bndmk_bnd_m32
INSTRUCTION: F3 0F 1B /r | BNDMK bnd, m32 | MPX
	ops: w=reg nma=rm;mpx | UInt32
	flags: 16 32 dec-opt=MPX ignores-seg
	intel: flags=mem-size=ignore
	masm: flags=force-size=default
	nasm: flags=mem-size=ignore
END

# Code: Bndmk_bnd_m64
INSTRUCTION: F3 0F 1B /r | BNDMK bnd, m64 | MPX
	ops: w=reg nma=rm;mpx | UInt64
	flags: 64 dec-opt=MPX ignores-seg
	intel: flags=mem-size=ignore
	masm: flags=force-size=default
	nasm: flags=mem-size=ignore
END

# Code: Bndcn_bnd_rm32
INSTRUCTION: F2 0F 1B /r | BNDCN bnd, r/m32 | MPX
	ops: r=reg nma=rm;mpx | UInt32
	flags: 16 32 dec-opt=MPX ignores-seg
	intel: flags=mem-size=ignore
	nasm: flags=mem-size=ignore
END

# Code: Bndcn_bnd_rm64
INSTRUCTION: F2 0F 1B /r | BNDCN bnd, r/m64 | MPX
	ops: r=reg nma=rm;mpx | UInt64
	flags: 64 dec-opt=MPX ignores-seg
	intel: flags=mem-size=ignore
	nasm: flags=mem-size=ignore
END

# Code: Cldemote_m8
INSTRUCTION: NP 0F 1C /0 | CLDEMOTE m8 | CLDEMOTE
	ops: nma=rm | UInt8
	flags: tsx-impl-abort
	intel: flags=mem-size=ignore
	masm: flags=force-size=default
	nasm: flags=mem-size=ignore
END

# Code: Rdsspd_r32
INSTRUCTION: F3 0F 1E /1 | RDSSPD r32 | CET_SS
	ops: w=rm
END

# Code: Rdsspq_r64
INSTRUCTION: F3 o64 0F 1E /1 | RDSSPQ r64 | CET_SS
	ops: w=rm
	flags: 64
END

# Code: Endbr64
INSTRUCTION: F3 0F 1E FA | ENDBR64 | CET_IBT
END

# Code: Endbr32
INSTRUCTION: F3 0F 1E FB | ENDBR32 | CET_IBT
END

# Code: Nop_rm16
INSTRUCTION: o16 0F 1F /0 | NOP r/m16 | MULTIBYTENOP
	ops: n=rm | UInt16
	flags: nop
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Nop_rm32
INSTRUCTION: o32 0F 1F /0 | NOP r/m32 | MULTIBYTENOP
	ops: n=rm | UInt32
	flags: nop
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Nop_rm64
INSTRUCTION: o64 0F 1F /0 | NOP r/m64 | MULTIBYTENOP
	ops: n=rm | UInt64
	flags: 64 nop
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Mov_r32_cr
INSTRUCTION: 0F 20 /r | MOV r32, cr | INTEL386
	ops: w=rm r=reg;lock
	rflags: u=oszacp
	# May cause a TSX abort if VM exit
	flags: 16 32 cpl0 ignore-mod amd-lock-reg-bit intel-may-vm-exit amd-may-vm-exit tsx-impl-abort
	gas: suffix=l
END

# Code: Mov_r64_cr
INSTRUCTION: 0F 20 /r | MOV r64, cr | X64
	ops: w=rm r=reg;lock
	rflags: u=oszacp
	# May cause a TSX abort if VM exit
	flags: 64 cpl0 fo64 ignore-mod amd-lock-reg-bit intel-may-vm-exit amd-may-vm-exit tsx-impl-abort
	gas: suffix=q
END

# Code: Mov_r32_dr
INSTRUCTION: 0F 21 /r | MOV r32, dr | INTEL386
	ops: w=rm r=reg
	rflags: u=oszacp
	# May cause a TSX abort if VM exit
	flags: 16 32 cpl0 ignore-mod intel-may-vm-exit amd-may-vm-exit tsx-impl-abort
	gas: suffix=l
END

# Code: Mov_r64_dr
INSTRUCTION: 0F 21 /r | MOV r64, dr | X64
	ops: w=rm r=reg
	rflags: u=oszacp
	# May cause a TSX abort if VM exit
	flags: 64 cpl0 fo64 ignore-mod intel-may-vm-exit amd-may-vm-exit tsx-impl-abort
	gas: suffix=q
END

# Code: Mov_cr_r32
INSTRUCTION: 0F 22 /r | MOV cr, r32 | INTEL386
	ops: w=reg;lock r=rm
	rflags: u=oszacp
	flags: 16 32 cpl0 ignore-mod amd-lock-reg-bit serialize-intel serialize-amd intel-may-vm-exit amd-may-vm-exit tsx-impl-abort
	gas: suffix=l
END

# Code: Mov_cr_r64
INSTRUCTION: 0F 22 /r | MOV cr, r64 | X64
	ops: w=reg;lock r=rm
	rflags: u=oszacp
	# Not serializing if CR8 (Intel)
	flags: 64 cpl0 fo64 ignore-mod amd-lock-reg-bit serialize-intel serialize-amd intel-may-vm-exit amd-may-vm-exit tsx-impl-abort
	gas: suffix=q
END

# Code: Mov_dr_r32
INSTRUCTION: 0F 23 /r | MOV dr, r32 | INTEL386
	ops: w=reg r=rm
	rflags: u=oszacp
	flags: 16 32 cpl0 ignore-mod serialize-intel serialize-amd intel-may-vm-exit amd-may-vm-exit tsx-impl-abort
	gas: suffix=l
END

# Code: Mov_dr_r64
INSTRUCTION: 0F 23 /r | MOV dr, r64 | X64
	ops: w=reg r=rm
	rflags: u=oszacp
	flags: 64 cpl0 fo64 ignore-mod serialize-intel serialize-amd intel-may-vm-exit amd-may-vm-exit tsx-impl-abort
	gas: suffix=q
END

# Code: Mov_r32_tr
INSTRUCTION: 0F 24 /r | MOV r32, tr | MOV_TR
	ops: w=rm r=reg
	rflags: u=oszacp
	flags: 16 32 dec-opt=MovTr cpl0 ignore-mod
	gas: suffix=l
END

# Code: Mov_tr_r32
INSTRUCTION: 0F 26 /r | MOV tr, r32 | MOV_TR
	ops: w=reg r=rm
	rflags: u=oszacp
	flags: 16 32 dec-opt=MovTr cpl0 ignore-mod
	gas: suffix=l
END

# Code: Movaps_xmm_xmmm128
INSTRUCTION: NP 0F 28 /r | MOVAPS xmm1, xmm2/m128 | SSE
	ops: w=reg r=rm | Packed128_Float32
END

# Code: VEX_Vmovaps_xmm_xmmm128
INSTRUCTION: VEX.128.0F.WIG 28 /r | VMOVAPS xmm1, xmm2/m128 | AVX
	ops: w=reg r=rm | Packed128_Float32
END

# Code: VEX_Vmovaps_ymm_ymmm256
INSTRUCTION: VEX.256.0F.WIG 28 /r | VMOVAPS ymm1, ymm2/m256 | AVX
	ops: w=reg r=rm | Packed256_Float32
END

# Code: EVEX_Vmovaps_xmm_k1z_xmmm128
INSTRUCTION: EVEX.128.0F.W0 28 /r | VMOVAPS xmm1 {k1}{z}, xmm2/m128 | AVX512VL AVX512F | N16
	ops: w=reg r=rm | Packed128_Float32
END

# Code: EVEX_Vmovaps_ymm_k1z_ymmm256
INSTRUCTION: EVEX.256.0F.W0 28 /r | VMOVAPS ymm1 {k1}{z}, ymm2/m256 | AVX512VL AVX512F | N32
	ops: w=reg r=rm | Packed256_Float32
END

# Code: EVEX_Vmovaps_zmm_k1z_zmmm512
INSTRUCTION: EVEX.512.0F.W0 28 /r | VMOVAPS zmm1 {k1}{z}, zmm2/m512 | AVX512F | N64
	ops: wvmm=reg r=rm | Packed512_Float32
END

# Code: Movapd_xmm_xmmm128
INSTRUCTION: 66 0F 28 /r | MOVAPD xmm1, xmm2/m128 | SSE2
	ops: w=reg r=rm | Packed128_Float64
END

# Code: VEX_Vmovapd_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 28 /r | VMOVAPD xmm1, xmm2/m128 | AVX
	ops: w=reg r=rm | Packed128_Float64
END

# Code: VEX_Vmovapd_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 28 /r | VMOVAPD ymm1, ymm2/m256 | AVX
	ops: w=reg r=rm | Packed256_Float64
END

# Code: EVEX_Vmovapd_xmm_k1z_xmmm128
INSTRUCTION: EVEX.128.66.0F.W1 28 /r | VMOVAPD xmm1 {k1}{z}, xmm2/m128 | AVX512VL AVX512F | N16
	ops: w=reg r=rm | Packed128_Float64
END

# Code: EVEX_Vmovapd_ymm_k1z_ymmm256
INSTRUCTION: EVEX.256.66.0F.W1 28 /r | VMOVAPD ymm1 {k1}{z}, ymm2/m256 | AVX512VL AVX512F | N32
	ops: w=reg r=rm | Packed256_Float64
END

# Code: EVEX_Vmovapd_zmm_k1z_zmmm512
INSTRUCTION: EVEX.512.66.0F.W1 28 /r | VMOVAPD zmm1 {k1}{z}, zmm2/m512 | AVX512F | N64
	ops: wvmm=reg r=rm | Packed512_Float64
END

# Code: Movaps_xmmm128_xmm
INSTRUCTION: NP 0F 29 /r | MOVAPS xmm2/m128, xmm1 | SSE
	ops: w=rm r=reg | Packed128_Float32
END

# Code: VEX_Vmovaps_xmmm128_xmm
INSTRUCTION: VEX.128.0F.WIG 29 /r | VMOVAPS xmm2/m128, xmm1 | AVX
	ops: w=rm r=reg | Packed128_Float32
END

# Code: VEX_Vmovaps_ymmm256_ymm
INSTRUCTION: VEX.256.0F.WIG 29 /r | VMOVAPS ymm2/m256, ymm1 | AVX
	ops: w=rm r=reg | Packed256_Float32
END

# Code: EVEX_Vmovaps_xmmm128_k1z_xmm
INSTRUCTION: EVEX.128.0F.W0 29 /r | VMOVAPS xmm2/m128 {k1}{z}, xmm1 | AVX512VL AVX512F | N16
	ops: w=rm r=reg | Packed128_Float32
END

# Code: EVEX_Vmovaps_ymmm256_k1z_ymm
INSTRUCTION: EVEX.256.0F.W0 29 /r | VMOVAPS ymm2/m256 {k1}{z}, ymm1 | AVX512VL AVX512F | N32
	ops: w=rm r=reg | Packed256_Float32
END

# Code: EVEX_Vmovaps_zmmm512_k1z_zmm
INSTRUCTION: EVEX.512.0F.W0 29 /r | VMOVAPS zmm2/m512 {k1}{z}, zmm1 | AVX512F | N64
	ops: wvmm=rm r=reg | Packed512_Float32
END

# Code: Movapd_xmmm128_xmm
INSTRUCTION: 66 0F 29 /r | MOVAPD xmm2/m128, xmm1 | SSE2
	ops: w=rm r=reg | Packed128_Float64
END

# Code: VEX_Vmovapd_xmmm128_xmm
INSTRUCTION: VEX.128.66.0F.WIG 29 /r | VMOVAPD xmm2/m128, xmm1 | AVX
	ops: w=rm r=reg | Packed128_Float64
END

# Code: VEX_Vmovapd_ymmm256_ymm
INSTRUCTION: VEX.256.66.0F.WIG 29 /r | VMOVAPD ymm2/m256, ymm1 | AVX
	ops: w=rm r=reg | Packed256_Float64
END

# Code: EVEX_Vmovapd_xmmm128_k1z_xmm
INSTRUCTION: EVEX.128.66.0F.W1 29 /r | VMOVAPD xmm2/m128 {k1}{z}, xmm1 | AVX512VL AVX512F | N16
	ops: w=rm r=reg | Packed128_Float64
END

# Code: EVEX_Vmovapd_ymmm256_k1z_ymm
INSTRUCTION: EVEX.256.66.0F.W1 29 /r | VMOVAPD ymm2/m256 {k1}{z}, ymm1 | AVX512VL AVX512F | N32
	ops: w=rm r=reg | Packed256_Float64
END

# Code: EVEX_Vmovapd_zmmm512_k1z_zmm
INSTRUCTION: EVEX.512.66.0F.W1 29 /r | VMOVAPD zmm2/m512 {k1}{z}, zmm1 | AVX512F | N64
	ops: wvmm=rm r=reg | Packed512_Float64
END

# Code: Cvtpi2ps_xmm_mmm64
INSTRUCTION: NP 0F 2A /r | CVTPI2PS xmm, mm/m64 | SSE
	ops: rw=reg r=rm | Packed64_Int32
	flags: tsx-impl-abort
	masm: flags=force-size=default
END

# Code: Cvtpi2pd_xmm_mmm64
INSTRUCTION: 66 0F 2A /r | CVTPI2PD xmm, mm/m64 | SSE2
	ops: w=reg r=rm | Packed64_Int32
	flags: tsx-impl-abort
	masm: flags=force-size=default
END

# Code: Cvtsi2ss_xmm_rm32
INSTRUCTION: F3 0F 2A /r | CVTSI2SS xmm1, r/m32 | SSE
	ops: rw=reg r=rm | Int32
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Cvtsi2ss_xmm_rm64
INSTRUCTION: F3 o64 0F 2A /r | CVTSI2SS xmm1, r/m64 | SSE
	ops: rw=reg r=rm | Int64
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: VEX_Vcvtsi2ss_xmm_xmm_rm32
INSTRUCTION: VEX.LIG.F3.0F.W0 2A /r | VCVTSI2SS xmm1, xmm2, r/m32 | AVX
	ops: w=reg r=vvvv r=rm | Int32
	flags: wig32
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: VEX_Vcvtsi2ss_xmm_xmm_rm64
INSTRUCTION: VEX.LIG.F3.0F.W1 2A /r | VCVTSI2SS xmm1, xmm2, r/m64 | AVX
	ops: w=reg r=vvvv r=rm | Int64
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: EVEX_Vcvtsi2ss_xmm_xmm_rm32_er
INSTRUCTION: EVEX.LIG.F3.0F.W0 2A /r | VCVTSI2SS xmm1, xmm2, r/m32{er} | AVX512F | N4
	ops: w=reg r=vvvv r=rm | Int32
	flags: wig32
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: EVEX_Vcvtsi2ss_xmm_xmm_rm64_er
INSTRUCTION: EVEX.LIG.F3.0F.W1 2A /r | VCVTSI2SS xmm1, xmm2, r/m64{er} | AVX512F | N8
	ops: w=reg r=vvvv r=rm | Int64
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Cvtsi2sd_xmm_rm32
INSTRUCTION: F2 0F 2A /r | CVTSI2SD xmm1, r/m32 | SSE2
	ops: rw=reg r=rm | Int32
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Cvtsi2sd_xmm_rm64
INSTRUCTION: F2 o64 0F 2A /r | CVTSI2SD xmm1, r/m64 | SSE2
	ops: rw=reg r=rm | Int64
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: VEX_Vcvtsi2sd_xmm_xmm_rm32
INSTRUCTION: VEX.LIG.F2.0F.W0 2A /r | VCVTSI2SD xmm1, xmm2, r/m32 | AVX
	ops: w=reg r=vvvv r=rm | Int32
	flags: wig32
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: VEX_Vcvtsi2sd_xmm_xmm_rm64
INSTRUCTION: VEX.LIG.F2.0F.W1 2A /r | VCVTSI2SD xmm1, xmm2, r/m64 | AVX
	ops: w=reg r=vvvv r=rm | Int64
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: EVEX_Vcvtsi2sd_xmm_xmm_rm32_er
INSTRUCTION: EVEX.LIG.F2.0F.W0 2A /r | VCVTSI2SD xmm1, xmm2, r/m32{er} | AVX512F | N4
	ops: w=reg r=vvvv r=rm | Int32
	flags: wig32 ignore-er
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: EVEX_Vcvtsi2sd_xmm_xmm_rm64_er
INSTRUCTION: EVEX.LIG.F2.0F.W1 2A /r | VCVTSI2SD xmm1, xmm2, r/m64{er} | AVX512F | N8
	ops: w=reg r=vvvv r=rm | Int64
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Movntps_m128_xmm
INSTRUCTION: NP 0F 2B /r | MOVNTPS m128, xmm1 | SSE
	ops: w=rm r=reg | Packed128_Float32
	flags: tsx-impl-abort non-temporal
END

# Code: VEX_Vmovntps_m128_xmm
INSTRUCTION: VEX.128.0F.WIG 2B /r | VMOVNTPS m128, xmm1 | AVX
	ops: w=rm r=reg | Packed128_Float32
	flags: tsx-impl-abort non-temporal
	masm: flags=force-size=default
END

# Code: VEX_Vmovntps_m256_ymm
INSTRUCTION: VEX.256.0F.WIG 2B /r | VMOVNTPS m256, ymm1 | AVX
	ops: w=rm r=reg | Packed256_Float32
	flags: tsx-impl-abort non-temporal
	masm: flags=force-size=default
END

# Code: EVEX_Vmovntps_m128_xmm
INSTRUCTION: EVEX.128.0F.W0 2B /r | VMOVNTPS m128, xmm1 | AVX512VL AVX512F | N16
	ops: w=rm r=reg | Packed128_Float32
	flags: tsx-impl-abort non-temporal
	masm: flags=force-size=default
END

# Code: EVEX_Vmovntps_m256_ymm
INSTRUCTION: EVEX.256.0F.W0 2B /r | VMOVNTPS m256, ymm1 | AVX512VL AVX512F | N32
	ops: w=rm r=reg | Packed256_Float32
	flags: tsx-impl-abort non-temporal
	masm: flags=force-size=default
END

# Code: EVEX_Vmovntps_m512_zmm
INSTRUCTION: EVEX.512.0F.W0 2B /r | VMOVNTPS m512, zmm1 | AVX512F | N64
	ops: w=rm r=reg | Packed512_Float32
	flags: tsx-impl-abort non-temporal
	masm: flags=force-size=default
END

# Code: Movntpd_m128_xmm
INSTRUCTION: 66 0F 2B /r | MOVNTPD m128, xmm1 | SSE2
	ops: w=rm r=reg | Packed128_Float64
	flags: tsx-impl-abort non-temporal
END

# Code: VEX_Vmovntpd_m128_xmm
INSTRUCTION: VEX.128.66.0F.WIG 2B /r | VMOVNTPD m128, xmm1 | AVX
	ops: w=rm r=reg | Packed128_Float64
	flags: tsx-impl-abort non-temporal
	masm: flags=force-size=default
END

# Code: VEX_Vmovntpd_m256_ymm
INSTRUCTION: VEX.256.66.0F.WIG 2B /r | VMOVNTPD m256, ymm1 | AVX
	ops: w=rm r=reg | Packed256_Float64
	flags: tsx-impl-abort non-temporal
	masm: flags=force-size=default
END

# Code: EVEX_Vmovntpd_m128_xmm
INSTRUCTION: EVEX.128.66.0F.W1 2B /r | VMOVNTPD m128, xmm1 | AVX512VL AVX512F | N16
	ops: w=rm r=reg | Packed128_Float64
	flags: tsx-impl-abort non-temporal
	masm: flags=force-size=default
END

# Code: EVEX_Vmovntpd_m256_ymm
INSTRUCTION: EVEX.256.66.0F.W1 2B /r | VMOVNTPD m256, ymm1 | AVX512VL AVX512F | N32
	ops: w=rm r=reg | Packed256_Float64
	flags: tsx-impl-abort non-temporal
	masm: flags=force-size=default
END

# Code: EVEX_Vmovntpd_m512_zmm
INSTRUCTION: EVEX.512.66.0F.W1 2B /r | VMOVNTPD m512, zmm1 | AVX512F | N64
	ops: w=rm r=reg | Packed512_Float64
	flags: tsx-impl-abort non-temporal
	masm: flags=force-size=default
END

# Code: Movntss_m32_xmm
INSTRUCTION: F3 0F 2B /r | MOVNTSS m32, xmm1 | SSE4A
	ops: w=rm r=reg | Float32
	flags: non-temporal
	masm: flags=force-size=default
END

# Code: Movntsd_m64_xmm
INSTRUCTION: F2 0F 2B /r | MOVNTSD m64, xmm1 | SSE4A
	ops: w=rm r=reg | Float64
	flags: non-temporal
	masm: flags=force-size=default
END

# Code: Cvttps2pi_mm_xmmm64
INSTRUCTION: NP 0F 2C /r | CVTTPS2PI mm, xmm/m64 | SSE
	ops: w=reg r=rm | Packed64_Float32
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx;force-size=default
END

# Code: Cvttpd2pi_mm_xmmm128
INSTRUCTION: 66 0F 2C /r | CVTTPD2PI mm, xmm/m128 | SSE2
	ops: w=reg r=rm | Packed128_Float64
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Cvttss2si_r32_xmmm32
INSTRUCTION: F3 0F 2C /r | CVTTSS2SI r32, xmm1/m32 | SSE
	ops: w=reg r=rm | Float32
	masm: flags=force-size=default
END

# Code: Cvttss2si_r64_xmmm32
INSTRUCTION: F3 o64 0F 2C /r | CVTTSS2SI r64, xmm1/m32 | SSE
	ops: w=reg r=rm | Float32
	flags: 64
	masm: flags=force-size=default
END

# Code: VEX_Vcvttss2si_r32_xmmm32
INSTRUCTION: VEX.LIG.F3.0F.W0 2C /r | VCVTTSS2SI r32, xmm1/m32 | AVX
	ops: w=reg r=rm | Float32
	flags: wig32
	masm: flags=force-size=default
END

# Code: VEX_Vcvttss2si_r64_xmmm32
INSTRUCTION: VEX.LIG.F3.0F.W1 2C /r | VCVTTSS2SI r64, xmm1/m32 | AVX
	ops: w=reg r=rm | Float32
	flags: 64
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttss2si_r32_xmmm32_sae
INSTRUCTION: EVEX.LIG.F3.0F.W0 2C /r | VCVTTSS2SI r32, xmm1/m32{sae} | AVX512F | N4
	ops: w=reg r=rm | Float32
	flags: wig32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttss2si_r64_xmmm32_sae
INSTRUCTION: EVEX.LIG.F3.0F.W1 2C /r | VCVTTSS2SI r64, xmm1/m32{sae} | AVX512F | N4
	ops: w=reg r=rm | Float32
	flags: 64
	masm: flags=force-size=default
END

# Code: Cvttsd2si_r32_xmmm64
INSTRUCTION: F2 0F 2C /r | CVTTSD2SI r32, xmm1/m64 | SSE2
	ops: w=reg r=rm | Float64
	masm: flags=force-size=default
END

# Code: Cvttsd2si_r64_xmmm64
INSTRUCTION: F2 o64 0F 2C /r | CVTTSD2SI r64, xmm1/m64 | SSE2
	ops: w=reg r=rm | Float64
	flags: 64
	masm: flags=force-size=default
END

# Code: VEX_Vcvttsd2si_r32_xmmm64
INSTRUCTION: VEX.LIG.F2.0F.W0 2C /r | VCVTTSD2SI r32, xmm1/m64 | AVX
	ops: w=reg r=rm | Float64
	flags: wig32
	masm: flags=force-size=default
END

# Code: VEX_Vcvttsd2si_r64_xmmm64
INSTRUCTION: VEX.LIG.F2.0F.W1 2C /r | VCVTTSD2SI r64, xmm1/m64 | AVX
	ops: w=reg r=rm | Float64
	flags: 64
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttsd2si_r32_xmmm64_sae
INSTRUCTION: EVEX.LIG.F2.0F.W0 2C /r | VCVTTSD2SI r32, xmm1/m64{sae} | AVX512F | N8
	ops: w=reg r=rm | Float64
	flags: wig32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttsd2si_r64_xmmm64_sae
INSTRUCTION: EVEX.LIG.F2.0F.W1 2C /r | VCVTTSD2SI r64, xmm1/m64{sae} | AVX512F | N8
	ops: w=reg r=rm | Float64
	flags: 64
	masm: flags=force-size=default
END

# Code: Cvtps2pi_mm_xmmm64
INSTRUCTION: NP 0F 2D /r | CVTPS2PI mm, xmm/m64 | SSE
	ops: w=reg r=rm | Packed64_Float32
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx;force-size=default
END

# Code: Cvtpd2pi_mm_xmmm128
INSTRUCTION: 66 0F 2D /r | CVTPD2PI mm, xmm/m128 | SSE2
	ops: w=reg r=rm | Packed128_Float64
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Cvtss2si_r32_xmmm32
INSTRUCTION: F3 0F 2D /r | CVTSS2SI r32, xmm1/m32 | SSE
	ops: w=reg r=rm | Float32
	masm: flags=force-size=default
END

# Code: Cvtss2si_r64_xmmm32
INSTRUCTION: F3 o64 0F 2D /r | CVTSS2SI r64, xmm1/m32 | SSE
	ops: w=reg r=rm | Float32
	flags: 64
	masm: flags=force-size=default
END

# Code: VEX_Vcvtss2si_r32_xmmm32
INSTRUCTION: VEX.LIG.F3.0F.W0 2D /r | VCVTSS2SI r32, xmm1/m32 | AVX
	ops: w=reg r=rm | Float32
	flags: wig32
	masm: flags=force-size=default
END

# Code: VEX_Vcvtss2si_r64_xmmm32
INSTRUCTION: VEX.LIG.F3.0F.W1 2D /r | VCVTSS2SI r64, xmm1/m32 | AVX
	ops: w=reg r=rm | Float32
	flags: 64
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtss2si_r32_xmmm32_er
INSTRUCTION: EVEX.LIG.F3.0F.W0 2D /r | VCVTSS2SI r32, xmm1/m32{er} | AVX512F | N4
	ops: w=reg r=rm | Float32
	flags: wig32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtss2si_r64_xmmm32_er
INSTRUCTION: EVEX.LIG.F3.0F.W1 2D /r | VCVTSS2SI r64, xmm1/m32{er} | AVX512F | N4
	ops: w=reg r=rm | Float32
	flags: 64
	masm: flags=force-size=default
END

# Code: Cvtsd2si_r32_xmmm64
INSTRUCTION: F2 0F 2D /r | CVTSD2SI r32, xmm1/m64 | SSE2
	ops: w=reg r=rm | Float64
	masm: flags=force-size=default
END

# Code: Cvtsd2si_r64_xmmm64
INSTRUCTION: F2 o64 0F 2D /r | CVTSD2SI r64, xmm1/m64 | SSE2
	ops: w=reg r=rm | Float64
	flags: 64
	masm: flags=force-size=default
END

# Code: VEX_Vcvtsd2si_r32_xmmm64
INSTRUCTION: VEX.LIG.F2.0F.W0 2D /r | VCVTSD2SI r32, xmm1/m64 | AVX
	ops: w=reg r=rm | Float64
	flags: wig32
	masm: flags=force-size=default
END

# Code: VEX_Vcvtsd2si_r64_xmmm64
INSTRUCTION: VEX.LIG.F2.0F.W1 2D /r | VCVTSD2SI r64, xmm1/m64 | AVX
	ops: w=reg r=rm | Float64
	flags: 64
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtsd2si_r32_xmmm64_er
INSTRUCTION: EVEX.LIG.F2.0F.W0 2D /r | VCVTSD2SI r32, xmm1/m64{er} | AVX512F | N8
	ops: w=reg r=rm | Float64
	flags: wig32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtsd2si_r64_xmmm64_er
INSTRUCTION: EVEX.LIG.F2.0F.W1 2D /r | VCVTSD2SI r64, xmm1/m64{er} | AVX512F | N8
	ops: w=reg r=rm | Float64
	flags: 64
	masm: flags=force-size=default
END

# Code: Ucomiss_xmm_xmmm32
INSTRUCTION: NP 0F 2E /r | UCOMISS xmm1, xmm2/m32 | SSE
	ops: r=reg r=rm | Float32
	rflags: w=zcp 0=osa
	masm: flags=force-size=default
END

# Code: VEX_Vucomiss_xmm_xmmm32
INSTRUCTION: VEX.LIG.0F.WIG 2E /r | VUCOMISS xmm1, xmm2/m32 | AVX
	ops: r=reg r=rm | Float32
	rflags: w=zcp 0=osa
	masm: flags=force-size=default
END

# Code: EVEX_Vucomiss_xmm_xmmm32_sae
INSTRUCTION: EVEX.LIG.0F.W0 2E /r | VUCOMISS xmm1, xmm2/m32{sae} | AVX512F | N4
	ops: r=reg r=rm | Float32
	rflags: w=zcp 0=osa
	masm: flags=force-size=default
END

# Code: Ucomisd_xmm_xmmm64
INSTRUCTION: 66 0F 2E /r | UCOMISD xmm1, xmm2/m64 | SSE2
	ops: r=reg r=rm | Float64
	rflags: w=zcp 0=osa
	masm: flags=force-size=default
END

# Code: VEX_Vucomisd_xmm_xmmm64
INSTRUCTION: VEX.LIG.66.0F.WIG 2E /r | VUCOMISD xmm1, xmm2/m64 | AVX
	ops: r=reg r=rm | Float64
	rflags: w=zcp 0=osa
	masm: flags=force-size=default
END

# Code: EVEX_Vucomisd_xmm_xmmm64_sae
INSTRUCTION: EVEX.LIG.66.0F.W1 2E /r | VUCOMISD xmm1, xmm2/m64{sae} | AVX512F | N8
	ops: r=reg r=rm | Float64
	rflags: w=zcp 0=osa
	masm: flags=force-size=default
END

# Code: Comiss_xmm_xmmm32
INSTRUCTION: NP 0F 2F /r | COMISS xmm1, xmm2/m32 | SSE
	ops: r=reg r=rm | Float32
	rflags: w=zcp 0=osa
	masm: flags=force-size=default
END

# Code: Comisd_xmm_xmmm64
INSTRUCTION: 66 0F 2F /r | COMISD xmm1, xmm2/m64 | SSE2
	ops: r=reg r=rm | Float64
	rflags: w=zcp 0=osa
	masm: flags=force-size=default
END

# Code: VEX_Vcomiss_xmm_xmmm32
INSTRUCTION: VEX.LIG.0F.WIG 2F /r | VCOMISS xmm1, xmm2/m32 | AVX
	ops: r=reg r=rm | Float32
	rflags: w=zcp 0=osa
	masm: flags=force-size=default
END

# Code: VEX_Vcomisd_xmm_xmmm64
INSTRUCTION: VEX.LIG.66.0F.WIG 2F /r | VCOMISD xmm1, xmm2/m64 | AVX
	ops: r=reg r=rm | Float64
	rflags: w=zcp 0=osa
	masm: flags=force-size=default
END

# Code: EVEX_Vcomiss_xmm_xmmm32_sae
INSTRUCTION: EVEX.LIG.0F.W0 2F /r | VCOMISS xmm1, xmm2/m32{sae} | AVX512F | N4
	ops: r=reg r=rm | Float32
	rflags: w=zcp 0=osa
	masm: flags=force-size=default
END

# Code: EVEX_Vcomisd_xmm_xmmm64_sae
INSTRUCTION: EVEX.LIG.66.0F.W1 2F /r | VCOMISD xmm1, xmm2/m64{sae} | AVX512F | N8
	ops: r=reg r=rm | Float64
	rflags: w=zcp 0=osa
	masm: flags=force-size=default
END

# Code: Wrmsr
INSTRUCTION: 0F 30 | WRMSR | MSR
	implied: r=eax;ecx;edx
	# Not serializing if writing to some MSRs (Intel, AMD)
	flags: cpl0 serialize-intel serialize-amd intel-may-vm-exit tdx-non-root-may-gen-ex amd-may-vm-exit tsx-impl-abort
END

# Code: Rdtsc
INSTRUCTION: 0F 31 | RDTSC | TSC
	implied: w=eax;edx
	# If CR4.TSD=1, CPL=0 is required
	# May cause a TSX abort if VM exit
	flags: may-require-cpl0 intel-may-vm-exit no-in-sgx1 amd-may-vm-exit tsx-impl-abort
END

# Code: Rdmsr
INSTRUCTION: 0F 32 | RDMSR | MSR
	implied: r=ecx w=eax;edx
	flags: cpl0 intel-may-vm-exit tdx-non-root-may-gen-ex amd-may-vm-exit tsx-impl-abort
END

# Code: Rdpmc
INSTRUCTION: 0F 33 | RDPMC | RDPMC
	implied: r=ecx w=eax;edx
	# If CR4.PCE=0, CPL=0 is required
	# May cause a TSX abort if VM exit
	flags: may-require-cpl0 intel-may-vm-exit no-in-sgx amd-may-vm-exit tsx-impl-abort
END

# Code: Sysenter
INSTRUCTION: 0F 34 | SYSENTER | SEP
	# w=esp will be converted to w=rsp if 64-bit code
	implied: w=esp
	rflags: 0=i
	# Not supported by AMD in 64-bit mode but the AMD decoder should still decode it.
	flags: cflow=call no-in-sgx tsx-impl-abort
END

# Code: Sysexitd
INSTRUCTION: 0F 35 | SYSEXIT | SEP
	# w=esp will be converted to w=rsp if 64-bit code
	implied: r=ecx;edx w=esp w=cs;ss
	code-mnemonic: sysexitd
	# Not supported by AMD in 64-bit mode but the AMD decoder should still decode it.
	# AMD: no-rm no-v86 or #GP(0)
	# #UD if CR4.FRED=1
	flags: cpl0 cflow=ret tsx-impl-abort asm=sysexit
	gas: suffix=l osz-suffix-3 16 32
END

# Code: Sysexitq
INSTRUCTION: o64 0F 35 | SYSEXITQ | SEP
	implied: r=rcx;rdx w=rsp w=cs;ss
	# Not supported by AMD in 64-bit mode but the AMD decoder should still decode it.
	# #UD if CR4.FRED=1
	flags: 64 cpl0 cflow=ret tsx-impl-abort asm=sysexitq
	nasm: mnemonic=sysexit flags=o64
END

# Code: Getsecd
INSTRUCTION: NP 0F 37 | GETSEC | SMX
	implied: r=eax
	code-mnemonic: getsecd
	flags: save-restore may-require-cpl0 intel-vm-exit no-in-sgx tdx-non-root-ud tsx-impl-abort
END

# Code: Getsecq
INSTRUCTION: NP o64 0F 37 | GETSECQ | SMX
	implied: r=eax
	flags: 64 save-restore may-require-cpl0 intel-vm-exit no-in-sgx tdx-non-root-ud tsx-impl-abort asm=getsecq
	gas: mnemonic=getsec flags=o64
	nasm: mnemonic=getsec flags=o64
END

# Code: Cmovo_r16_rm16
INSTRUCTION: o16 0F 40 /r | CMOVO r16, r/m16 | CMOV
	ops: cw=reg r=rm | UInt16
	rflags: r=o
	flags: cc=cmov;o;
	gas: suffix=w cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovo_r32_rm32
INSTRUCTION: o32 0F 40 /r | CMOVO r32, r/m32 | CMOV
	ops: cw32_rw64=reg r=rm | UInt32
	rflags: r=o
	flags: cc=cmov;o;
	gas: suffix=l cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovo_r64_rm64
INSTRUCTION: o64 0F 40 /r | CMOVO r64, r/m64 | CMOV
	ops: cw=reg r=rm | UInt64
	rflags: r=o
	flags: 64 cc=cmov;o;
	gas: suffix=q cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovno_r16_rm16
INSTRUCTION: o16 0F 41 /r | CMOVNO r16, r/m16 | CMOV
	ops: cw=reg r=rm | UInt16
	rflags: r=o
	flags: cc=cmov;no;
	gas: suffix=w cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovno_r32_rm32
INSTRUCTION: o32 0F 41 /r | CMOVNO r32, r/m32 | CMOV
	ops: cw32_rw64=reg r=rm | UInt32
	rflags: r=o
	flags: cc=cmov;no;
	gas: suffix=l cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovno_r64_rm64
INSTRUCTION: o64 0F 41 /r | CMOVNO r64, r/m64 | CMOV
	ops: cw=reg r=rm | UInt64
	rflags: r=o
	flags: 64 cc=cmov;no;
	gas: suffix=q cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovb_r16_rm16
INSTRUCTION: o16 0F 42 /r | CMOVB r16, r/m16 | CMOV
	ops: cw=reg r=rm | UInt16
	rflags: r=c
	flags: cc=cmov;b;
	gas: suffix=w cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovb_r32_rm32
INSTRUCTION: o32 0F 42 /r | CMOVB r32, r/m32 | CMOV
	ops: cw32_rw64=reg r=rm | UInt32
	rflags: r=c
	flags: cc=cmov;b;
	gas: suffix=l cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovb_r64_rm64
INSTRUCTION: o64 0F 42 /r | CMOVB r64, r/m64 | CMOV
	ops: cw=reg r=rm | UInt64
	rflags: r=c
	flags: 64 cc=cmov;b;
	gas: suffix=q cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovae_r16_rm16
INSTRUCTION: o16 0F 43 /r | CMOVAE r16, r/m16 | CMOV
	ops: cw=reg r=rm | UInt16
	rflags: r=c
	flags: cc=cmov;ae;
	gas: suffix=w cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovae_r32_rm32
INSTRUCTION: o32 0F 43 /r | CMOVAE r32, r/m32 | CMOV
	ops: cw32_rw64=reg r=rm | UInt32
	rflags: r=c
	flags: cc=cmov;ae;
	gas: suffix=l cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovae_r64_rm64
INSTRUCTION: o64 0F 43 /r | CMOVAE r64, r/m64 | CMOV
	ops: cw=reg r=rm | UInt64
	rflags: r=c
	flags: 64 cc=cmov;ae;
	gas: suffix=q cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmove_r16_rm16
INSTRUCTION: o16 0F 44 /r | CMOVE r16, r/m16 | CMOV
	ops: cw=reg r=rm | UInt16
	rflags: r=z
	flags: cc=cmov;e;
	gas: suffix=w cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmove_r32_rm32
INSTRUCTION: o32 0F 44 /r | CMOVE r32, r/m32 | CMOV
	ops: cw32_rw64=reg r=rm | UInt32
	rflags: r=z
	flags: cc=cmov;e;
	gas: suffix=l cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmove_r64_rm64
INSTRUCTION: o64 0F 44 /r | CMOVE r64, r/m64 | CMOV
	ops: cw=reg r=rm | UInt64
	rflags: r=z
	flags: 64 cc=cmov;e;
	gas: suffix=q cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovne_r16_rm16
INSTRUCTION: o16 0F 45 /r | CMOVNE r16, r/m16 | CMOV
	ops: cw=reg r=rm | UInt16
	rflags: r=z
	flags: cc=cmov;ne;
	gas: suffix=w cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovne_r32_rm32
INSTRUCTION: o32 0F 45 /r | CMOVNE r32, r/m32 | CMOV
	ops: cw32_rw64=reg r=rm | UInt32
	rflags: r=z
	flags: cc=cmov;ne;
	gas: suffix=l cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovne_r64_rm64
INSTRUCTION: o64 0F 45 /r | CMOVNE r64, r/m64 | CMOV
	ops: cw=reg r=rm | UInt64
	rflags: r=z
	flags: 64 cc=cmov;ne;
	gas: suffix=q cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovbe_r16_rm16
INSTRUCTION: o16 0F 46 /r | CMOVBE r16, r/m16 | CMOV
	ops: cw=reg r=rm | UInt16
	rflags: r=zc
	flags: cc=cmov;be;
	gas: suffix=w cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovbe_r32_rm32
INSTRUCTION: o32 0F 46 /r | CMOVBE r32, r/m32 | CMOV
	ops: cw32_rw64=reg r=rm | UInt32
	rflags: r=zc
	flags: cc=cmov;be;
	gas: suffix=l cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovbe_r64_rm64
INSTRUCTION: o64 0F 46 /r | CMOVBE r64, r/m64 | CMOV
	ops: cw=reg r=rm | UInt64
	rflags: r=zc
	flags: 64 cc=cmov;be;
	gas: suffix=q cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmova_r16_rm16
INSTRUCTION: o16 0F 47 /r | CMOVA r16, r/m16 | CMOV
	ops: cw=reg r=rm | UInt16
	rflags: r=zc
	flags: cc=cmov;a;
	gas: suffix=w cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmova_r32_rm32
INSTRUCTION: o32 0F 47 /r | CMOVA r32, r/m32 | CMOV
	ops: cw32_rw64=reg r=rm | UInt32
	rflags: r=zc
	flags: cc=cmov;a;
	gas: suffix=l cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmova_r64_rm64
INSTRUCTION: o64 0F 47 /r | CMOVA r64, r/m64 | CMOV
	ops: cw=reg r=rm | UInt64
	rflags: r=zc
	flags: 64 cc=cmov;a;
	gas: suffix=q cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovs_r16_rm16
INSTRUCTION: o16 0F 48 /r | CMOVS r16, r/m16 | CMOV
	ops: cw=reg r=rm | UInt16
	rflags: r=s
	flags: cc=cmov;s;
	gas: suffix=w cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovs_r32_rm32
INSTRUCTION: o32 0F 48 /r | CMOVS r32, r/m32 | CMOV
	ops: cw32_rw64=reg r=rm | UInt32
	rflags: r=s
	flags: cc=cmov;s;
	gas: suffix=l cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovs_r64_rm64
INSTRUCTION: o64 0F 48 /r | CMOVS r64, r/m64 | CMOV
	ops: cw=reg r=rm | UInt64
	rflags: r=s
	flags: 64 cc=cmov;s;
	gas: suffix=q cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovns_r16_rm16
INSTRUCTION: o16 0F 49 /r | CMOVNS r16, r/m16 | CMOV
	ops: cw=reg r=rm | UInt16
	rflags: r=s
	flags: cc=cmov;ns;
	gas: suffix=w cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovns_r32_rm32
INSTRUCTION: o32 0F 49 /r | CMOVNS r32, r/m32 | CMOV
	ops: cw32_rw64=reg r=rm | UInt32
	rflags: r=s
	flags: cc=cmov;ns;
	gas: suffix=l cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovns_r64_rm64
INSTRUCTION: o64 0F 49 /r | CMOVNS r64, r/m64 | CMOV
	ops: cw=reg r=rm | UInt64
	rflags: r=s
	flags: 64 cc=cmov;ns;
	gas: suffix=q cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovp_r16_rm16
INSTRUCTION: o16 0F 4A /r | CMOVP r16, r/m16 | CMOV
	ops: cw=reg r=rm | UInt16
	rflags: r=p
	flags: cc=cmov;p;
	gas: suffix=w cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovp_r32_rm32
INSTRUCTION: o32 0F 4A /r | CMOVP r32, r/m32 | CMOV
	ops: cw32_rw64=reg r=rm | UInt32
	rflags: r=p
	flags: cc=cmov;p;
	gas: suffix=l cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovp_r64_rm64
INSTRUCTION: o64 0F 4A /r | CMOVP r64, r/m64 | CMOV
	ops: cw=reg r=rm | UInt64
	rflags: r=p
	flags: 64 cc=cmov;p;
	gas: suffix=q cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovnp_r16_rm16
INSTRUCTION: o16 0F 4B /r | CMOVNP r16, r/m16 | CMOV
	ops: cw=reg r=rm | UInt16
	rflags: r=p
	flags: cc=cmov;np;
	gas: suffix=w cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovnp_r32_rm32
INSTRUCTION: o32 0F 4B /r | CMOVNP r32, r/m32 | CMOV
	ops: cw32_rw64=reg r=rm | UInt32
	rflags: r=p
	flags: cc=cmov;np;
	gas: suffix=l cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovnp_r64_rm64
INSTRUCTION: o64 0F 4B /r | CMOVNP r64, r/m64 | CMOV
	ops: cw=reg r=rm | UInt64
	rflags: r=p
	flags: 64 cc=cmov;np;
	gas: suffix=q cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovl_r16_rm16
INSTRUCTION: o16 0F 4C /r | CMOVL r16, r/m16 | CMOV
	ops: cw=reg r=rm | UInt16
	rflags: r=os
	flags: cc=cmov;l;
	gas: suffix=w cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovl_r32_rm32
INSTRUCTION: o32 0F 4C /r | CMOVL r32, r/m32 | CMOV
	ops: cw32_rw64=reg r=rm | UInt32
	rflags: r=os
	flags: cc=cmov;l;
	gas: suffix=l cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovl_r64_rm64
INSTRUCTION: o64 0F 4C /r | CMOVL r64, r/m64 | CMOV
	ops: cw=reg r=rm | UInt64
	rflags: r=os
	flags: 64 cc=cmov;l;
	gas: suffix=q cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovge_r16_rm16
INSTRUCTION: o16 0F 4D /r | CMOVGE r16, r/m16 | CMOV
	ops: cw=reg r=rm | UInt16
	rflags: r=os
	flags: cc=cmov;ge;
	gas: suffix=w cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovge_r32_rm32
INSTRUCTION: o32 0F 4D /r | CMOVGE r32, r/m32 | CMOV
	ops: cw32_rw64=reg r=rm | UInt32
	rflags: r=os
	flags: cc=cmov;ge;
	gas: suffix=l cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovge_r64_rm64
INSTRUCTION: o64 0F 4D /r | CMOVGE r64, r/m64 | CMOV
	ops: cw=reg r=rm | UInt64
	rflags: r=os
	flags: 64 cc=cmov;ge;
	gas: suffix=q cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovle_r16_rm16
INSTRUCTION: o16 0F 4E /r | CMOVLE r16, r/m16 | CMOV
	ops: cw=reg r=rm | UInt16
	rflags: r=osz
	flags: cc=cmov;le;
	gas: suffix=w cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovle_r32_rm32
INSTRUCTION: o32 0F 4E /r | CMOVLE r32, r/m32 | CMOV
	ops: cw32_rw64=reg r=rm | UInt32
	rflags: r=osz
	flags: cc=cmov;le;
	gas: suffix=l cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovle_r64_rm64
INSTRUCTION: o64 0F 4E /r | CMOVLE r64, r/m64 | CMOV
	ops: cw=reg r=rm | UInt64
	rflags: r=osz
	flags: 64 cc=cmov;le;
	gas: suffix=q cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovg_r16_rm16
INSTRUCTION: o16 0F 4F /r | CMOVG r16, r/m16 | CMOV
	ops: cw=reg r=rm | UInt16
	rflags: r=osz
	flags: cc=cmov;g;
	gas: suffix=w cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovg_r32_rm32
INSTRUCTION: o32 0F 4F /r | CMOVG r32, r/m32 | CMOV
	ops: cw32_rw64=reg r=rm | UInt32
	rflags: r=osz
	flags: cc=cmov;g;
	gas: suffix=l cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: Cmovg_r64_rm64
INSTRUCTION: o64 0F 4F /r | CMOVG r64, r/m64 | CMOV
	ops: cw=reg r=rm | UInt64
	rflags: r=osz
	flags: 64 cc=cmov;g;
	gas: suffix=q cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Kandw_kr_kr_kr
INSTRUCTION: VEX.L1.0F.W0 41 /r | KANDW k1, k2, k3 | AVX512F
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_Kandq_kr_kr_kr
INSTRUCTION: VEX.L1.0F.W1 41 /r | KANDQ k1, k2, k3 | AVX512BW
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_Kandb_kr_kr_kr
INSTRUCTION: VEX.L1.66.0F.W0 41 /r | KANDB k1, k2, k3 | AVX512DQ
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_Kandd_kr_kr_kr
INSTRUCTION: VEX.L1.66.0F.W1 41 /r | KANDD k1, k2, k3 | AVX512BW
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_Kandnw_kr_kr_kr
INSTRUCTION: VEX.L1.0F.W0 42 /r | KANDNW k1, k2, k3 | AVX512F
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_Kandnq_kr_kr_kr
INSTRUCTION: VEX.L1.0F.W1 42 /r | KANDNQ k1, k2, k3 | AVX512BW
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_Kandnb_kr_kr_kr
INSTRUCTION: VEX.L1.66.0F.W0 42 /r | KANDNB k1, k2, k3 | AVX512DQ
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_Kandnd_kr_kr_kr
INSTRUCTION: VEX.L1.66.0F.W1 42 /r | KANDND k1, k2, k3 | AVX512BW
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_Knotw_kr_kr
INSTRUCTION: VEX.L0.0F.W0 44 /r | KNOTW k1, k2 | AVX512F
	ops: w=reg r=rm
END

# Code: VEX_Knotq_kr_kr
INSTRUCTION: VEX.L0.0F.W1 44 /r | KNOTQ k1, k2 | AVX512BW
	ops: w=reg r=rm
END

# Code: VEX_Knotb_kr_kr
INSTRUCTION: VEX.L0.66.0F.W0 44 /r | KNOTB k1, k2 | AVX512DQ
	ops: w=reg r=rm
END

# Code: VEX_Knotd_kr_kr
INSTRUCTION: VEX.L0.66.0F.W1 44 /r | KNOTD k1, k2 | AVX512BW
	ops: w=reg r=rm
END

# Code: VEX_Korw_kr_kr_kr
INSTRUCTION: VEX.L1.0F.W0 45 /r | KORW k1, k2, k3 | AVX512F
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_Korq_kr_kr_kr
INSTRUCTION: VEX.L1.0F.W1 45 /r | KORQ k1, k2, k3 | AVX512BW
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_Korb_kr_kr_kr
INSTRUCTION: VEX.L1.66.0F.W0 45 /r | KORB k1, k2, k3 | AVX512DQ
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_Kord_kr_kr_kr
INSTRUCTION: VEX.L1.66.0F.W1 45 /r | KORD k1, k2, k3 | AVX512BW
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_Kxnorw_kr_kr_kr
INSTRUCTION: VEX.L1.0F.W0 46 /r | KXNORW k1, k2, k3 | AVX512F
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_Kxnorq_kr_kr_kr
INSTRUCTION: VEX.L1.0F.W1 46 /r | KXNORQ k1, k2, k3 | AVX512BW
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_Kxnorb_kr_kr_kr
INSTRUCTION: VEX.L1.66.0F.W0 46 /r | KXNORB k1, k2, k3 | AVX512DQ
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_Kxnord_kr_kr_kr
INSTRUCTION: VEX.L1.66.0F.W1 46 /r | KXNORD k1, k2, k3 | AVX512BW
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_Kxorw_kr_kr_kr
INSTRUCTION: VEX.L1.0F.W0 47 /r | KXORW k1, k2, k3 | AVX512F
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_Kxorq_kr_kr_kr
INSTRUCTION: VEX.L1.0F.W1 47 /r | KXORQ k1, k2, k3 | AVX512BW
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_Kxorb_kr_kr_kr
INSTRUCTION: VEX.L1.66.0F.W0 47 /r | KXORB k1, k2, k3 | AVX512DQ
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_Kxord_kr_kr_kr
INSTRUCTION: VEX.L1.66.0F.W1 47 /r | KXORD k1, k2, k3 | AVX512BW
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_Kaddw_kr_kr_kr
INSTRUCTION: VEX.L1.0F.W0 4A /r | KADDW k1, k2, k3 | AVX512DQ
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_Kaddq_kr_kr_kr
INSTRUCTION: VEX.L1.0F.W1 4A /r | KADDQ k1, k2, k3 | AVX512BW
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_Kaddb_kr_kr_kr
INSTRUCTION: VEX.L1.66.0F.W0 4A /r | KADDB k1, k2, k3 | AVX512DQ
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_Kaddd_kr_kr_kr
INSTRUCTION: VEX.L1.66.0F.W1 4A /r | KADDD k1, k2, k3 | AVX512BW
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_Kunpckwd_kr_kr_kr
INSTRUCTION: VEX.L1.0F.W0 4B /r | KUNPCKWD k1, k2, k3 | AVX512BW
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_Kunpckdq_kr_kr_kr
INSTRUCTION: VEX.L1.0F.W1 4B /r | KUNPCKDQ k1, k2, k3 | AVX512BW
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_Kunpckbw_kr_kr_kr
INSTRUCTION: VEX.L1.66.0F.W0 4B /r | KUNPCKBW k1, k2, k3 | AVX512F
	ops: w=reg r=vvvv r=rm
END

# Code: Movmskps_r32_xmm
INSTRUCTION: NP 0F 50 /r | MOVMSKPS r32, xmm | SSE
	ops: w=reg r=rm
END

# Code: Movmskps_r64_xmm
INSTRUCTION: NP o64 0F 50 /r | MOVMSKPS r64, xmm | SSE
	ops: w=reg r=rm
	flags: 64
	intel: reg32
END

# Code: VEX_Vmovmskps_r32_xmm
INSTRUCTION: VEX.128.0F.W0 50 /r | VMOVMSKPS r32, xmm2 | AVX
	ops: w=reg r=rm
	flags: wig32
END

# Code: VEX_Vmovmskps_r64_xmm
INSTRUCTION: VEX.128.0F.W1 50 /r | VMOVMSKPS r64, xmm2 | AVX
	ops: w=reg r=rm
	flags: 64
	intel: reg32
END

# Code: VEX_Vmovmskps_r32_ymm
INSTRUCTION: VEX.256.0F.W0 50 /r | VMOVMSKPS r32, ymm2 | AVX
	ops: w=reg r=rm
	flags: wig32
END

# Code: VEX_Vmovmskps_r64_ymm
INSTRUCTION: VEX.256.0F.W1 50 /r | VMOVMSKPS r64, ymm2 | AVX
	ops: w=reg r=rm
	flags: 64
	intel: reg32
END

# Code: Movmskpd_r32_xmm
INSTRUCTION: 66 0F 50 /r | MOVMSKPD r32, xmm | SSE2
	ops: w=reg r=rm
END

# Code: Movmskpd_r64_xmm
INSTRUCTION: 66 o64 0F 50 /r | MOVMSKPD r64, xmm | SSE2
	ops: w=reg r=rm
	flags: 64
	intel: reg32
END

# Code: VEX_Vmovmskpd_r32_xmm
INSTRUCTION: VEX.128.66.0F.W0 50 /r | VMOVMSKPD r32, xmm2 | AVX
	ops: w=reg r=rm
	flags: wig32
END

# Code: VEX_Vmovmskpd_r64_xmm
INSTRUCTION: VEX.128.66.0F.W1 50 /r | VMOVMSKPD r64, xmm2 | AVX
	ops: w=reg r=rm
	flags: 64
	intel: reg32
END

# Code: VEX_Vmovmskpd_r32_ymm
INSTRUCTION: VEX.256.66.0F.W0 50 /r | VMOVMSKPD r32, ymm2 | AVX
	ops: w=reg r=rm
	flags: wig32
END

# Code: VEX_Vmovmskpd_r64_ymm
INSTRUCTION: VEX.256.66.0F.W1 50 /r | VMOVMSKPD r64, ymm2 | AVX
	ops: w=reg r=rm
	flags: 64
	intel: reg32
END

# Code: Sqrtps_xmm_xmmm128
INSTRUCTION: NP 0F 51 /r | SQRTPS xmm1, xmm2/m128 | SSE
	ops: w=reg r=rm | Packed128_Float32
END

# Code: VEX_Vsqrtps_xmm_xmmm128
INSTRUCTION: VEX.128.0F.WIG 51 /r | VSQRTPS xmm1, xmm2/m128 | AVX
	ops: w=reg r=rm | Packed128_Float32
END

# Code: VEX_Vsqrtps_ymm_ymmm256
INSTRUCTION: VEX.256.0F.WIG 51 /r | VSQRTPS ymm1, ymm2/m256 | AVX
	ops: w=reg r=rm | Packed256_Float32
END

# Code: EVEX_Vsqrtps_xmm_k1z_xmmm128b32
INSTRUCTION: EVEX.128.0F.W0 51 /r | VSQRTPS xmm1 {k1}{z}, xmm2/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vsqrtps_ymm_k1z_ymmm256b32
INSTRUCTION: EVEX.256.0F.W0 51 /r | VSQRTPS ymm1 {k1}{z}, ymm2/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vsqrtps_zmm_k1z_zmmm512b32_er
INSTRUCTION: EVEX.512.0F.W0 51 /r | VSQRTPS zmm1 {k1}{z}, zmm2/m512/m32bcst{er} | AVX512F | N64b4
	ops: wvmm=reg r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: Sqrtpd_xmm_xmmm128
INSTRUCTION: 66 0F 51 /r | SQRTPD xmm1, xmm2/m128 | SSE2
	ops: w=reg r=rm | Packed128_Float64
END

# Code: VEX_Vsqrtpd_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 51 /r | VSQRTPD xmm1, xmm2/m128 | AVX
	ops: w=reg r=rm | Packed128_Float64
END

# Code: VEX_Vsqrtpd_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 51 /r | VSQRTPD ymm1, ymm2/m256 | AVX
	ops: w=reg r=rm | Packed256_Float64
END

# Code: EVEX_Vsqrtpd_xmm_k1z_xmmm128b64
INSTRUCTION: EVEX.128.66.0F.W1 51 /r | VSQRTPD xmm1 {k1}{z}, xmm2/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vsqrtpd_ymm_k1z_ymmm256b64
INSTRUCTION: EVEX.256.66.0F.W1 51 /r | VSQRTPD ymm1 {k1}{z}, ymm2/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vsqrtpd_zmm_k1z_zmmm512b64_er
INSTRUCTION: EVEX.512.66.0F.W1 51 /r | VSQRTPD zmm1 {k1}{z}, zmm2/m512/m64bcst{er} | AVX512F | N64b8
	ops: wvmm=reg r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: Sqrtss_xmm_xmmm32
INSTRUCTION: F3 0F 51 /r | SQRTSS xmm1, xmm2/m32 | SSE
	ops: rw=reg r=rm | Float32
	masm: flags=force-size=default
END

# Code: VEX_Vsqrtss_xmm_xmm_xmmm32
INSTRUCTION: VEX.LIG.F3.0F.WIG 51 /r | VSQRTSS xmm1, xmm2, xmm3/m32 | AVX
	ops: w=reg r=vvvv r=rm | Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vsqrtss_xmm_k1z_xmm_xmmm32_er
INSTRUCTION: EVEX.LIG.F3.0F.W0 51 /r | VSQRTSS xmm1 {k1}{z}, xmm2, xmm3/m32{er} | AVX512F | N4
	ops: w=reg r=vvvv r=rm | Float32
	masm: flags=force-size=default
END

# Code: Sqrtsd_xmm_xmmm64
INSTRUCTION: F2 0F 51 /r | SQRTSD xmm1, xmm2/m64 | SSE2
	ops: rw=reg r=rm | Float64
	masm: flags=force-size=default
END

# Code: VEX_Vsqrtsd_xmm_xmm_xmmm64
INSTRUCTION: VEX.LIG.F2.0F.WIG 51 /r | VSQRTSD xmm1, xmm2, xmm3/m64 | AVX
	ops: w=reg r=vvvv r=rm | Float64
	masm: flags=force-size=default
END

# Code: EVEX_Vsqrtsd_xmm_k1z_xmm_xmmm64_er
INSTRUCTION: EVEX.LIG.F2.0F.W1 51 /r | VSQRTSD xmm1 {k1}{z}, xmm2, xmm3/m64{er} | AVX512F | N8
	ops: w=reg r=vvvv r=rm | Float64
	masm: flags=force-size=default
END

# Code: Rsqrtps_xmm_xmmm128
INSTRUCTION: NP 0F 52 /r | RSQRTPS xmm1, xmm2/m128 | SSE
	ops: w=reg r=rm | Packed128_Float32
END

# Code: VEX_Vrsqrtps_xmm_xmmm128
INSTRUCTION: VEX.128.0F.WIG 52 /r | VRSQRTPS xmm1, xmm2/m128 | AVX
	ops: w=reg r=rm | Packed128_Float32
END

# Code: VEX_Vrsqrtps_ymm_ymmm256
INSTRUCTION: VEX.256.0F.WIG 52 /r | VRSQRTPS ymm1, ymm2/m256 | AVX
	ops: w=reg r=rm | Packed256_Float32
END

# Code: Rsqrtss_xmm_xmmm32
INSTRUCTION: F3 0F 52 /r | RSQRTSS xmm1, xmm2/m32 | SSE
	ops: rw=reg r=rm | Float32
	masm: flags=force-size=default
END

# Code: VEX_Vrsqrtss_xmm_xmm_xmmm32
INSTRUCTION: VEX.LIG.F3.0F.WIG 52 /r | VRSQRTSS xmm1, xmm2, xmm3/m32 | AVX
	ops: w=reg r=vvvv r=rm | Float32
	masm: flags=force-size=default
END

# Code: Rcpps_xmm_xmmm128
INSTRUCTION: NP 0F 53 /r | RCPPS xmm1, xmm2/m128 | SSE
	ops: w=reg r=rm | Packed128_Float32
END

# Code: VEX_Vrcpps_xmm_xmmm128
INSTRUCTION: VEX.128.0F.WIG 53 /r | VRCPPS xmm1, xmm2/m128 | AVX
	ops: w=reg r=rm | Packed128_Float32
END

# Code: VEX_Vrcpps_ymm_ymmm256
INSTRUCTION: VEX.256.0F.WIG 53 /r | VRCPPS ymm1, ymm2/m256 | AVX
	ops: w=reg r=rm | Packed256_Float32
END

# Code: Rcpss_xmm_xmmm32
INSTRUCTION: F3 0F 53 /r | RCPSS xmm1, xmm2/m32 | SSE
	ops: rw=reg r=rm | Float32
	masm: flags=force-size=default
END

# Code: VEX_Vrcpss_xmm_xmm_xmmm32
INSTRUCTION: VEX.LIG.F3.0F.WIG 53 /r | VRCPSS xmm1, xmm2, xmm3/m32 | AVX
	ops: w=reg r=vvvv r=rm | Float32
END

# Code: Andps_xmm_xmmm128
INSTRUCTION: NP 0F 54 /r | ANDPS xmm1, xmm2/m128 | SSE
	ops: rw=reg r=rm | Packed128_Float32
END

# Code: VEX_Vandps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.0F.WIG 54 /r | VANDPS xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vandps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.0F.WIG 54 /r | VANDPS ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float32
END

# Code: EVEX_Vandps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.0F.W0 54 /r | VANDPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512DQ | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vandps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.0F.W0 54 /r | VANDPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512DQ | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vandps_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.0F.W0 54 /r | VANDPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512DQ | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: Andpd_xmm_xmmm128
INSTRUCTION: 66 0F 54 /r | ANDPD xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_Float64
END

# Code: VEX_Vandpd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 54 /r | VANDPD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vandpd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 54 /r | VANDPD ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vandpd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F.W1 54 /r | VANDPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512DQ | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vandpd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F.W1 54 /r | VANDPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512DQ | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vandpd_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F.W1 54 /r | VANDPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512DQ | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: Andnps_xmm_xmmm128
INSTRUCTION: NP 0F 55 /r | ANDNPS xmm1, xmm2/m128 | SSE
	ops: rw=reg r=rm | Packed128_Float32
END

# Code: VEX_Vandnps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.0F.WIG 55 /r | VANDNPS xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vandnps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.0F.WIG 55 /r | VANDNPS ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float32
END

# Code: EVEX_Vandnps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.0F.W0 55 /r | VANDNPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512DQ | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vandnps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.0F.W0 55 /r | VANDNPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512DQ | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vandnps_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.0F.W0 55 /r | VANDNPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512DQ | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: Andnpd_xmm_xmmm128
INSTRUCTION: 66 0F 55 /r | ANDNPD xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_Float64
END

# Code: VEX_Vandnpd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 55 /r | VANDNPD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vandnpd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 55 /r | VANDNPD ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vandnpd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F.W1 55 /r | VANDNPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512DQ | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vandnpd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F.W1 55 /r | VANDNPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512DQ | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vandnpd_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F.W1 55 /r | VANDNPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512DQ | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: Orps_xmm_xmmm128
INSTRUCTION: NP 0F 56 /r | ORPS xmm1, xmm2/m128 | SSE
	ops: rw=reg r=rm | Packed128_Float32
END

# Code: VEX_Vorps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.0F.WIG 56 /r | VORPS xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vorps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.0F.WIG 56 /r | VORPS ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float32
END

# Code: EVEX_Vorps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.0F.W0 56 /r | VORPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512DQ | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vorps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.0F.W0 56 /r | VORPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512DQ | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vorps_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.0F.W0 56 /r | VORPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512DQ | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: Orpd_xmm_xmmm128
INSTRUCTION: 66 0F 56 /r | ORPD xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_Float64
END

# Code: VEX_Vorpd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 56 /r | VORPD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vorpd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 56 /r | VORPD ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vorpd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F.W1 56 /r | VORPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512DQ | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vorpd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F.W1 56 /r | VORPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512DQ | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vorpd_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F.W1 56 /r | VORPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512DQ | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: Xorps_xmm_xmmm128
INSTRUCTION: NP 0F 57 /r | XORPS xmm1, xmm2/m128 | SSE
	ops: rw=reg r=rm | Packed128_Float32
	implied: zero-reg-regmem
END

# Code: VEX_Vxorps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.0F.WIG 57 /r | VXORPS xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float32
	implied: zero-reg-reg-regmem
END

# Code: VEX_Vxorps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.0F.WIG 57 /r | VXORPS ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float32
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vxorps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.0F.W0 57 /r | VXORPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512DQ | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vxorps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.0F.W0 57 /r | VXORPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512DQ | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vxorps_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.0F.W0 57 /r | VXORPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512DQ | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
	implied: zero-reg-reg-regmem
END

# Code: Xorpd_xmm_xmmm128
INSTRUCTION: 66 0F 57 /r | XORPD xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_Float64
	implied: zero-reg-regmem
END

# Code: VEX_Vxorpd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 57 /r | VXORPD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float64
	implied: zero-reg-reg-regmem
END

# Code: VEX_Vxorpd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 57 /r | VXORPD ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float64
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vxorpd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F.W1 57 /r | VXORPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512DQ | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vxorpd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F.W1 57 /r | VXORPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512DQ | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vxorpd_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F.W1 57 /r | VXORPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512DQ | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
	implied: zero-reg-reg-regmem
END

# Code: Addps_xmm_xmmm128
INSTRUCTION: NP 0F 58 /r | ADDPS xmm1, xmm2/m128 | SSE
	ops: rw=reg r=rm | Packed128_Float32
END

# Code: VEX_Vaddps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.0F.WIG 58 /r | VADDPS xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vaddps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.0F.WIG 58 /r | VADDPS ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float32
END

# Code: EVEX_Vaddps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.0F.W0 58 /r | VADDPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vaddps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.0F.W0 58 /r | VADDPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vaddps_zmm_k1z_zmm_zmmm512b32_er
INSTRUCTION: EVEX.512.0F.W0 58 /r | VADDPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er} | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: Addpd_xmm_xmmm128
INSTRUCTION: 66 0F 58 /r | ADDPD xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_Float64
END

# Code: VEX_Vaddpd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 58 /r | VADDPD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vaddpd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 58 /r | VADDPD ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vaddpd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F.W1 58 /r | VADDPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vaddpd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F.W1 58 /r | VADDPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vaddpd_zmm_k1z_zmm_zmmm512b64_er
INSTRUCTION: EVEX.512.66.0F.W1 58 /r | VADDPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er} | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: Addss_xmm_xmmm32
INSTRUCTION: F3 0F 58 /r | ADDSS xmm1, xmm2/m32 | SSE
	ops: rw=reg r=rm | Float32
	masm: flags=force-size=default
END

# Code: VEX_Vaddss_xmm_xmm_xmmm32
INSTRUCTION: VEX.LIG.F3.0F.WIG 58 /r | VADDSS xmm1, xmm2, xmm3/m32 | AVX
	ops: w=reg r=vvvv r=rm | Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vaddss_xmm_k1z_xmm_xmmm32_er
INSTRUCTION: EVEX.LIG.F3.0F.W0 58 /r | VADDSS xmm1 {k1}{z}, xmm2, xmm3/m32{er} | AVX512F | N4
	ops: w=reg r=vvvv r=rm | Float32
	masm: flags=force-size=default
END

# Code: Addsd_xmm_xmmm64
INSTRUCTION: F2 0F 58 /r | ADDSD xmm1, xmm2/m64 | SSE2
	ops: rw=reg r=rm | Float64
	masm: flags=force-size=default
END

# Code: VEX_Vaddsd_xmm_xmm_xmmm64
INSTRUCTION: VEX.LIG.F2.0F.WIG 58 /r | VADDSD xmm1, xmm2, xmm3/m64 | AVX
	ops: w=reg r=vvvv r=rm | Float64
	masm: flags=force-size=default
END

# Code: EVEX_Vaddsd_xmm_k1z_xmm_xmmm64_er
INSTRUCTION: EVEX.LIG.F2.0F.W1 58 /r | VADDSD xmm1 {k1}{z}, xmm2, xmm3/m64{er} | AVX512F | N8
	ops: w=reg r=vvvv r=rm | Float64
	masm: flags=force-size=default
END

# Code: Mulps_xmm_xmmm128
INSTRUCTION: NP 0F 59 /r | MULPS xmm1, xmm2/m128 | SSE
	ops: rw=reg r=rm | Packed128_Float32
END

# Code: VEX_Vmulps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.0F.WIG 59 /r | VMULPS xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vmulps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.0F.WIG 59 /r | VMULPS ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float32
END

# Code: EVEX_Vmulps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.0F.W0 59 /r | VMULPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vmulps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.0F.W0 59 /r | VMULPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vmulps_zmm_k1z_zmm_zmmm512b32_er
INSTRUCTION: EVEX.512.0F.W0 59 /r | VMULPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er} | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: Mulpd_xmm_xmmm128
INSTRUCTION: 66 0F 59 /r | MULPD xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_Float64
END

# Code: VEX_Vmulpd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 59 /r | VMULPD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vmulpd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 59 /r | VMULPD ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vmulpd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F.W1 59 /r | VMULPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vmulpd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F.W1 59 /r | VMULPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vmulpd_zmm_k1z_zmm_zmmm512b64_er
INSTRUCTION: EVEX.512.66.0F.W1 59 /r | VMULPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er} | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: Mulss_xmm_xmmm32
INSTRUCTION: F3 0F 59 /r | MULSS xmm1, xmm2/m32 | SSE
	ops: rw=reg r=rm | Float32
	masm: flags=force-size=default
END

# Code: VEX_Vmulss_xmm_xmm_xmmm32
INSTRUCTION: VEX.LIG.F3.0F.WIG 59 /r | VMULSS xmm1, xmm2, xmm3/m32 | AVX
	ops: w=reg r=vvvv r=rm | Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vmulss_xmm_k1z_xmm_xmmm32_er
INSTRUCTION: EVEX.LIG.F3.0F.W0 59 /r | VMULSS xmm1 {k1}{z}, xmm2, xmm3/m32{er} | AVX512F | N4
	ops: w=reg r=vvvv r=rm | Float32
	masm: flags=force-size=default
END

# Code: Mulsd_xmm_xmmm64
INSTRUCTION: F2 0F 59 /r | MULSD xmm1, xmm2/m64 | SSE2
	ops: rw=reg r=rm | Float64
	masm: flags=force-size=default
END

# Code: VEX_Vmulsd_xmm_xmm_xmmm64
INSTRUCTION: VEX.LIG.F2.0F.WIG 59 /r | VMULSD xmm1, xmm2, xmm3/m64 | AVX
	ops: w=reg r=vvvv r=rm | Float64
	masm: flags=force-size=default
END

# Code: EVEX_Vmulsd_xmm_k1z_xmm_xmmm64_er
INSTRUCTION: EVEX.LIG.F2.0F.W1 59 /r | VMULSD xmm1 {k1}{z}, xmm2, xmm3/m64{er} | AVX512F | N8
	ops: w=reg r=vvvv r=rm | Float64
	masm: flags=force-size=default
END

# Code: Cvtps2pd_xmm_xmmm64
INSTRUCTION: NP 0F 5A /r | CVTPS2PD xmm1, xmm2/m64 | SSE2
	ops: w=reg r=rm | Packed64_Float32
	masm: flags=force-size=default
END

# Code: VEX_Vcvtps2pd_xmm_xmmm64
INSTRUCTION: VEX.128.0F.WIG 5A /r | VCVTPS2PD xmm1, xmm2/m64 | AVX
	ops: w=reg r=rm | Packed64_Float32
	masm: flags=force-size=default
END

# Code: VEX_Vcvtps2pd_ymm_xmmm128
INSTRUCTION: VEX.256.0F.WIG 5A /r | VCVTPS2PD ymm1, xmm2/m128 | AVX
	ops: w=reg r=rm | Packed128_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtps2pd_xmm_k1z_xmmm64b32
INSTRUCTION: EVEX.128.0F.W0 5A /r | VCVTPS2PD xmm1 {k1}{z}, xmm2/m64/m32bcst | AVX512VL AVX512F | N8b4
	ops: w=reg r=rm | Packed64_Float32 Broadcast64_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtps2pd_ymm_k1z_xmmm128b32
INSTRUCTION: EVEX.256.0F.W0 5A /r | VCVTPS2PD ymm1 {k1}{z}, xmm2/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=rm | Packed128_Float32 Broadcast128_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtps2pd_zmm_k1z_ymmm256b32_sae
INSTRUCTION: EVEX.512.0F.W0 5A /r | VCVTPS2PD zmm1 {k1}{z}, ymm2/m256/m32bcst{sae} | AVX512F | N32b4
	ops: wvmm=reg r=rm | Packed256_Float32 Broadcast256_Float32
	masm: flags=force-size=default
END

# Code: Cvtpd2ps_xmm_xmmm128
INSTRUCTION: 66 0F 5A /r | CVTPD2PS xmm1, xmm2/m128 | SSE2
	ops: w=reg r=rm | Packed128_Float64
END

# Code: VEX_Vcvtpd2ps_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 5A /r | VCVTPD2PS xmm1, xmm2/m128 | AVX
	ops: w=reg r=rm | Packed128_Float64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=x
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: VEX_Vcvtpd2ps_xmm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 5A /r | VCVTPD2PS xmm1, ymm2/m256 | AVX
	ops: w=reg r=rm | Packed256_Float64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=y
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: EVEX_Vcvtpd2ps_xmm_k1z_xmmm128b64
INSTRUCTION: EVEX.128.66.0F.W1 5A /r | VCVTPD2PS xmm1 {k1}{z}, xmm2/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=rm | Packed128_Float64 Broadcast128_Float64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=x
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vcvtpd2ps_xmm_k1z_ymmm256b64
INSTRUCTION: EVEX.256.66.0F.W1 5A /r | VCVTPD2PS xmm1 {k1}{z}, ymm2/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=rm | Packed256_Float64 Broadcast256_Float64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=y
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vcvtpd2ps_ymm_k1z_zmmm512b64_er
INSTRUCTION: EVEX.512.66.0F.W1 5A /r | VCVTPD2PS ymm1 {k1}{z}, zmm2/m512/m64bcst{er} | AVX512F | N64b8
	ops: w=reg r=rm | Packed512_Float64 Broadcast512_Float64
	masm: flags=force-size=default
END

# Code: Cvtss2sd_xmm_xmmm32
INSTRUCTION: F3 0F 5A /r | CVTSS2SD xmm1, xmm2/m32 | SSE2
	ops: rw=reg r=rm | Float32
	masm: flags=force-size=default
END

# Code: VEX_Vcvtss2sd_xmm_xmm_xmmm32
INSTRUCTION: VEX.LIG.F3.0F.WIG 5A /r | VCVTSS2SD xmm1, xmm2, xmm3/m32 | AVX
	ops: w=reg r=vvvv r=rm | Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtss2sd_xmm_k1z_xmm_xmmm32_sae
INSTRUCTION: EVEX.LIG.F3.0F.W0 5A /r | VCVTSS2SD xmm1 {k1}{z}, xmm2, xmm3/m32{sae} | AVX512F | N4
	ops: w=reg r=vvvv r=rm | Float32
	masm: flags=force-size=default
END

# Code: Cvtsd2ss_xmm_xmmm64
INSTRUCTION: F2 0F 5A /r | CVTSD2SS xmm1, xmm2/m64 | SSE2
	ops: rw=reg r=rm | Float64
	masm: flags=force-size=default
END

# Code: VEX_Vcvtsd2ss_xmm_xmm_xmmm64
INSTRUCTION: VEX.LIG.F2.0F.WIG 5A /r | VCVTSD2SS xmm1, xmm2, xmm3/m64 | AVX
	ops: w=reg r=vvvv r=rm | Float64
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtsd2ss_xmm_k1z_xmm_xmmm64_er
INSTRUCTION: EVEX.LIG.F2.0F.W1 5A /r | VCVTSD2SS xmm1 {k1}{z}, xmm2, xmm3/m64{er} | AVX512F | N8
	ops: w=reg r=vvvv r=rm | Float64
	masm: flags=force-size=default
END

# Code: Cvtdq2ps_xmm_xmmm128
INSTRUCTION: NP 0F 5B /r | CVTDQ2PS xmm1, xmm2/m128 | SSE2
	ops: w=reg r=rm | Packed128_Int32
END

# Code: VEX_Vcvtdq2ps_xmm_xmmm128
INSTRUCTION: VEX.128.0F.WIG 5B /r | VCVTDQ2PS xmm1, xmm2/m128 | AVX
	ops: w=reg r=rm | Packed128_Int32
	masm: flags=force-size=default
END

# Code: VEX_Vcvtdq2ps_ymm_ymmm256
INSTRUCTION: VEX.256.0F.WIG 5B /r | VCVTDQ2PS ymm1, ymm2/m256 | AVX
	ops: w=reg r=rm | Packed256_Int32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtdq2ps_xmm_k1z_xmmm128b32
INSTRUCTION: EVEX.128.0F.W0 5B /r | VCVTDQ2PS xmm1 {k1}{z}, xmm2/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=rm | Packed128_Int32 Broadcast128_Int32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtdq2ps_ymm_k1z_ymmm256b32
INSTRUCTION: EVEX.256.0F.W0 5B /r | VCVTDQ2PS ymm1 {k1}{z}, ymm2/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=rm | Packed256_Int32 Broadcast256_Int32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtdq2ps_zmm_k1z_zmmm512b32_er
INSTRUCTION: EVEX.512.0F.W0 5B /r | VCVTDQ2PS zmm1 {k1}{z}, zmm2/m512/m32bcst{er} | AVX512F | N64b4
	ops: wvmm=reg r=rm | Packed512_Int32 Broadcast512_Int32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtqq2ps_xmm_k1z_xmmm128b64
INSTRUCTION: EVEX.128.0F.W1 5B /r | VCVTQQ2PS xmm1 {k1}{z}, xmm2/m128/m64bcst | AVX512VL AVX512DQ | N16b8
	ops: w=reg r=rm | Packed128_Int64 Broadcast128_Int64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=x
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vcvtqq2ps_xmm_k1z_ymmm256b64
INSTRUCTION: EVEX.256.0F.W1 5B /r | VCVTQQ2PS xmm1 {k1}{z}, ymm2/m256/m64bcst | AVX512VL AVX512DQ | N32b8
	ops: w=reg r=rm | Packed256_Int64 Broadcast256_Int64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=y
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vcvtqq2ps_ymm_k1z_zmmm512b64_er
INSTRUCTION: EVEX.512.0F.W1 5B /r | VCVTQQ2PS ymm1 {k1}{z}, zmm2/m512/m64bcst{er} | AVX512DQ | N64b8
	ops: w=reg r=rm | Packed512_Int64 Broadcast512_Int64
	masm: flags=force-size=default
END

# Code: Cvtps2dq_xmm_xmmm128
INSTRUCTION: 66 0F 5B /r | CVTPS2DQ xmm1, xmm2/m128 | SSE2
	ops: w=reg r=rm | Packed128_Float32
END

# Code: VEX_Vcvtps2dq_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 5B /r | VCVTPS2DQ xmm1, xmm2/m128 | AVX
	ops: w=reg r=rm | Packed128_Float32
	masm: flags=force-size=default
END

# Code: VEX_Vcvtps2dq_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 5B /r | VCVTPS2DQ ymm1, ymm2/m256 | AVX
	ops: w=reg r=rm | Packed256_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtps2dq_xmm_k1z_xmmm128b32
INSTRUCTION: EVEX.128.66.0F.W0 5B /r | VCVTPS2DQ xmm1 {k1}{z}, xmm2/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=rm | Packed128_Float32 Broadcast128_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtps2dq_ymm_k1z_ymmm256b32
INSTRUCTION: EVEX.256.66.0F.W0 5B /r | VCVTPS2DQ ymm1 {k1}{z}, ymm2/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=rm | Packed256_Float32 Broadcast256_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtps2dq_zmm_k1z_zmmm512b32_er
INSTRUCTION: EVEX.512.66.0F.W0 5B /r | VCVTPS2DQ zmm1 {k1}{z}, zmm2/m512/m32bcst{er} | AVX512F | N64b4
	ops: wvmm=reg r=rm | Packed512_Float32 Broadcast512_Float32
	masm: flags=force-size=default
END

# Code: Cvttps2dq_xmm_xmmm128
INSTRUCTION: F3 0F 5B /r | CVTTPS2DQ xmm1, xmm2/m128 | SSE2
	ops: w=reg r=rm | Packed128_Float32
END

# Code: VEX_Vcvttps2dq_xmm_xmmm128
INSTRUCTION: VEX.128.F3.0F.WIG 5B /r | VCVTTPS2DQ xmm1, xmm2/m128 | AVX
	ops: w=reg r=rm | Packed128_Float32
	masm: flags=force-size=default
END

# Code: VEX_Vcvttps2dq_ymm_ymmm256
INSTRUCTION: VEX.256.F3.0F.WIG 5B /r | VCVTTPS2DQ ymm1, ymm2/m256 | AVX
	ops: w=reg r=rm | Packed256_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttps2dq_xmm_k1z_xmmm128b32
INSTRUCTION: EVEX.128.F3.0F.W0 5B /r | VCVTTPS2DQ xmm1 {k1}{z}, xmm2/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=rm | Packed128_Float32 Broadcast128_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttps2dq_ymm_k1z_ymmm256b32
INSTRUCTION: EVEX.256.F3.0F.W0 5B /r | VCVTTPS2DQ ymm1 {k1}{z}, ymm2/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=rm | Packed256_Float32 Broadcast256_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttps2dq_zmm_k1z_zmmm512b32_sae
INSTRUCTION: EVEX.512.F3.0F.W0 5B /r | VCVTTPS2DQ zmm1 {k1}{z}, zmm2/m512/m32bcst{sae} | AVX512F | N64b4
	ops: wvmm=reg r=rm | Packed512_Float32 Broadcast512_Float32
	masm: flags=force-size=default
END

# Code: Subps_xmm_xmmm128
INSTRUCTION: NP 0F 5C /r | SUBPS xmm1, xmm2/m128 | SSE
	ops: rw=reg r=rm | Packed128_Float32
END

# Code: VEX_Vsubps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.0F.WIG 5C /r | VSUBPS xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vsubps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.0F.WIG 5C /r | VSUBPS ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float32
END

# Code: EVEX_Vsubps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.0F.W0 5C /r | VSUBPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vsubps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.0F.W0 5C /r | VSUBPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vsubps_zmm_k1z_zmm_zmmm512b32_er
INSTRUCTION: EVEX.512.0F.W0 5C /r | VSUBPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er} | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: Subpd_xmm_xmmm128
INSTRUCTION: 66 0F 5C /r | SUBPD xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_Float64
END

# Code: VEX_Vsubpd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 5C /r | VSUBPD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vsubpd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 5C /r | VSUBPD ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vsubpd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F.W1 5C /r | VSUBPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vsubpd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F.W1 5C /r | VSUBPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vsubpd_zmm_k1z_zmm_zmmm512b64_er
INSTRUCTION: EVEX.512.66.0F.W1 5C /r | VSUBPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er} | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: Subss_xmm_xmmm32
INSTRUCTION: F3 0F 5C /r | SUBSS xmm1, xmm2/m32 | SSE
	ops: rw=reg r=rm | Float32
	masm: flags=force-size=default
END

# Code: VEX_Vsubss_xmm_xmm_xmmm32
INSTRUCTION: VEX.LIG.F3.0F.WIG 5C /r | VSUBSS xmm1, xmm2, xmm3/m32 | AVX
	ops: w=reg r=vvvv r=rm | Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vsubss_xmm_k1z_xmm_xmmm32_er
INSTRUCTION: EVEX.LIG.F3.0F.W0 5C /r | VSUBSS xmm1 {k1}{z}, xmm2, xmm3/m32{er} | AVX512F | N4
	ops: w=reg r=vvvv r=rm | Float32
	masm: flags=force-size=default
END

# Code: Subsd_xmm_xmmm64
INSTRUCTION: F2 0F 5C /r | SUBSD xmm1, xmm2/m64 | SSE2
	ops: rw=reg r=rm | Float64
	masm: flags=force-size=default
END

# Code: VEX_Vsubsd_xmm_xmm_xmmm64
INSTRUCTION: VEX.LIG.F2.0F.WIG 5C /r | VSUBSD xmm1, xmm2, xmm3/m64 | AVX
	ops: w=reg r=vvvv r=rm | Float64
	masm: flags=force-size=default
END

# Code: EVEX_Vsubsd_xmm_k1z_xmm_xmmm64_er
INSTRUCTION: EVEX.LIG.F2.0F.W1 5C /r | VSUBSD xmm1 {k1}{z}, xmm2, xmm3/m64{er} | AVX512F | N8
	ops: w=reg r=vvvv r=rm | Float64
	masm: flags=force-size=default
END

# Code: Minps_xmm_xmmm128
INSTRUCTION: NP 0F 5D /r | MINPS xmm1, xmm2/m128 | SSE
	ops: rw=reg r=rm | Packed128_Float32
END

# Code: VEX_Vminps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.0F.WIG 5D /r | VMINPS xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vminps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.0F.WIG 5D /r | VMINPS ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float32
END

# Code: EVEX_Vminps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.0F.W0 5D /r | VMINPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vminps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.0F.W0 5D /r | VMINPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vminps_zmm_k1z_zmm_zmmm512b32_sae
INSTRUCTION: EVEX.512.0F.W0 5D /r | VMINPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{sae} | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: Minpd_xmm_xmmm128
INSTRUCTION: 66 0F 5D /r | MINPD xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_Float64
END

# Code: VEX_Vminpd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 5D /r | VMINPD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vminpd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 5D /r | VMINPD ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vminpd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F.W1 5D /r | VMINPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vminpd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F.W1 5D /r | VMINPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vminpd_zmm_k1z_zmm_zmmm512b64_sae
INSTRUCTION: EVEX.512.66.0F.W1 5D /r | VMINPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{sae} | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: Minss_xmm_xmmm32
INSTRUCTION: F3 0F 5D /r | MINSS xmm1, xmm2/m32 | SSE
	ops: rw=reg r=rm | Float32
	masm: flags=force-size=default
END

# Code: VEX_Vminss_xmm_xmm_xmmm32
INSTRUCTION: VEX.LIG.F3.0F.WIG 5D /r | VMINSS xmm1, xmm2, xmm3/m32 | AVX
	ops: w=reg r=vvvv r=rm | Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vminss_xmm_k1z_xmm_xmmm32_sae
INSTRUCTION: EVEX.LIG.F3.0F.W0 5D /r | VMINSS xmm1 {k1}{z}, xmm2, xmm3/m32{sae} | AVX512F | N4
	ops: w=reg r=vvvv r=rm | Float32
	masm: flags=force-size=default
END

# Code: Minsd_xmm_xmmm64
INSTRUCTION: F2 0F 5D /r | MINSD xmm1, xmm2/m64 | SSE2
	ops: rw=reg r=rm | Float64
	masm: flags=force-size=default
END

# Code: VEX_Vminsd_xmm_xmm_xmmm64
INSTRUCTION: VEX.LIG.F2.0F.WIG 5D /r | VMINSD xmm1, xmm2, xmm3/m64 | AVX
	ops: w=reg r=vvvv r=rm | Float64
	masm: flags=force-size=default
END

# Code: EVEX_Vminsd_xmm_k1z_xmm_xmmm64_sae
INSTRUCTION: EVEX.LIG.F2.0F.W1 5D /r | VMINSD xmm1 {k1}{z}, xmm2, xmm3/m64{sae} | AVX512F | N8
	ops: w=reg r=vvvv r=rm | Float64
	masm: flags=force-size=default
END

# Code: Divps_xmm_xmmm128
INSTRUCTION: NP 0F 5E /r | DIVPS xmm1, xmm2/m128 | SSE
	ops: rw=reg r=rm | Packed128_Float32
END

# Code: VEX_Vdivps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.0F.WIG 5E /r | VDIVPS xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vdivps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.0F.WIG 5E /r | VDIVPS ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float32
END

# Code: EVEX_Vdivps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.0F.W0 5E /r | VDIVPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vdivps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.0F.W0 5E /r | VDIVPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vdivps_zmm_k1z_zmm_zmmm512b32_er
INSTRUCTION: EVEX.512.0F.W0 5E /r | VDIVPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er} | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: Divpd_xmm_xmmm128
INSTRUCTION: 66 0F 5E /r | DIVPD xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_Float64
END

# Code: VEX_Vdivpd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 5E /r | VDIVPD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vdivpd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 5E /r | VDIVPD ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vdivpd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F.W1 5E /r | VDIVPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vdivpd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F.W1 5E /r | VDIVPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vdivpd_zmm_k1z_zmm_zmmm512b64_er
INSTRUCTION: EVEX.512.66.0F.W1 5E /r | VDIVPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er} | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: Divss_xmm_xmmm32
INSTRUCTION: F3 0F 5E /r | DIVSS xmm1, xmm2/m32 | SSE
	ops: rw=reg r=rm | Float32
	masm: flags=force-size=default
END

# Code: VEX_Vdivss_xmm_xmm_xmmm32
INSTRUCTION: VEX.LIG.F3.0F.WIG 5E /r | VDIVSS xmm1, xmm2, xmm3/m32 | AVX
	ops: w=reg r=vvvv r=rm | Float32
END

# Code: EVEX_Vdivss_xmm_k1z_xmm_xmmm32_er
INSTRUCTION: EVEX.LIG.F3.0F.W0 5E /r | VDIVSS xmm1 {k1}{z}, xmm2, xmm3/m32{er} | AVX512F | N4
	ops: w=reg r=vvvv r=rm | Float32
	masm: flags=force-size=default
END

# Code: Divsd_xmm_xmmm64
INSTRUCTION: F2 0F 5E /r | DIVSD xmm1, xmm2/m64 | SSE2
	ops: rw=reg r=rm | Float64
	masm: flags=force-size=default
END

# Code: VEX_Vdivsd_xmm_xmm_xmmm64
INSTRUCTION: VEX.LIG.F2.0F.WIG 5E /r | VDIVSD xmm1, xmm2, xmm3/m64 | AVX
	ops: w=reg r=vvvv r=rm | Float64
END

# Code: EVEX_Vdivsd_xmm_k1z_xmm_xmmm64_er
INSTRUCTION: EVEX.LIG.F2.0F.W1 5E /r | VDIVSD xmm1 {k1}{z}, xmm2, xmm3/m64{er} | AVX512F | N8
	ops: w=reg r=vvvv r=rm | Float64
	masm: flags=force-size=default
END

# Code: Maxps_xmm_xmmm128
INSTRUCTION: NP 0F 5F /r | MAXPS xmm1, xmm2/m128 | SSE
	ops: rw=reg r=rm | Packed128_Float32
END

# Code: VEX_Vmaxps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.0F.WIG 5F /r | VMAXPS xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vmaxps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.0F.WIG 5F /r | VMAXPS ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float32
END

# Code: EVEX_Vmaxps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.0F.W0 5F /r | VMAXPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vmaxps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.0F.W0 5F /r | VMAXPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vmaxps_zmm_k1z_zmm_zmmm512b32_sae
INSTRUCTION: EVEX.512.0F.W0 5F /r | VMAXPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{sae} | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: Maxpd_xmm_xmmm128
INSTRUCTION: 66 0F 5F /r | MAXPD xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_Float64
END

# Code: VEX_Vmaxpd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 5F /r | VMAXPD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vmaxpd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 5F /r | VMAXPD ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vmaxpd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F.W1 5F /r | VMAXPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vmaxpd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F.W1 5F /r | VMAXPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vmaxpd_zmm_k1z_zmm_zmmm512b64_sae
INSTRUCTION: EVEX.512.66.0F.W1 5F /r | VMAXPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{sae} | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: Maxss_xmm_xmmm32
INSTRUCTION: F3 0F 5F /r | MAXSS xmm1, xmm2/m32 | SSE
	ops: rw=reg r=rm | Float32
	masm: flags=force-size=default
END

# Code: VEX_Vmaxss_xmm_xmm_xmmm32
INSTRUCTION: VEX.LIG.F3.0F.WIG 5F /r | VMAXSS xmm1, xmm2, xmm3/m32 | AVX
	ops: w=reg r=vvvv r=rm | Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vmaxss_xmm_k1z_xmm_xmmm32_sae
INSTRUCTION: EVEX.LIG.F3.0F.W0 5F /r | VMAXSS xmm1 {k1}{z}, xmm2, xmm3/m32{sae} | AVX512F | N4
	ops: w=reg r=vvvv r=rm | Float32
	masm: flags=force-size=default
END

# Code: Maxsd_xmm_xmmm64
INSTRUCTION: F2 0F 5F /r | MAXSD xmm1, xmm2/m64 | SSE2
	ops: rw=reg r=rm | Float64
	masm: flags=force-size=default
END

# Code: VEX_Vmaxsd_xmm_xmm_xmmm64
INSTRUCTION: VEX.LIG.F2.0F.WIG 5F /r | VMAXSD xmm1, xmm2, xmm3/m64 | AVX
	ops: w=reg r=vvvv r=rm | Float64
	masm: flags=force-size=default
END

# Code: EVEX_Vmaxsd_xmm_k1z_xmm_xmmm64_sae
INSTRUCTION: EVEX.LIG.F2.0F.W1 5F /r | VMAXSD xmm1 {k1}{z}, xmm2, xmm3/m64{sae} | AVX512F | N8
	ops: w=reg r=vvvv r=rm | Float64
	masm: flags=force-size=default
END

# Code: Punpcklbw_mm_mmm32
INSTRUCTION: NP 0F 60 /r | PUNPCKLBW mm, mm/m32 | MMX
	ops: rw=reg r=rm | Packed32_UInt8
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Punpcklbw_xmm_xmmm128
INSTRUCTION: 66 0F 60 /r | PUNPCKLBW xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt8
END

# Code: VEX_Vpunpcklbw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 60 /r | VPUNPCKLBW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
END

# Code: VEX_Vpunpcklbw_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 60 /r | VPUNPCKLBW ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
END

# Code: EVEX_Vpunpcklbw_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG 60 /r | VPUNPCKLBW xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
END

# Code: EVEX_Vpunpcklbw_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG 60 /r | VPUNPCKLBW ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
END

# Code: EVEX_Vpunpcklbw_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG 60 /r | VPUNPCKLBW zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt8
END

# Code: Punpcklwd_mm_mmm32
INSTRUCTION: NP 0F 61 /r | PUNPCKLWD mm, mm/m32 | MMX
	ops: rw=reg r=rm | Packed32_UInt16
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Punpcklwd_xmm_xmmm128
INSTRUCTION: 66 0F 61 /r | PUNPCKLWD xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt16
END

# Code: VEX_Vpunpcklwd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 61 /r | VPUNPCKLWD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: VEX_Vpunpcklwd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 61 /r | VPUNPCKLWD ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: EVEX_Vpunpcklwd_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG 61 /r | VPUNPCKLWD xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: EVEX_Vpunpcklwd_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG 61 /r | VPUNPCKLWD ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: EVEX_Vpunpcklwd_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG 61 /r | VPUNPCKLWD zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt16
END

# Code: Punpckldq_mm_mmm32
INSTRUCTION: NP 0F 62 /r | PUNPCKLDQ mm, mm/m32 | MMX
	ops: rw=reg r=rm | Int32
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Punpckldq_xmm_xmmm128
INSTRUCTION: 66 0F 62 /r | PUNPCKLDQ xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt32
END

# Code: VEX_Vpunpckldq_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 62 /r | VPUNPCKLDQ xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt32
END

# Code: VEX_Vpunpckldq_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 62 /r | VPUNPCKLDQ ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt32
END

# Code: EVEX_Vpunpckldq_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F.W0 62 /r | VPUNPCKLDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_UInt32 Broadcast128_UInt32
END

# Code: EVEX_Vpunpckldq_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F.W0 62 /r | VPUNPCKLDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vpunpckldq_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F.W0 62 /r | VPUNPCKLDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: Packsswb_mm_mmm64
INSTRUCTION: NP 0F 63 /r | PACKSSWB mm1, mm2/m64 | MMX
	ops: rw=reg r=rm | Packed64_Int16
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Packsswb_xmm_xmmm128
INSTRUCTION: 66 0F 63 /r | PACKSSWB xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_Int16
END

# Code: VEX_Vpacksswb_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 63 /r | VPACKSSWB xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int16
END

# Code: VEX_Vpacksswb_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 63 /r | VPACKSSWB ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Int16
END

# Code: EVEX_Vpacksswb_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG 63 /r | VPACKSSWB xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_Int16
END

# Code: EVEX_Vpacksswb_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG 63 /r | VPACKSSWB ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_Int16
END

# Code: EVEX_Vpacksswb_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG 63 /r | VPACKSSWB zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_Int16
END

# Code: Pcmpgtb_mm_mmm64
INSTRUCTION: NP 0F 64 /r | PCMPGTB mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_Int8
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Pcmpgtb_xmm_xmmm128
INSTRUCTION: 66 0F 64 /r | PCMPGTB xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_Int8
END

# Code: VEX_Vpcmpgtb_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 64 /r | VPCMPGTB xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int8
END

# Code: VEX_Vpcmpgtb_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 64 /r | VPCMPGTB ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Int8
END

# Code: EVEX_Vpcmpgtb_kr_k1_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG 64 /r | VPCMPGTB k1 {k2}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_Int8
	flags: implied-z
END

# Code: EVEX_Vpcmpgtb_kr_k1_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG 64 /r | VPCMPGTB k1 {k2}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_Int8
	flags: implied-z
END

# Code: EVEX_Vpcmpgtb_kr_k1_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG 64 /r | VPCMPGTB k1 {k2}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: w=reg r=vvvv r=rm | Packed512_Int8
	flags: implied-z
END

# Code: Pcmpgtw_mm_mmm64
INSTRUCTION: NP 0F 65 /r | PCMPGTW mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_Int16
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Pcmpgtw_xmm_xmmm128
INSTRUCTION: 66 0F 65 /r | PCMPGTW xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_Int16
END

# Code: VEX_Vpcmpgtw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 65 /r | VPCMPGTW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int16
END

# Code: VEX_Vpcmpgtw_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 65 /r | VPCMPGTW ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Int16
END

# Code: EVEX_Vpcmpgtw_kr_k1_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG 65 /r | VPCMPGTW k1 {k2}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_Int16
	flags: implied-z
END

# Code: EVEX_Vpcmpgtw_kr_k1_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG 65 /r | VPCMPGTW k1 {k2}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_Int16
	flags: implied-z
END

# Code: EVEX_Vpcmpgtw_kr_k1_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG 65 /r | VPCMPGTW k1 {k2}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: w=reg r=vvvv r=rm | Packed512_Int16
	flags: implied-z
END

# Code: Pcmpgtd_mm_mmm64
INSTRUCTION: NP 0F 66 /r | PCMPGTD mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_Int32
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Pcmpgtd_xmm_xmmm128
INSTRUCTION: 66 0F 66 /r | PCMPGTD xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_Int32
END

# Code: VEX_Vpcmpgtd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 66 /r | VPCMPGTD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int32
END

# Code: VEX_Vpcmpgtd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 66 /r | VPCMPGTD ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Int32
END

# Code: EVEX_Vpcmpgtd_kr_k1_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F.W0 66 /r | VPCMPGTD k1 {k2}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_Int32 Broadcast128_Int32
	flags: implied-z
END

# Code: EVEX_Vpcmpgtd_kr_k1_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F.W0 66 /r | VPCMPGTD k1 {k2}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_Int32 Broadcast256_Int32
	flags: implied-z
END

# Code: EVEX_Vpcmpgtd_kr_k1_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F.W0 66 /r | VPCMPGTD k1 {k2}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: w=reg r=vvvv r=rm | Packed512_Int32 Broadcast512_Int32
	flags: implied-z
END

# Code: Packuswb_mm_mmm64
INSTRUCTION: NP 0F 67 /r | PACKUSWB mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_Int16
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Packuswb_xmm_xmmm128
INSTRUCTION: 66 0F 67 /r | PACKUSWB xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_Int16
END

# Code: VEX_Vpackuswb_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 67 /r | VPACKUSWB xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int16
END

# Code: VEX_Vpackuswb_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 67 /r | VPACKUSWB ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Int16
END

# Code: EVEX_Vpackuswb_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG 67 /r | VPACKUSWB xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_Int16
END

# Code: EVEX_Vpackuswb_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG 67 /r | VPACKUSWB ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_Int16
END

# Code: EVEX_Vpackuswb_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG 67 /r | VPACKUSWB zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_Int16
END

# Code: Punpckhbw_mm_mmm64
INSTRUCTION: NP 0F 68 /r | PUNPCKHBW mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_UInt8
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Punpckhbw_xmm_xmmm128
INSTRUCTION: 66 0F 68 /r | PUNPCKHBW xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt8
END

# Code: VEX_Vpunpckhbw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 68 /r | VPUNPCKHBW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
END

# Code: VEX_Vpunpckhbw_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 68 /r | VPUNPCKHBW ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
END

# Code: EVEX_Vpunpckhbw_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG 68 /r | VPUNPCKHBW xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
END

# Code: EVEX_Vpunpckhbw_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG 68 /r | VPUNPCKHBW ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
END

# Code: EVEX_Vpunpckhbw_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG 68 /r | VPUNPCKHBW zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt8
END

# Code: Punpckhwd_mm_mmm64
INSTRUCTION: NP 0F 69 /r | PUNPCKHWD mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_UInt16
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Punpckhwd_xmm_xmmm128
INSTRUCTION: 66 0F 69 /r | PUNPCKHWD xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt16
END

# Code: VEX_Vpunpckhwd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 69 /r | VPUNPCKHWD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: VEX_Vpunpckhwd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 69 /r | VPUNPCKHWD ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: EVEX_Vpunpckhwd_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG 69 /r | VPUNPCKHWD xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: EVEX_Vpunpckhwd_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG 69 /r | VPUNPCKHWD ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: EVEX_Vpunpckhwd_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG 69 /r | VPUNPCKHWD zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt16
END

# Code: Punpckhdq_mm_mmm64
INSTRUCTION: NP 0F 6A /r | PUNPCKHDQ mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_UInt32
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Punpckhdq_xmm_xmmm128
INSTRUCTION: 66 0F 6A /r | PUNPCKHDQ xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt32
END

# Code: VEX_Vpunpckhdq_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 6A /r | VPUNPCKHDQ xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt32
END

# Code: VEX_Vpunpckhdq_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 6A /r | VPUNPCKHDQ ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt32
END

# Code: EVEX_Vpunpckhdq_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F.W0 6A /r | VPUNPCKHDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_UInt32 Broadcast128_UInt32
END

# Code: EVEX_Vpunpckhdq_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F.W0 6A /r | VPUNPCKHDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vpunpckhdq_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F.W0 6A /r | VPUNPCKHDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: Packssdw_mm_mmm64
INSTRUCTION: NP 0F 6B /r | PACKSSDW mm1, mm2/m64 | MMX
	ops: rw=reg r=rm | Packed64_Int32
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Packssdw_xmm_xmmm128
INSTRUCTION: 66 0F 6B /r | PACKSSDW xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_Int32
END

# Code: VEX_Vpackssdw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 6B /r | VPACKSSDW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int32
END

# Code: VEX_Vpackssdw_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 6B /r | VPACKSSDW ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Int32
END

# Code: EVEX_Vpackssdw_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F.W0 6B /r | VPACKSSDW xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512BW | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_Int32 Broadcast128_Int32
END

# Code: EVEX_Vpackssdw_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F.W0 6B /r | VPACKSSDW ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512BW | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_Int32 Broadcast256_Int32
END

# Code: EVEX_Vpackssdw_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F.W0 6B /r | VPACKSSDW zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512BW | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_Int32 Broadcast512_Int32
END

# Code: Punpcklqdq_xmm_xmmm128
INSTRUCTION: 66 0F 6C /r | PUNPCKLQDQ xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt64
END

# Code: VEX_Vpunpcklqdq_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 6C /r | VPUNPCKLQDQ xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt64
END

# Code: VEX_Vpunpcklqdq_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 6C /r | VPUNPCKLQDQ ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt64
END

# Code: EVEX_Vpunpcklqdq_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F.W1 6C /r | VPUNPCKLQDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Vpunpcklqdq_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F.W1 6C /r | VPUNPCKLQDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vpunpcklqdq_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F.W1 6C /r | VPUNPCKLQDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: Punpckhqdq_xmm_xmmm128
INSTRUCTION: 66 0F 6D /r | PUNPCKHQDQ xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt64
END

# Code: VEX_Vpunpckhqdq_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 6D /r | VPUNPCKHQDQ xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt64
END

# Code: VEX_Vpunpckhqdq_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 6D /r | VPUNPCKHQDQ ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt64
END

# Code: EVEX_Vpunpckhqdq_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F.W1 6D /r | VPUNPCKHQDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Vpunpckhqdq_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F.W1 6D /r | VPUNPCKHQDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vpunpckhqdq_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F.W1 6D /r | VPUNPCKHQDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: Movd_mm_rm32
INSTRUCTION: NP 0F 6E /r | MOVD mm, r/m32 | MMX
	ops: w=reg r=rm | UInt32
	flags: tsx-impl-abort
	masm: flags=force-size=default
END

# Code: Movq_mm_rm64
INSTRUCTION: NP o64 0F 6E /r | MOVQ mm, r/m64 | MMX
	ops: w=reg r=rm | UInt64
	flags: 64 tsx-impl-abort asm-ig-mem
END

# Code: Movd_xmm_rm32
INSTRUCTION: 66 0F 6E /r | MOVD xmm, r/m32 | SSE2
	ops: w=reg r=rm | UInt32
	masm: flags=force-size=default
END

# Code: Movq_xmm_rm64
INSTRUCTION: 66 o64 0F 6E /r | MOVQ xmm, r/m64 | SSE2
	ops: w=reg r=rm | UInt64
	flags: 64 asm-ig-mem
	masm: flags=force-size=default
END

# Code: VEX_Vmovd_xmm_rm32
INSTRUCTION: VEX.128.66.0F.W0 6E /r | VMOVD xmm1, r/m32 | AVX
	ops: w=reg r=rm | UInt32
	flags: wig32
	masm: flags=force-size=default
END

# Code: VEX_Vmovq_xmm_rm64
INSTRUCTION: VEX.128.66.0F.W1 6E /r | VMOVQ xmm1, r/m64 | AVX
	ops: w=reg r=rm | UInt64
	flags: 64 asm-ig-mem
	masm: flags=force-size=default
END

# Code: EVEX_Vmovd_xmm_rm32
INSTRUCTION: EVEX.128.66.0F.W0 6E /r | VMOVD xmm1, r/m32 | AVX512F | N4
	ops: w=reg r=rm | UInt32
	flags: wig32
	masm: flags=force-size=default
END

# Code: EVEX_Vmovq_xmm_rm64
INSTRUCTION: EVEX.128.66.0F.W1 6E /r | VMOVQ xmm1, r/m64 | AVX512F | N8
	ops: w=reg r=rm | UInt64
	flags: 64 asm-ig-mem
	masm: flags=force-size=default
END

# Code: Movq_mm_mmm64
INSTRUCTION: NP 0F 6F /r | MOVQ mm, mm/m64 | MMX
	ops: w=reg r=rm | UInt64
	flags: tsx-impl-abort
END

# Code: Movdqa_xmm_xmmm128
INSTRUCTION: 66 0F 6F /r | MOVDQA xmm1, xmm2/m128 | SSE2
	ops: w=reg r=rm | Packed128_UInt32
END

# Code: VEX_Vmovdqa_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 6F /r | VMOVDQA xmm1, xmm2/m128 | AVX
	ops: w=reg r=rm | Packed128_UInt32
	masm: flags=force-size=default
END

# Code: VEX_Vmovdqa_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 6F /r | VMOVDQA ymm1, ymm2/m256 | AVX
	ops: w=reg r=rm | Packed256_UInt32
	masm: flags=force-size=default
END

# Code: EVEX_Vmovdqa32_xmm_k1z_xmmm128
INSTRUCTION: EVEX.128.66.0F.W0 6F /r | VMOVDQA32 xmm1 {k1}{z}, xmm2/m128 | AVX512VL AVX512F | N16
	ops: w=reg r=rm | Packed128_UInt32
END

# Code: EVEX_Vmovdqa32_ymm_k1z_ymmm256
INSTRUCTION: EVEX.256.66.0F.W0 6F /r | VMOVDQA32 ymm1 {k1}{z}, ymm2/m256 | AVX512VL AVX512F | N32
	ops: w=reg r=rm | Packed256_UInt32
END

# Code: EVEX_Vmovdqa32_zmm_k1z_zmmm512
INSTRUCTION: EVEX.512.66.0F.W0 6F /r | VMOVDQA32 zmm1 {k1}{z}, zmm2/m512 | AVX512F | N64
	ops: wvmm=reg r=rm | Packed512_UInt32
END

# Code: EVEX_Vmovdqa64_xmm_k1z_xmmm128
INSTRUCTION: EVEX.128.66.0F.W1 6F /r | VMOVDQA64 xmm1 {k1}{z}, xmm2/m128 | AVX512VL AVX512F | N16
	ops: w=reg r=rm | Packed128_UInt64
END

# Code: EVEX_Vmovdqa64_ymm_k1z_ymmm256
INSTRUCTION: EVEX.256.66.0F.W1 6F /r | VMOVDQA64 ymm1 {k1}{z}, ymm2/m256 | AVX512VL AVX512F | N32
	ops: w=reg r=rm | Packed256_UInt64
END

# Code: EVEX_Vmovdqa64_zmm_k1z_zmmm512
INSTRUCTION: EVEX.512.66.0F.W1 6F /r | VMOVDQA64 zmm1 {k1}{z}, zmm2/m512 | AVX512F | N64
	ops: wvmm=reg r=rm | Packed512_UInt64
END

# Code: Movdqu_xmm_xmmm128
INSTRUCTION: F3 0F 6F /r | MOVDQU xmm1, xmm2/m128 | SSE2
	ops: w=reg r=rm | Packed128_UInt32
END

# Code: VEX_Vmovdqu_xmm_xmmm128
INSTRUCTION: VEX.128.F3.0F.WIG 6F /r | VMOVDQU xmm1, xmm2/m128 | AVX
	ops: w=reg r=rm | Packed128_UInt32
	masm: flags=force-size=default
END

# Code: VEX_Vmovdqu_ymm_ymmm256
INSTRUCTION: VEX.256.F3.0F.WIG 6F /r | VMOVDQU ymm1, ymm2/m256 | AVX
	ops: w=reg r=rm | Packed256_UInt32
	masm: flags=force-size=default
END

# Code: EVEX_Vmovdqu32_xmm_k1z_xmmm128
INSTRUCTION: EVEX.128.F3.0F.W0 6F /r | VMOVDQU32 xmm1 {k1}{z}, xmm2/m128 | AVX512VL AVX512F | N16
	ops: w=reg r=rm | Packed128_UInt32
END

# Code: EVEX_Vmovdqu32_ymm_k1z_ymmm256
INSTRUCTION: EVEX.256.F3.0F.W0 6F /r | VMOVDQU32 ymm1 {k1}{z}, ymm2/m256 | AVX512VL AVX512F | N32
	ops: w=reg r=rm | Packed256_UInt32
END

# Code: EVEX_Vmovdqu32_zmm_k1z_zmmm512
INSTRUCTION: EVEX.512.F3.0F.W0 6F /r | VMOVDQU32 zmm1 {k1}{z}, zmm2/m512 | AVX512F | N64
	ops: wvmm=reg r=rm | Packed512_UInt32
END

# Code: EVEX_Vmovdqu64_xmm_k1z_xmmm128
INSTRUCTION: EVEX.128.F3.0F.W1 6F /r | VMOVDQU64 xmm1 {k1}{z}, xmm2/m128 | AVX512VL AVX512F | N16
	ops: w=reg r=rm | Packed128_UInt64
END

# Code: EVEX_Vmovdqu64_ymm_k1z_ymmm256
INSTRUCTION: EVEX.256.F3.0F.W1 6F /r | VMOVDQU64 ymm1 {k1}{z}, ymm2/m256 | AVX512VL AVX512F | N32
	ops: w=reg r=rm | Packed256_UInt64
END

# Code: EVEX_Vmovdqu64_zmm_k1z_zmmm512
INSTRUCTION: EVEX.512.F3.0F.W1 6F /r | VMOVDQU64 zmm1 {k1}{z}, zmm2/m512 | AVX512F | N64
	ops: wvmm=reg r=rm | Packed512_UInt64
END

# Code: EVEX_Vmovdqu8_xmm_k1z_xmmm128
INSTRUCTION: EVEX.128.F2.0F.W0 6F /r | VMOVDQU8 xmm1 {k1}{z}, xmm2/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=rm | Packed128_UInt8
END

# Code: EVEX_Vmovdqu8_ymm_k1z_ymmm256
INSTRUCTION: EVEX.256.F2.0F.W0 6F /r | VMOVDQU8 ymm1 {k1}{z}, ymm2/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=rm | Packed256_UInt8
END

# Code: EVEX_Vmovdqu8_zmm_k1z_zmmm512
INSTRUCTION: EVEX.512.F2.0F.W0 6F /r | VMOVDQU8 zmm1 {k1}{z}, zmm2/m512 | AVX512BW | N64
	ops: wvmm=reg r=rm | Packed512_UInt8
END

# Code: EVEX_Vmovdqu16_xmm_k1z_xmmm128
INSTRUCTION: EVEX.128.F2.0F.W1 6F /r | VMOVDQU16 xmm1 {k1}{z}, xmm2/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=rm | Packed128_UInt16
END

# Code: EVEX_Vmovdqu16_ymm_k1z_ymmm256
INSTRUCTION: EVEX.256.F2.0F.W1 6F /r | VMOVDQU16 ymm1 {k1}{z}, ymm2/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=rm | Packed256_UInt16
END

# Code: EVEX_Vmovdqu16_zmm_k1z_zmmm512
INSTRUCTION: EVEX.512.F2.0F.W1 6F /r | VMOVDQU16 zmm1 {k1}{z}, zmm2/m512 | AVX512BW | N64
	ops: wvmm=reg r=rm | Packed512_UInt16
END

# Code: Pshufw_mm_mmm64_imm8
INSTRUCTION: NP 0F 70 /r ib | PSHUFW mm1, mm2/m64, imm8 | SSE
	ops: w=reg r=rm r=imm | Packed64_UInt16
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Pshufd_xmm_xmmm128_imm8
INSTRUCTION: 66 0F 70 /r ib | PSHUFD xmm1, xmm2/m128, imm8 | SSE2
	ops: w=reg r=rm r=imm | Packed128_UInt32
END

# Code: VEX_Vpshufd_xmm_xmmm128_imm8
INSTRUCTION: VEX.128.66.0F.WIG 70 /r ib | VPSHUFD xmm1, xmm2/m128, imm8 | AVX
	ops: w=reg r=rm r=imm | Packed128_UInt32
END

# Code: VEX_Vpshufd_ymm_ymmm256_imm8
INSTRUCTION: VEX.256.66.0F.WIG 70 /r ib | VPSHUFD ymm1, ymm2/m256, imm8 | AVX2
	ops: w=reg r=rm r=imm | Packed256_UInt32
END

# Code: EVEX_Vpshufd_xmm_k1z_xmmm128b32_imm8
INSTRUCTION: EVEX.128.66.0F.W0 70 /r ib | VPSHUFD xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8 | AVX512VL AVX512F | N16b4
	ops: w=reg r=rm r=imm | Packed128_UInt32 Broadcast128_UInt32
END

# Code: EVEX_Vpshufd_ymm_k1z_ymmm256b32_imm8
INSTRUCTION: EVEX.256.66.0F.W0 70 /r ib | VPSHUFD ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8 | AVX512VL AVX512F | N32b4
	ops: w=reg r=rm r=imm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vpshufd_zmm_k1z_zmmm512b32_imm8
INSTRUCTION: EVEX.512.66.0F.W0 70 /r ib | VPSHUFD zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8 | AVX512F | N64b4
	ops: wvmm=reg r=rm r=imm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: Pshufhw_xmm_xmmm128_imm8
INSTRUCTION: F3 0F 70 /r ib | PSHUFHW xmm1, xmm2/m128, imm8 | SSE2
	ops: w=reg r=rm r=imm | Packed128_UInt16
END

# Code: VEX_Vpshufhw_xmm_xmmm128_imm8
INSTRUCTION: VEX.128.F3.0F.WIG 70 /r ib | VPSHUFHW xmm1, xmm2/m128, imm8 | AVX
	ops: w=reg r=rm r=imm | Packed128_UInt16
END

# Code: VEX_Vpshufhw_ymm_ymmm256_imm8
INSTRUCTION: VEX.256.F3.0F.WIG 70 /r ib | VPSHUFHW ymm1, ymm2/m256, imm8 | AVX2
	ops: w=reg r=rm r=imm | Packed256_UInt16
END

# Code: EVEX_Vpshufhw_xmm_k1z_xmmm128_imm8
INSTRUCTION: EVEX.128.F3.0F.WIG 70 /r ib | VPSHUFHW xmm1 {k1}{z}, xmm2/m128, imm8 | AVX512VL AVX512BW | N16
	ops: w=reg r=rm r=imm | Packed128_UInt16
END

# Code: EVEX_Vpshufhw_ymm_k1z_ymmm256_imm8
INSTRUCTION: EVEX.256.F3.0F.WIG 70 /r ib | VPSHUFHW ymm1 {k1}{z}, ymm2/m256, imm8 | AVX512VL AVX512BW | N32
	ops: w=reg r=rm r=imm | Packed256_UInt16
END

# Code: EVEX_Vpshufhw_zmm_k1z_zmmm512_imm8
INSTRUCTION: EVEX.512.F3.0F.WIG 70 /r ib | VPSHUFHW zmm1 {k1}{z}, zmm2/m512, imm8 | AVX512BW | N64
	ops: wvmm=reg r=rm r=imm | Packed512_UInt16
END

# Code: Pshuflw_xmm_xmmm128_imm8
INSTRUCTION: F2 0F 70 /r ib | PSHUFLW xmm1, xmm2/m128, imm8 | SSE2
	ops: w=reg r=rm r=imm | Packed128_UInt16
END

# Code: VEX_Vpshuflw_xmm_xmmm128_imm8
INSTRUCTION: VEX.128.F2.0F.WIG 70 /r ib | VPSHUFLW xmm1, xmm2/m128, imm8 | AVX
	ops: w=reg r=rm r=imm | Packed128_UInt16
END

# Code: VEX_Vpshuflw_ymm_ymmm256_imm8
INSTRUCTION: VEX.256.F2.0F.WIG 70 /r ib | VPSHUFLW ymm1, ymm2/m256, imm8 | AVX2
	ops: w=reg r=rm r=imm | Packed256_UInt16
END

# Code: EVEX_Vpshuflw_xmm_k1z_xmmm128_imm8
INSTRUCTION: EVEX.128.F2.0F.WIG 70 /r ib | VPSHUFLW xmm1 {k1}{z}, xmm2/m128, imm8 | AVX512VL AVX512BW | N16
	ops: w=reg r=rm r=imm | Packed128_UInt16
END

# Code: EVEX_Vpshuflw_ymm_k1z_ymmm256_imm8
INSTRUCTION: EVEX.256.F2.0F.WIG 70 /r ib | VPSHUFLW ymm1 {k1}{z}, ymm2/m256, imm8 | AVX512VL AVX512BW | N32
	ops: w=reg r=rm r=imm | Packed256_UInt16
END

# Code: EVEX_Vpshuflw_zmm_k1z_zmmm512_imm8
INSTRUCTION: EVEX.512.F2.0F.WIG 70 /r ib | VPSHUFLW zmm1 {k1}{z}, zmm2/m512, imm8 | AVX512BW | N64
	ops: wvmm=reg r=rm r=imm | Packed512_UInt16
END

# Code: Psrlw_mm_imm8
INSTRUCTION: NP 0F 71 /2 ib | PSRLW mm, imm8 | MMX
	ops: rw=rm r=imm
	flags: tsx-impl-abort
END

# Code: Psrlw_xmm_imm8
INSTRUCTION: 66 0F 71 /2 ib | PSRLW xmm1, imm8 | SSE2
	ops: rw=rm r=imm
END

# Code: VEX_Vpsrlw_xmm_xmm_imm8
INSTRUCTION: VEX.128.66.0F.WIG 71 /2 ib | VPSRLW xmm1, xmm2, imm8 | AVX
	ops: w=vvvv r=rm r=imm
END

# Code: VEX_Vpsrlw_ymm_ymm_imm8
INSTRUCTION: VEX.256.66.0F.WIG 71 /2 ib | VPSRLW ymm1, ymm2, imm8 | AVX2
	ops: w=vvvv r=rm r=imm
END

# Code: EVEX_Vpsrlw_xmm_k1z_xmmm128_imm8
INSTRUCTION: EVEX.128.66.0F.WIG 71 /2 ib | VPSRLW xmm1 {k1}{z}, xmm2/m128, imm8 | AVX512VL AVX512BW | N16
	ops: w=vvvv r=rm r=imm | Packed128_UInt16
END

# Code: EVEX_Vpsrlw_ymm_k1z_ymmm256_imm8
INSTRUCTION: EVEX.256.66.0F.WIG 71 /2 ib | VPSRLW ymm1 {k1}{z}, ymm2/m256, imm8 | AVX512VL AVX512BW | N32
	ops: w=vvvv r=rm r=imm | Packed256_UInt16
END

# Code: EVEX_Vpsrlw_zmm_k1z_zmmm512_imm8
INSTRUCTION: EVEX.512.66.0F.WIG 71 /2 ib | VPSRLW zmm1 {k1}{z}, zmm2/m512, imm8 | AVX512BW | N64
	ops: wvmm=vvvv r=rm r=imm | Packed512_UInt16
END

# Code: Psraw_mm_imm8
INSTRUCTION: NP 0F 71 /4 ib | PSRAW mm, imm8 | MMX
	ops: rw=rm r=imm
	flags: tsx-impl-abort
END

# Code: Psraw_xmm_imm8
INSTRUCTION: 66 0F 71 /4 ib | PSRAW xmm1, imm8 | SSE2
	ops: rw=rm r=imm
END

# Code: VEX_Vpsraw_xmm_xmm_imm8
INSTRUCTION: VEX.128.66.0F.WIG 71 /4 ib | VPSRAW xmm1, xmm2, imm8 | AVX
	ops: w=vvvv r=rm r=imm
END

# Code: VEX_Vpsraw_ymm_ymm_imm8
INSTRUCTION: VEX.256.66.0F.WIG 71 /4 ib | VPSRAW ymm1, ymm2, imm8 | AVX2
	ops: w=vvvv r=rm r=imm
END

# Code: EVEX_Vpsraw_xmm_k1z_xmmm128_imm8
INSTRUCTION: EVEX.128.66.0F.WIG 71 /4 ib | VPSRAW xmm1 {k1}{z}, xmm2/m128, imm8 | AVX512VL AVX512BW | N16
	ops: w=vvvv r=rm r=imm | Packed128_Int16
END

# Code: EVEX_Vpsraw_ymm_k1z_ymmm256_imm8
INSTRUCTION: EVEX.256.66.0F.WIG 71 /4 ib | VPSRAW ymm1 {k1}{z}, ymm2/m256, imm8 | AVX512VL AVX512BW | N32
	ops: w=vvvv r=rm r=imm | Packed256_Int16
END

# Code: EVEX_Vpsraw_zmm_k1z_zmmm512_imm8
INSTRUCTION: EVEX.512.66.0F.WIG 71 /4 ib | VPSRAW zmm1 {k1}{z}, zmm2/m512, imm8 | AVX512BW | N64
	ops: wvmm=vvvv r=rm r=imm | Packed512_Int16
END

# Code: Psllw_mm_imm8
INSTRUCTION: NP 0F 71 /6 ib | PSLLW mm1, imm8 | MMX
	ops: rw=rm r=imm
	flags: tsx-impl-abort
END

# Code: Psllw_xmm_imm8
INSTRUCTION: 66 0F 71 /6 ib | PSLLW xmm1, imm8 | SSE2
	ops: rw=rm r=imm
END

# Code: VEX_Vpsllw_xmm_xmm_imm8
INSTRUCTION: VEX.128.66.0F.WIG 71 /6 ib | VPSLLW xmm1, xmm2, imm8 | AVX
	ops: w=vvvv r=rm r=imm
END

# Code: VEX_Vpsllw_ymm_ymm_imm8
INSTRUCTION: VEX.256.66.0F.WIG 71 /6 ib | VPSLLW ymm1, ymm2, imm8 | AVX2
	ops: w=vvvv r=rm r=imm
END

# Code: EVEX_Vpsllw_xmm_k1z_xmmm128_imm8
INSTRUCTION: EVEX.128.66.0F.WIG 71 /6 ib | VPSLLW xmm1 {k1}{z}, xmm2/m128, imm8 | AVX512VL AVX512BW | N16
	ops: w=vvvv r=rm r=imm | Packed128_UInt16
END

# Code: EVEX_Vpsllw_ymm_k1z_ymmm256_imm8
INSTRUCTION: EVEX.256.66.0F.WIG 71 /6 ib | VPSLLW ymm1 {k1}{z}, ymm2/m256, imm8 | AVX512VL AVX512BW | N32
	ops: w=vvvv r=rm r=imm | Packed256_UInt16
END

# Code: EVEX_Vpsllw_zmm_k1z_zmmm512_imm8
INSTRUCTION: EVEX.512.66.0F.WIG 71 /6 ib | VPSLLW zmm1 {k1}{z}, zmm2/m512, imm8 | AVX512BW | N64
	ops: wvmm=vvvv r=rm r=imm | Packed512_UInt16
END

# Code: EVEX_Vprord_xmm_k1z_xmmm128b32_imm8
INSTRUCTION: EVEX.128.66.0F.W0 72 /0 ib | VPRORD xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8 | AVX512VL AVX512F | N16b4
	ops: w=vvvv r=rm r=imm | Packed128_UInt32 Broadcast128_UInt32
END

# Code: EVEX_Vprord_ymm_k1z_ymmm256b32_imm8
INSTRUCTION: EVEX.256.66.0F.W0 72 /0 ib | VPRORD ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8 | AVX512VL AVX512F | N32b4
	ops: w=vvvv r=rm r=imm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vprord_zmm_k1z_zmmm512b32_imm8
INSTRUCTION: EVEX.512.66.0F.W0 72 /0 ib | VPRORD zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8 | AVX512F | N64b4
	ops: wvmm=vvvv r=rm r=imm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: EVEX_Vprorq_xmm_k1z_xmmm128b64_imm8
INSTRUCTION: EVEX.128.66.0F.W1 72 /0 ib | VPRORQ xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8 | AVX512VL AVX512F | N16b8
	ops: w=vvvv r=rm r=imm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Vprorq_ymm_k1z_ymmm256b64_imm8
INSTRUCTION: EVEX.256.66.0F.W1 72 /0 ib | VPRORQ ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8 | AVX512VL AVX512F | N32b8
	ops: w=vvvv r=rm r=imm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vprorq_zmm_k1z_zmmm512b64_imm8
INSTRUCTION: EVEX.512.66.0F.W1 72 /0 ib | VPRORQ zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8 | AVX512F | N64b8
	ops: wvmm=vvvv r=rm r=imm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: EVEX_Vprold_xmm_k1z_xmmm128b32_imm8
INSTRUCTION: EVEX.128.66.0F.W0 72 /1 ib | VPROLD xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8 | AVX512VL AVX512F | N16b4
	ops: w=vvvv r=rm r=imm | Packed128_UInt32 Broadcast128_UInt32
END

# Code: EVEX_Vprold_ymm_k1z_ymmm256b32_imm8
INSTRUCTION: EVEX.256.66.0F.W0 72 /1 ib | VPROLD ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8 | AVX512VL AVX512F | N32b4
	ops: w=vvvv r=rm r=imm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vprold_zmm_k1z_zmmm512b32_imm8
INSTRUCTION: EVEX.512.66.0F.W0 72 /1 ib | VPROLD zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8 | AVX512F | N64b4
	ops: wvmm=vvvv r=rm r=imm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: EVEX_Vprolq_xmm_k1z_xmmm128b64_imm8
INSTRUCTION: EVEX.128.66.0F.W1 72 /1 ib | VPROLQ xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8 | AVX512VL AVX512F | N16b8
	ops: w=vvvv r=rm r=imm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Vprolq_ymm_k1z_ymmm256b64_imm8
INSTRUCTION: EVEX.256.66.0F.W1 72 /1 ib | VPROLQ ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8 | AVX512VL AVX512F | N32b8
	ops: w=vvvv r=rm r=imm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vprolq_zmm_k1z_zmmm512b64_imm8
INSTRUCTION: EVEX.512.66.0F.W1 72 /1 ib | VPROLQ zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8 | AVX512F | N64b8
	ops: wvmm=vvvv r=rm r=imm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: Psrld_mm_imm8
INSTRUCTION: NP 0F 72 /2 ib | PSRLD mm, imm8 | MMX
	ops: rw=rm r=imm
	flags: tsx-impl-abort
END

# Code: Psrld_xmm_imm8
INSTRUCTION: 66 0F 72 /2 ib | PSRLD xmm1, imm8 | SSE2
	ops: rw=rm r=imm
END

# Code: VEX_Vpsrld_xmm_xmm_imm8
INSTRUCTION: VEX.128.66.0F.WIG 72 /2 ib | VPSRLD xmm1, xmm2, imm8 | AVX
	ops: w=vvvv r=rm r=imm
END

# Code: VEX_Vpsrld_ymm_ymm_imm8
INSTRUCTION: VEX.256.66.0F.WIG 72 /2 ib | VPSRLD ymm1, ymm2, imm8 | AVX2
	ops: w=vvvv r=rm r=imm
END

# Code: EVEX_Vpsrld_xmm_k1z_xmmm128b32_imm8
INSTRUCTION: EVEX.128.66.0F.W0 72 /2 ib | VPSRLD xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8 | AVX512VL AVX512F | N16b4
	ops: w=vvvv r=rm r=imm | Packed128_UInt32 Broadcast128_UInt32
END

# Code: EVEX_Vpsrld_ymm_k1z_ymmm256b32_imm8
INSTRUCTION: EVEX.256.66.0F.W0 72 /2 ib | VPSRLD ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8 | AVX512VL AVX512F | N32b4
	ops: w=vvvv r=rm r=imm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vpsrld_zmm_k1z_zmmm512b32_imm8
INSTRUCTION: EVEX.512.66.0F.W0 72 /2 ib | VPSRLD zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8 | AVX512F | N64b4
	ops: wvmm=vvvv r=rm r=imm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: Psrad_mm_imm8
INSTRUCTION: NP 0F 72 /4 ib | PSRAD mm, imm8 | MMX
	ops: rw=rm r=imm
	flags: tsx-impl-abort
END

# Code: Psrad_xmm_imm8
INSTRUCTION: 66 0F 72 /4 ib | PSRAD xmm1, imm8 | SSE2
	ops: rw=rm r=imm
END

# Code: VEX_Vpsrad_xmm_xmm_imm8
INSTRUCTION: VEX.128.66.0F.WIG 72 /4 ib | VPSRAD xmm1, xmm2, imm8 | AVX
	ops: w=vvvv r=rm r=imm
END

# Code: VEX_Vpsrad_ymm_ymm_imm8
INSTRUCTION: VEX.256.66.0F.WIG 72 /4 ib | VPSRAD ymm1, ymm2, imm8 | AVX2
	ops: w=vvvv r=rm r=imm
END

# Code: EVEX_Vpsrad_xmm_k1z_xmmm128b32_imm8
INSTRUCTION: EVEX.128.66.0F.W0 72 /4 ib | VPSRAD xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8 | AVX512VL AVX512F | N16b4
	ops: w=vvvv r=rm r=imm | Packed128_Int32 Broadcast128_Int32
END

# Code: EVEX_Vpsrad_ymm_k1z_ymmm256b32_imm8
INSTRUCTION: EVEX.256.66.0F.W0 72 /4 ib | VPSRAD ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8 | AVX512VL AVX512F | N32b4
	ops: w=vvvv r=rm r=imm | Packed256_Int32 Broadcast256_Int32
END

# Code: EVEX_Vpsrad_zmm_k1z_zmmm512b32_imm8
INSTRUCTION: EVEX.512.66.0F.W0 72 /4 ib | VPSRAD zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8 | AVX512F | N64b4
	ops: wvmm=vvvv r=rm r=imm | Packed512_Int32 Broadcast512_Int32
END

# Code: EVEX_Vpsraq_xmm_k1z_xmmm128b64_imm8
INSTRUCTION: EVEX.128.66.0F.W1 72 /4 ib | VPSRAQ xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8 | AVX512VL AVX512F | N16b8
	ops: w=vvvv r=rm r=imm | Packed128_Int64 Broadcast128_Int64
END

# Code: EVEX_Vpsraq_ymm_k1z_ymmm256b64_imm8
INSTRUCTION: EVEX.256.66.0F.W1 72 /4 ib | VPSRAQ ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8 | AVX512VL AVX512F | N32b8
	ops: w=vvvv r=rm r=imm | Packed256_Int64 Broadcast256_Int64
END

# Code: EVEX_Vpsraq_zmm_k1z_zmmm512b64_imm8
INSTRUCTION: EVEX.512.66.0F.W1 72 /4 ib | VPSRAQ zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8 | AVX512F | N64b8
	ops: wvmm=vvvv r=rm r=imm | Packed512_Int64 Broadcast512_Int64
END

# Code: Pslld_mm_imm8
INSTRUCTION: NP 0F 72 /6 ib | PSLLD mm, imm8 | MMX
	ops: rw=rm r=imm
	flags: tsx-impl-abort
END

# Code: Pslld_xmm_imm8
INSTRUCTION: 66 0F 72 /6 ib | PSLLD xmm1, imm8 | SSE2
	ops: rw=rm r=imm
END

# Code: VEX_Vpslld_xmm_xmm_imm8
INSTRUCTION: VEX.128.66.0F.WIG 72 /6 ib | VPSLLD xmm1, xmm2, imm8 | AVX
	ops: w=vvvv r=rm r=imm
END

# Code: VEX_Vpslld_ymm_ymm_imm8
INSTRUCTION: VEX.256.66.0F.WIG 72 /6 ib | VPSLLD ymm1, ymm2, imm8 | AVX2
	ops: w=vvvv r=rm r=imm
END

# Code: EVEX_Vpslld_xmm_k1z_xmmm128b32_imm8
INSTRUCTION: EVEX.128.66.0F.W0 72 /6 ib | VPSLLD xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8 | AVX512VL AVX512F | N16b4
	ops: w=vvvv r=rm r=imm | Packed128_UInt32 Broadcast128_UInt32
END

# Code: EVEX_Vpslld_ymm_k1z_ymmm256b32_imm8
INSTRUCTION: EVEX.256.66.0F.W0 72 /6 ib | VPSLLD ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8 | AVX512VL AVX512F | N32b4
	ops: w=vvvv r=rm r=imm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vpslld_zmm_k1z_zmmm512b32_imm8
INSTRUCTION: EVEX.512.66.0F.W0 72 /6 ib | VPSLLD zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8 | AVX512F | N64b4
	ops: wvmm=vvvv r=rm r=imm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: Psrlq_mm_imm8
INSTRUCTION: NP 0F 73 /2 ib | PSRLQ mm, imm8 | MMX
	ops: rw=rm r=imm
	flags: tsx-impl-abort
END

# Code: Psrlq_xmm_imm8
INSTRUCTION: 66 0F 73 /2 ib | PSRLQ xmm1, imm8 | SSE2
	ops: rw=rm r=imm
END

# Code: VEX_Vpsrlq_xmm_xmm_imm8
INSTRUCTION: VEX.128.66.0F.WIG 73 /2 ib | VPSRLQ xmm1, xmm2, imm8 | AVX
	ops: w=vvvv r=rm r=imm
END

# Code: VEX_Vpsrlq_ymm_ymm_imm8
INSTRUCTION: VEX.256.66.0F.WIG 73 /2 ib | VPSRLQ ymm1, ymm2, imm8 | AVX2
	ops: w=vvvv r=rm r=imm
END

# Code: EVEX_Vpsrlq_xmm_k1z_xmmm128b64_imm8
INSTRUCTION: EVEX.128.66.0F.W1 73 /2 ib | VPSRLQ xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8 | AVX512VL AVX512F | N16b8
	ops: w=vvvv r=rm r=imm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Vpsrlq_ymm_k1z_ymmm256b64_imm8
INSTRUCTION: EVEX.256.66.0F.W1 73 /2 ib | VPSRLQ ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8 | AVX512VL AVX512F | N32b8
	ops: w=vvvv r=rm r=imm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vpsrlq_zmm_k1z_zmmm512b64_imm8
INSTRUCTION: EVEX.512.66.0F.W1 73 /2 ib | VPSRLQ zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8 | AVX512F | N64b8
	ops: wvmm=vvvv r=rm r=imm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: Psrldq_xmm_imm8
INSTRUCTION: 66 0F 73 /3 ib | PSRLDQ xmm1, imm8 | SSE2
	ops: rw=rm r=imm
END

# Code: VEX_Vpsrldq_xmm_xmm_imm8
INSTRUCTION: VEX.128.66.0F.WIG 73 /3 ib | VPSRLDQ xmm1, xmm2, imm8 | AVX
	ops: w=vvvv r=rm r=imm
END

# Code: VEX_Vpsrldq_ymm_ymm_imm8
INSTRUCTION: VEX.256.66.0F.WIG 73 /3 ib | VPSRLDQ ymm1, ymm2, imm8 | AVX2
	ops: w=vvvv r=rm r=imm
END

# Code: EVEX_Vpsrldq_xmm_xmmm128_imm8
INSTRUCTION: EVEX.128.66.0F.WIG 73 /3 ib | VPSRLDQ xmm1, xmm2/m128, imm8 | AVX512VL AVX512BW | N16
	ops: w=vvvv r=rm r=imm | UInt128
END

# Code: EVEX_Vpsrldq_ymm_ymmm256_imm8
INSTRUCTION: EVEX.256.66.0F.WIG 73 /3 ib | VPSRLDQ ymm1, ymm2/m256, imm8 | AVX512VL AVX512BW | N32
	ops: w=vvvv r=rm r=imm | Packed256_UInt128
END

# Code: EVEX_Vpsrldq_zmm_zmmm512_imm8
INSTRUCTION: EVEX.512.66.0F.WIG 73 /3 ib | VPSRLDQ zmm1, zmm2/m512, imm8 | AVX512BW | N64
	ops: w=vvvv r=rm r=imm | Packed512_UInt128
END

# Code: Psllq_mm_imm8
INSTRUCTION: NP 0F 73 /6 ib | PSLLQ mm, imm8 | MMX
	ops: rw=rm r=imm
	flags: tsx-impl-abort
END

# Code: Psllq_xmm_imm8
INSTRUCTION: 66 0F 73 /6 ib | PSLLQ xmm1, imm8 | SSE2
	ops: rw=rm r=imm
END

# Code: VEX_Vpsllq_xmm_xmm_imm8
INSTRUCTION: VEX.128.66.0F.WIG 73 /6 ib | VPSLLQ xmm1, xmm2, imm8 | AVX
	ops: w=vvvv r=rm r=imm
END

# Code: VEX_Vpsllq_ymm_ymm_imm8
INSTRUCTION: VEX.256.66.0F.WIG 73 /6 ib | VPSLLQ ymm1, ymm2, imm8 | AVX2
	ops: w=vvvv r=rm r=imm
END

# Code: EVEX_Vpsllq_xmm_k1z_xmmm128b64_imm8
INSTRUCTION: EVEX.128.66.0F.W1 73 /6 ib | VPSLLQ xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8 | AVX512VL AVX512F | N16b8
	ops: w=vvvv r=rm r=imm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Vpsllq_ymm_k1z_ymmm256b64_imm8
INSTRUCTION: EVEX.256.66.0F.W1 73 /6 ib | VPSLLQ ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8 | AVX512VL AVX512F | N32b8
	ops: w=vvvv r=rm r=imm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vpsllq_zmm_k1z_zmmm512b64_imm8
INSTRUCTION: EVEX.512.66.0F.W1 73 /6 ib | VPSLLQ zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8 | AVX512F | N64b8
	ops: wvmm=vvvv r=rm r=imm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: Pslldq_xmm_imm8
INSTRUCTION: 66 0F 73 /7 ib | PSLLDQ xmm1, imm8 | SSE2
	ops: rw=rm r=imm
END

# Code: VEX_Vpslldq_xmm_xmm_imm8
INSTRUCTION: VEX.128.66.0F.WIG 73 /7 ib | VPSLLDQ xmm1, xmm2, imm8 | AVX
	ops: w=vvvv r=rm r=imm
END

# Code: VEX_Vpslldq_ymm_ymm_imm8
INSTRUCTION: VEX.256.66.0F.WIG 73 /7 ib | VPSLLDQ ymm1, ymm2, imm8 | AVX2
	ops: w=vvvv r=rm r=imm
END

# Code: EVEX_Vpslldq_xmm_xmmm128_imm8
INSTRUCTION: EVEX.128.66.0F.WIG 73 /7 ib | VPSLLDQ xmm1, xmm2/m128, imm8 | AVX512VL AVX512BW | N16
	ops: w=vvvv r=rm r=imm | UInt128
END

# Code: EVEX_Vpslldq_ymm_ymmm256_imm8
INSTRUCTION: EVEX.256.66.0F.WIG 73 /7 ib | VPSLLDQ ymm1, ymm2/m256, imm8 | AVX512VL AVX512BW | N32
	ops: w=vvvv r=rm r=imm | Packed256_UInt128
END

# Code: EVEX_Vpslldq_zmm_zmmm512_imm8
INSTRUCTION: EVEX.512.66.0F.WIG 73 /7 ib | VPSLLDQ zmm1, zmm2/m512, imm8 | AVX512BW | N64
	ops: w=vvvv r=rm r=imm | Packed512_UInt128
END

# Code: Pcmpeqb_mm_mmm64
INSTRUCTION: NP 0F 74 /r | PCMPEQB mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_UInt8
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Pcmpeqb_xmm_xmmm128
INSTRUCTION: 66 0F 74 /r | PCMPEQB xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt8
END

# Code: VEX_Vpcmpeqb_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 74 /r | VPCMPEQB xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
END

# Code: VEX_Vpcmpeqb_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 74 /r | VPCMPEQB ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
END

# Code: EVEX_Vpcmpeqb_kr_k1_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG 74 /r | VPCMPEQB k1 {k2}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
	flags: implied-z
END

# Code: EVEX_Vpcmpeqb_kr_k1_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG 74 /r | VPCMPEQB k1 {k2}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
	flags: implied-z
END

# Code: EVEX_Vpcmpeqb_kr_k1_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG 74 /r | VPCMPEQB k1 {k2}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: w=reg r=vvvv r=rm | Packed512_UInt8
	flags: implied-z
END

# Code: Pcmpeqw_mm_mmm64
INSTRUCTION: NP 0F 75 /r | PCMPEQW mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_UInt16
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Pcmpeqw_xmm_xmmm128
INSTRUCTION: 66 0F 75 /r | PCMPEQW xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt16
END

# Code: VEX_Vpcmpeqw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 75 /r | VPCMPEQW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: VEX_Vpcmpeqw_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 75 /r | VPCMPEQW ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: EVEX_Vpcmpeqw_kr_k1_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG 75 /r | VPCMPEQW k1 {k2}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
	flags: implied-z
END

# Code: EVEX_Vpcmpeqw_kr_k1_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG 75 /r | VPCMPEQW k1 {k2}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
	flags: implied-z
END

# Code: EVEX_Vpcmpeqw_kr_k1_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG 75 /r | VPCMPEQW k1 {k2}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: w=reg r=vvvv r=rm | Packed512_UInt16
	flags: implied-z
END

# Code: Pcmpeqd_mm_mmm64
INSTRUCTION: NP 0F 76 /r | PCMPEQD mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_UInt32
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Pcmpeqd_xmm_xmmm128
INSTRUCTION: 66 0F 76 /r | PCMPEQD xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt32
END

# Code: VEX_Vpcmpeqd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 76 /r | VPCMPEQD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt32
END

# Code: VEX_Vpcmpeqd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 76 /r | VPCMPEQD ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt32
END

# Code: EVEX_Vpcmpeqd_kr_k1_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F.W0 76 /r | VPCMPEQD k1 {k2}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_UInt32 Broadcast128_UInt32
	flags: implied-z
END

# Code: EVEX_Vpcmpeqd_kr_k1_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F.W0 76 /r | VPCMPEQD k1 {k2}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_UInt32 Broadcast256_UInt32
	flags: implied-z
END

# Code: EVEX_Vpcmpeqd_kr_k1_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F.W0 76 /r | VPCMPEQD k1 {k2}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: w=reg r=vvvv r=rm | Packed512_UInt32 Broadcast512_UInt32
	flags: implied-z
END

# Code: Emms
INSTRUCTION: NP 0F 77 | EMMS | MMX
	flags: tsx-impl-abort
END

# Code: VEX_Vzeroupper
INSTRUCTION: VEX.128.0F.WIG 77 | VZEROUPPER | AVX
	# rw since low 128 bits are preserved and upper bits are cleared. It will be
	# converted to r=xmm0-xmm7/15 w=vmm0-vmm7/15 since it's VEX encoded.
	implied: rw;!64=xmm0-xmm7 rw;64=xmm0-xmm15
	flags: tsx-impl-abort
END

# Code: VEX_Vzeroall
INSTRUCTION: VEX.256.0F.WIG 77 | VZEROALL | AVX
	implied: w;!64=vmm0-vmm7 w;64=vmm0-vmm15
END

# Code: Vmread_rm32_r32
INSTRUCTION: NP 0F 78 /r | VMREAD r/m32, r32 | VMX
	ops: w=rm r=reg | UInt32
	rflags: w=zc 0=osap
	flags: 16 32 cpl0 no-rm no-v86 no-cm vmx=op intel-may-vm-exit tdx-non-root-ud tsx-impl-abort
	gas: suffix=l
	masm: flags=force-size=default
END

# Code: Vmread_rm64_r64
INSTRUCTION: NP 0F 78 /r | VMREAD r/m64, r64 | VMX
	ops: w=rm r=reg | UInt64
	rflags: w=zc 0=osap
	flags: 64 cpl0 no-rm no-v86 no-cm vmx=op intel-may-vm-exit tdx-non-root-ud tsx-impl-abort
	gas: suffix=q
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttps2udq_xmm_k1z_xmmm128b32
INSTRUCTION: EVEX.128.0F.W0 78 /r | VCVTTPS2UDQ xmm1 {k1}{z}, xmm2/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=rm | Packed128_Float32 Broadcast128_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttps2udq_ymm_k1z_ymmm256b32
INSTRUCTION: EVEX.256.0F.W0 78 /r | VCVTTPS2UDQ ymm1 {k1}{z}, ymm2/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=rm | Packed256_Float32 Broadcast256_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttps2udq_zmm_k1z_zmmm512b32_sae
INSTRUCTION: EVEX.512.0F.W0 78 /r | VCVTTPS2UDQ zmm1 {k1}{z}, zmm2/m512/m32bcst{sae} | AVX512F | N64b4
	ops: wvmm=reg r=rm | Packed512_Float32 Broadcast512_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttpd2udq_xmm_k1z_xmmm128b64
INSTRUCTION: EVEX.128.0F.W1 78 /r | VCVTTPD2UDQ xmm1 {k1}{z}, xmm2/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=rm | Packed128_Float64 Broadcast128_Float64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=x
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vcvttpd2udq_xmm_k1z_ymmm256b64
INSTRUCTION: EVEX.256.0F.W1 78 /r | VCVTTPD2UDQ xmm1 {k1}{z}, ymm2/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=rm | Packed256_Float64 Broadcast256_Float64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=y
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vcvttpd2udq_ymm_k1z_zmmm512b64_sae
INSTRUCTION: EVEX.512.0F.W1 78 /r | VCVTTPD2UDQ ymm1 {k1}{z}, zmm2/m512/m64bcst{sae} | AVX512F | N64b8
	ops: w=reg r=rm | Packed512_Float64 Broadcast512_Float64
	masm: flags=force-size=default
END

# Code: Extrq_xmm_imm8_imm8
INSTRUCTION: 66 0F 78 /0 ib ib | EXTRQ xmm1, imm8, imm8 | SSE4A
	ops: rw=rm r=imm r=imm
END

# Code: EVEX_Vcvttps2uqq_xmm_k1z_xmmm64b32
INSTRUCTION: EVEX.128.66.0F.W0 78 /r | VCVTTPS2UQQ xmm1 {k1}{z}, xmm2/m64/m32bcst | AVX512VL AVX512DQ | N8b4
	ops: w=reg r=rm | Packed64_Float32 Broadcast64_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttps2uqq_ymm_k1z_xmmm128b32
INSTRUCTION: EVEX.256.66.0F.W0 78 /r | VCVTTPS2UQQ ymm1 {k1}{z}, xmm2/m128/m32bcst | AVX512VL AVX512DQ | N16b4
	ops: w=reg r=rm | Packed128_Float32 Broadcast128_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttps2uqq_zmm_k1z_ymmm256b32_sae
INSTRUCTION: EVEX.512.66.0F.W0 78 /r | VCVTTPS2UQQ zmm1 {k1}{z}, ymm2/m256/m32bcst{sae} | AVX512DQ | N32b4
	ops: wvmm=reg r=rm | Packed256_Float32 Broadcast256_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttpd2uqq_xmm_k1z_xmmm128b64
INSTRUCTION: EVEX.128.66.0F.W1 78 /r | VCVTTPD2UQQ xmm1 {k1}{z}, xmm2/m128/m64bcst | AVX512VL AVX512DQ | N16b8
	ops: w=reg r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vcvttpd2uqq_ymm_k1z_ymmm256b64
INSTRUCTION: EVEX.256.66.0F.W1 78 /r | VCVTTPD2UQQ ymm1 {k1}{z}, ymm2/m256/m64bcst | AVX512VL AVX512DQ | N32b8
	ops: w=reg r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vcvttpd2uqq_zmm_k1z_zmmm512b64_sae
INSTRUCTION: EVEX.512.66.0F.W1 78 /r | VCVTTPD2UQQ zmm1 {k1}{z}, zmm2/m512/m64bcst{sae} | AVX512DQ | N64b8
	ops: wvmm=reg r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: EVEX_Vcvttss2usi_r32_xmmm32_sae
INSTRUCTION: EVEX.LIG.F3.0F.W0 78 /r | VCVTTSS2USI r32, xmm1/m32{sae} | AVX512F | N4
	ops: w=reg r=rm | Float32
	flags: wig32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttss2usi_r64_xmmm32_sae
INSTRUCTION: EVEX.LIG.F3.0F.W1 78 /r | VCVTTSS2USI r64, xmm1/m32{sae} | AVX512F | N4
	ops: w=reg r=rm | Float32
	flags: 64
	masm: flags=force-size=default
END

# Code: Insertq_xmm_xmm_imm8_imm8
INSTRUCTION: F2 0F 78 /r ib ib | INSERTQ xmm1, xmm2, imm8, imm8 | SSE4A
	ops: w=reg r=rm r=imm r=imm
END

# Code: EVEX_Vcvttsd2usi_r32_xmmm64_sae
INSTRUCTION: EVEX.LIG.F2.0F.W0 78 /r | VCVTTSD2USI r32, xmm1/m64{sae} | AVX512F | N8
	ops: w=reg r=rm | Float64
	flags: wig32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttsd2usi_r64_xmmm64_sae
INSTRUCTION: EVEX.LIG.F2.0F.W1 78 /r | VCVTTSD2USI r64, xmm1/m64{sae} | AVX512F | N8
	ops: w=reg r=rm | Float64
	flags: 64
	masm: flags=force-size=default
END

# Code: Vmwrite_r32_rm32
INSTRUCTION: NP 0F 79 /r | VMWRITE r32, r/m32 | VMX
	ops: r=reg r=rm | UInt32
	rflags: w=zc 0=osap
	flags: 16 32 cpl0 no-rm no-v86 no-cm vmx=op intel-may-vm-exit tdx-non-root-ud tsx-impl-abort
	gas: suffix=l
	masm: flags=force-size=default
END

# Code: Vmwrite_r64_rm64
INSTRUCTION: NP 0F 79 /r | VMWRITE r64, r/m64 | VMX
	ops: r=reg r=rm | UInt64
	rflags: w=zc 0=osap
	flags: 64 cpl0 no-rm no-v86 no-cm vmx=op intel-may-vm-exit tdx-non-root-ud tsx-impl-abort
	gas: suffix=q
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtps2udq_xmm_k1z_xmmm128b32
INSTRUCTION: EVEX.128.0F.W0 79 /r | VCVTPS2UDQ xmm1 {k1}{z}, xmm2/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=rm | Packed128_Float32 Broadcast128_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtps2udq_ymm_k1z_ymmm256b32
INSTRUCTION: EVEX.256.0F.W0 79 /r | VCVTPS2UDQ ymm1 {k1}{z}, ymm2/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=rm | Packed256_Float32 Broadcast256_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtps2udq_zmm_k1z_zmmm512b32_er
INSTRUCTION: EVEX.512.0F.W0 79 /r | VCVTPS2UDQ zmm1 {k1}{z}, zmm2/m512/m32bcst{er} | AVX512F | N64b4
	ops: wvmm=reg r=rm | Packed512_Float32 Broadcast512_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtpd2udq_xmm_k1z_xmmm128b64
INSTRUCTION: EVEX.128.0F.W1 79 /r | VCVTPD2UDQ xmm1 {k1}{z}, xmm2/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=rm | Packed128_Float64 Broadcast128_Float64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=x
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vcvtpd2udq_xmm_k1z_ymmm256b64
INSTRUCTION: EVEX.256.0F.W1 79 /r | VCVTPD2UDQ xmm1 {k1}{z}, ymm2/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=rm | Packed256_Float64 Broadcast256_Float64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=y
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vcvtpd2udq_ymm_k1z_zmmm512b64_er
INSTRUCTION: EVEX.512.0F.W1 79 /r | VCVTPD2UDQ ymm1 {k1}{z}, zmm2/m512/m64bcst{er} | AVX512F | N64b8
	ops: w=reg r=rm | Packed512_Float64 Broadcast512_Float64
	masm: flags=force-size=default
END

# Code: Extrq_xmm_xmm
INSTRUCTION: 66 0F 79 /r | EXTRQ xmm1, xmm2 | SSE4A
	ops: rw=reg r=rm
END

# Code: EVEX_Vcvtps2uqq_xmm_k1z_xmmm64b32
INSTRUCTION: EVEX.128.66.0F.W0 79 /r | VCVTPS2UQQ xmm1 {k1}{z}, xmm2/m64/m32bcst | AVX512VL AVX512DQ | N8b4
	ops: w=reg r=rm | Packed64_Float32 Broadcast64_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtps2uqq_ymm_k1z_xmmm128b32
INSTRUCTION: EVEX.256.66.0F.W0 79 /r | VCVTPS2UQQ ymm1 {k1}{z}, xmm2/m128/m32bcst | AVX512VL AVX512DQ | N16b4
	ops: w=reg r=rm | Packed128_Float32 Broadcast128_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtps2uqq_zmm_k1z_ymmm256b32_er
INSTRUCTION: EVEX.512.66.0F.W0 79 /r | VCVTPS2UQQ zmm1 {k1}{z}, ymm2/m256/m32bcst{er} | AVX512DQ | N32b4
	ops: wvmm=reg r=rm | Packed256_Float32 Broadcast256_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtpd2uqq_xmm_k1z_xmmm128b64
INSTRUCTION: EVEX.128.66.0F.W1 79 /r | VCVTPD2UQQ xmm1 {k1}{z}, xmm2/m128/m64bcst | AVX512VL AVX512DQ | N16b8
	ops: w=reg r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vcvtpd2uqq_ymm_k1z_ymmm256b64
INSTRUCTION: EVEX.256.66.0F.W1 79 /r | VCVTPD2UQQ ymm1 {k1}{z}, ymm2/m256/m64bcst | AVX512VL AVX512DQ | N32b8
	ops: w=reg r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vcvtpd2uqq_zmm_k1z_zmmm512b64_er
INSTRUCTION: EVEX.512.66.0F.W1 79 /r | VCVTPD2UQQ zmm1 {k1}{z}, zmm2/m512/m64bcst{er} | AVX512DQ | N64b8
	ops: wvmm=reg r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: EVEX_Vcvtss2usi_r32_xmmm32_er
INSTRUCTION: EVEX.LIG.F3.0F.W0 79 /r | VCVTSS2USI r32, xmm1/m32{er} | AVX512F | N4
	ops: w=reg r=rm | Float32
	flags: wig32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtss2usi_r64_xmmm32_er
INSTRUCTION: EVEX.LIG.F3.0F.W1 79 /r | VCVTSS2USI r64, xmm1/m32{er} | AVX512F | N4
	ops: w=reg r=rm | Float32
	flags: 64
	masm: flags=force-size=default
END

# Code: Insertq_xmm_xmm
INSTRUCTION: F2 0F 79 /r | INSERTQ xmm1, xmm2 | SSE4A
	ops: rw=reg r=rm
END

# Code: EVEX_Vcvtsd2usi_r32_xmmm64_er
INSTRUCTION: EVEX.LIG.F2.0F.W0 79 /r | VCVTSD2USI r32, xmm1/m64{er} | AVX512F | N8
	ops: w=reg r=rm | Float64
	flags: wig32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtsd2usi_r64_xmmm64_er
INSTRUCTION: EVEX.LIG.F2.0F.W1 79 /r | VCVTSD2USI r64, xmm1/m64{er} | AVX512F | N8
	ops: w=reg r=rm | Float64
	flags: 64
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttps2qq_xmm_k1z_xmmm64b32
INSTRUCTION: EVEX.128.66.0F.W0 7A /r | VCVTTPS2QQ xmm1 {k1}{z}, xmm2/m64/m32bcst | AVX512VL AVX512DQ | N8b4
	ops: w=reg r=rm | Packed64_Float32 Broadcast64_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttps2qq_ymm_k1z_xmmm128b32
INSTRUCTION: EVEX.256.66.0F.W0 7A /r | VCVTTPS2QQ ymm1 {k1}{z}, xmm2/m128/m32bcst | AVX512VL AVX512DQ | N16b4
	ops: w=reg r=rm | Packed128_Float32 Broadcast128_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttps2qq_zmm_k1z_ymmm256b32_sae
INSTRUCTION: EVEX.512.66.0F.W0 7A /r | VCVTTPS2QQ zmm1 {k1}{z}, ymm2/m256/m32bcst{sae} | AVX512DQ | N32b4
	ops: wvmm=reg r=rm | Packed256_Float32 Broadcast256_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttpd2qq_xmm_k1z_xmmm128b64
INSTRUCTION: EVEX.128.66.0F.W1 7A /r | VCVTTPD2QQ xmm1 {k1}{z}, xmm2/m128/m64bcst | AVX512VL AVX512DQ | N16b8
	ops: w=reg r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vcvttpd2qq_ymm_k1z_ymmm256b64
INSTRUCTION: EVEX.256.66.0F.W1 7A /r | VCVTTPD2QQ ymm1 {k1}{z}, ymm2/m256/m64bcst | AVX512VL AVX512DQ | N32b8
	ops: w=reg r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vcvttpd2qq_zmm_k1z_zmmm512b64_sae
INSTRUCTION: EVEX.512.66.0F.W1 7A /r | VCVTTPD2QQ zmm1 {k1}{z}, zmm2/m512/m64bcst{sae} | AVX512DQ | N64b8
	ops: wvmm=reg r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: EVEX_Vcvtudq2pd_xmm_k1z_xmmm64b32
INSTRUCTION: EVEX.128.F3.0F.W0 7A /r | VCVTUDQ2PD xmm1 {k1}{z}, xmm2/m64/m32bcst | AVX512VL AVX512F | N8b4
	ops: w=reg r=rm | Packed64_UInt32 Broadcast64_UInt32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtudq2pd_ymm_k1z_xmmm128b32
INSTRUCTION: EVEX.256.F3.0F.W0 7A /r | VCVTUDQ2PD ymm1 {k1}{z}, xmm2/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=rm | Packed128_UInt32 Broadcast128_UInt32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtudq2pd_zmm_k1z_ymmm256b32_er
INSTRUCTION: EVEX.512.F3.0F.W0 7A /r | VCVTUDQ2PD zmm1 {k1}{z}, ymm2/m256/m32bcst{er} | AVX512F | N32b4
	ops: wvmm=reg r=rm | Packed256_UInt32 Broadcast256_UInt32
	flags: ignore-er
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtuqq2pd_xmm_k1z_xmmm128b64
INSTRUCTION: EVEX.128.F3.0F.W1 7A /r | VCVTUQQ2PD xmm1 {k1}{z}, xmm2/m128/m64bcst | AVX512VL AVX512DQ | N16b8
	ops: w=reg r=rm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Vcvtuqq2pd_ymm_k1z_ymmm256b64
INSTRUCTION: EVEX.256.F3.0F.W1 7A /r | VCVTUQQ2PD ymm1 {k1}{z}, ymm2/m256/m64bcst | AVX512VL AVX512DQ | N32b8
	ops: w=reg r=rm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vcvtuqq2pd_zmm_k1z_zmmm512b64_er
INSTRUCTION: EVEX.512.F3.0F.W1 7A /r | VCVTUQQ2PD zmm1 {k1}{z}, zmm2/m512/m64bcst{er} | AVX512DQ | N64b8
	ops: wvmm=reg r=rm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: EVEX_Vcvtudq2ps_xmm_k1z_xmmm128b32
INSTRUCTION: EVEX.128.F2.0F.W0 7A /r | VCVTUDQ2PS xmm1 {k1}{z}, xmm2/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=rm | Packed128_UInt32 Broadcast128_UInt32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtudq2ps_ymm_k1z_ymmm256b32
INSTRUCTION: EVEX.256.F2.0F.W0 7A /r | VCVTUDQ2PS ymm1 {k1}{z}, ymm2/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=rm | Packed256_UInt32 Broadcast256_UInt32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtudq2ps_zmm_k1z_zmmm512b32_er
INSTRUCTION: EVEX.512.F2.0F.W0 7A /r | VCVTUDQ2PS zmm1 {k1}{z}, zmm2/m512/m32bcst{er} | AVX512F | N64b4
	ops: wvmm=reg r=rm | Packed512_UInt32 Broadcast512_UInt32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtuqq2ps_xmm_k1z_xmmm128b64
INSTRUCTION: EVEX.128.F2.0F.W1 7A /r | VCVTUQQ2PS xmm1 {k1}{z}, xmm2/m128/m64bcst | AVX512VL AVX512DQ | N16b8
	ops: w=reg r=rm | Packed128_UInt64 Broadcast128_UInt64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=x
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vcvtuqq2ps_xmm_k1z_ymmm256b64
INSTRUCTION: EVEX.256.F2.0F.W1 7A /r | VCVTUQQ2PS xmm1 {k1}{z}, ymm2/m256/m64bcst | AVX512VL AVX512DQ | N32b8
	ops: w=reg r=rm | Packed256_UInt64 Broadcast256_UInt64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=y
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vcvtuqq2ps_ymm_k1z_zmmm512b64_er
INSTRUCTION: EVEX.512.F2.0F.W1 7A /r | VCVTUQQ2PS ymm1 {k1}{z}, zmm2/m512/m64bcst{er} | AVX512DQ | N64b8
	ops: w=reg r=rm | Packed512_UInt64 Broadcast512_UInt64
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtps2qq_xmm_k1z_xmmm64b32
INSTRUCTION: EVEX.128.66.0F.W0 7B /r | VCVTPS2QQ xmm1 {k1}{z}, xmm2/m64/m32bcst | AVX512VL AVX512DQ | N8b4
	ops: w=reg r=rm | Packed64_Float32 Broadcast64_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtps2qq_ymm_k1z_xmmm128b32
INSTRUCTION: EVEX.256.66.0F.W0 7B /r | VCVTPS2QQ ymm1 {k1}{z}, xmm2/m128/m32bcst | AVX512VL AVX512DQ | N16b4
	ops: w=reg r=rm | Packed128_Float32 Broadcast128_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtps2qq_zmm_k1z_ymmm256b32_er
INSTRUCTION: EVEX.512.66.0F.W0 7B /r | VCVTPS2QQ zmm1 {k1}{z}, ymm2/m256/m32bcst{er} | AVX512DQ | N32b4
	ops: wvmm=reg r=rm | Packed256_Float32 Broadcast256_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtpd2qq_xmm_k1z_xmmm128b64
INSTRUCTION: EVEX.128.66.0F.W1 7B /r | VCVTPD2QQ xmm1 {k1}{z}, xmm2/m128/m64bcst | AVX512VL AVX512DQ | N16b8
	ops: w=reg r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vcvtpd2qq_ymm_k1z_ymmm256b64
INSTRUCTION: EVEX.256.66.0F.W1 7B /r | VCVTPD2QQ ymm1 {k1}{z}, ymm2/m256/m64bcst | AVX512VL AVX512DQ | N32b8
	ops: w=reg r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vcvtpd2qq_zmm_k1z_zmmm512b64_er
INSTRUCTION: EVEX.512.66.0F.W1 7B /r | VCVTPD2QQ zmm1 {k1}{z}, zmm2/m512/m64bcst{er} | AVX512DQ | N64b8
	ops: wvmm=reg r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: EVEX_Vcvtusi2ss_xmm_xmm_rm32_er
INSTRUCTION: EVEX.LIG.F3.0F.W0 7B /r | VCVTUSI2SS xmm1, xmm2, r/m32{er} | AVX512F | N4
	ops: w=reg r=vvvv r=rm | UInt32
	flags: wig32
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: EVEX_Vcvtusi2ss_xmm_xmm_rm64_er
INSTRUCTION: EVEX.LIG.F3.0F.W1 7B /r | VCVTUSI2SS xmm1, xmm2, r/m64{er} | AVX512F | N8
	ops: w=reg r=vvvv r=rm | UInt64
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: EVEX_Vcvtusi2sd_xmm_xmm_rm32_er
INSTRUCTION: EVEX.LIG.F2.0F.W0 7B /r | VCVTUSI2SD xmm1, xmm2, r/m32{er} | AVX512F | N4
	ops: w=reg r=vvvv r=rm | UInt32
	flags: wig32 ignore-er
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: EVEX_Vcvtusi2sd_xmm_xmm_rm64_er
INSTRUCTION: EVEX.LIG.F2.0F.W1 7B /r | VCVTUSI2SD xmm1, xmm2, r/m64{er} | AVX512F | N8
	ops: w=reg r=vvvv r=rm | UInt64
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Haddpd_xmm_xmmm128
INSTRUCTION: 66 0F 7C /r | HADDPD xmm1, xmm2/m128 | SSE3
	ops: rw=reg r=rm | Packed128_Float64
END

# Code: VEX_Vhaddpd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 7C /r | VHADDPD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vhaddpd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 7C /r | VHADDPD ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float64
END

# Code: Haddps_xmm_xmmm128
INSTRUCTION: F2 0F 7C /r | HADDPS xmm1, xmm2/m128 | SSE3
	ops: rw=reg r=rm | Packed128_Float32
END

# Code: VEX_Vhaddps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.F2.0F.WIG 7C /r | VHADDPS xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vhaddps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.F2.0F.WIG 7C /r | VHADDPS ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float32
END

# Code: Hsubpd_xmm_xmmm128
INSTRUCTION: 66 0F 7D /r | HSUBPD xmm1, xmm2/m128 | SSE3
	ops: rw=reg r=rm | Packed128_Float64
END

# Code: VEX_Vhsubpd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG 7D /r | VHSUBPD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vhsubpd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG 7D /r | VHSUBPD ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float64
END

# Code: Hsubps_xmm_xmmm128
INSTRUCTION: F2 0F 7D /r | HSUBPS xmm1, xmm2/m128 | SSE3
	ops: rw=reg r=rm | Packed128_Float32
END

# Code: VEX_Vhsubps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.F2.0F.WIG 7D /r | VHSUBPS xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vhsubps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.F2.0F.WIG 7D /r | VHSUBPS ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float32
END

# Code: Movd_rm32_mm
INSTRUCTION: NP 0F 7E /r | MOVD r/m32, mm | MMX
	ops: w=rm r=reg | UInt32
	flags: tsx-impl-abort
	masm: flags=force-size=default
END

# Code: Movq_rm64_mm
INSTRUCTION: NP o64 0F 7E /r | MOVQ r/m64, mm | MMX
	ops: w=rm r=reg | UInt64
	flags: 64 tsx-impl-abort asm-ig-mem
END

# Code: Movd_rm32_xmm
INSTRUCTION: 66 0F 7E /r | MOVD r/m32, xmm | SSE2
	ops: w=rm r=reg | UInt32
	masm: flags=force-size=default
END

# Code: Movq_rm64_xmm
INSTRUCTION: 66 o64 0F 7E /r | MOVQ r/m64, xmm | SSE2
	ops: w=rm r=reg | UInt64
	flags: 64 asm-ig-mem
	masm: flags=force-size=default
END

# Code: VEX_Vmovd_rm32_xmm
INSTRUCTION: VEX.128.66.0F.W0 7E /r | VMOVD r/m32, xmm1 | AVX
	ops: w=rm r=reg | UInt32
	flags: wig32
	masm: flags=force-size=default
END

# Code: VEX_Vmovq_rm64_xmm
INSTRUCTION: VEX.128.66.0F.W1 7E /r | VMOVQ r/m64, xmm1 | AVX
	ops: w=rm r=reg | UInt64
	flags: 64 asm-ig-mem
	masm: flags=force-size=default
END

# Code: EVEX_Vmovd_rm32_xmm
INSTRUCTION: EVEX.128.66.0F.W0 7E /r | VMOVD r/m32, xmm1 | AVX512F | N4
	ops: w=rm r=reg | UInt32
	flags: wig32
	masm: flags=force-size=default
END

# Code: EVEX_Vmovq_rm64_xmm
INSTRUCTION: EVEX.128.66.0F.W1 7E /r | VMOVQ r/m64, xmm1 | AVX512F | N8
	ops: w=rm r=reg | UInt64
	flags: 64 asm-ig-mem
	masm: flags=force-size=default
END

# Code: Movq_xmm_xmmm64
INSTRUCTION: F3 0F 7E /r | MOVQ xmm1, xmm2/m64 | SSE2
	ops: w=reg r=rm | UInt64
	masm: flags=force-size=default
END

# Code: VEX_Vmovq_xmm_xmmm64
INSTRUCTION: VEX.128.F3.0F.WIG 7E /r | VMOVQ xmm1, xmm2/m64 | AVX
	ops: w=reg r=rm | UInt64
	masm: flags=force-size=default
END

# Code: EVEX_Vmovq_xmm_xmmm64
INSTRUCTION: EVEX.128.F3.0F.W1 7E /r | VMOVQ xmm1, xmm2/m64 | AVX512F | N8
	ops: w=reg r=rm | UInt64
	masm: flags=force-size=default
END

# Code: Movq_mmm64_mm
INSTRUCTION: NP 0F 7F /r | MOVQ mm/m64, mm | MMX
	ops: w=rm r=reg | UInt64
	flags: tsx-impl-abort
END

# Code: Movdqa_xmmm128_xmm
INSTRUCTION: 66 0F 7F /r | MOVDQA xmm2/m128, xmm1 | SSE2
	ops: w=rm r=reg | Packed128_UInt32
END

# Code: VEX_Vmovdqa_xmmm128_xmm
INSTRUCTION: VEX.128.66.0F.WIG 7F /r | VMOVDQA xmm2/m128, xmm1 | AVX
	ops: w=rm r=reg | Packed128_UInt32
	masm: flags=force-size=default
END

# Code: VEX_Vmovdqa_ymmm256_ymm
INSTRUCTION: VEX.256.66.0F.WIG 7F /r | VMOVDQA ymm2/m256, ymm1 | AVX
	ops: w=rm r=reg | Packed256_UInt32
	masm: flags=force-size=default
END

# Code: EVEX_Vmovdqa32_xmmm128_k1z_xmm
INSTRUCTION: EVEX.128.66.0F.W0 7F /r | VMOVDQA32 xmm2/m128 {k1}{z}, xmm1 | AVX512VL AVX512F | N16
	ops: w=rm r=reg | Packed128_UInt32
END

# Code: EVEX_Vmovdqa32_ymmm256_k1z_ymm
INSTRUCTION: EVEX.256.66.0F.W0 7F /r | VMOVDQA32 ymm2/m256 {k1}{z}, ymm1 | AVX512VL AVX512F | N32
	ops: w=rm r=reg | Packed256_UInt32
END

# Code: EVEX_Vmovdqa32_zmmm512_k1z_zmm
INSTRUCTION: EVEX.512.66.0F.W0 7F /r | VMOVDQA32 zmm2/m512 {k1}{z}, zmm1 | AVX512F | N64
	ops: wvmm=rm r=reg | Packed512_UInt32
END

# Code: EVEX_Vmovdqa64_xmmm128_k1z_xmm
INSTRUCTION: EVEX.128.66.0F.W1 7F /r | VMOVDQA64 xmm2/m128 {k1}{z}, xmm1 | AVX512VL AVX512F | N16
	ops: w=rm r=reg | Packed128_UInt64
END

# Code: EVEX_Vmovdqa64_ymmm256_k1z_ymm
INSTRUCTION: EVEX.256.66.0F.W1 7F /r | VMOVDQA64 ymm2/m256 {k1}{z}, ymm1 | AVX512VL AVX512F | N32
	ops: w=rm r=reg | Packed256_UInt64
END

# Code: EVEX_Vmovdqa64_zmmm512_k1z_zmm
INSTRUCTION: EVEX.512.66.0F.W1 7F /r | VMOVDQA64 zmm2/m512 {k1}{z}, zmm1 | AVX512F | N64
	ops: wvmm=rm r=reg | Packed512_UInt64
END

# Code: Movdqu_xmmm128_xmm
INSTRUCTION: F3 0F 7F /r | MOVDQU xmm2/m128, xmm1 | SSE2
	ops: w=rm r=reg | Packed128_UInt32
END

# Code: VEX_Vmovdqu_xmmm128_xmm
INSTRUCTION: VEX.128.F3.0F.WIG 7F /r | VMOVDQU xmm2/m128, xmm1 | AVX
	ops: w=rm r=reg | Packed128_UInt32
	masm: flags=force-size=default
END

# Code: VEX_Vmovdqu_ymmm256_ymm
INSTRUCTION: VEX.256.F3.0F.WIG 7F /r | VMOVDQU ymm2/m256, ymm1 | AVX
	ops: w=rm r=reg | Packed256_UInt32
	masm: flags=force-size=default
END

# Code: EVEX_Vmovdqu32_xmmm128_k1z_xmm
INSTRUCTION: EVEX.128.F3.0F.W0 7F /r | VMOVDQU32 xmm2/m128 {k1}{z}, xmm1 | AVX512VL AVX512F | N16
	ops: w=rm r=reg | Packed128_UInt32
END

# Code: EVEX_Vmovdqu32_ymmm256_k1z_ymm
INSTRUCTION: EVEX.256.F3.0F.W0 7F /r | VMOVDQU32 ymm2/m256 {k1}{z}, ymm1 | AVX512VL AVX512F | N32
	ops: w=rm r=reg | Packed256_UInt32
END

# Code: EVEX_Vmovdqu32_zmmm512_k1z_zmm
INSTRUCTION: EVEX.512.F3.0F.W0 7F /r | VMOVDQU32 zmm2/m512 {k1}{z}, zmm1 | AVX512F | N64
	ops: wvmm=rm r=reg | Packed512_UInt32
END

# Code: EVEX_Vmovdqu64_xmmm128_k1z_xmm
INSTRUCTION: EVEX.128.F3.0F.W1 7F /r | VMOVDQU64 xmm2/m128 {k1}{z}, xmm1 | AVX512VL AVX512F | N16
	ops: w=rm r=reg | Packed128_UInt64
END

# Code: EVEX_Vmovdqu64_ymmm256_k1z_ymm
INSTRUCTION: EVEX.256.F3.0F.W1 7F /r | VMOVDQU64 ymm2/m256 {k1}{z}, ymm1 | AVX512VL AVX512F | N32
	ops: w=rm r=reg | Packed256_UInt64
END

# Code: EVEX_Vmovdqu64_zmmm512_k1z_zmm
INSTRUCTION: EVEX.512.F3.0F.W1 7F /r | VMOVDQU64 zmm2/m512 {k1}{z}, zmm1 | AVX512F | N64
	ops: wvmm=rm r=reg | Packed512_UInt64
END

# Code: EVEX_Vmovdqu8_xmmm128_k1z_xmm
INSTRUCTION: EVEX.128.F2.0F.W0 7F /r | VMOVDQU8 xmm2/m128 {k1}{z}, xmm1 | AVX512VL AVX512BW | N16
	ops: w=rm r=reg | Packed128_UInt8
END

# Code: EVEX_Vmovdqu8_ymmm256_k1z_ymm
INSTRUCTION: EVEX.256.F2.0F.W0 7F /r | VMOVDQU8 ymm2/m256 {k1}{z}, ymm1 | AVX512VL AVX512BW | N32
	ops: w=rm r=reg | Packed256_UInt8
END

# Code: EVEX_Vmovdqu8_zmmm512_k1z_zmm
INSTRUCTION: EVEX.512.F2.0F.W0 7F /r | VMOVDQU8 zmm2/m512 {k1}{z}, zmm1 | AVX512BW | N64
	ops: wvmm=rm r=reg | Packed512_UInt8
END

# Code: EVEX_Vmovdqu16_xmmm128_k1z_xmm
INSTRUCTION: EVEX.128.F2.0F.W1 7F /r | VMOVDQU16 xmm2/m128 {k1}{z}, xmm1 | AVX512VL AVX512BW | N16
	ops: w=rm r=reg | Packed128_UInt16
END

# Code: EVEX_Vmovdqu16_ymmm256_k1z_ymm
INSTRUCTION: EVEX.256.F2.0F.W1 7F /r | VMOVDQU16 ymm2/m256 {k1}{z}, ymm1 | AVX512VL AVX512BW | N32
	ops: w=rm r=reg | Packed256_UInt16
END

# Code: EVEX_Vmovdqu16_zmmm512_k1z_zmm
INSTRUCTION: EVEX.512.F2.0F.W1 7F /r | VMOVDQU16 zmm2/m512 {k1}{z}, zmm1 | AVX512BW | N64
	ops: wvmm=rm r=reg | Packed512_UInt16
END

# Code: Jo_rel16
INSTRUCTION: o16 0F 80 cw | JO rel16 | INTEL386
	ops: r=br
	rflags: r=o
	flags: bnd ht cc=j;o; br=jcc-near cflow=br-cond no-intel-dec64
END

# Code: Jo_rel32_32
INSTRUCTION: o32 0F 80 cd | JO rel32 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=o
	flags: 16 32 bnd ht cc=j;o; br=jcc-near cflow=br-cond
END

# Code: Jo_rel32_64
INSTRUCTION: o64 0F 80 cd | JO rel32 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=o
	flags: 64 bnd ht cc=j;o; br=jcc-near cflow=br-cond intel-fo64 do64
END

# Code: Jno_rel16
INSTRUCTION: o16 0F 81 cw | JNO rel16 | INTEL386
	ops: r=br
	rflags: r=o
	flags: bnd ht cc=j;no; br=jcc-near cflow=br-cond no-intel-dec64
END

# Code: Jno_rel32_32
INSTRUCTION: o32 0F 81 cd | JNO rel32 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=o
	flags: 16 32 bnd ht cc=j;no; br=jcc-near cflow=br-cond
END

# Code: Jno_rel32_64
INSTRUCTION: o64 0F 81 cd | JNO rel32 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=o
	flags: 64 bnd ht cc=j;no; br=jcc-near cflow=br-cond intel-fo64 do64
END

# Code: Jb_rel16
INSTRUCTION: o16 0F 82 cw | JB rel16 | INTEL386
	ops: r=br
	rflags: r=c
	flags: bnd ht cc=j;b; br=jcc-near cflow=br-cond no-intel-dec64
END

# Code: Jb_rel32_32
INSTRUCTION: o32 0F 82 cd | JB rel32 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=c
	flags: 16 32 bnd ht cc=j;b; br=jcc-near cflow=br-cond
END

# Code: Jb_rel32_64
INSTRUCTION: o64 0F 82 cd | JB rel32 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=c
	flags: 64 bnd ht cc=j;b; br=jcc-near cflow=br-cond intel-fo64 do64
END

# Code: Jae_rel16
INSTRUCTION: o16 0F 83 cw | JAE rel16 | INTEL386
	ops: r=br
	rflags: r=c
	flags: bnd ht cc=j;ae; br=jcc-near cflow=br-cond no-intel-dec64
END

# Code: Jae_rel32_32
INSTRUCTION: o32 0F 83 cd | JAE rel32 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=c
	flags: 16 32 bnd ht cc=j;ae; br=jcc-near cflow=br-cond
END

# Code: Jae_rel32_64
INSTRUCTION: o64 0F 83 cd | JAE rel32 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=c
	flags: 64 bnd ht cc=j;ae; br=jcc-near cflow=br-cond intel-fo64 do64
END

# Code: Je_rel16
INSTRUCTION: o16 0F 84 cw | JE rel16 | INTEL386
	ops: r=br
	rflags: r=z
	flags: bnd ht cc=j;e; br=jcc-near cflow=br-cond no-intel-dec64
END

# Code: Je_rel32_32
INSTRUCTION: o32 0F 84 cd | JE rel32 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=z
	flags: 16 32 bnd ht cc=j;e; br=jcc-near cflow=br-cond
END

# Code: Je_rel32_64
INSTRUCTION: o64 0F 84 cd | JE rel32 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=z
	flags: 64 bnd ht cc=j;e; br=jcc-near cflow=br-cond intel-fo64 do64
END

# Code: Jne_rel16
INSTRUCTION: o16 0F 85 cw | JNE rel16 | INTEL386
	ops: r=br
	rflags: r=z
	flags: bnd ht cc=j;ne; br=jcc-near cflow=br-cond no-intel-dec64
END

# Code: Jne_rel32_32
INSTRUCTION: o32 0F 85 cd | JNE rel32 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=z
	flags: 16 32 bnd ht cc=j;ne; br=jcc-near cflow=br-cond
END

# Code: Jne_rel32_64
INSTRUCTION: o64 0F 85 cd | JNE rel32 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=z
	flags: 64 bnd ht cc=j;ne; br=jcc-near cflow=br-cond intel-fo64 do64
END

# Code: Jbe_rel16
INSTRUCTION: o16 0F 86 cw | JBE rel16 | INTEL386
	ops: r=br
	rflags: r=zc
	flags: bnd ht cc=j;be; br=jcc-near cflow=br-cond no-intel-dec64
END

# Code: Jbe_rel32_32
INSTRUCTION: o32 0F 86 cd | JBE rel32 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=zc
	flags: 16 32 bnd ht cc=j;be; br=jcc-near cflow=br-cond
END

# Code: Jbe_rel32_64
INSTRUCTION: o64 0F 86 cd | JBE rel32 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=zc
	flags: 64 bnd ht cc=j;be; br=jcc-near cflow=br-cond intel-fo64 do64
END

# Code: Ja_rel16
INSTRUCTION: o16 0F 87 cw | JA rel16 | INTEL386
	ops: r=br
	rflags: r=zc
	flags: bnd ht cc=j;a; br=jcc-near cflow=br-cond no-intel-dec64
END

# Code: Ja_rel32_32
INSTRUCTION: o32 0F 87 cd | JA rel32 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=zc
	flags: 16 32 bnd ht cc=j;a; br=jcc-near cflow=br-cond
END

# Code: Ja_rel32_64
INSTRUCTION: o64 0F 87 cd | JA rel32 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=zc
	flags: 64 bnd ht cc=j;a; br=jcc-near cflow=br-cond intel-fo64 do64
END

# Code: Js_rel16
INSTRUCTION: o16 0F 88 cw | JS rel16 | INTEL386
	ops: r=br
	rflags: r=s
	flags: bnd ht cc=j;s; br=jcc-near cflow=br-cond no-intel-dec64
END

# Code: Js_rel32_32
INSTRUCTION: o32 0F 88 cd | JS rel32 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=s
	flags: 16 32 bnd ht cc=j;s; br=jcc-near cflow=br-cond
END

# Code: Js_rel32_64
INSTRUCTION: o64 0F 88 cd | JS rel32 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=s
	flags: 64 bnd ht cc=j;s; br=jcc-near cflow=br-cond intel-fo64 do64
END

# Code: Jns_rel16
INSTRUCTION: o16 0F 89 cw | JNS rel16 | INTEL386
	ops: r=br
	rflags: r=s
	flags: bnd ht cc=j;ns; br=jcc-near cflow=br-cond no-intel-dec64
END

# Code: Jns_rel32_32
INSTRUCTION: o32 0F 89 cd | JNS rel32 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=s
	flags: 16 32 bnd ht cc=j;ns; br=jcc-near cflow=br-cond
END

# Code: Jns_rel32_64
INSTRUCTION: o64 0F 89 cd | JNS rel32 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=s
	flags: 64 bnd ht cc=j;ns; br=jcc-near cflow=br-cond intel-fo64 do64
END

# Code: Jp_rel16
INSTRUCTION: o16 0F 8A cw | JP rel16 | INTEL386
	ops: r=br
	rflags: r=p
	flags: bnd ht cc=j;p; br=jcc-near cflow=br-cond no-intel-dec64
END

# Code: Jp_rel32_32
INSTRUCTION: o32 0F 8A cd | JP rel32 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=p
	flags: 16 32 bnd ht cc=j;p; br=jcc-near cflow=br-cond
END

# Code: Jp_rel32_64
INSTRUCTION: o64 0F 8A cd | JP rel32 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=p
	flags: 64 bnd ht cc=j;p; br=jcc-near cflow=br-cond intel-fo64 do64
END

# Code: Jnp_rel16
INSTRUCTION: o16 0F 8B cw | JNP rel16 | INTEL386
	ops: r=br
	rflags: r=p
	flags: bnd ht cc=j;np; br=jcc-near cflow=br-cond no-intel-dec64
END

# Code: Jnp_rel32_32
INSTRUCTION: o32 0F 8B cd | JNP rel32 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=p
	flags: 16 32 bnd ht cc=j;np; br=jcc-near cflow=br-cond
END

# Code: Jnp_rel32_64
INSTRUCTION: o64 0F 8B cd | JNP rel32 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=p
	flags: 64 bnd ht cc=j;np; br=jcc-near cflow=br-cond intel-fo64 do64
END

# Code: Jl_rel16
INSTRUCTION: o16 0F 8C cw | JL rel16 | INTEL386
	ops: r=br
	rflags: r=os
	flags: bnd ht cc=j;l; br=jcc-near cflow=br-cond no-intel-dec64

END

# Code: Jl_rel32_32
INSTRUCTION: o32 0F 8C cd | JL rel32 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=os
	flags: 16 32 bnd ht cc=j;l; br=jcc-near cflow=br-cond
END

# Code: Jl_rel32_64
INSTRUCTION: o64 0F 8C cd | JL rel32 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=os
	flags: 64 bnd ht cc=j;l; br=jcc-near cflow=br-cond intel-fo64 do64
END

# Code: Jge_rel16
INSTRUCTION: o16 0F 8D cw | JGE rel16 | INTEL386
	ops: r=br
	rflags: r=os
	flags: bnd ht cc=j;ge; br=jcc-near cflow=br-cond no-intel-dec64
END

# Code: Jge_rel32_32
INSTRUCTION: o32 0F 8D cd | JGE rel32 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=os
	flags: 16 32 bnd ht cc=j;ge; br=jcc-near cflow=br-cond
END

# Code: Jge_rel32_64
INSTRUCTION: o64 0F 8D cd | JGE rel32 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=os
	flags: 64 bnd ht cc=j;ge; br=jcc-near cflow=br-cond intel-fo64 do64
END

# Code: Jle_rel16
INSTRUCTION: o16 0F 8E cw | JLE rel16 | INTEL386
	ops: r=br
	rflags: r=osz
	flags: bnd ht cc=j;le; br=jcc-near cflow=br-cond no-intel-dec64
END

# Code: Jle_rel32_32
INSTRUCTION: o32 0F 8E cd | JLE rel32 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=osz
	flags: 16 32 bnd ht cc=j;le; br=jcc-near cflow=br-cond
END

# Code: Jle_rel32_64
INSTRUCTION: o64 0F 8E cd | JLE rel32 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=osz
	flags: 64 bnd ht cc=j;le; br=jcc-near cflow=br-cond intel-fo64 do64
END

# Code: Jg_rel16
INSTRUCTION: o16 0F 8F cw | JG rel16 | INTEL386
	ops: r=br
	rflags: r=osz
	flags: bnd ht cc=j;g; br=jcc-near cflow=br-cond no-intel-dec64
END

# Code: Jg_rel32_32
INSTRUCTION: o32 0F 8F cd | JG rel32 | INTEL386
	ops: r=br
	code-suffix: 32
	rflags: r=osz
	flags: 16 32 bnd ht cc=j;g; br=jcc-near cflow=br-cond
END

# Code: Jg_rel32_64
INSTRUCTION: o64 0F 8F cd | JG rel32 | X64
	ops: r=br
	code-suffix: 64
	rflags: r=osz
	flags: 64 bnd ht cc=j;g; br=jcc-near cflow=br-cond intel-fo64 do64
END

# Code: Seto_rm8
INSTRUCTION: 0F 90 /r | SETO r/m8 | INTEL386
	ops: w=rm | UInt8
	rflags: r=o
	flags: cc=set;o;
	gas: suffix=b cc
	intel: cc
	masm: flags=force-size=default cc
	nasm: cc
END

# Code: Setno_rm8
INSTRUCTION: 0F 91 /r | SETNO r/m8 | INTEL386
	ops: w=rm | UInt8
	rflags: r=o
	flags: cc=set;no;
	gas: suffix=b cc
	intel: cc
	masm: flags=force-size=default cc
	nasm: cc
END

# Code: Setb_rm8
INSTRUCTION: 0F 92 /r | SETB r/m8 | INTEL386
	ops: w=rm | UInt8
	rflags: r=c
	flags: cc=set;b;
	gas: suffix=b cc
	intel: cc
	masm: flags=force-size=default cc
	nasm: cc
END

# Code: Setae_rm8
INSTRUCTION: 0F 93 /r | SETAE r/m8 | INTEL386
	ops: w=rm | UInt8
	rflags: r=c
	flags: cc=set;ae;
	gas: suffix=b cc
	intel: cc
	masm: flags=force-size=default cc
	nasm: cc
END

# Code: Sete_rm8
INSTRUCTION: 0F 94 /r | SETE r/m8 | INTEL386
	ops: w=rm | UInt8
	rflags: r=z
	flags: cc=set;e;
	gas: suffix=b cc
	intel: cc
	masm: flags=force-size=default cc
	nasm: cc
END

# Code: Setne_rm8
INSTRUCTION: 0F 95 /r | SETNE r/m8 | INTEL386
	ops: w=rm | UInt8
	rflags: r=z
	flags: cc=set;ne;
	gas: suffix=b cc
	intel: cc
	masm: flags=force-size=default cc
	nasm: cc
END

# Code: Setbe_rm8
INSTRUCTION: 0F 96 /r | SETBE r/m8 | INTEL386
	ops: w=rm | UInt8
	rflags: r=zc
	flags: cc=set;be;
	gas: suffix=b cc
	intel: cc
	masm: flags=force-size=default cc
	nasm: cc
END

# Code: Seta_rm8
INSTRUCTION: 0F 97 /r | SETA r/m8 | INTEL386
	ops: w=rm | UInt8
	rflags: r=zc
	flags: cc=set;a;
	gas: suffix=b cc
	intel: cc
	masm: flags=force-size=default cc
	nasm: cc
END

# Code: Sets_rm8
INSTRUCTION: 0F 98 /r | SETS r/m8 | INTEL386
	ops: w=rm | UInt8
	rflags: r=s
	flags: cc=set;s;
	gas: suffix=b cc
	intel: cc
	masm: flags=force-size=default cc
	nasm: cc
END

# Code: Setns_rm8
INSTRUCTION: 0F 99 /r | SETNS r/m8 | INTEL386
	ops: w=rm | UInt8
	rflags: r=s
	flags: cc=set;ns;
	gas: suffix=b cc
	intel: cc
	masm: flags=force-size=default cc
	nasm: cc
END

# Code: Setp_rm8
INSTRUCTION: 0F 9A /r | SETP r/m8 | INTEL386
	ops: w=rm | UInt8
	rflags: r=p
	flags: cc=set;p;
	gas: suffix=b cc
	intel: cc
	masm: flags=force-size=default cc
	nasm: cc
END

# Code: Setnp_rm8
INSTRUCTION: 0F 9B /r | SETNP r/m8 | INTEL386
	ops: w=rm | UInt8
	rflags: r=p
	flags: cc=set;np;
	gas: suffix=b cc
	intel: cc
	masm: flags=force-size=default cc
	nasm: cc
END

# Code: Setl_rm8
INSTRUCTION: 0F 9C /r | SETL r/m8 | INTEL386
	ops: w=rm | UInt8
	rflags: r=os
	flags: cc=set;l;
	gas: suffix=b cc
	intel: cc
	masm: flags=force-size=default cc
	nasm: cc
END

# Code: Setge_rm8
INSTRUCTION: 0F 9D /r | SETGE r/m8 | INTEL386
	ops: w=rm | UInt8
	rflags: r=os
	flags: cc=set;ge;
	gas: suffix=b cc
	intel: cc
	masm: flags=force-size=default cc
	nasm: cc
END

# Code: Setle_rm8
INSTRUCTION: 0F 9E /r | SETLE r/m8 | INTEL386
	ops: w=rm | UInt8
	rflags: r=osz
	flags: cc=set;le;
	gas: suffix=b cc
	intel: cc
	masm: flags=force-size=default cc
	nasm: cc
END

# Code: Setg_rm8
INSTRUCTION: 0F 9F /r | SETG r/m8 | INTEL386
	ops: w=rm | UInt8
	rflags: r=osz
	flags: cc=set;g;
	gas: suffix=b cc
	intel: cc
	masm: flags=force-size=default cc
	nasm: cc
END

# Code: VEX_Kmovw_kr_km16
INSTRUCTION: VEX.L0.0F.W0 90 /r | KMOVW k1, k2/m16 | AVX512F
	ops: w=reg r=rm | UInt16
	masm: flags=force-size=default
END

# Code: VEX_Kmovq_kr_km64
INSTRUCTION: VEX.L0.0F.W1 90 /r | KMOVQ k1, k2/m64 | AVX512BW
	ops: w=reg r=rm | UInt64
	masm: flags=force-size=default
END

# Code: VEX_Kmovb_kr_km8
INSTRUCTION: VEX.L0.66.0F.W0 90 /r | KMOVB k1, k2/m8 | AVX512DQ
	ops: w=reg r=rm | UInt8
	masm: flags=force-size=default
END

# Code: VEX_Kmovd_kr_km32
INSTRUCTION: VEX.L0.66.0F.W1 90 /r | KMOVD k1, k2/m32 | AVX512BW
	ops: w=reg r=rm | UInt32
	masm: flags=force-size=default
END

# Code: VEX_Kmovw_m16_kr
INSTRUCTION: VEX.L0.0F.W0 91 /r | KMOVW m16, k1 | AVX512F
	ops: w=rm r=reg | UInt16
	masm: flags=force-size=default
END

# Code: VEX_Kmovq_m64_kr
INSTRUCTION: VEX.L0.0F.W1 91 /r | KMOVQ m64, k1 | AVX512BW
	ops: w=rm r=reg | UInt64
	masm: flags=force-size=default
END

# Code: VEX_Kmovb_m8_kr
INSTRUCTION: VEX.L0.66.0F.W0 91 /r | KMOVB m8, k1 | AVX512DQ
	ops: w=rm r=reg | UInt8
	masm: flags=force-size=default
END

# Code: VEX_Kmovd_m32_kr
INSTRUCTION: VEX.L0.66.0F.W1 91 /r | KMOVD m32, k1 | AVX512BW
	ops: w=rm r=reg | UInt32
	masm: flags=force-size=default
END

# Code: VEX_Kmovw_kr_r32
INSTRUCTION: VEX.L0.0F.W0 92 /r | KMOVW k1, r32 | AVX512F
	ops: w=reg r=rm
END

# Code: VEX_Kmovb_kr_r32
INSTRUCTION: VEX.L0.66.0F.W0 92 /r | KMOVB k1, r32 | AVX512DQ
	ops: w=reg r=rm
END

# Code: VEX_Kmovd_kr_r32
INSTRUCTION: VEX.L0.F2.0F.W0 92 /r | KMOVD k1, r32 | AVX512BW
	ops: w=reg r=rm
	flags: wig32
END

# Code: VEX_Kmovq_kr_r64
INSTRUCTION: VEX.L0.F2.0F.W1 92 /r | KMOVQ k1, r64 | AVX512BW
	ops: w=reg r=rm
	flags: 64
END

# Code: VEX_Kmovw_r32_kr
INSTRUCTION: VEX.L0.0F.W0 93 /r | KMOVW r32, k1 | AVX512F
	ops: w=reg r=rm
END

# Code: VEX_Kmovb_r32_kr
INSTRUCTION: VEX.L0.66.0F.W0 93 /r | KMOVB r32, k1 | AVX512DQ
	ops: w=reg r=rm
END

# Code: VEX_Kmovd_r32_kr
INSTRUCTION: VEX.L0.F2.0F.W0 93 /r | KMOVD r32, k1 | AVX512BW
	ops: w=reg r=rm
	flags: wig32
END

# Code: VEX_Kmovq_r64_kr
INSTRUCTION: VEX.L0.F2.0F.W1 93 /r | KMOVQ r64, k1 | AVX512BW
	ops: w=reg r=rm
	flags: 64
END

# Code: VEX_Kortestw_kr_kr
INSTRUCTION: VEX.L0.0F.W0 98 /r | KORTESTW k1, k2 | AVX512F
	ops: r=reg r=rm
	rflags: w=zc 0=osap
END

# Code: VEX_Kortestq_kr_kr
INSTRUCTION: VEX.L0.0F.W1 98 /r | KORTESTQ k1, k2 | AVX512BW
	ops: r=reg r=rm
	rflags: w=zc 0=osap
END

# Code: VEX_Kortestb_kr_kr
INSTRUCTION: VEX.L0.66.0F.W0 98 /r | KORTESTB k1, k2 | AVX512DQ
	ops: r=reg r=rm
	rflags: w=zc 0=osap
END

# Code: VEX_Kortestd_kr_kr
INSTRUCTION: VEX.L0.66.0F.W1 98 /r | KORTESTD k1, k2 | AVX512BW
	ops: r=reg r=rm
	rflags: w=zc 0=osap
END

# Code: VEX_Ktestw_kr_kr
INSTRUCTION: VEX.L0.0F.W0 99 /r | KTESTW k1, k2 | AVX512DQ
	ops: r=reg r=rm
	rflags: w=zc 0=osap
END

# Code: VEX_Ktestq_kr_kr
INSTRUCTION: VEX.L0.0F.W1 99 /r | KTESTQ k1, k2 | AVX512BW
	ops: r=reg r=rm
	rflags: w=zc 0=osap
END

# Code: VEX_Ktestb_kr_kr
INSTRUCTION: VEX.L0.66.0F.W0 99 /r | KTESTB k1, k2 | AVX512DQ
	ops: r=reg r=rm
	rflags: w=zc 0=osap
END

# Code: VEX_Ktestd_kr_kr
INSTRUCTION: VEX.L0.66.0F.W1 99 /r | KTESTD k1, k2 | AVX512BW
	ops: r=reg r=rm
	rflags: w=zc 0=osap
END

# Code: Pushw_FS
INSTRUCTION: o16 0F A0 | PUSH FS | INTEL386
	ops: r=r:fs
	implied: push=1x2
	code-mnemonic: pushw
	flags: sp=push;2
	gas: suffix=w osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Pushd_FS
INSTRUCTION: o32 0F A0 | PUSH FS | INTEL386
	ops: r=r:fs
	implied: push=1x4
	code-mnemonic: pushd
	flags: 16 32 sp=push;4
	gas: suffix=l osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Pushq_FS
INSTRUCTION: o64 0F A0 | PUSH FS | X64
	ops: r=r:fs
	implied: push=1x8
	code-mnemonic: pushq
	flags: 64 sp=push;8 do64
	gas: suffix=q osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Popw_FS
INSTRUCTION: o16 0F A1 | POP FS | INTEL386
	ops: w=r:fs
	implied: pop=1x2
	code-mnemonic: popw
	flags: sp=pop;2 no-in-sgx tsx-impl-abort
	gas: suffix=w osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Popd_FS
INSTRUCTION: o32 0F A1 | POP FS | INTEL386
	ops: w=r:fs
	implied: pop=1x4
	code-mnemonic: popd
	flags: 16 32 sp=pop;4 no-in-sgx tsx-impl-abort
	gas: suffix=l osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Popq_FS
INSTRUCTION: o64 0F A1 | POP FS | X64
	ops: w=r:fs
	implied: pop=1x8
	code-mnemonic: popq
	flags: 64 sp=pop;8 do64 no-in-sgx tsx-impl-abort
	gas: suffix=q osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Cpuid
INSTRUCTION: 0F A2 | CPUID | CPUID
	implied: rw=eax cr=ecx w=ecx;edx;ebx
	# Some Intel CPUs support CPUID faulting when executing CPUID and CPL>0 and !SMM
	# when enabled with MISC_FEATURES_ENABLES[0]=1 (MSR=140h)
	flags: serialize-intel serialize-amd may-require-cpl0 intel-vm-exit no-in-sgx tdx-non-root-may-gen-ex amd-may-vm-exit tsx-abort
END

# Code: Bt_rm16_r16
INSTRUCTION: o16 0F A3 /r | BT r/m16, r16 | INTEL386
	ops: r=rm r=reg | UInt16
	rflags: u=osap w=c
	gas: suffix=w
END

# Code: Bt_rm32_r32
INSTRUCTION: o32 0F A3 /r | BT r/m32, r32 | INTEL386
	ops: r=rm r=reg | UInt32
	rflags: u=osap w=c
	gas: suffix=l
END

# Code: Bt_rm64_r64
INSTRUCTION: o64 0F A3 /r | BT r/m64, r64 | X64
	ops: r=rm r=reg | UInt64
	rflags: u=osap w=c
	flags: 64
	gas: suffix=q
END

# Code: Shld_rm16_r16_imm8
INSTRUCTION: o16 0F A4 /r ib | SHLD r/m16, r16, imm8 | INTEL386
	ops: rw=rm r=reg r=imm | UInt16
	implied: shift-mask=0x1F
	rflags: u=oa w=szcp
	gas: suffix=w
END

# Code: Shld_rm32_r32_imm8
INSTRUCTION: o32 0F A4 /r ib | SHLD r/m32, r32, imm8 | INTEL386
	ops: rw=rm r=reg r=imm | UInt32
	implied: shift-mask=0x1F
	rflags: u=oa w=szcp
	gas: suffix=l
END

# Code: Shld_rm64_r64_imm8
INSTRUCTION: o64 0F A4 /r ib | SHLD r/m64, r64, imm8 | X64
	ops: rw=rm r=reg r=imm | UInt64
	implied: shift-mask=0x3F
	rflags: u=oa w=szcp
	flags: 64
	gas: suffix=q
END

# Code: Shld_rm16_r16_CL
INSTRUCTION: o16 0F A5 /r | SHLD r/m16, r16, CL | INTEL386
	ops: rw=rm r=reg r=r:cl | UInt16
	rflags: u=oa w=szcp
	gas: suffix=w
END

# Code: Shld_rm32_r32_CL
INSTRUCTION: o32 0F A5 /r | SHLD r/m32, r32, CL | INTEL386
	ops: rw=rm r=reg r=r:cl | UInt32
	rflags: u=oa w=szcp
	gas: suffix=l
END

# Code: Shld_rm64_r64_CL
INSTRUCTION: o64 0F A5 /r | SHLD r/m64, r64, CL | X64
	ops: rw=rm r=reg r=r:cl | UInt64
	rflags: u=oa w=szcp
	flags: 64
	gas: suffix=q
END

# Code: Montmul_16
INSTRUCTION: a16 F3 0F A6 C0 | MONTMUL | PADLOCK_PMM
	implied: cr=[es:si=Unknown] rcw=ecx cr=eax cw=eax;edx
	code-suffix: 16
	# Requires 32-bit addressing (Zhaoxin KX-6580 CPU, tested by @tremalrik)
	flags: 16 32 a32-req ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Montmul_32
INSTRUCTION: a32 F3 0F A6 C0 | MONTMUL | PADLOCK_PMM
	implied: cr=[es:esi=Unknown] rcw=ecx cr=eax cw=eax;edx
	code-suffix: 32
	# Requires 32-bit addressing (Zhaoxin KX-6580 CPU, tested by @tremalrik)
	flags: a32-req ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Montmul_64
INSTRUCTION: a64 F3 0F A6 C0 | MONTMUL | PADLOCK_PMM
	implied: cr=[es:rsi=Unknown] rcw=rcx cr=eax cw=eax;edx
	code-suffix: 64
	# Requires 32-bit addressing (Zhaoxin KX-6580 CPU, tested by @tremalrik)
	flags: 64 a32-req ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xsha1_16
INSTRUCTION: a16 F3 0F A6 C8 | XSHA1 | PADLOCK_PHE
	implied: cr=[es:si=Unknown] crcw=[es:di=Unknown] cw=si rcw=ax;cx
	code-suffix: 16
	flags: 16 32 ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xsha1_32
INSTRUCTION: a32 F3 0F A6 C8 | XSHA1 | PADLOCK_PHE
	implied: cr=[es:esi=Unknown] crcw=[es:edi=Unknown] cw=esi rcw=eax;ecx
	code-suffix: 32
	flags: ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xsha1_64
INSTRUCTION: a64 F3 0F A6 C8 | XSHA1 | PADLOCK_PHE
	implied: cr=[es:rsi=Unknown] crcw=[es:rdi=Unknown] cw=rsi rcw=rax;rcx
	code-suffix: 64
	flags: 64 ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xsha256_16
INSTRUCTION: a16 F3 0F A6 D0 | XSHA256 | PADLOCK_PHE
	implied: cr=[es:si=Unknown] crcw=[es:di=Unknown] cw=si rcw=ax;cx
	code-suffix: 16
	flags: 16 32 ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xsha256_32
INSTRUCTION: a32 F3 0F A6 D0 | XSHA256 | PADLOCK_PHE
	implied: cr=[es:esi=Unknown] crcw=[es:edi=Unknown] cw=esi rcw=eax;ecx
	code-suffix: 32
	flags: ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xsha256_64
INSTRUCTION: a64 F3 0F A6 D0 | XSHA256 | PADLOCK_PHE
	implied: cr=[es:rsi=Unknown] crcw=[es:rdi=Unknown] cw=rsi rcw=rax;rcx
	code-suffix: 64
	flags: 64 ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xsha512_alt_16
INSTRUCTION: a16 F3 0F A6 D8 | XSHA512_ALT | PADLOCK_PHE
	# Seems to be the same as XSHA512 (Zhaoxin KX-6580 CPU, tested by @tremalrik)
	implied: cr=[es:si=Unknown] crcw=[es:di=Unknown] cw=si rcw=cx
	code-suffix: 16
	flags: 16 32 ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xsha512_alt_32
INSTRUCTION: a32 F3 0F A6 D8 | XSHA512_ALT | PADLOCK_PHE
	implied: cr=[es:esi=Unknown] crcw=[es:edi=Unknown] cw=esi rcw=ecx
	code-suffix: 32
	flags: ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xsha512_alt_64
INSTRUCTION: a64 F3 0F A6 D8 | XSHA512_ALT | PADLOCK_PHE
	implied: cr=[es:rsi=Unknown] crcw=[es:rdi=Unknown] cw=rsi rcw=rcx
	code-suffix: 64
	flags: 64 ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xsha512_16
INSTRUCTION: a16 F3 0F A6 E0 | XSHA512 | PADLOCK_PHE
	# https://github.com/openssl/openssl/blob/27aca04e13ca8a9bead49de7bc380110ecb7064e/engines/asm/e_padlock-x86.pl#L597
	# rAX isn't used like in XSHA256
	implied: cr=[es:si=Unknown] crcw=[es:di=Unknown] cw=si rcw=cx
	code-suffix: 16
	flags: 16 32 ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xsha512_32
INSTRUCTION: a32 F3 0F A6 E0 | XSHA512 | PADLOCK_PHE
	implied: cr=[es:esi=Unknown] crcw=[es:edi=Unknown] cw=esi rcw=ecx
	code-suffix: 32
	flags: ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xsha512_64
INSTRUCTION: a64 F3 0F A6 E0 | XSHA512 | PADLOCK_PHE
	implied: cr=[es:rsi=Unknown] crcw=[es:rdi=Unknown] cw=rsi rcw=rcx
	code-suffix: 64
	flags: 64 ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xbts_r16_rm16
INSTRUCTION: o16 0F A6 /r | XBTS r16, r/m16 | INTEL386_A0_ONLY
	ops: rw=reg r=rm | UInt16
	implied: r=ax;cl
	flags: 16 32 dec-opt=Xbts
	gas: suffix=w
END

# Code: Xbts_r32_rm32
INSTRUCTION: o32 0F A6 /r | XBTS r32, r/m32 | INTEL386_A0_ONLY
	ops: rw=reg r=rm | UInt32
	implied: r=eax;cl
	flags: 16 32 dec-opt=Xbts
	gas: suffix=l
END

# Code: Xstore_16
INSTRUCTION: a16 0F A7 C0 | XSTORE | PADLOCK_RNG
	implied: xstore=2
	code-suffix: 16
	flags: 16 32 rep ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xstore_32
INSTRUCTION: a32 0F A7 C0 | XSTORE | PADLOCK_RNG
	implied: xstore=4
	code-suffix: 32
	flags: rep ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xstore_64
INSTRUCTION: a64 0F A7 C0 | XSTORE | PADLOCK_RNG
	implied: xstore=8
	code-suffix: 64
	flags: 64 rep ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xcryptecb_16
INSTRUCTION: a16 F3 0F A7 C8 | XCRYPTECB | PADLOCK_ACE
	implied: cr=[es:dx=Unknown];[es:bx=Unknown];[es:si=Unknown] cw=[es:di=Unknown] rcw=cx cw=si;di
	code-suffix: 16
	flags: 16 32 ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xcryptecb_32
INSTRUCTION: a32 F3 0F A7 C8 | XCRYPTECB | PADLOCK_ACE
	implied: cr=[es:edx=Unknown];[es:ebx=Unknown];[es:esi=Unknown] cw=[es:edi=Unknown] rcw=ecx cw=esi;edi
	code-suffix: 32
	flags: ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xcryptecb_64
INSTRUCTION: a64 F3 0F A7 C8 | XCRYPTECB | PADLOCK_ACE
	implied: cr=[es:rdx=Unknown];[es:rbx=Unknown];[es:rsi=Unknown] cw=[es:rdi=Unknown] rcw=rcx cw=rsi;rdi
	code-suffix: 64
	flags: 64 ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xcryptcbc_16
INSTRUCTION: a16 F3 0F A7 D0 | XCRYPTCBC | PADLOCK_ACE
	implied: crcw=[es:ax=Unknown] cr=[es:dx=Unknown];[es:bx=Unknown];[es:si=Unknown] cw=[es:di=Unknown] rcw=cx cw=si;di
	code-suffix: 16
	flags: 16 32 ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xcryptcbc_32
INSTRUCTION: a32 F3 0F A7 D0 | XCRYPTCBC | PADLOCK_ACE
	implied: crcw=[es:eax=Unknown] cr=[es:edx=Unknown];[es:ebx=Unknown];[es:esi=Unknown] cw=[es:edi=Unknown] rcw=ecx cw=esi;edi
	code-suffix: 32
	flags: ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xcryptcbc_64
INSTRUCTION: a64 F3 0F A7 D0 | XCRYPTCBC | PADLOCK_ACE
	implied: crcw=[es:rax=Unknown] cr=[es:rdx=Unknown];[es:rbx=Unknown];[es:rsi=Unknown] cw=[es:rdi=Unknown] rcw=rcx cw=rsi;rdi
	code-suffix: 64
	flags: 64 ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xcryptctr_16
INSTRUCTION: a16 F3 0F A7 D8 | XCRYPTCTR | PADLOCK_ACE
	implied: crcw=[es:ax=Unknown] cr=[es:dx=Unknown];[es:bx=Unknown];[es:si=Unknown] cw=[es:di=Unknown] rcw=cx cw=si;di
	code-suffix: 16
	flags: 16 32 ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xcryptctr_32
INSTRUCTION: a32 F3 0F A7 D8 | XCRYPTCTR | PADLOCK_ACE
	implied: crcw=[es:eax=Unknown] cr=[es:edx=Unknown];[es:ebx=Unknown];[es:esi=Unknown] cw=[es:edi=Unknown] rcw=ecx cw=esi;edi
	code-suffix: 32
	flags: ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xcryptctr_64
INSTRUCTION: a64 F3 0F A7 D8 | XCRYPTCTR | PADLOCK_ACE
	implied: crcw=[es:rax=Unknown] cr=[es:rdx=Unknown];[es:rbx=Unknown];[es:rsi=Unknown] cw=[es:rdi=Unknown] rcw=rcx cw=rsi;rdi
	code-suffix: 64
	flags: 64 ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xcryptcfb_16
INSTRUCTION: a16 F3 0F A7 E0 | XCRYPTCFB | PADLOCK_ACE
	implied: crcw=[es:ax=Unknown] cr=[es:dx=Unknown];[es:bx=Unknown];[es:si=Unknown] cw=[es:di=Unknown] rcw=cx cw=si;di
	code-suffix: 16
	flags: 16 32 ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xcryptcfb_32
INSTRUCTION: a32 F3 0F A7 E0 | XCRYPTCFB | PADLOCK_ACE
	implied: crcw=[es:eax=Unknown] cr=[es:edx=Unknown];[es:ebx=Unknown];[es:esi=Unknown] cw=[es:edi=Unknown] rcw=ecx cw=esi;edi
	code-suffix: 32
	flags: ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xcryptcfb_64
INSTRUCTION: a64 F3 0F A7 E0 | XCRYPTCFB | PADLOCK_ACE
	implied: crcw=[es:rax=Unknown] cr=[es:rdx=Unknown];[es:rbx=Unknown];[es:rsi=Unknown] cw=[es:rdi=Unknown] rcw=rcx cw=rsi;rdi
	code-suffix: 64
	flags: 64 ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xcryptofb_16
INSTRUCTION: a16 F3 0F A7 E8 | XCRYPTOFB | PADLOCK_ACE
	implied: crcw=[es:ax=Unknown] cr=[es:dx=Unknown];[es:bx=Unknown];[es:si=Unknown] cw=[es:di=Unknown] rcw=cx cw=si;di
	code-suffix: 16
	flags: 16 32 ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xcryptofb_32
INSTRUCTION: a32 F3 0F A7 E8 | XCRYPTOFB | PADLOCK_ACE
	implied: crcw=[es:eax=Unknown] cr=[es:edx=Unknown];[es:ebx=Unknown];[es:esi=Unknown] cw=[es:edi=Unknown] rcw=ecx cw=esi;edi
	code-suffix: 32
	flags: ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xcryptofb_64
INSTRUCTION: a64 F3 0F A7 E8 | XCRYPTOFB | PADLOCK_ACE
	implied: crcw=[es:rax=Unknown] cr=[es:rdx=Unknown];[es:rbx=Unknown];[es:rsi=Unknown] cw=[es:rdi=Unknown] rcw=rcx cw=rsi;rdi
	code-suffix: 64
	flags: 64 ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xstore_alt_16
INSTRUCTION: a16 F3 0F A7 F8 | XSTORE_ALT | PADLOCK_RNG
	# Seems to be an alias of XSTORE but doesn't accept F2 prefix (Zhaoxin KX-6580 CPU, tested by @tremalrik)
	implied: xstore=2
	code-suffix: 16
	flags: 16 32 ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xstore_alt_32
INSTRUCTION: a32 F3 0F A7 F8 | XSTORE_ALT | PADLOCK_RNG
	implied: xstore=4
	code-suffix: 32
	flags: ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Xstore_alt_64
INSTRUCTION: a64 F3 0F A7 F8 | XSTORE_ALT | PADLOCK_RNG
	implied: xstore=8
	code-suffix: 64
	flags: 64 ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Ibts_rm16_r16
INSTRUCTION: o16 0F A7 /r | IBTS r/m16, r16 | INTEL386_A0_ONLY
	ops: rw=rm r=reg | UInt16
	implied: r=ax;cl
	flags: 16 32 dec-opt=Xbts
	gas: suffix=w
END

# Code: Ibts_rm32_r32
INSTRUCTION: o32 0F A7 /r | IBTS r/m32, r32 | INTEL386_A0_ONLY
	ops: rw=rm r=reg | UInt32
	implied: r=eax;cl
	flags: 16 32 dec-opt=Xbts
	gas: suffix=l
END

# Code: Cmpxchg486_rm8_r8
INSTRUCTION: 0F A6 /r | CMPXCHG r/m8, r8 | INTEL486_A_ONLY
	ops: rcw=rm r=reg | UInt8
	implied: rcw=al
	code-mnemonic: cmpxchg486
	rflags: w=oszacp
	flags: 16 32 dec-opt=Cmpxchg486A asm-ig
	fast: mnemonic=cmpxchg486
	gas: mnemonic=cmpxchg486 suffix=b
	intel: mnemonic=cmpxchg486
	masm: mnemonic=cmpxchg486
	nasm: mnemonic=cmpxchg486
END

# Code: Cmpxchg486_rm16_r16
INSTRUCTION: o16 0F A7 /r | CMPXCHG r/m16, r16 | INTEL486_A_ONLY
	ops: rcw=rm r=reg | UInt16
	implied: rcw=ax
	code-mnemonic: cmpxchg486
	rflags: w=oszacp
	flags: 16 32 dec-opt=Cmpxchg486A asm-ig
	fast: mnemonic=cmpxchg486
	gas: mnemonic=cmpxchg486 suffix=w
	intel: mnemonic=cmpxchg486
	masm: mnemonic=cmpxchg486
	nasm: mnemonic=cmpxchg486
END

# Code: Cmpxchg486_rm32_r32
INSTRUCTION: o32 0F A7 /r | CMPXCHG r/m32, r32 | INTEL486_A_ONLY
	ops: rcw=rm r=reg | UInt32
	implied: rcw=eax
	code-mnemonic: cmpxchg486
	rflags: w=oszacp
	flags: 16 32 dec-opt=Cmpxchg486A asm-ig
	fast: mnemonic=cmpxchg486
	gas: mnemonic=cmpxchg486 suffix=l
	intel: mnemonic=cmpxchg486
	masm: mnemonic=cmpxchg486
	nasm: mnemonic=cmpxchg486
END

# Code: Pushw_GS
INSTRUCTION: o16 0F A8 | PUSH GS | INTEL386
	ops: r=r:gs
	implied: push=1x2
	code-mnemonic: pushw
	flags: sp=push;2
	gas: suffix=w osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Pushd_GS
INSTRUCTION: o32 0F A8 | PUSH GS | INTEL386
	ops: r=r:gs
	implied: push=1x4
	code-mnemonic: pushd
	flags: 16 32 sp=push;4
	gas: suffix=l osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Pushq_GS
INSTRUCTION: o64 0F A8 | PUSH GS | X64
	ops: r=r:gs
	implied: push=1x8
	code-mnemonic: pushq
	flags: 64 sp=push;8 do64
	gas: suffix=q osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Popw_GS
INSTRUCTION: o16 0F A9 | POP GS | INTEL386
	ops: w=r:gs
	implied: pop=1x2
	code-mnemonic: popw
	flags: sp=pop;2 no-in-sgx tsx-impl-abort
	gas: suffix=w osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Popd_GS
INSTRUCTION: o32 0F A9 | POP GS | INTEL386
	ops: w=r:gs
	implied: pop=1x4
	code-mnemonic: popd
	flags: 16 32 sp=pop;4 no-in-sgx tsx-impl-abort
	gas: suffix=l osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Popq_GS
INSTRUCTION: o64 0F A9 | POP GS | X64
	ops: w=r:gs
	implied: pop=1x8
	code-mnemonic: popq
	flags: 64 sp=pop;8 do64 no-in-sgx tsx-impl-abort
	gas: suffix=q osz-suffix-4
	intel: osz
	masm: osz-suffix-1
	nasm: osz
END

# Code: Rsm
INSTRUCTION: 0F AA | RSM | SMM
	rflags: w=oszacpdiA
	# #UD if not in SMM, #UD if in SMM + VMX root operation, VM exit if in SMM + VMX non-root operation.
	# This instruction doesn't require CPL=0 and SDMv3 8.3 says it's a "non-privileged serializing instruction".
	flags: save-restore privileged cflow=ret serialize-intel serialize-amd no-outside-smm no-in-vmx-root intel-vm-exit no-in-sgx tdx-non-root-ud amd-may-vm-exit tsx-impl-abort
END

# Code: Bts_rm16_r16
INSTRUCTION: o16 0F AB /r | BTS r/m16, r16 | INTEL386
	ops: rw=rm r=reg | UInt16
	rflags: u=osap w=c
	flags: lock xacquire xrelease
	gas: suffix=w
END

# Code: Bts_rm32_r32
INSTRUCTION: o32 0F AB /r | BTS r/m32, r32 | INTEL386
	ops: rw=rm r=reg | UInt32
	rflags: u=osap w=c
	flags: lock xacquire xrelease
	gas: suffix=l
END

# Code: Bts_rm64_r64
INSTRUCTION: o64 0F AB /r | BTS r/m64, r64 | X64
	ops: rw=rm r=reg | UInt64
	rflags: u=osap w=c
	flags: 64 lock xacquire xrelease
	gas: suffix=q
END

# Code: Shrd_rm16_r16_imm8
INSTRUCTION: o16 0F AC /r ib | SHRD r/m16, r16, imm8 | INTEL386
	ops: rw=rm r=reg r=imm | UInt16
	implied: shift-mask=0x1F
	rflags: u=oa w=szcp
	gas: suffix=w
END

# Code: Shrd_rm32_r32_imm8
INSTRUCTION: o32 0F AC /r ib | SHRD r/m32, r32, imm8 | INTEL386
	ops: rw=rm r=reg r=imm | UInt32
	implied: shift-mask=0x1F
	rflags: u=oa w=szcp
	gas: suffix=l
END

# Code: Shrd_rm64_r64_imm8
INSTRUCTION: o64 0F AC /r ib | SHRD r/m64, r64, imm8 | X64
	ops: rw=rm r=reg r=imm | UInt64
	implied: shift-mask=0x3F
	rflags: u=oa w=szcp
	flags: 64
	gas: suffix=q
END

# Code: Shrd_rm16_r16_CL
INSTRUCTION: o16 0F AD /r | SHRD r/m16, r16, CL | INTEL386
	ops: rw=rm r=reg r=r:cl | UInt16
	rflags: u=oa w=szcp
	gas: suffix=w
END

# Code: Shrd_rm32_r32_CL
INSTRUCTION: o32 0F AD /r | SHRD r/m32, r32, CL | INTEL386
	ops: rw=rm r=reg r=r:cl | UInt32
	rflags: u=oa w=szcp
	gas: suffix=l
END

# Code: Shrd_rm64_r64_CL
INSTRUCTION: o64 0F AD /r | SHRD r/m64, r64, CL | X64
	ops: rw=rm r=reg r=r:cl | UInt64
	rflags: u=oa w=szcp
	flags: 64
	gas: suffix=q
END

# Code: Fxsave_m512byte
INSTRUCTION: NP 0F AE /0 | FXSAVE m512byte | FXSR
	ops: w=rm | Fxsave_512Byte
	code-memory-size: 512byte
	flags: save-restore tsx-impl-abort no-wait
END

# Code: Fxsave64_m512byte
INSTRUCTION: NP o64 0F AE /0 | FXSAVE64 m512byte | FXSR
	ops: w=rm | Fxsave64_512Byte
	code-memory-size: 512byte
	flags: 64 save-restore tsx-impl-abort no-wait
END

# Code: Rdfsbase_r32
INSTRUCTION: F3 0F AE /0 | RDFSBASE r32 | FSGSBASE
	ops: w=rm
	flags: 64
END

# Code: Rdfsbase_r64
INSTRUCTION: F3 o64 0F AE /0 | RDFSBASE r64 | FSGSBASE
	ops: w=rm
	flags: 64
END

# Code: Fxrstor_m512byte
INSTRUCTION: NP 0F AE /1 | FXRSTOR m512byte | FXSR
	ops: r=rm | Fxsave_512Byte
	code-memory-size: 512byte
	flags: save-restore tsx-impl-abort no-wait
END

# Code: Fxrstor64_m512byte
INSTRUCTION: NP o64 0F AE /1 | FXRSTOR64 m512byte | FXSR
	ops: r=rm | Fxsave64_512Byte
	code-memory-size: 512byte
	flags: 64 save-restore tsx-impl-abort no-wait
END

# Code: Rdgsbase_r32
INSTRUCTION: F3 0F AE /1 | RDGSBASE r32 | FSGSBASE
	ops: w=rm
	flags: 64
END

# Code: Rdgsbase_r64
INSTRUCTION: F3 o64 0F AE /1 | RDGSBASE r64 | FSGSBASE
	ops: w=rm
	flags: 64
END

# Code: Ldmxcsr_m32
INSTRUCTION: NP 0F AE /2 | LDMXCSR m32 | SSE
	ops: r=rm | UInt32
END

# Code: Wrfsbase_r32
INSTRUCTION: F3 0F AE /2 | WRFSBASE r32 | FSGSBASE
	ops: r=rm
	flags: 64 tsx-impl-abort
END

# Code: Wrfsbase_r64
INSTRUCTION: F3 o64 0F AE /2 | WRFSBASE r64 | FSGSBASE
	ops: r=rm
	flags: 64 tsx-impl-abort
END

# Code: VEX_Vldmxcsr_m32
INSTRUCTION: VEX.LZ.0F.WIG AE /2 | VLDMXCSR m32 | AVX
	ops: r=rm | UInt32
	masm: flags=force-size=default
END

# Code: Stmxcsr_m32
INSTRUCTION: NP 0F AE /3 | STMXCSR m32 | SSE
	ops: w=rm | UInt32
END

# Code: Wrgsbase_r32
INSTRUCTION: F3 0F AE /3 | WRGSBASE r32 | FSGSBASE
	ops: r=rm
	flags: 64 tsx-impl-abort
END

# Code: Wrgsbase_r64
INSTRUCTION: F3 o64 0F AE /3 | WRGSBASE r64 | FSGSBASE
	ops: r=rm
	flags: 64 tsx-impl-abort
END

# Code: VEX_Vstmxcsr_m32
INSTRUCTION: VEX.LZ.0F.WIG AE /3 | VSTMXCSR m32 | AVX
	ops: w=rm | UInt32
	masm: flags=force-size=default
END

# Code: Xsave_mem
INSTRUCTION: NP 0F AE /4 | XSAVE mem | XSAVE
	ops: rw=rm | Xsave
	implied: r=eax;edx
	code-memory-size: em
	flags: save-restore tsx-impl-abort
END

# Code: Xsave64_mem
INSTRUCTION: NP o64 0F AE /4 | XSAVE64 mem | XSAVE
	ops: rw=rm | Xsave64
	implied: r=eax;edx
	code-memory-size: em
	flags: 64 save-restore tsx-impl-abort
END

# Code: Ptwrite_rm32
INSTRUCTION: F3 0F AE /4 | PTWRITE r/m32 | PTWRITE
	ops: r=rm | UInt32
	flags: no-66
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Ptwrite_rm64
INSTRUCTION: F3 o64 0F AE /4 | PTWRITE r/m64 | PTWRITE
	ops: r=rm | UInt64
	flags: 64 no-66
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Xrstor_mem
INSTRUCTION: NP 0F AE /5 | XRSTOR mem | XSAVE
	ops: r=rm | Xsave
	implied: r=eax;edx
	code-memory-size: em
	flags: save-restore tsx-impl-abort
END

# Code: Xrstor64_mem
INSTRUCTION: NP o64 0F AE /5 | XRSTOR64 mem | XSAVE
	ops: r=rm | Xsave64
	implied: r=eax;edx
	code-memory-size: em
	flags: 64 save-restore tsx-impl-abort
END

# Code: Incsspd_r32
INSTRUCTION: F3 0F AE /5 | INCSSPD r32 | CET_SS
	ops: r=rm
	implied: last-gpr-8
	flags: no-rm no-v86
END

# Code: Incsspq_r64
INSTRUCTION: F3 o64 0F AE /5 | INCSSPQ r64 | CET_SS
	ops: r=rm
	implied: last-gpr-8
	flags: 64 no-rm no-v86
END

# Code: Xsaveopt_mem
INSTRUCTION: NP 0F AE /6 | XSAVEOPT mem | XSAVEOPT
	ops: rw=rm | Xsave
	implied: r=eax;edx
	code-memory-size: em
	flags: save-restore tsx-impl-abort
END

# Code: Xsaveopt64_mem
INSTRUCTION: NP o64 0F AE /6 | XSAVEOPT64 mem | XSAVEOPT
	ops: rw=rm | Xsave64
	implied: r=eax;edx
	code-memory-size: em
	flags: 64 save-restore tsx-impl-abort
END

# Code: Clwb_m8
INSTRUCTION: 66 0F AE /6 | CLWB m8 | CLWB
	# It can fault and the access is treated as a byte load
	ops: r=rm | UInt8
	flags: tsx-impl-abort
	nasm: flags=mem-size=ignore
END

# Code: Tpause_r32
INSTRUCTION: 66 0F AE /6 | TPAUSE r32, <edx>, <eax> | WAITPKG
	ops: r=rm
	implied: r=eax;edx
	rflags: w=c 0=oszap
	# May cause a TSX abort if VM exit
	flags: intel-may-vm-exit tsx-impl-abort
END

# Code: Tpause_r64
INSTRUCTION: 66 o64 0F AE /6 | TPAUSE r64, <edx>, <eax> | WAITPKG
	ops: r=rm
	implied: r=eax;edx last-gpr-32
	rflags: w=c 0=oszap
	# May cause a TSX abort if VM exit
	flags: 64 intel-may-vm-exit tsx-impl-abort
	gas: reg32
	intel: reg32
	masm: reg32
	nasm: reg32
END

# Code: Clrssbsy_m64
INSTRUCTION: F3 0F AE /6 | CLRSSBSY m64 | CET_SS
	ops: rw=rm | UInt64
	rflags: w=c 0=oszap
	flags: cpl0 no-rm no-v86
	masm: flags=force-size=default
END

# Code: Umonitor_r16
INSTRUCTION: a16 F3 0F AE /6 | UMONITOR r16 | WAITPKG
	ops: r=rm
	implied: r=[seg:op0-reg=UInt8]
	flags: 16 32 tsx-abort
END

# Code: Umonitor_r32
INSTRUCTION: a32 F3 0F AE /6 | UMONITOR r32 | WAITPKG
	ops: r=rm
	implied: r=[seg:op0-reg=UInt8]
	flags: tsx-abort
END

# Code: Umonitor_r64
INSTRUCTION: a64 F3 0F AE /6 | UMONITOR r64 | WAITPKG
	ops: r=rm
	implied: r=[seg:op0-reg=UInt8]
	flags: 64 tsx-abort
END

# Code: Umwait_r32
INSTRUCTION: F2 0F AE /6 | UMWAIT r32, <edx>, <eax> | WAITPKG
	ops: r=rm
	implied: r=eax;edx
	rflags: w=c 0=oszap
	flags: intel-may-vm-exit tsx-abort
END

# Code: Umwait_r64
INSTRUCTION: F2 o64 0F AE /6 | UMWAIT r64, <edx>, <eax> | WAITPKG
	ops: r=rm
	implied: r=eax;edx last-gpr-32
	rflags: w=c 0=oszap
	flags: 64 intel-may-vm-exit tsx-abort
	gas: reg32
	intel: reg32
	masm: reg32
	nasm: reg32
END

# Code: Clflush_m8
INSTRUCTION: NP 0F AE /7 | CLFLUSH m8 | CLFSH
	# It can fault and the access is treated as a byte load
	ops: r=rm | UInt8
	flags: tsx-impl-abort
	nasm: flags=mem-size=ignore
END

# Code: Clflushopt_m8
INSTRUCTION: 66 0F AE /7 | CLFLUSHOPT m8 | CLFLUSHOPT
	# It can fault and the access is treated as a byte load
	ops: r=rm | UInt8
	flags: tsx-impl-abort
	nasm: flags=mem-size=ignore
END

# Code: Lfence
INSTRUCTION: NP 0F AE E8 | LFENCE | SSE2
END

# Code: Lfence_E9
INSTRUCTION: NP 0F AE E9 | LFENCE | SSE2
	code-suffix: E9
	flags: asm-ig
END

# Code: Lfence_EA
INSTRUCTION: NP 0F AE EA | LFENCE | SSE2
	code-suffix: EA
	flags: asm-ig
END

# Code: Lfence_EB
INSTRUCTION: NP 0F AE EB | LFENCE | SSE2
	code-suffix: EB
	flags: asm-ig
END

# Code: Lfence_EC
INSTRUCTION: NP 0F AE EC | LFENCE | SSE2
	code-suffix: EC
	flags: asm-ig
END

# Code: Lfence_ED
INSTRUCTION: NP 0F AE ED | LFENCE | SSE2
	code-suffix: ED
	flags: asm-ig
END

# Code: Lfence_EE
INSTRUCTION: NP 0F AE EE | LFENCE | SSE2
	code-suffix: EE
	flags: asm-ig
END

# Code: Lfence_EF
INSTRUCTION: NP 0F AE EF | LFENCE | SSE2
	code-suffix: EF
	flags: asm-ig
END

# Code: Mfence
INSTRUCTION: NP 0F AE F0 | MFENCE | SSE2
	flags: serialize-amd
END

# Code: Mfence_F1
INSTRUCTION: NP 0F AE F1 | MFENCE | SSE2
	code-suffix: F1
	flags: serialize-amd asm-ig
END

# Code: Mfence_F2
INSTRUCTION: NP 0F AE F2 | MFENCE | SSE2
	code-suffix: F2
	flags: serialize-amd asm-ig
END

# Code: Mfence_F3
INSTRUCTION: NP 0F AE F3 | MFENCE | SSE2
	code-suffix: F3
	flags: serialize-amd asm-ig
END

# Code: Mfence_F4
INSTRUCTION: NP 0F AE F4 | MFENCE | SSE2
	code-suffix: F4
	flags: serialize-amd asm-ig
END

# Code: Mfence_F5
INSTRUCTION: NP 0F AE F5 | MFENCE | SSE2
	code-suffix: F5
	flags: serialize-amd asm-ig
END

# Code: Mfence_F6
INSTRUCTION: NP 0F AE F6 | MFENCE | SSE2
	code-suffix: F6
	flags: serialize-amd asm-ig
END

# Code: Mfence_F7
INSTRUCTION: NP 0F AE F7 | MFENCE | SSE2
	code-suffix: F7
	flags: serialize-amd asm-ig
END

# Code: Sfence
INSTRUCTION: NP 0F AE F8 | SFENCE | SSE
END

# Code: Sfence_F9
INSTRUCTION: NP 0F AE F9 | SFENCE | SSE
	code-suffix: F9
	flags: asm-ig
END

# Code: Sfence_FA
INSTRUCTION: NP 0F AE FA | SFENCE | SSE
	code-suffix: FA
	flags: asm-ig
END

# Code: Sfence_FB
INSTRUCTION: NP 0F AE FB | SFENCE | SSE
	code-suffix: FB
	flags: asm-ig
END

# Code: Sfence_FC
INSTRUCTION: NP 0F AE FC | SFENCE | SSE
	code-suffix: FC
	flags: asm-ig
END

# Code: Sfence_FD
INSTRUCTION: NP 0F AE FD | SFENCE | SSE
	code-suffix: FD
	flags: asm-ig
END

# Code: Sfence_FE
INSTRUCTION: NP 0F AE FE | SFENCE | SSE
	code-suffix: FE
	flags: asm-ig
END

# Code: Sfence_FF
INSTRUCTION: NP 0F AE FF | SFENCE | SSE
	code-suffix: FF
	flags: asm-ig
END

# Code: Pcommit
INSTRUCTION: 66 0F AE F8 | PCOMMIT | PCOMMIT
	flags: dec-opt=Pcommit intel-may-vm-exit no-in-sgx tsx-impl-abort
END

# Code: Imul_r16_rm16
INSTRUCTION: o16 0F AF /r | IMUL r16, r/m16 | INTEL386
	ops: rw=reg r=rm | Int16
	rflags: u=szap w=oc
	gas: suffix=w
END

# Code: Imul_r32_rm32
INSTRUCTION: o32 0F AF /r | IMUL r32, r/m32 | INTEL386
	ops: rw=reg r=rm | Int32
	rflags: u=szap w=oc
	gas: suffix=l
END

# Code: Imul_r64_rm64
INSTRUCTION: o64 0F AF /r | IMUL r64, r/m64 | X64
	ops: rw=reg r=rm | Int64
	rflags: u=szap w=oc
	flags: 64
	gas: suffix=q
END

# Code: Cmpxchg_rm8_r8
INSTRUCTION: 0F B0 /r | CMPXCHG r/m8, r8 | INTEL486
	ops: rcw=rm r=reg | UInt8
	implied: rcw=al
	rflags: w=oszacp
	flags: lock xacquire xrelease
	gas: suffix=b
END

# Code: Cmpxchg_rm16_r16
INSTRUCTION: o16 0F B1 /r | CMPXCHG r/m16, r16 | INTEL486
	ops: rcw=rm r=reg | UInt16
	implied: rcw=ax
	rflags: w=oszacp
	flags: lock xacquire xrelease
	gas: suffix=w
END

# Code: Cmpxchg_rm32_r32
INSTRUCTION: o32 0F B1 /r | CMPXCHG r/m32, r32 | INTEL486
	ops: rcw=rm r=reg | UInt32
	implied: rcw=eax
	rflags: w=oszacp
	flags: lock xacquire xrelease
	gas: suffix=l
END

# Code: Cmpxchg_rm64_r64
INSTRUCTION: o64 0F B1 /r | CMPXCHG r/m64, r64 | X64
	ops: rcw=rm r=reg | UInt64
	implied: rcw=rax
	rflags: w=oszacp
	flags: 64 lock xacquire xrelease
	gas: suffix=q
END

# Code: Lss_r16_m1616
INSTRUCTION: o16 0F B2 /r | LSS r16, m16:16 | INTEL386
	ops: w=reg r=rm | SegPtr16
	implied: w=ss
	code-memory-size: 1616
	flags: no-in-sgx tsx-impl-abort
	gas: suffix=w
	nasm: flags=mem-size=ignore
END

# Code: Lss_r32_m1632
INSTRUCTION: o32 0F B2 /r | LSS r32, m16:32 | INTEL386
	ops: w=reg r=rm | SegPtr32
	implied: w=ss
	code-memory-size: 1632
	flags: no-in-sgx tsx-impl-abort
	gas: suffix=l
	nasm: flags=mem-size=ignore
END

# Code: Lss_r64_m1664
INSTRUCTION: o64 0F B2 /r | LSS r64, m16:64 | X64
	ops: w=reg r=rm | SegPtr64
	implied: w=ss
	code-memory-size: 1664
	flags: 64 no-amd-dec no-in-sgx tsx-impl-abort
	gas: suffix=q
	nasm: flags=mem-size=ignore
END

# Code: Btr_rm16_r16
INSTRUCTION: o16 0F B3 /r | BTR r/m16, r16 | INTEL386
	ops: rw=rm r=reg | UInt16
	rflags: u=osap w=c
	flags: lock xacquire xrelease
	gas: suffix=w
END

# Code: Btr_rm32_r32
INSTRUCTION: o32 0F B3 /r | BTR r/m32, r32 | INTEL386
	ops: rw=rm r=reg | UInt32
	rflags: u=osap w=c
	flags: lock xacquire xrelease
	gas: suffix=l
END

# Code: Btr_rm64_r64
INSTRUCTION: o64 0F B3 /r | BTR r/m64, r64 | X64
	ops: rw=rm r=reg | UInt64
	rflags: u=osap w=c
	flags: 64 lock xacquire xrelease
	gas: suffix=q
END

# Code: Lfs_r16_m1616
INSTRUCTION: o16 0F B4 /r | LFS r16, m16:16 | INTEL386
	ops: w=reg r=rm | SegPtr16
	implied: w=fs
	code-memory-size: 1616
	flags: no-in-sgx tsx-impl-abort
	gas: suffix=w
	nasm: flags=mem-size=ignore
END

# Code: Lfs_r32_m1632
INSTRUCTION: o32 0F B4 /r | LFS r32, m16:32 | INTEL386
	ops: w=reg r=rm | SegPtr32
	implied: w=fs
	code-memory-size: 1632
	flags: no-in-sgx tsx-impl-abort
	gas: suffix=l
	nasm: flags=mem-size=ignore
END

# Code: Lfs_r64_m1664
INSTRUCTION: o64 0F B4 /r | LFS r64, m16:64 | X64
	ops: w=reg r=rm | SegPtr64
	implied: w=fs
	code-memory-size: 1664
	flags: 64 no-amd-dec no-in-sgx tsx-impl-abort
	gas: suffix=q
	nasm: flags=mem-size=ignore
END

# Code: Lgs_r16_m1616
INSTRUCTION: o16 0F B5 /r | LGS r16, m16:16 | INTEL386
	ops: w=reg r=rm | SegPtr16
	implied: w=gs
	code-memory-size: 1616
	flags: no-in-sgx tsx-impl-abort
	gas: suffix=w
	nasm: flags=mem-size=ignore
END

# Code: Lgs_r32_m1632
INSTRUCTION: o32 0F B5 /r | LGS r32, m16:32 | INTEL386
	ops: w=reg r=rm | SegPtr32
	implied: w=gs
	code-memory-size: 1632
	flags: no-in-sgx tsx-impl-abort
	gas: suffix=l
	nasm: flags=mem-size=ignore
END

# Code: Lgs_r64_m1664
INSTRUCTION: o64 0F B5 /r | LGS r64, m16:64 | X64
	ops: w=reg r=rm | SegPtr64
	implied: w=gs
	code-memory-size: 1664
	flags: 64 no-amd-dec no-in-sgx tsx-impl-abort
	gas: suffix=q
	nasm: flags=mem-size=ignore
END

# Code: Movzx_r16_rm8
INSTRUCTION: o16 0F B6 /r | MOVZX r16, r/m8 | INTEL386
	ops: w=reg r=rm | UInt8
	fast: flags=force-size=always
	gas: mnemonic=movzbw
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Movzx_r32_rm8
INSTRUCTION: o32 0F B6 /r | MOVZX r32, r/m8 | INTEL386
	ops: w=reg r=rm | UInt8
	fast: flags=force-size=always
	gas: mnemonic=movzbl
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Movzx_r64_rm8
INSTRUCTION: o64 0F B6 /r | MOVZX r64, r/m8 | X64
	ops: w=reg r=rm | UInt8
	flags: 64
	fast: flags=force-size=always
	gas: mnemonic=movzbq
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Movzx_r16_rm16
INSTRUCTION: o16 0F B7 /r | MOVZX r16, r/m16 | INTEL386
	ops: w=reg r=rm | UInt16
	fast: flags=force-size=always
	gas: mnemonic=movzxw
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Movzx_r32_rm16
INSTRUCTION: o32 0F B7 /r | MOVZX r32, r/m16 | INTEL386
	ops: w=reg r=rm | UInt16
	fast: flags=force-size=always
	gas: mnemonic=movzwl
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Movzx_r64_rm16
INSTRUCTION: o64 0F B7 /r | MOVZX r64, r/m16 | X64
	ops: w=reg r=rm | UInt16
	flags: 64
	fast: flags=force-size=always
	gas: mnemonic=movzwq
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Jmpe_disp16
INSTRUCTION: o16 0F B8 cw | JMPE disp16 | IA64
	ops: r=br
	flags: 16 32 dec-opt=Jmpe br=jmpe-near cflow=br
	gas: osz
	nasm: osz-call
END

# Code: Jmpe_disp32
INSTRUCTION: o32 0F B8 cd | JMPE disp32 | IA64
	ops: r=br
	flags: 16 32 dec-opt=Jmpe br=jmpe-near cflow=br
	gas: osz
	nasm: osz-call
END

# Code: Popcnt_r16_rm16
INSTRUCTION: o16 F3 0F B8 /r | POPCNT r16, r/m16 | POPCNT
	ops: w=reg r=rm | UInt16
	rflags: w=z 0=osacp
	gas: suffix=w
END

# Code: Popcnt_r32_rm32
INSTRUCTION: o32 F3 0F B8 /r | POPCNT r32, r/m32 | POPCNT
	ops: w=reg r=rm | UInt32
	rflags: w=z 0=osacp
	gas: suffix=l
END

# Code: Popcnt_r64_rm64
INSTRUCTION: F3 o64 0F B8 /r | POPCNT r64, r/m64 | POPCNT
	ops: w=reg r=rm | UInt64
	rflags: w=z 0=osacp
	flags: 64
	gas: suffix=q
END

# Code: Ud1_r16_rm16
INSTRUCTION: o16 0F B9 /r | UD1 r16, r/m16 | INTEL286
	ops: n=reg n=rm | UInt16
	flags: cflow=ex intel-vm-exit tsx-impl-abort
	gas: suffix=w
END

# Code: Ud1_r32_rm32
INSTRUCTION: o32 0F B9 /r | UD1 r32, r/m32 | INTEL386
	ops: n=reg n=rm | UInt32
	flags: cflow=ex intel-vm-exit tsx-impl-abort
	gas: suffix=l
END

# Code: Ud1_r64_rm64
INSTRUCTION: o64 0F B9 /r | UD1 r64, r/m64 | X64
	ops: n=reg n=rm | UInt64
	flags: 64 cflow=ex intel-vm-exit tsx-impl-abort
	gas: suffix=q
END

# Code: Bt_rm16_imm8
INSTRUCTION: o16 0F BA /4 ib | BT r/m16, imm8 | INTEL386
	ops: r=rm r=imm | UInt16
	rflags: u=osap w=c
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Bt_rm32_imm8
INSTRUCTION: o32 0F BA /4 ib | BT r/m32, imm8 | INTEL386
	ops: r=rm r=imm | UInt32
	rflags: u=osap w=c
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Bt_rm64_imm8
INSTRUCTION: o64 0F BA /4 ib | BT r/m64, imm8 | X64
	ops: r=rm r=imm | UInt64
	rflags: u=osap w=c
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Bts_rm16_imm8
INSTRUCTION: o16 0F BA /5 ib | BTS r/m16, imm8 | INTEL386
	ops: rw=rm r=imm | UInt16
	rflags: u=osap w=c
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Bts_rm32_imm8
INSTRUCTION: o32 0F BA /5 ib | BTS r/m32, imm8 | INTEL386
	ops: rw=rm r=imm | UInt32
	rflags: u=osap w=c
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Bts_rm64_imm8
INSTRUCTION: o64 0F BA /5 ib | BTS r/m64, imm8 | X64
	ops: rw=rm r=imm | UInt64
	rflags: u=osap w=c
	flags: 64 lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Btr_rm16_imm8
INSTRUCTION: o16 0F BA /6 ib | BTR r/m16, imm8 | INTEL386
	ops: rw=rm r=imm | UInt16
	rflags: u=osap w=c
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Btr_rm32_imm8
INSTRUCTION: o32 0F BA /6 ib | BTR r/m32, imm8 | INTEL386
	ops: rw=rm r=imm | UInt32
	rflags: u=osap w=c
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Btr_rm64_imm8
INSTRUCTION: o64 0F BA /6 ib | BTR r/m64, imm8 | X64
	ops: rw=rm r=imm | UInt64
	rflags: u=osap w=c
	flags: 64 lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Btc_rm16_imm8
INSTRUCTION: o16 0F BA /7 ib | BTC r/m16, imm8 | INTEL386
	ops: rw=rm r=imm | UInt16
	rflags: u=osap w=c
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Btc_rm32_imm8
INSTRUCTION: o32 0F BA /7 ib | BTC r/m32, imm8 | INTEL386
	ops: rw=rm r=imm | UInt32
	rflags: u=osap w=c
	flags: lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Btc_rm64_imm8
INSTRUCTION: o64 0F BA /7 ib | BTC r/m64, imm8 | X64
	ops: rw=rm r=imm | UInt64
	rflags: u=osap w=c
	flags: 64 lock xacquire xrelease
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Btc_rm16_r16
INSTRUCTION: o16 0F BB /r | BTC r/m16, r16 | INTEL386
	ops: rw=rm r=reg | UInt16
	rflags: u=osap w=c
	flags: lock xacquire xrelease
	gas: suffix=w
END

# Code: Btc_rm32_r32
INSTRUCTION: o32 0F BB /r | BTC r/m32, r32 | INTEL386
	ops: rw=rm r=reg | UInt32
	rflags: u=osap w=c
	flags: lock xacquire xrelease
	gas: suffix=l
END

# Code: Btc_rm64_r64
INSTRUCTION: o64 0F BB /r | BTC r/m64, r64 | X64
	ops: rw=rm r=reg | UInt64
	rflags: u=osap w=c
	flags: 64 lock xacquire xrelease
	gas: suffix=q
END

# Code: Bsf_r16_rm16
INSTRUCTION: o16 0F BC /r | BSF r16, r/m16 | INTEL386
	ops: cw=reg r=rm | UInt16
	rflags: u=osacp w=z
	gas: suffix=w
END

# Code: Bsf_r32_rm32
INSTRUCTION: o32 0F BC /r | BSF r32, r/m32 | INTEL386
	ops: cw=reg r=rm | UInt32
	rflags: u=osacp w=z
	gas: suffix=l
END

# Code: Bsf_r64_rm64
INSTRUCTION: o64 0F BC /r | BSF r64, r/m64 | X64
	ops: cw=reg r=rm | UInt64
	rflags: u=osacp w=z
	flags: 64
	gas: suffix=q
END

# Code: Tzcnt_r16_rm16
INSTRUCTION: o16 F3 0F BC /r | TZCNT r16, r/m16 | BMI1
	ops: w=reg r=rm | UInt16
	rflags: u=osap w=zc
	gas: suffix=w
END

# Code: Tzcnt_r32_rm32
INSTRUCTION: o32 F3 0F BC /r | TZCNT r32, r/m32 | BMI1
	ops: w=reg r=rm | UInt32
	rflags: u=osap w=zc
	gas: suffix=l
END

# Code: Tzcnt_r64_rm64
INSTRUCTION: F3 o64 0F BC /r | TZCNT r64, r/m64 | BMI1
	ops: w=reg r=rm | UInt64
	rflags: u=osap w=zc
	flags: 64
	gas: suffix=q
END

# Code: Bsr_r16_rm16
INSTRUCTION: o16 0F BD /r | BSR r16, r/m16 | INTEL386
	ops: cw=reg r=rm | UInt16
	rflags: u=osacp w=z
	gas: suffix=w
END

# Code: Bsr_r32_rm32
INSTRUCTION: o32 0F BD /r | BSR r32, r/m32 | INTEL386
	ops: cw=reg r=rm | UInt32
	rflags: u=osacp w=z
	gas: suffix=l
END

# Code: Bsr_r64_rm64
INSTRUCTION: o64 0F BD /r | BSR r64, r/m64 | X64
	ops: cw=reg r=rm | UInt64
	rflags: u=osacp w=z
	flags: 64
	gas: suffix=q
END

# Code: Lzcnt_r16_rm16
INSTRUCTION: o16 F3 0F BD /r | LZCNT r16, r/m16 | LZCNT
	ops: w=reg r=rm | UInt16
	rflags: u=osap w=zc
	gas: suffix=w
END

# Code: Lzcnt_r32_rm32
INSTRUCTION: o32 F3 0F BD /r | LZCNT r32, r/m32 | LZCNT
	ops: w=reg r=rm | UInt32
	rflags: u=osap w=zc
	gas: suffix=l
END

# Code: Lzcnt_r64_rm64
INSTRUCTION: F3 o64 0F BD /r | LZCNT r64, r/m64 | LZCNT
	ops: w=reg r=rm | UInt64
	rflags: u=osap w=zc
	flags: 64
	gas: suffix=q
END

# Code: Movsx_r16_rm8
INSTRUCTION: o16 0F BE /r | MOVSX r16, r/m8 | INTEL386
	ops: w=reg r=rm | Int8
	fast: flags=force-size=always
	gas: mnemonic=movsbw
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Movsx_r32_rm8
INSTRUCTION: o32 0F BE /r | MOVSX r32, r/m8 | INTEL386
	ops: w=reg r=rm | Int8
	fast: flags=force-size=always
	gas: mnemonic=movsbl
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Movsx_r64_rm8
INSTRUCTION: o64 0F BE /r | MOVSX r64, r/m8 | X64
	ops: w=reg r=rm | Int8
	flags: 64
	fast: flags=force-size=always
	gas: mnemonic=movsbq
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Movsx_r16_rm16
INSTRUCTION: o16 0F BF /r | MOVSX r16, r/m16 | INTEL386
	ops: w=reg r=rm | Int16
	fast: flags=force-size=always
	gas: mnemonic=movsxw
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Movsx_r32_rm16
INSTRUCTION: o32 0F BF /r | MOVSX r32, r/m16 | INTEL386
	ops: w=reg r=rm | Int16
	fast: flags=force-size=always
	gas: mnemonic=movswl
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Movsx_r64_rm16
INSTRUCTION: o64 0F BF /r | MOVSX r64, r/m16 | X64
	ops: w=reg r=rm | Int16
	flags: 64
	fast: flags=force-size=always
	gas: mnemonic=movswq
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Xadd_rm8_r8
INSTRUCTION: 0F C0 /r | XADD r/m8, r8 | INTEL486
	ops: rw=rm rw=reg | UInt8
	rflags: w=oszacp
	flags: lock xacquire xrelease
	gas: suffix=b
END

# Code: Xadd_rm16_r16
INSTRUCTION: o16 0F C1 /r | XADD r/m16, r16 | INTEL486
	ops: rw=rm rw=reg | UInt16
	rflags: w=oszacp
	flags: lock xacquire xrelease
	gas: suffix=w
END

# Code: Xadd_rm32_r32
INSTRUCTION: o32 0F C1 /r | XADD r/m32, r32 | INTEL486
	ops: rw=rm rw=reg | UInt32
	rflags: w=oszacp
	flags: lock xacquire xrelease
	gas: suffix=l
END

# Code: Xadd_rm64_r64
INSTRUCTION: o64 0F C1 /r | XADD r/m64, r64 | X64
	ops: rw=rm rw=reg | UInt64
	rflags: w=oszacp
	flags: 64 lock xacquire xrelease
	gas: suffix=q
END

# Code: Cmpps_xmm_xmmm128_imm8
INSTRUCTION: NP 0F C2 /r ib | CMPPS xmm1, xmm2/m128, imm8 | SSE
	ops: rw=reg r=rm r=imm | Packed128_Float32
	flags: pseudo=cmpps
END

# Code: VEX_Vcmpps_xmm_xmm_xmmm128_imm8
INSTRUCTION: VEX.128.0F.WIG C2 /r ib | VCMPPS xmm1, xmm2, xmm3/m128, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | Packed128_Float32
	flags: pseudo=vcmpps
END

# Code: VEX_Vcmpps_ymm_ymm_ymmm256_imm8
INSTRUCTION: VEX.256.0F.WIG C2 /r ib | VCMPPS ymm1, ymm2, ymm3/m256, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | Packed256_Float32
	flags: pseudo=vcmpps
END

# Code: EVEX_Vcmpps_kr_k1_xmm_xmmm128b32_imm8
INSTRUCTION: EVEX.128.0F.W0 C2 /r ib | VCMPPS k1 {k2}, xmm2, xmm3/m128/m32bcst, imm8 | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm r=imm | Packed128_Float32 Broadcast128_Float32
	flags: pseudo=vcmpps implied-z
END

# Code: EVEX_Vcmpps_kr_k1_ymm_ymmm256b32_imm8
INSTRUCTION: EVEX.256.0F.W0 C2 /r ib | VCMPPS k1 {k2}, ymm2, ymm3/m256/m32bcst, imm8 | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm r=imm | Packed256_Float32 Broadcast256_Float32
	flags: pseudo=vcmpps implied-z
END

# Code: EVEX_Vcmpps_kr_k1_zmm_zmmm512b32_imm8_sae
INSTRUCTION: EVEX.512.0F.W0 C2 /r ib | VCMPPS k1 {k2}, zmm2, zmm3/m512/m32bcst{sae}, imm8 | AVX512F | N64b4
	ops: w=reg r=vvvv r=rm r=imm | Packed512_Float32 Broadcast512_Float32
	flags: pseudo=vcmpps implied-z
END

# Code: Cmppd_xmm_xmmm128_imm8
INSTRUCTION: 66 0F C2 /r ib | CMPPD xmm1, xmm2/m128, imm8 | SSE2
	ops: rw=reg r=rm r=imm | Packed128_Float64
	flags: pseudo=cmppd
END

# Code: VEX_Vcmppd_xmm_xmm_xmmm128_imm8
INSTRUCTION: VEX.128.66.0F.WIG C2 /r ib | VCMPPD xmm1, xmm2, xmm3/m128, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | Packed128_Float64
	flags: pseudo=vcmppd
END

# Code: VEX_Vcmppd_ymm_ymm_ymmm256_imm8
INSTRUCTION: VEX.256.66.0F.WIG C2 /r ib | VCMPPD ymm1, ymm2, ymm3/m256, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | Packed256_Float64
	flags: pseudo=vcmppd
END

# Code: EVEX_Vcmppd_kr_k1_xmm_xmmm128b64_imm8
INSTRUCTION: EVEX.128.66.0F.W1 C2 /r ib | VCMPPD k1 {k2}, xmm2, xmm3/m128/m64bcst, imm8 | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm r=imm | Packed128_Float64 Broadcast128_Float64
	flags: pseudo=vcmppd implied-z
END

# Code: EVEX_Vcmppd_kr_k1_ymm_ymmm256b64_imm8
INSTRUCTION: EVEX.256.66.0F.W1 C2 /r ib | VCMPPD k1 {k2}, ymm2, ymm3/m256/m64bcst, imm8 | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm r=imm | Packed256_Float64 Broadcast256_Float64
	flags: pseudo=vcmppd implied-z
END

# Code: EVEX_Vcmppd_kr_k1_zmm_zmmm512b64_imm8_sae
INSTRUCTION: EVEX.512.66.0F.W1 C2 /r ib | VCMPPD k1 {k2}, zmm2, zmm3/m512/m64bcst{sae}, imm8 | AVX512F | N64b8
	ops: w=reg r=vvvv r=rm r=imm | Packed512_Float64 Broadcast512_Float64
	flags: pseudo=vcmppd implied-z
END

# Code: Cmpss_xmm_xmmm32_imm8
INSTRUCTION: F3 0F C2 /r ib | CMPSS xmm1, xmm2/m32, imm8 | SSE
	ops: rw=reg r=rm r=imm | Float32
	flags: pseudo=cmpss
	masm: flags=force-size=default
END

# Code: VEX_Vcmpss_xmm_xmm_xmmm32_imm8
INSTRUCTION: VEX.LIG.F3.0F.WIG C2 /r ib | VCMPSS xmm1, xmm2, xmm3/m32, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | Float32
	flags: pseudo=vcmpss
	masm: flags=force-size=default
END

# Code: EVEX_Vcmpss_kr_k1_xmm_xmmm32_imm8_sae
INSTRUCTION: EVEX.LIG.F3.0F.W0 C2 /r ib | VCMPSS k1 {k2}, xmm2, xmm3/m32{sae}, imm8 | AVX512F | N4
	ops: w=reg r=vvvv r=rm r=imm | Float32
	flags: pseudo=vcmpss implied-z
	masm: flags=force-size=default
END

# Code: Cmpsd_xmm_xmmm64_imm8
INSTRUCTION: F2 0F C2 /r ib | CMPSD xmm1, xmm2/m64, imm8 | SSE2
	ops: rw=reg r=rm r=imm | Float64
	flags: pseudo=cmpsd
	masm: flags=force-size=default
END

# Code: VEX_Vcmpsd_xmm_xmm_xmmm64_imm8
INSTRUCTION: VEX.LIG.F2.0F.WIG C2 /r ib | VCMPSD xmm1, xmm2, xmm3/m64, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | Float64
	flags: pseudo=vcmpsd
	masm: flags=force-size=default
END

# Code: EVEX_Vcmpsd_kr_k1_xmm_xmmm64_imm8_sae
INSTRUCTION: EVEX.LIG.F2.0F.W1 C2 /r ib | VCMPSD k1 {k2}, xmm2, xmm3/m64{sae}, imm8 | AVX512F | N8
	ops: w=reg r=vvvv r=rm r=imm | Float64
	flags: pseudo=vcmpsd implied-z
	masm: flags=force-size=default
END

# Code: Movnti_m32_r32
INSTRUCTION: NP 0F C3 /r | MOVNTI m32, r32 | SSE2
	ops: w=rm r=reg | UInt32
	flags: tsx-impl-abort non-temporal
	gas: suffix=l
END

# Code: Movnti_m64_r64
INSTRUCTION: NP o64 0F C3 /r | MOVNTI m64, r64 | SSE2
	ops: w=rm r=reg | UInt64
	flags: 64 tsx-impl-abort non-temporal
	gas: suffix=q
END

# Code: Pinsrw_mm_r32m16_imm8
INSTRUCTION: NP 0F C4 /r ib | PINSRW mm, r32/m16, imm8 | SSE
	ops: rw=reg r=rm r=imm | UInt16
	implied: last-gpr-16
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx;force-size=default
END

# Code: Pinsrw_mm_r64m16_imm8
INSTRUCTION: NP o64 0F C4 /r ib | PINSRW mm, r64/m16, imm8 | SSE
	ops: rw=reg r=rm r=imm | UInt16
	implied: last-gpr-16
	flags: 64 tsx-impl-abort
	intel: reg32
	masm: flags=mem-size=mmx;force-size=default
	nasm: reg32
END

# Code: Pinsrw_xmm_r32m16_imm8
INSTRUCTION: 66 0F C4 /r ib | PINSRW xmm, r32/m16, imm8 | SSE2
	ops: rw=reg r=rm r=imm | UInt16
	implied: last-gpr-16
	masm: flags=force-size=default
END

# Code: Pinsrw_xmm_r64m16_imm8
INSTRUCTION: 66 o64 0F C4 /r ib | PINSRW xmm, r64/m16, imm8 | SSE2
	ops: rw=reg r=rm r=imm | UInt16
	implied: last-gpr-16
	flags: 64
	intel: reg32
	masm: flags=force-size=default
END

# Code: VEX_Vpinsrw_xmm_xmm_r32m16_imm8
INSTRUCTION: VEX.128.66.0F.W0 C4 /r ib | VPINSRW xmm1, xmm2, r32/m16, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | UInt16
	implied: last-gpr-16
	flags: wig32
	masm: flags=force-size=default
END

# Code: VEX_Vpinsrw_xmm_xmm_r64m16_imm8
INSTRUCTION: VEX.128.66.0F.W1 C4 /r ib | VPINSRW xmm1, xmm2, r64/m16, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | UInt16
	implied: last-gpr-16
	flags: 64 asm-ig-mem
	intel: reg32
	masm: flags=force-size=default reg32
	nasm: reg32
END

# Code: EVEX_Vpinsrw_xmm_xmm_r32m16_imm8
INSTRUCTION: EVEX.128.66.0F.W0 C4 /r ib | VPINSRW xmm1, xmm2, r32/m16, imm8 | AVX512BW | N2
	ops: w=reg r=vvvv r=rm r=imm | UInt16
	implied: last-gpr-16
	flags: wig32
	masm: flags=force-size=default
END

# Code: EVEX_Vpinsrw_xmm_xmm_r64m16_imm8
INSTRUCTION: EVEX.128.66.0F.W1 C4 /r ib | VPINSRW xmm1, xmm2, r64/m16, imm8 | AVX512BW | N2
	ops: w=reg r=vvvv r=rm r=imm | UInt16
	implied: last-gpr-16
	flags: 64 asm-ig-mem
	intel: reg32
	masm: flags=force-size=default reg32
	nasm: reg32
END

# Code: Pextrw_r32_mm_imm8
INSTRUCTION: NP 0F C5 /r ib | PEXTRW r32, mm, imm8 | SSE
	ops: w=reg r=rm r=imm
	flags: tsx-impl-abort
END

# Code: Pextrw_r64_mm_imm8
INSTRUCTION: NP o64 0F C5 /r ib | PEXTRW r64, mm, imm8 | SSE
	ops: w=reg r=rm r=imm
	flags: 64 tsx-impl-abort
	intel: reg32
	nasm: reg32
END

# Code: Pextrw_r32_xmm_imm8
INSTRUCTION: 66 0F C5 /r ib | PEXTRW r32, xmm, imm8 | SSE2
	ops: w=reg r=rm r=imm
END

# Code: Pextrw_r64_xmm_imm8
INSTRUCTION: 66 o64 0F C5 /r ib | PEXTRW r64, xmm, imm8 | SSE2
	ops: w=reg r=rm r=imm
	flags: 64
	intel: reg32
END

# Code: VEX_Vpextrw_r32_xmm_imm8
INSTRUCTION: VEX.128.66.0F.W0 C5 /r ib | VPEXTRW r32, xmm1, imm8 | AVX
	ops: w=reg r=rm r=imm
	flags: wig32
END

# Code: VEX_Vpextrw_r64_xmm_imm8
INSTRUCTION: VEX.128.66.0F.W1 C5 /r ib | VPEXTRW r64, xmm1, imm8 | AVX
	ops: w=reg r=rm r=imm
	flags: 64
	intel: reg32
END

# Code: EVEX_Vpextrw_r32_xmm_imm8
INSTRUCTION: EVEX.128.66.0F.W0 C5 /r ib | VPEXTRW r32, xmm1, imm8 | AVX512BW
	ops: w=reg r=rm r=imm
	flags: wig32
END

# Code: EVEX_Vpextrw_r64_xmm_imm8
INSTRUCTION: EVEX.128.66.0F.W1 C5 /r ib | VPEXTRW r64, xmm1, imm8 | AVX512BW
	ops: w=reg r=rm r=imm
	flags: 64
	intel: reg32
END

# Code: Shufps_xmm_xmmm128_imm8
INSTRUCTION: NP 0F C6 /r ib | SHUFPS xmm1, xmm2/m128, imm8 | SSE
	ops: rw=reg r=rm r=imm | Packed128_Float32
END

# Code: VEX_Vshufps_xmm_xmm_xmmm128_imm8
INSTRUCTION: VEX.128.0F.WIG C6 /r ib | VSHUFPS xmm1, xmm2, xmm3/m128, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | Packed128_Float32
END

# Code: VEX_Vshufps_ymm_ymm_ymmm256_imm8
INSTRUCTION: VEX.256.0F.WIG C6 /r ib | VSHUFPS ymm1, ymm2, ymm3/m256, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | Packed256_Float32
END

# Code: EVEX_Vshufps_xmm_k1z_xmm_xmmm128b32_imm8
INSTRUCTION: EVEX.128.0F.W0 C6 /r ib | VSHUFPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst, imm8 | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm r=imm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vshufps_ymm_k1z_ymm_ymmm256b32_imm8
INSTRUCTION: EVEX.256.0F.W0 C6 /r ib | VSHUFPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst, imm8 | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm r=imm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vshufps_zmm_k1z_zmm_zmmm512b32_imm8
INSTRUCTION: EVEX.512.0F.W0 C6 /r ib | VSHUFPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst, imm8 | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm r=imm | Packed512_Float32 Broadcast512_Float32
END

# Code: Shufpd_xmm_xmmm128_imm8
INSTRUCTION: 66 0F C6 /r ib | SHUFPD xmm1, xmm2/m128, imm8 | SSE2
	ops: rw=reg r=rm r=imm | Packed128_Float64
END

# Code: VEX_Vshufpd_xmm_xmm_xmmm128_imm8
INSTRUCTION: VEX.128.66.0F.WIG C6 /r ib | VSHUFPD xmm1, xmm2, xmm3/m128, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | Packed128_Float64
END

# Code: VEX_Vshufpd_ymm_ymm_ymmm256_imm8
INSTRUCTION: VEX.256.66.0F.WIG C6 /r ib | VSHUFPD ymm1, ymm2, ymm3/m256, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | Packed256_Float64
END

# Code: EVEX_Vshufpd_xmm_k1z_xmm_xmmm128b64_imm8
INSTRUCTION: EVEX.128.66.0F.W1 C6 /r ib | VSHUFPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst, imm8 | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm r=imm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vshufpd_ymm_k1z_ymm_ymmm256b64_imm8
INSTRUCTION: EVEX.256.66.0F.W1 C6 /r ib | VSHUFPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst, imm8 | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm r=imm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vshufpd_zmm_k1z_zmm_zmmm512b64_imm8
INSTRUCTION: EVEX.512.66.0F.W1 C6 /r ib | VSHUFPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst, imm8 | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm r=imm | Packed512_Float64 Broadcast512_Float64
END

# Code: Cmpxchg8b_m64
INSTRUCTION: 0F C7 /1 | CMPXCHG8B m64 | CX8
	ops: rcw=rm | UInt64
	implied: rcw=eax;edx cr=ecx;ebx
	rflags: w=z
	flags: lock xacquire xrelease
	masm: flags=force-size=default
	nasm: flags=mem-size=ignore
END

# Code: Cmpxchg16b_m128
INSTRUCTION: o64 0F C7 /1 | CMPXCHG16B m128 | CMPXCHG16B
	ops: rcw=rm | UInt128
	implied: rcw=rax;rdx cr=rcx;rbx
	rflags: w=z
	flags: 64 lock
	masm: flags=mem-size=normal
	nasm: flags=mem-size=ignore
END

# Code: Xrstors_mem
INSTRUCTION: NP 0F C7 /3 | XRSTORS mem | XSAVES
	ops: r=rm | Xsave
	implied: r=eax;edx
	code-memory-size: em
	flags: cpl0 save-restore intel-may-vm-exit tsx-impl-abort
END

# Code: Xrstors64_mem
INSTRUCTION: NP o64 0F C7 /3 | XRSTORS64 mem | XSAVES
	ops: r=rm | Xsave64
	implied: r=eax;edx
	code-memory-size: em
	flags: 64 cpl0 save-restore intel-may-vm-exit tsx-impl-abort
END

# Code: Xsavec_mem
INSTRUCTION: NP 0F C7 /4 | XSAVEC mem | XSAVEC
	ops: w=rm | Xsave
	implied: r=eax;edx
	code-memory-size: em
	flags: save-restore tsx-impl-abort
END

# Code: Xsavec64_mem
INSTRUCTION: NP o64 0F C7 /4 | XSAVEC64 mem | XSAVEC
	ops: w=rm | Xsave64
	implied: r=eax;edx
	code-memory-size: em
	flags: 64 save-restore tsx-impl-abort
END

# Code: Xsaves_mem
INSTRUCTION: NP 0F C7 /5 | XSAVES mem | XSAVES
	ops: w=rm | Xsave
	implied: r=eax;edx
	code-memory-size: em
	flags: cpl0 save-restore intel-may-vm-exit tsx-impl-abort
END

# Code: Xsaves64_mem
INSTRUCTION: NP o64 0F C7 /5 | XSAVES64 mem | XSAVES
	ops: w=rm | Xsave64
	implied: r=eax;edx
	code-memory-size: em
	flags: 64 cpl0 save-restore intel-may-vm-exit tsx-impl-abort
END

# Code: Vmptrld_m64
INSTRUCTION: NP 0F C7 /6 | VMPTRLD m64 | VMX
	ops: r=rm | UInt64
	rflags: w=zc 0=osap
	flags: cpl0 no-rm no-v86 no-cm vmx=op intel-vm-exit tdx-non-root-ud tsx-impl-abort
	masm: flags=force-size=default
	nasm: flags=mem-size=ignore
END

# Code: Vmclear_m64
INSTRUCTION: 66 0F C7 /6 | VMCLEAR m64 | VMX
	ops: r=rm | UInt64
	rflags: w=zc 0=osap
	flags: cpl0 no-rm no-v86 no-cm vmx=op intel-vm-exit tdx-non-root-ud tsx-impl-abort
	masm: flags=force-size=default
	nasm: flags=mem-size=ignore
END

# Code: Vmxon_m64
INSTRUCTION: F3 0F C7 /6 | VMXON m64 | VMX
	ops: r=rm | UInt64
	rflags: w=zc 0=osap
	flags: cpl0 no-rm no-v86 no-cm intel-vm-exit tdx-non-root-ud tsx-impl-abort
	masm: flags=force-size=default
	nasm: flags=mem-size=ignore
END

# Code: Rdrand_r16
INSTRUCTION: o16 0F C7 /6 | RDRAND r16 | RDRAND
	ops: w=rm
	rflags: w=c 0=oszap
	# May cause a TSX abort if VM exit
	flags: nfx intel-may-vm-exit tsx-impl-abort
END

# Code: Rdrand_r32
INSTRUCTION: o32 0F C7 /6 | RDRAND r32 | RDRAND
	ops: w=rm
	rflags: w=c 0=oszap
	# May cause a TSX abort if VM exit
	flags: nfx intel-may-vm-exit tsx-impl-abort
END

# Code: Rdrand_r64
INSTRUCTION: o64 0F C7 /6 | RDRAND r64 | RDRAND
	ops: w=rm
	rflags: w=c 0=oszap
	# May cause a TSX abort if VM exit
	flags: 64 nfx intel-may-vm-exit tsx-impl-abort
END

# Code: Vmptrst_m64
INSTRUCTION: NP 0F C7 /7 | VMPTRST m64 | VMX
	ops: w=rm | UInt64
	rflags: 0=oszapc
	flags: cpl0 no-rm no-v86 no-cm vmx=op intel-vm-exit tdx-non-root-ud tsx-impl-abort
	masm: flags=force-size=default
	nasm: flags=mem-size=ignore
END

# Code: Rdseed_r16
INSTRUCTION: o16 0F C7 /7 | RDSEED r16 | RDSEED
	ops: w=rm
	rflags: w=c 0=oszap
	# May cause a TSX abort if VM exit
	flags: nfx intel-may-vm-exit tsx-impl-abort
END

# Code: Rdseed_r32
INSTRUCTION: o32 0F C7 /7 | RDSEED r32 | RDSEED
	ops: w=rm
	rflags: w=c 0=oszap
	# May cause a TSX abort if VM exit
	flags: nfx intel-may-vm-exit tsx-impl-abort
END

# Code: Rdseed_r64
INSTRUCTION: o64 0F C7 /7 | RDSEED r64 | RDSEED
	ops: w=rm
	rflags: w=c 0=oszap
	# May cause a TSX abort if VM exit
	flags: 64 nfx intel-may-vm-exit tsx-impl-abort
END

# Code: Rdpid_r32
INSTRUCTION: F3 0F C7 /7 | RDPID r32 | RDPID
	ops: w=rm
	flags: 16 32
END

# Code: Rdpid_r64
INSTRUCTION: F3 0F C7 /7 | RDPID r64 | RDPID
	ops: w=rm
	flags: 64
END

# Code: Bswap_r16
INSTRUCTION: o16 0F C8+rw | BSWAP r16 | INTEL486
	ops: rw=opcode
	gas: suffix=w
END

# Code: Bswap_r32
INSTRUCTION: o32 0F C8+rd | BSWAP r32 | INTEL486
	ops: rw=opcode
	gas: suffix=l
END

# Code: Bswap_r64
INSTRUCTION: o64 0F C8+ro | BSWAP r64 | X64
	ops: rw=opcode
	flags: 64
	gas: suffix=q
END

# Code: Addsubpd_xmm_xmmm128
INSTRUCTION: 66 0F D0 /r | ADDSUBPD xmm1, xmm2/m128 | SSE3
	ops: rw=reg r=rm | Packed128_Float64
END

# Code: VEX_Vaddsubpd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG D0 /r | VADDSUBPD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vaddsubpd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG D0 /r | VADDSUBPD ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float64
END

# Code: Addsubps_xmm_xmmm128
INSTRUCTION: F2 0F D0 /r | ADDSUBPS xmm1, xmm2/m128 | SSE3
	ops: rw=reg r=rm | Packed128_Float32
END

# Code: VEX_Vaddsubps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.F2.0F.WIG D0 /r | VADDSUBPS xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vaddsubps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.F2.0F.WIG D0 /r | VADDSUBPS ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float32
END

# Code: Psrlw_mm_mmm64
INSTRUCTION: NP 0F D1 /r | PSRLW mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_UInt16
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Psrlw_xmm_xmmm128
INSTRUCTION: 66 0F D1 /r | PSRLW xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt16
END

# Code: VEX_Vpsrlw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG D1 /r | VPSRLW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: VEX_Vpsrlw_ymm_ymm_xmmm128
INSTRUCTION: VEX.256.66.0F.WIG D1 /r | VPSRLW ymm1, ymm2, xmm3/m128 | AVX2
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: EVEX_Vpsrlw_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG D1 /r | VPSRLW xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: EVEX_Vpsrlw_ymm_k1z_ymm_xmmm128
INSTRUCTION: EVEX.256.66.0F.WIG D1 /r | VPSRLW ymm1 {k1}{z}, ymm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: EVEX_Vpsrlw_zmm_k1z_zmm_xmmm128
INSTRUCTION: EVEX.512.66.0F.WIG D1 /r | VPSRLW zmm1 {k1}{z}, zmm2, xmm3/m128 | AVX512BW | N16
	ops: wvmm=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: Psrld_mm_mmm64
INSTRUCTION: NP 0F D2 /r | PSRLD mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_UInt32
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Psrld_xmm_xmmm128
INSTRUCTION: 66 0F D2 /r | PSRLD xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt32
END

# Code: VEX_Vpsrld_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG D2 /r | VPSRLD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt32
END

# Code: VEX_Vpsrld_ymm_ymm_xmmm128
INSTRUCTION: VEX.256.66.0F.WIG D2 /r | VPSRLD ymm1, ymm2, xmm3/m128 | AVX2
	ops: w=reg r=vvvv r=rm | Packed128_UInt32
END

# Code: EVEX_Vpsrld_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.W0 D2 /r | VPSRLD xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512F | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt32
END

# Code: EVEX_Vpsrld_ymm_k1z_ymm_xmmm128
INSTRUCTION: EVEX.256.66.0F.W0 D2 /r | VPSRLD ymm1 {k1}{z}, ymm2, xmm3/m128 | AVX512VL AVX512F | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt32
END

# Code: EVEX_Vpsrld_zmm_k1z_zmm_xmmm128
INSTRUCTION: EVEX.512.66.0F.W0 D2 /r | VPSRLD zmm1 {k1}{z}, zmm2, xmm3/m128 | AVX512F | N16
	ops: wvmm=reg r=vvvv r=rm | Packed128_UInt32
END

# Code: Psrlq_mm_mmm64
INSTRUCTION: NP 0F D3 /r | PSRLQ mm, mm/m64 | MMX
	ops: rw=reg r=rm | UInt64
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Psrlq_xmm_xmmm128
INSTRUCTION: 66 0F D3 /r | PSRLQ xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt64
END

# Code: VEX_Vpsrlq_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG D3 /r | VPSRLQ xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt64
END

# Code: VEX_Vpsrlq_ymm_ymm_xmmm128
INSTRUCTION: VEX.256.66.0F.WIG D3 /r | VPSRLQ ymm1, ymm2, xmm3/m128 | AVX2
	ops: w=reg r=vvvv r=rm | Packed128_UInt64
END

# Code: EVEX_Vpsrlq_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.W1 D3 /r | VPSRLQ xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512F | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt64
END

# Code: EVEX_Vpsrlq_ymm_k1z_ymm_xmmm128
INSTRUCTION: EVEX.256.66.0F.W1 D3 /r | VPSRLQ ymm1 {k1}{z}, ymm2, xmm3/m128 | AVX512VL AVX512F | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt64
END

# Code: EVEX_Vpsrlq_zmm_k1z_zmm_xmmm128
INSTRUCTION: EVEX.512.66.0F.W1 D3 /r | VPSRLQ zmm1 {k1}{z}, zmm2, xmm3/m128 | AVX512F | N16
	ops: wvmm=reg r=vvvv r=rm | Packed128_UInt64
END

# Code: Paddq_mm_mmm64
INSTRUCTION: NP 0F D4 /r | PADDQ mm, mm/m64 | MMX
	ops: rw=reg r=rm | UInt64
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Paddq_xmm_xmmm128
INSTRUCTION: 66 0F D4 /r | PADDQ xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt64
END

# Code: VEX_Vpaddq_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG D4 /r | VPADDQ xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt64
END

# Code: VEX_Vpaddq_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG D4 /r | VPADDQ ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt64
END

# Code: EVEX_Vpaddq_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F.W1 D4 /r | VPADDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Vpaddq_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F.W1 D4 /r | VPADDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vpaddq_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F.W1 D4 /r | VPADDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: Pmullw_mm_mmm64
INSTRUCTION: NP 0F D5 /r | PMULLW mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_Int16
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Pmullw_xmm_xmmm128
INSTRUCTION: 66 0F D5 /r | PMULLW xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_Int16
END

# Code: VEX_Vpmullw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG D5 /r | VPMULLW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int16
END

# Code: VEX_Vpmullw_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG D5 /r | VPMULLW ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Int16
END

# Code: EVEX_Vpmullw_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG D5 /r | VPMULLW xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_Int16
END

# Code: EVEX_Vpmullw_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG D5 /r | VPMULLW ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_Int16
END

# Code: EVEX_Vpmullw_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG D5 /r | VPMULLW zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_Int16
END

# Code: Movq_xmmm64_xmm
INSTRUCTION: 66 0F D6 /r | MOVQ xmm2/m64, xmm1 | SSE2
	ops: w=rm r=reg | UInt64
	masm: flags=force-size=default
END

# Code: VEX_Vmovq_xmmm64_xmm
INSTRUCTION: VEX.128.66.0F.WIG D6 /r | VMOVQ xmm1/m64, xmm2 | AVX
	ops: w=rm r=reg | UInt64
	masm: flags=force-size=default
END

# Code: EVEX_Vmovq_xmmm64_xmm
INSTRUCTION: EVEX.128.66.0F.W1 D6 /r | VMOVQ xmm1/m64, xmm2 | AVX512F | N8
	ops: w=rm r=reg | UInt64
	masm: flags=force-size=default
END

# Code: Movq2dq_xmm_mm
INSTRUCTION: F3 0F D6 /r | MOVQ2DQ xmm, mm | SSE2
	ops: w=reg r=rm
	flags: tsx-impl-abort
END

# Code: Movdq2q_mm_xmm
INSTRUCTION: F2 0F D6 /r | MOVDQ2Q mm, xmm | SSE2
	ops: w=reg r=rm
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Pmovmskb_r32_mm
INSTRUCTION: NP 0F D7 /r | PMOVMSKB r32, mm | SSE
	ops: w=reg r=rm
	flags: tsx-impl-abort
END

# Code: Pmovmskb_r64_mm
INSTRUCTION: NP o64 0F D7 /r | PMOVMSKB r64, mm | SSE
	ops: w=reg r=rm
	flags: 64 tsx-impl-abort
	intel: reg32
	nasm: reg32
END

# Code: Pmovmskb_r32_xmm
INSTRUCTION: 66 0F D7 /r | PMOVMSKB r32, xmm | SSE2
	ops: w=reg r=rm
END

# Code: Pmovmskb_r64_xmm
INSTRUCTION: 66 o64 0F D7 /r | PMOVMSKB r64, xmm | SSE2
	ops: w=reg r=rm
	flags: 64
	intel: reg32
	nasm: reg32
END

# Code: VEX_Vpmovmskb_r32_xmm
INSTRUCTION: VEX.128.66.0F.W0 D7 /r | VPMOVMSKB r32, xmm1 | AVX
	ops: w=reg r=rm
	flags: wig32
END

# Code: VEX_Vpmovmskb_r64_xmm
INSTRUCTION: VEX.128.66.0F.W1 D7 /r | VPMOVMSKB r64, xmm1 | AVX
	ops: w=reg r=rm
	flags: 64
	intel: reg32
END

# Code: VEX_Vpmovmskb_r32_ymm
INSTRUCTION: VEX.256.66.0F.W0 D7 /r | VPMOVMSKB r32, ymm1 | AVX2
	ops: w=reg r=rm
	flags: wig32
END

# Code: VEX_Vpmovmskb_r64_ymm
INSTRUCTION: VEX.256.66.0F.W1 D7 /r | VPMOVMSKB r64, ymm1 | AVX2
	ops: w=reg r=rm
	flags: 64
	intel: reg32
END

# Code: Psubusb_mm_mmm64
INSTRUCTION: NP 0F D8 /r | PSUBUSB mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_UInt8
	implied: zero-reg-regmem
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Psubusb_xmm_xmmm128
INSTRUCTION: 66 0F D8 /r | PSUBUSB xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt8
	implied: zero-reg-regmem
END

# Code: VEX_Vpsubusb_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG D8 /r | VPSUBUSB xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
	implied: zero-reg-reg-regmem
END

# Code: VEX_Vpsubusb_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG D8 /r | VPSUBUSB ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vpsubusb_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG D8 /r | VPSUBUSB xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vpsubusb_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG D8 /r | VPSUBUSB ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vpsubusb_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG D8 /r | VPSUBUSB zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt8
	implied: zero-reg-reg-regmem
END

# Code: Psubusw_mm_mmm64
INSTRUCTION: NP 0F D9 /r | PSUBUSW mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_UInt16
	implied: zero-reg-regmem
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Psubusw_xmm_xmmm128
INSTRUCTION: 66 0F D9 /r | PSUBUSW xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt16
	implied: zero-reg-regmem
END

# Code: VEX_Vpsubusw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG D9 /r | VPSUBUSW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
	implied: zero-reg-reg-regmem
END

# Code: VEX_Vpsubusw_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG D9 /r | VPSUBUSW ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vpsubusw_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG D9 /r | VPSUBUSW xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vpsubusw_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG D9 /r | VPSUBUSW ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vpsubusw_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG D9 /r | VPSUBUSW zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt16
	implied: zero-reg-reg-regmem
END

# Code: Pminub_mm_mmm64
INSTRUCTION: NP 0F DA /r | PMINUB mm1, mm2/m64 | SSE
	ops: rw=reg r=rm | Packed64_UInt8
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Pminub_xmm_xmmm128
INSTRUCTION: 66 0F DA /r | PMINUB xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt8
END

# Code: VEX_Vpminub_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG DA /r | VPMINUB xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
END

# Code: VEX_Vpminub_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG DA /r | VPMINUB ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
END

# Code: EVEX_Vpminub_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG DA /r | VPMINUB xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
END

# Code: EVEX_Vpminub_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG DA /r | VPMINUB ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
END

# Code: EVEX_Vpminub_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG DA /r | VPMINUB zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt8
END

# Code: Pand_mm_mmm64
INSTRUCTION: NP 0F DB /r | PAND mm, mm/m64 | MMX
	ops: rw=reg r=rm | UInt64
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Pand_xmm_xmmm128
INSTRUCTION: 66 0F DB /r | PAND xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | UInt128
END

# Code: VEX_Vpand_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG DB /r | VPAND xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | UInt128
END

# Code: VEX_Vpand_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG DB /r | VPAND ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt128
END

# Code: EVEX_Vpandd_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F.W0 DB /r | VPANDD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_UInt32 Broadcast128_UInt32
END

# Code: EVEX_Vpandd_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F.W0 DB /r | VPANDD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vpandd_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F.W0 DB /r | VPANDD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: EVEX_Vpandq_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F.W1 DB /r | VPANDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Vpandq_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F.W1 DB /r | VPANDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vpandq_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F.W1 DB /r | VPANDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: Paddusb_mm_mmm64
INSTRUCTION: NP 0F DC /r | PADDUSB mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_UInt8
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Paddusb_xmm_xmmm128
INSTRUCTION: 66 0F DC /r | PADDUSB xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt8
END

# Code: VEX_Vpaddusb_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG DC /r | VPADDUSB xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
END

# Code: VEX_Vpaddusb_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG DC /r | VPADDUSB ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
END

# Code: EVEX_Vpaddusb_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG DC /r | VPADDUSB xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
END

# Code: EVEX_Vpaddusb_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG DC /r | VPADDUSB ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
END

# Code: EVEX_Vpaddusb_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG DC /r | VPADDUSB zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt8
END

# Code: Paddusw_mm_mmm64
INSTRUCTION: NP 0F DD /r | PADDUSW mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_UInt16
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Paddusw_xmm_xmmm128
INSTRUCTION: 66 0F DD /r | PADDUSW xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt16
END

# Code: VEX_Vpaddusw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG DD /r | VPADDUSW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: VEX_Vpaddusw_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG DD /r | VPADDUSW ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: EVEX_Vpaddusw_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG DD /r | VPADDUSW xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: EVEX_Vpaddusw_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG DD /r | VPADDUSW ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: EVEX_Vpaddusw_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG DD /r | VPADDUSW zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt16
END

# Code: Pmaxub_mm_mmm64
INSTRUCTION: NP 0F DE /r | PMAXUB mm1, mm2/m64 | SSE
	ops: rw=reg r=rm | Packed64_UInt8
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Pmaxub_xmm_xmmm128
INSTRUCTION: 66 0F DE /r | PMAXUB xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt8
END

# Code: VEX_Vpmaxub_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG DE /r | VPMAXUB xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
END

# Code: VEX_Vpmaxub_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG DE /r | VPMAXUB ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
END

# Code: EVEX_Vpmaxub_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG DE /r | VPMAXUB xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
END

# Code: EVEX_Vpmaxub_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG DE /r | VPMAXUB ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
END

# Code: EVEX_Vpmaxub_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG DE /r | VPMAXUB zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt8
END

# Code: Pandn_mm_mmm64
INSTRUCTION: NP 0F DF /r | PANDN mm, mm/m64 | MMX
	ops: rw=reg r=rm | UInt64
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Pandn_xmm_xmmm128
INSTRUCTION: 66 0F DF /r | PANDN xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | UInt128
END

# Code: VEX_Vpandn_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG DF /r | VPANDN xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | UInt128
END

# Code: VEX_Vpandn_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG DF /r | VPANDN ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt128
END

# Code: EVEX_Vpandnd_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F.W0 DF /r | VPANDND xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_UInt32 Broadcast128_UInt32
END

# Code: EVEX_Vpandnd_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F.W0 DF /r | VPANDND ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vpandnd_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F.W0 DF /r | VPANDND zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: EVEX_Vpandnq_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F.W1 DF /r | VPANDNQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Vpandnq_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F.W1 DF /r | VPANDNQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vpandnq_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F.W1 DF /r | VPANDNQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: Pavgb_mm_mmm64
INSTRUCTION: NP 0F E0 /r | PAVGB mm1, mm2/m64 | SSE
	ops: rw=reg r=rm | Packed64_UInt8
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Pavgb_xmm_xmmm128
INSTRUCTION: 66 0F E0 /r | PAVGB xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt8
END

# Code: VEX_Vpavgb_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG E0 /r | VPAVGB xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
END

# Code: VEX_Vpavgb_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG E0 /r | VPAVGB ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
END

# Code: EVEX_Vpavgb_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG E0 /r | VPAVGB xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
END

# Code: EVEX_Vpavgb_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG E0 /r | VPAVGB ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
END

# Code: EVEX_Vpavgb_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG E0 /r | VPAVGB zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt8
END

# Code: Psraw_mm_mmm64
INSTRUCTION: NP 0F E1 /r | PSRAW mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_Int16
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Psraw_xmm_xmmm128
INSTRUCTION: 66 0F E1 /r | PSRAW xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_Int16
END

# Code: VEX_Vpsraw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG E1 /r | VPSRAW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int16
END

# Code: VEX_Vpsraw_ymm_ymm_xmmm128
INSTRUCTION: VEX.256.66.0F.WIG E1 /r | VPSRAW ymm1, ymm2, xmm3/m128 | AVX2
	ops: w=reg r=vvvv r=rm | Packed128_Int16
END

# Code: EVEX_Vpsraw_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG E1 /r | VPSRAW xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_Int16
END

# Code: EVEX_Vpsraw_ymm_k1z_ymm_xmmm128
INSTRUCTION: EVEX.256.66.0F.WIG E1 /r | VPSRAW ymm1 {k1}{z}, ymm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_Int16
END

# Code: EVEX_Vpsraw_zmm_k1z_zmm_xmmm128
INSTRUCTION: EVEX.512.66.0F.WIG E1 /r | VPSRAW zmm1 {k1}{z}, zmm2, xmm3/m128 | AVX512BW | N16
	ops: wvmm=reg r=vvvv r=rm | Packed128_Int16
END

# Code: Psrad_mm_mmm64
INSTRUCTION: NP 0F E2 /r | PSRAD mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_Int32
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Psrad_xmm_xmmm128
INSTRUCTION: 66 0F E2 /r | PSRAD xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_Int32
END

# Code: VEX_Vpsrad_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG E2 /r | VPSRAD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int32
END

# Code: VEX_Vpsrad_ymm_ymm_xmmm128
INSTRUCTION: VEX.256.66.0F.WIG E2 /r | VPSRAD ymm1, ymm2, xmm3/m128 | AVX2
	ops: w=reg r=vvvv r=rm | Packed128_Int32
END

# Code: EVEX_Vpsrad_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.W0 E2 /r | VPSRAD xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512F | N16
	ops: w=reg r=vvvv r=rm | Packed128_Int32
END

# Code: EVEX_Vpsrad_ymm_k1z_ymm_xmmm128
INSTRUCTION: EVEX.256.66.0F.W0 E2 /r | VPSRAD ymm1 {k1}{z}, ymm2, xmm3/m128 | AVX512VL AVX512F | N16
	ops: w=reg r=vvvv r=rm | Packed128_Int32
END

# Code: EVEX_Vpsrad_zmm_k1z_zmm_xmmm128
INSTRUCTION: EVEX.512.66.0F.W0 E2 /r | VPSRAD zmm1 {k1}{z}, zmm2, xmm3/m128 | AVX512F | N16
	ops: wvmm=reg r=vvvv r=rm | Packed128_Int32
END

# Code: EVEX_Vpsraq_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.W1 E2 /r | VPSRAQ xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512F | N16
	ops: w=reg r=vvvv r=rm | Packed128_Int64
END

# Code: EVEX_Vpsraq_ymm_k1z_ymm_xmmm128
INSTRUCTION: EVEX.256.66.0F.W1 E2 /r | VPSRAQ ymm1 {k1}{z}, ymm2, xmm3/m128 | AVX512VL AVX512F | N16
	ops: w=reg r=vvvv r=rm | Packed128_Int64
END

# Code: EVEX_Vpsraq_zmm_k1z_zmm_xmmm128
INSTRUCTION: EVEX.512.66.0F.W1 E2 /r | VPSRAQ zmm1 {k1}{z}, zmm2, xmm3/m128 | AVX512F | N16
	ops: wvmm=reg r=vvvv r=rm | Packed128_Int64
END

# Code: Pavgw_mm_mmm64
INSTRUCTION: NP 0F E3 /r | PAVGW mm1, mm2/m64 | SSE
	ops: rw=reg r=rm | Packed64_UInt16
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Pavgw_xmm_xmmm128
INSTRUCTION: 66 0F E3 /r | PAVGW xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt16
END

# Code: VEX_Vpavgw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG E3 /r | VPAVGW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: VEX_Vpavgw_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG E3 /r | VPAVGW ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: EVEX_Vpavgw_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG E3 /r | VPAVGW xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: EVEX_Vpavgw_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG E3 /r | VPAVGW ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: EVEX_Vpavgw_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG E3 /r | VPAVGW zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt16
END

# Code: Pmulhuw_mm_mmm64
INSTRUCTION: NP 0F E4 /r | PMULHUW mm1, mm2/m64 | SSE
	ops: rw=reg r=rm | Packed64_UInt16
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Pmulhuw_xmm_xmmm128
INSTRUCTION: 66 0F E4 /r | PMULHUW xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt16
END

# Code: VEX_Vpmulhuw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG E4 /r | VPMULHUW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: VEX_Vpmulhuw_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG E4 /r | VPMULHUW ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: EVEX_Vpmulhuw_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG E4 /r | VPMULHUW xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: EVEX_Vpmulhuw_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG E4 /r | VPMULHUW ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: EVEX_Vpmulhuw_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG E4 /r | VPMULHUW zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt16
END

# Code: Pmulhw_mm_mmm64
INSTRUCTION: NP 0F E5 /r | PMULHW mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_Int16
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Pmulhw_xmm_xmmm128
INSTRUCTION: 66 0F E5 /r | PMULHW xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_Int16
END

# Code: VEX_Vpmulhw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG E5 /r | VPMULHW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int16
END

# Code: VEX_Vpmulhw_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG E5 /r | VPMULHW ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Int16
END

# Code: EVEX_Vpmulhw_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG E5 /r | VPMULHW xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_Int16
END

# Code: EVEX_Vpmulhw_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG E5 /r | VPMULHW ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_Int16
END

# Code: EVEX_Vpmulhw_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG E5 /r | VPMULHW zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_Int16
END

# Code: Cvttpd2dq_xmm_xmmm128
INSTRUCTION: 66 0F E6 /r | CVTTPD2DQ xmm1, xmm2/m128 | SSE2
	ops: w=reg r=rm | Packed128_Float64
END

# Code: VEX_Vcvttpd2dq_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG E6 /r | VCVTTPD2DQ xmm1, xmm2/m128 | AVX
	ops: w=reg r=rm | Packed128_Float64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=x
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: VEX_Vcvttpd2dq_xmm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG E6 /r | VCVTTPD2DQ xmm1, ymm2/m256 | AVX
	ops: w=reg r=rm | Packed256_Float64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=y
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: EVEX_Vcvttpd2dq_xmm_k1z_xmmm128b64
INSTRUCTION: EVEX.128.66.0F.W1 E6 /r | VCVTTPD2DQ xmm1 {k1}{z}, xmm2/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=rm | Packed128_Float64 Broadcast128_Float64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=x
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vcvttpd2dq_xmm_k1z_ymmm256b64
INSTRUCTION: EVEX.256.66.0F.W1 E6 /r | VCVTTPD2DQ xmm1 {k1}{z}, ymm2/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=rm | Packed256_Float64 Broadcast256_Float64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=y
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vcvttpd2dq_ymm_k1z_zmmm512b64_sae
INSTRUCTION: EVEX.512.66.0F.W1 E6 /r | VCVTTPD2DQ ymm1 {k1}{z}, zmm2/m512/m64bcst{sae} | AVX512F | N64b8
	ops: w=reg r=rm | Packed512_Float64 Broadcast512_Float64
	masm: flags=force-size=default
END

# Code: Cvtdq2pd_xmm_xmmm64
INSTRUCTION: F3 0F E6 /r | CVTDQ2PD xmm1, xmm2/m64 | SSE2
	ops: w=reg r=rm | Packed64_Int32
	masm: flags=force-size=default
END

# Code: VEX_Vcvtdq2pd_xmm_xmmm64
INSTRUCTION: VEX.128.F3.0F.WIG E6 /r | VCVTDQ2PD xmm1, xmm2/m64 | AVX
	ops: w=reg r=rm | Packed64_Int32
	masm: flags=force-size=default
END

# Code: VEX_Vcvtdq2pd_ymm_xmmm128
INSTRUCTION: VEX.256.F3.0F.WIG E6 /r | VCVTDQ2PD ymm1, xmm2/m128 | AVX
	ops: w=reg r=rm | Packed128_Int32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtdq2pd_xmm_k1z_xmmm64b32
INSTRUCTION: EVEX.128.F3.0F.W0 E6 /r | VCVTDQ2PD xmm1 {k1}{z}, xmm2/m64/m32bcst | AVX512VL AVX512F | N8b4
	ops: w=reg r=rm | Packed64_Int32 Broadcast64_Int32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtdq2pd_ymm_k1z_xmmm128b32
INSTRUCTION: EVEX.256.F3.0F.W0 E6 /r | VCVTDQ2PD ymm1 {k1}{z}, xmm2/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=rm | Packed128_Int32 Broadcast128_Int32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtdq2pd_zmm_k1z_ymmm256b32_er
INSTRUCTION: EVEX.512.F3.0F.W0 E6 /r | VCVTDQ2PD zmm1 {k1}{z}, ymm2/m256/m32bcst{er} | AVX512F | N32b4
	ops: wvmm=reg r=rm | Packed256_Int32 Broadcast256_Int32
	flags: ignore-er
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtqq2pd_xmm_k1z_xmmm128b64
INSTRUCTION: EVEX.128.F3.0F.W1 E6 /r | VCVTQQ2PD xmm1 {k1}{z}, xmm2/m128/m64bcst | AVX512VL AVX512DQ | N16b8
	ops: w=reg r=rm | Packed128_Int64 Broadcast128_Int64
END

# Code: EVEX_Vcvtqq2pd_ymm_k1z_ymmm256b64
INSTRUCTION: EVEX.256.F3.0F.W1 E6 /r | VCVTQQ2PD ymm1 {k1}{z}, ymm2/m256/m64bcst | AVX512VL AVX512DQ | N32b8
	ops: w=reg r=rm | Packed256_Int64 Broadcast256_Int64
END

# Code: EVEX_Vcvtqq2pd_zmm_k1z_zmmm512b64_er
INSTRUCTION: EVEX.512.F3.0F.W1 E6 /r | VCVTQQ2PD zmm1 {k1}{z}, zmm2/m512/m64bcst{er} | AVX512DQ | N64b8
	ops: wvmm=reg r=rm | Packed512_Int64 Broadcast512_Int64
END

# Code: Cvtpd2dq_xmm_xmmm128
INSTRUCTION: F2 0F E6 /r | CVTPD2DQ xmm1, xmm2/m128 | SSE2
	ops: w=reg r=rm | Packed128_Float64
END

# Code: VEX_Vcvtpd2dq_xmm_xmmm128
INSTRUCTION: VEX.128.F2.0F.WIG E6 /r | VCVTPD2DQ xmm1, xmm2/m128 | AVX
	ops: w=reg r=rm | Packed128_Float64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=x
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: VEX_Vcvtpd2dq_xmm_ymmm256
INSTRUCTION: VEX.256.F2.0F.WIG E6 /r | VCVTPD2DQ xmm1, ymm2/m256 | AVX
	ops: w=reg r=rm | Packed256_Float64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=y
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: EVEX_Vcvtpd2dq_xmm_k1z_xmmm128b64
INSTRUCTION: EVEX.128.F2.0F.W1 E6 /r | VCVTPD2DQ xmm1 {k1}{z}, xmm2/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=rm | Packed128_Float64 Broadcast128_Float64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=x
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vcvtpd2dq_xmm_k1z_ymmm256b64
INSTRUCTION: EVEX.256.F2.0F.W1 E6 /r | VCVTPD2DQ xmm1 {k1}{z}, ymm2/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=rm | Packed256_Float64 Broadcast256_Float64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=y
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vcvtpd2dq_ymm_k1z_zmmm512b64_er
INSTRUCTION: EVEX.512.F2.0F.W1 E6 /r | VCVTPD2DQ ymm1 {k1}{z}, zmm2/m512/m64bcst{er} | AVX512F | N64b8
	ops: w=reg r=rm | Packed512_Float64 Broadcast512_Float64
	masm: flags=force-size=default
END

# Code: Movntq_m64_mm
INSTRUCTION: NP 0F E7 /r | MOVNTQ m64, mm | SSE
	ops: w=rm r=reg | Packed64_UInt32
	flags: tsx-impl-abort non-temporal
	masm: flags=mem-size=mmx
END

# Code: Movntdq_m128_xmm
INSTRUCTION: 66 0F E7 /r | MOVNTDQ m128, xmm1 | SSE2
	ops: w=rm r=reg | Packed128_UInt32
	flags: tsx-impl-abort non-temporal
END

# Code: VEX_Vmovntdq_m128_xmm
INSTRUCTION: VEX.128.66.0F.WIG E7 /r | VMOVNTDQ m128, xmm1 | AVX
	ops: w=rm r=reg | Packed128_UInt32
	flags: tsx-impl-abort non-temporal
	masm: flags=force-size=default
END

# Code: VEX_Vmovntdq_m256_ymm
INSTRUCTION: VEX.256.66.0F.WIG E7 /r | VMOVNTDQ m256, ymm1 | AVX
	ops: w=rm r=reg | Packed256_UInt32
	flags: tsx-impl-abort non-temporal
	masm: flags=force-size=default
END

# Code: EVEX_Vmovntdq_m128_xmm
INSTRUCTION: EVEX.128.66.0F.W0 E7 /r | VMOVNTDQ m128, xmm1 | AVX512VL AVX512F | N16
	ops: w=rm r=reg | Packed128_UInt32
	flags: tsx-impl-abort non-temporal
	masm: flags=force-size=default
END

# Code: EVEX_Vmovntdq_m256_ymm
INSTRUCTION: EVEX.256.66.0F.W0 E7 /r | VMOVNTDQ m256, ymm1 | AVX512VL AVX512F | N32
	ops: w=rm r=reg | Packed256_UInt32
	flags: tsx-impl-abort non-temporal
	masm: flags=force-size=default
END

# Code: EVEX_Vmovntdq_m512_zmm
INSTRUCTION: EVEX.512.66.0F.W0 E7 /r | VMOVNTDQ m512, zmm1 | AVX512F | N64
	ops: w=rm r=reg | Packed512_UInt32
	flags: tsx-impl-abort non-temporal
	masm: flags=force-size=default
END

# Code: Psubsb_mm_mmm64
INSTRUCTION: NP 0F E8 /r | PSUBSB mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_Int8
	implied: zero-reg-regmem
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Psubsb_xmm_xmmm128
INSTRUCTION: 66 0F E8 /r | PSUBSB xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_Int8
	implied: zero-reg-regmem
END

# Code: VEX_Vpsubsb_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG E8 /r | VPSUBSB xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int8
	implied: zero-reg-reg-regmem
END

# Code: VEX_Vpsubsb_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG E8 /r | VPSUBSB ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Int8
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vpsubsb_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG E8 /r | VPSUBSB xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_Int8
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vpsubsb_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG E8 /r | VPSUBSB ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_Int8
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vpsubsb_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG E8 /r | VPSUBSB zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_Int8
	implied: zero-reg-reg-regmem
END

# Code: Psubsw_mm_mmm64
INSTRUCTION: NP 0F E9 /r | PSUBSW mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_Int16
	implied: zero-reg-regmem
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Psubsw_xmm_xmmm128
INSTRUCTION: 66 0F E9 /r | PSUBSW xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_Int16
	implied: zero-reg-regmem
END

# Code: VEX_Vpsubsw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG E9 /r | VPSUBSW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int16
	implied: zero-reg-reg-regmem
END

# Code: VEX_Vpsubsw_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG E9 /r | VPSUBSW ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Int16
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vpsubsw_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG E9 /r | VPSUBSW xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_Int16
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vpsubsw_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG E9 /r | VPSUBSW ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_Int16
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vpsubsw_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG E9 /r | VPSUBSW zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_Int16
	implied: zero-reg-reg-regmem
END

# Code: Pminsw_mm_mmm64
INSTRUCTION: NP 0F EA /r | PMINSW mm1, mm2/m64 | SSE
	ops: rw=reg r=rm | Packed64_Int16
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Pminsw_xmm_xmmm128
INSTRUCTION: 66 0F EA /r | PMINSW xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_Int16
END

# Code: VEX_Vpminsw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG EA /r | VPMINSW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int16
END

# Code: VEX_Vpminsw_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG EA /r | VPMINSW ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Int16
END

# Code: EVEX_Vpminsw_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG EA /r | VPMINSW xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_Int16
END

# Code: EVEX_Vpminsw_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG EA /r | VPMINSW ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_Int16
END

# Code: EVEX_Vpminsw_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG EA /r | VPMINSW zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_Int16
END

# Code: Por_mm_mmm64
INSTRUCTION: NP 0F EB /r | POR mm, mm/m64 | MMX
	ops: rw=reg r=rm | UInt64
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Por_xmm_xmmm128
INSTRUCTION: 66 0F EB /r | POR xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | UInt128
END

# Code: VEX_Vpor_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG EB /r | VPOR xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | UInt128
END

# Code: VEX_Vpor_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG EB /r | VPOR ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt128
END

# Code: EVEX_Vpord_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F.W0 EB /r | VPORD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_UInt32 Broadcast128_UInt32
END

# Code: EVEX_Vpord_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F.W0 EB /r | VPORD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vpord_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F.W0 EB /r | VPORD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: EVEX_Vporq_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F.W1 EB /r | VPORQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Vporq_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F.W1 EB /r | VPORQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vporq_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F.W1 EB /r | VPORQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: Paddsb_mm_mmm64
INSTRUCTION: NP 0F EC /r | PADDSB mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_Int8
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Paddsb_xmm_xmmm128
INSTRUCTION: 66 0F EC /r | PADDSB xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_Int8
END

# Code: VEX_Vpaddsb_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG EC /r | VPADDSB xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int8
END

# Code: VEX_Vpaddsb_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG EC /r | VPADDSB ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Int8
END

# Code: EVEX_Vpaddsb_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG EC /r | VPADDSB xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_Int8
END

# Code: EVEX_Vpaddsb_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG EC /r | VPADDSB ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_Int8
END

# Code: EVEX_Vpaddsb_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG EC /r | VPADDSB zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_Int8
END

# Code: Paddsw_mm_mmm64
INSTRUCTION: NP 0F ED /r | PADDSW mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_Int16
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Paddsw_xmm_xmmm128
INSTRUCTION: 66 0F ED /r | PADDSW xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_Int16
END

# Code: VEX_Vpaddsw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG ED /r | VPADDSW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int16
END

# Code: VEX_Vpaddsw_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG ED /r | VPADDSW ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Int16
END

# Code: EVEX_Vpaddsw_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG ED /r | VPADDSW xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_Int16
END

# Code: EVEX_Vpaddsw_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG ED /r | VPADDSW ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_Int16
END

# Code: EVEX_Vpaddsw_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG ED /r | VPADDSW zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_Int16
END

# Code: Pmaxsw_mm_mmm64
INSTRUCTION: NP 0F EE /r | PMAXSW mm1, mm2/m64 | SSE
	ops: rw=reg r=rm | Packed64_Int16
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Pmaxsw_xmm_xmmm128
INSTRUCTION: 66 0F EE /r | PMAXSW xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_Int16
END

# Code: VEX_Vpmaxsw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG EE /r | VPMAXSW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int16
END

# Code: VEX_Vpmaxsw_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG EE /r | VPMAXSW ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Int16
END

# Code: EVEX_Vpmaxsw_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG EE /r | VPMAXSW xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_Int16
END

# Code: EVEX_Vpmaxsw_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG EE /r | VPMAXSW ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_Int16
END

# Code: EVEX_Vpmaxsw_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG EE /r | VPMAXSW zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_Int16
END

# Code: Pxor_mm_mmm64
INSTRUCTION: NP 0F EF /r | PXOR mm, mm/m64 | MMX
	ops: rw=reg r=rm | UInt64
	implied: zero-reg-regmem
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Pxor_xmm_xmmm128
INSTRUCTION: 66 0F EF /r | PXOR xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | UInt128
	implied: zero-reg-regmem
END

# Code: VEX_Vpxor_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG EF /r | VPXOR xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | UInt128
	implied: zero-reg-reg-regmem
END

# Code: VEX_Vpxor_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG EF /r | VPXOR ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt128
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vpxord_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F.W0 EF /r | VPXORD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_UInt32 Broadcast128_UInt32
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vpxord_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F.W0 EF /r | VPXORD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_UInt32 Broadcast256_UInt32
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vpxord_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F.W0 EF /r | VPXORD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt32 Broadcast512_UInt32
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vpxorq_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F.W1 EF /r | VPXORQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_UInt64 Broadcast128_UInt64
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vpxorq_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F.W1 EF /r | VPXORQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_UInt64 Broadcast256_UInt64
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vpxorq_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F.W1 EF /r | VPXORQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt64 Broadcast512_UInt64
	implied: zero-reg-reg-regmem
END

# Code: Lddqu_xmm_m128
INSTRUCTION: F2 0F F0 /r | LDDQU xmm1, m128 | SSE3
	ops: w=reg r=rm | UInt128
	masm: flags=force-size=default
END

# Code: VEX_Vlddqu_xmm_m128
INSTRUCTION: VEX.128.F2.0F.WIG F0 /r | VLDDQU xmm1, m128 | AVX
	ops: w=reg r=rm | UInt128
	masm: flags=force-size=default
END

# Code: VEX_Vlddqu_ymm_m256
INSTRUCTION: VEX.256.F2.0F.WIG F0 /r | VLDDQU ymm1, m256 | AVX
	ops: w=reg r=rm | UInt256
	masm: flags=force-size=default
END

# Code: Psllw_mm_mmm64
INSTRUCTION: NP 0F F1 /r | PSLLW mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_UInt16
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Psllw_xmm_xmmm128
INSTRUCTION: 66 0F F1 /r | PSLLW xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt16
END

# Code: VEX_Vpsllw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG F1 /r | VPSLLW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: VEX_Vpsllw_ymm_ymm_xmmm128
INSTRUCTION: VEX.256.66.0F.WIG F1 /r | VPSLLW ymm1, ymm2, xmm3/m128 | AVX2
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: EVEX_Vpsllw_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG F1 /r | VPSLLW xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: EVEX_Vpsllw_ymm_k1z_ymm_xmmm128
INSTRUCTION: EVEX.256.66.0F.WIG F1 /r | VPSLLW ymm1 {k1}{z}, ymm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: EVEX_Vpsllw_zmm_k1z_zmm_xmmm128
INSTRUCTION: EVEX.512.66.0F.WIG F1 /r | VPSLLW zmm1 {k1}{z}, zmm2, xmm3/m128 | AVX512BW | N16
	ops: wvmm=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: Pslld_mm_mmm64
INSTRUCTION: NP 0F F2 /r | PSLLD mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_UInt32
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Pslld_xmm_xmmm128
INSTRUCTION: 66 0F F2 /r | PSLLD xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt32
END

# Code: VEX_Vpslld_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG F2 /r | VPSLLD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt32
END

# Code: VEX_Vpslld_ymm_ymm_xmmm128
INSTRUCTION: VEX.256.66.0F.WIG F2 /r | VPSLLD ymm1, ymm2, xmm3/m128 | AVX2
	ops: w=reg r=vvvv r=rm | Packed128_UInt32
END

# Code: EVEX_Vpslld_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.W0 F2 /r | VPSLLD xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512F | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt32
END

# Code: EVEX_Vpslld_ymm_k1z_ymm_xmmm128
INSTRUCTION: EVEX.256.66.0F.W0 F2 /r | VPSLLD ymm1 {k1}{z}, ymm2, xmm3/m128 | AVX512VL AVX512F | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt32
END

# Code: EVEX_Vpslld_zmm_k1z_zmm_xmmm128
INSTRUCTION: EVEX.512.66.0F.W0 F2 /r | VPSLLD zmm1 {k1}{z}, zmm2, xmm3/m128 | AVX512F | N16
	ops: wvmm=reg r=vvvv r=rm | Packed128_UInt32
END

# Code: Psllq_mm_mmm64
INSTRUCTION: NP 0F F3 /r | PSLLQ mm, mm/m64 | MMX
	ops: rw=reg r=rm | UInt64
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Psllq_xmm_xmmm128
INSTRUCTION: 66 0F F3 /r | PSLLQ xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt64
END

# Code: VEX_Vpsllq_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG F3 /r | VPSLLQ xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt64
END

# Code: VEX_Vpsllq_ymm_ymm_xmmm128
INSTRUCTION: VEX.256.66.0F.WIG F3 /r | VPSLLQ ymm1, ymm2, xmm3/m128 | AVX2
	ops: w=reg r=vvvv r=rm | Packed128_UInt64
END

# Code: EVEX_Vpsllq_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.W1 F3 /r | VPSLLQ xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512F | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt64
END

# Code: EVEX_Vpsllq_ymm_k1z_ymm_xmmm128
INSTRUCTION: EVEX.256.66.0F.W1 F3 /r | VPSLLQ ymm1 {k1}{z}, ymm2, xmm3/m128 | AVX512VL AVX512F | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt64
END

# Code: EVEX_Vpsllq_zmm_k1z_zmm_xmmm128
INSTRUCTION: EVEX.512.66.0F.W1 F3 /r | VPSLLQ zmm1 {k1}{z}, zmm2, xmm3/m128 | AVX512F | N16
	ops: wvmm=reg r=vvvv r=rm | Packed128_UInt64
END

# Code: Pmuludq_mm_mmm64
INSTRUCTION: NP 0F F4 /r | PMULUDQ mm1, mm2/m64 | SSE2
	ops: rw=reg r=rm | Packed64_UInt32
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Pmuludq_xmm_xmmm128
INSTRUCTION: 66 0F F4 /r | PMULUDQ xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt32
END

# Code: VEX_Vpmuludq_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG F4 /r | VPMULUDQ xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt32
END

# Code: VEX_Vpmuludq_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG F4 /r | VPMULUDQ ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt32
END

# Code: EVEX_Vpmuludq_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F.W1 F4 /r | VPMULUDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_UInt32 Broadcast128_2xUInt32
END

# Code: EVEX_Vpmuludq_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F.W1 F4 /r | VPMULUDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_UInt32 Broadcast256_2xUInt32
END

# Code: EVEX_Vpmuludq_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F.W1 F4 /r | VPMULUDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt32 Broadcast512_2xUInt32
END

# Code: Pmaddwd_mm_mmm64
INSTRUCTION: NP 0F F5 /r | PMADDWD mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_Int16
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Pmaddwd_xmm_xmmm128
INSTRUCTION: 66 0F F5 /r | PMADDWD xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_Int16
END

# Code: VEX_Vpmaddwd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG F5 /r | VPMADDWD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int16
END

# Code: VEX_Vpmaddwd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG F5 /r | VPMADDWD ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Int16
END

# Code: EVEX_Vpmaddwd_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG F5 /r | VPMADDWD xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_Int16
END

# Code: EVEX_Vpmaddwd_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG F5 /r | VPMADDWD ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_Int16
END

# Code: EVEX_Vpmaddwd_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG F5 /r | VPMADDWD zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_Int16
END

# Code: Psadbw_mm_mmm64
INSTRUCTION: NP 0F F6 /r | PSADBW mm1, mm2/m64 | SSE
	ops: rw=reg r=rm | Packed64_UInt8
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Psadbw_xmm_xmmm128
INSTRUCTION: 66 0F F6 /r | PSADBW xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt8
END

# Code: VEX_Vpsadbw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG F6 /r | VPSADBW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
END

# Code: VEX_Vpsadbw_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG F6 /r | VPSADBW ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
END

# Code: EVEX_Vpsadbw_xmm_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG F6 /r | VPSADBW xmm1, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
END

# Code: EVEX_Vpsadbw_ymm_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG F6 /r | VPSADBW ymm1, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
END

# Code: EVEX_Vpsadbw_zmm_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG F6 /r | VPSADBW zmm1, zmm2, zmm3/m512 | AVX512BW | N64
	ops: w=reg r=vvvv r=rm | Packed512_UInt8
END

# Code: Maskmovq_rDI_mm_mm
INSTRUCTION: NP 0F F7 /r | MASKMOVQ [m64], mm1, mm2 | SSE
	ops: w=seg-rdi r=reg r=rm | UInt64
	implied: w=[seg:a_rDI=default]
	flags: tsx-impl-abort non-temporal
	gas: maskmovq
	intel: maskmovq
	masm: flags=mem-size=mmx maskmovq
	nasm: maskmovq
END

# Code: Maskmovdqu_rDI_xmm_xmm
INSTRUCTION: 66 0F F7 /r | MASKMOVDQU [m128], xmm1, xmm2 | SSE2
	ops: w=seg-rdi r=reg r=rm | UInt128
	implied: w=[seg:a_rDI=default]
	flags: tsx-impl-abort non-temporal
	gas: maskmovq
	intel: maskmovq
	masm: maskmovq
	nasm: maskmovq
END

# Code: VEX_Vmaskmovdqu_rDI_xmm_xmm
INSTRUCTION: VEX.128.66.0F.WIG F7 /r | VMASKMOVDQU [m128], xmm1, xmm2 | AVX
	ops: w=seg-rdi r=reg r=rm | UInt128
	implied: w=[seg:a_rDI=default]
	flags: tsx-impl-abort non-temporal
	gas: maskmovq
	intel: maskmovq
	masm: maskmovq
	nasm: maskmovq
END

# Code: Psubb_mm_mmm64
INSTRUCTION: NP 0F F8 /r | PSUBB mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_UInt8
	implied: zero-reg-regmem
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Psubb_xmm_xmmm128
INSTRUCTION: 66 0F F8 /r | PSUBB xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt8
	implied: zero-reg-regmem
END

# Code: VEX_Vpsubb_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG F8 /r | VPSUBB xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
	implied: zero-reg-reg-regmem
END

# Code: VEX_Vpsubb_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG F8 /r | VPSUBB ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vpsubb_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG F8 /r | VPSUBB xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vpsubb_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG F8 /r | VPSUBB ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vpsubb_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG F8 /r | VPSUBB zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt8
	implied: zero-reg-reg-regmem
END

# Code: Psubw_mm_mmm64
INSTRUCTION: NP 0F F9 /r | PSUBW mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_UInt16
	implied: zero-reg-regmem
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Psubw_xmm_xmmm128
INSTRUCTION: 66 0F F9 /r | PSUBW xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt16
	implied: zero-reg-regmem
END

# Code: VEX_Vpsubw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG F9 /r | VPSUBW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
	implied: zero-reg-reg-regmem
END

# Code: VEX_Vpsubw_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG F9 /r | VPSUBW ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vpsubw_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG F9 /r | VPSUBW xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vpsubw_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG F9 /r | VPSUBW ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vpsubw_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG F9 /r | VPSUBW zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt16
	implied: zero-reg-reg-regmem
END

# Code: Psubd_mm_mmm64
INSTRUCTION: NP 0F FA /r | PSUBD mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_UInt32
	implied: zero-reg-regmem
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Psubd_xmm_xmmm128
INSTRUCTION: 66 0F FA /r | PSUBD xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt32
	implied: zero-reg-regmem
END

# Code: VEX_Vpsubd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG FA /r | VPSUBD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt32
	implied: zero-reg-reg-regmem
END

# Code: VEX_Vpsubd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG FA /r | VPSUBD ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt32
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vpsubd_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F.W0 FA /r | VPSUBD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_UInt32 Broadcast128_UInt32
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vpsubd_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F.W0 FA /r | VPSUBD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_UInt32 Broadcast256_UInt32
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vpsubd_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F.W0 FA /r | VPSUBD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt32 Broadcast512_UInt32
	implied: zero-reg-reg-regmem
END

# Code: Psubq_mm_mmm64
INSTRUCTION: NP 0F FB /r | PSUBQ mm1, mm2/m64 | SSE2
	ops: rw=reg r=rm | Int64
	implied: zero-reg-regmem
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Psubq_xmm_xmmm128
INSTRUCTION: 66 0F FB /r | PSUBQ xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt64
	implied: zero-reg-regmem
END

# Code: VEX_Vpsubq_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG FB /r | VPSUBQ xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt64
	implied: zero-reg-reg-regmem
END

# Code: VEX_Vpsubq_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG FB /r | VPSUBQ ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt64
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vpsubq_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F.W1 FB /r | VPSUBQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_UInt64 Broadcast128_UInt64
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vpsubq_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F.W1 FB /r | VPSUBQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_UInt64 Broadcast256_UInt64
	implied: zero-reg-reg-regmem
END

# Code: EVEX_Vpsubq_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F.W1 FB /r | VPSUBQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt64 Broadcast512_UInt64
	implied: zero-reg-reg-regmem
END

# Code: Paddb_mm_mmm64
INSTRUCTION: NP 0F FC /r | PADDB mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_UInt8
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Paddb_xmm_xmmm128
INSTRUCTION: 66 0F FC /r | PADDB xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt8
END

# Code: VEX_Vpaddb_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG FC /r | VPADDB xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
END

# Code: VEX_Vpaddb_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG FC /r | VPADDB ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
END

# Code: EVEX_Vpaddb_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG FC /r | VPADDB xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
END

# Code: EVEX_Vpaddb_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG FC /r | VPADDB ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
END

# Code: EVEX_Vpaddb_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG FC /r | VPADDB zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt8
END

# Code: Paddw_mm_mmm64
INSTRUCTION: NP 0F FD /r | PADDW mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_UInt16
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Paddw_xmm_xmmm128
INSTRUCTION: 66 0F FD /r | PADDW xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt16
END

# Code: VEX_Vpaddw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG FD /r | VPADDW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: VEX_Vpaddw_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG FD /r | VPADDW ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: EVEX_Vpaddw_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F.WIG FD /r | VPADDW xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: EVEX_Vpaddw_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F.WIG FD /r | VPADDW ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: EVEX_Vpaddw_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F.WIG FD /r | VPADDW zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt16
END

# Code: Paddd_mm_mmm64
INSTRUCTION: NP 0F FE /r | PADDD mm, mm/m64 | MMX
	ops: rw=reg r=rm | Packed64_UInt32
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Paddd_xmm_xmmm128
INSTRUCTION: 66 0F FE /r | PADDD xmm1, xmm2/m128 | SSE2
	ops: rw=reg r=rm | Packed128_UInt32
END

# Code: VEX_Vpaddd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F.WIG FE /r | VPADDD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt32
END

# Code: VEX_Vpaddd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F.WIG FE /r | VPADDD ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt32
END

# Code: EVEX_Vpaddd_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F.W0 FE /r | VPADDD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_UInt32 Broadcast128_UInt32
END

# Code: EVEX_Vpaddd_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F.W0 FE /r | VPADDD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vpaddd_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F.W0 FE /r | VPADDD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: Ud0_r16_rm16
INSTRUCTION: o16 0F FF /r | UD0 r16, r/m16 | INTEL286
	ops: n=reg n=rm | UInt16
	flags: cflow=ex no-amd-dec intel-vm-exit tsx-impl-abort
	gas: suffix=w
END

# Code: Ud0_r32_rm32
INSTRUCTION: o32 0F FF /r | UD0 r32, r/m32 | INTEL386
	ops: n=reg n=rm | UInt32
	flags: cflow=ex no-amd-dec intel-vm-exit tsx-impl-abort
	gas: suffix=l
END

# Code: Ud0_r64_rm64
INSTRUCTION: o64 0F FF /r | UD0 r64, r/m64 | X64
	ops: n=reg n=rm | UInt64
	flags: 64 cflow=ex no-amd-dec intel-vm-exit tsx-impl-abort
	gas: suffix=q
END

# Code: Pshufb_mm_mmm64
INSTRUCTION: NP 0F 38 00 /r | PSHUFB mm1, mm2/m64 | SSSE3
	ops: rw=reg r=rm | Packed64_UInt8
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Pshufb_xmm_xmmm128
INSTRUCTION: 66 0F 38 00 /r | PSHUFB xmm1, xmm2/m128 | SSSE3
	ops: rw=reg r=rm | Packed128_UInt8
END

# Code: VEX_Vpshufb_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG 00 /r | VPSHUFB xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
END

# Code: VEX_Vpshufb_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG 00 /r | VPSHUFB ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
END

# Code: EVEX_Vpshufb_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F38.WIG 00 /r | VPSHUFB xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
END

# Code: EVEX_Vpshufb_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F38.WIG 00 /r | VPSHUFB ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
END

# Code: EVEX_Vpshufb_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F38.WIG 00 /r | VPSHUFB zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt8
END

# Code: Phaddw_mm_mmm64
INSTRUCTION: NP 0F 38 01 /r | PHADDW mm1, mm2/m64 | SSSE3
	ops: rw=reg r=rm | Packed64_UInt16
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Phaddw_xmm_xmmm128
INSTRUCTION: 66 0F 38 01 /r | PHADDW xmm1, xmm2/m128 | SSSE3
	ops: rw=reg r=rm | Packed128_UInt16
END

# Code: VEX_Vphaddw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG 01 /r | VPHADDW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: VEX_Vphaddw_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG 01 /r | VPHADDW ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: Phaddd_mm_mmm64
INSTRUCTION: NP 0F 38 02 /r | PHADDD mm1, mm2/m64 | SSSE3
	ops: rw=reg r=rm | Packed64_UInt32
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Phaddd_xmm_xmmm128
INSTRUCTION: 66 0F 38 02 /r | PHADDD xmm1, xmm2/m128 | SSSE3
	ops: rw=reg r=rm | Packed128_UInt32
END

# Code: VEX_Vphaddd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG 02 /r | VPHADDD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt32
END

# Code: VEX_Vphaddd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG 02 /r | VPHADDD ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt32
END

# Code: Phaddsw_mm_mmm64
INSTRUCTION: NP 0F 38 03 /r | PHADDSW mm1, mm2/m64 | SSSE3
	ops: rw=reg r=rm | Packed64_Int16
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Phaddsw_xmm_xmmm128
INSTRUCTION: 66 0F 38 03 /r | PHADDSW xmm1, xmm2/m128 | SSSE3
	ops: rw=reg r=rm | Packed128_Int16
END

# Code: VEX_Vphaddsw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG 03 /r | VPHADDSW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int16
END

# Code: VEX_Vphaddsw_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG 03 /r | VPHADDSW ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Int16
END

# Code: Pmaddubsw_mm_mmm64
INSTRUCTION: NP 0F 38 04 /r | PMADDUBSW mm1, mm2/m64 | SSSE3
	ops: rw=reg r=rm | Packed64_Int8
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Pmaddubsw_xmm_xmmm128
INSTRUCTION: 66 0F 38 04 /r | PMADDUBSW xmm1, xmm2/m128 | SSSE3
	ops: rw=reg r=rm | Packed128_Int8
END

# Code: VEX_Vpmaddubsw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG 04 /r | VPMADDUBSW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int8
END

# Code: VEX_Vpmaddubsw_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG 04 /r | VPMADDUBSW ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Int8
END

# Code: EVEX_Vpmaddubsw_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F38.WIG 04 /r | VPMADDUBSW xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_Int8
END

# Code: EVEX_Vpmaddubsw_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F38.WIG 04 /r | VPMADDUBSW ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_Int8
END

# Code: EVEX_Vpmaddubsw_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F38.WIG 04 /r | VPMADDUBSW zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_Int8
END

# Code: Phsubw_mm_mmm64
INSTRUCTION: NP 0F 38 05 /r | PHSUBW mm1, mm2/m64 | SSSE3
	ops: rw=reg r=rm | Packed64_UInt16
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Phsubw_xmm_xmmm128
INSTRUCTION: 66 0F 38 05 /r | PHSUBW xmm1, xmm2/m128 | SSSE3
	ops: rw=reg r=rm | Packed128_UInt16
END

# Code: VEX_Vphsubw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG 05 /r | VPHSUBW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: VEX_Vphsubw_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG 05 /r | VPHSUBW ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: Phsubd_mm_mmm64
INSTRUCTION: NP 0F 38 06 /r | PHSUBD mm1, mm2/m64 | SSSE3
	ops: rw=reg r=rm | Packed64_UInt32
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Phsubd_xmm_xmmm128
INSTRUCTION: 66 0F 38 06 /r | PHSUBD xmm1, xmm2/m128 | SSSE3
	ops: rw=reg r=rm | Packed128_UInt32
END

# Code: VEX_Vphsubd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG 06 /r | VPHSUBD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt32
END

# Code: VEX_Vphsubd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG 06 /r | VPHSUBD ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt32
END

# Code: Phsubsw_mm_mmm64
INSTRUCTION: NP 0F 38 07 /r | PHSUBSW mm1, mm2/m64 | SSSE3
	ops: rw=reg r=rm | Packed64_Int16
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Phsubsw_xmm_xmmm128
INSTRUCTION: 66 0F 38 07 /r | PHSUBSW xmm1, xmm2/m128 | SSSE3
	ops: rw=reg r=rm | Packed128_Int16
END

# Code: VEX_Vphsubsw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG 07 /r | VPHSUBSW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int16
END

# Code: VEX_Vphsubsw_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG 07 /r | VPHSUBSW ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Int16
END

# Code: Psignb_mm_mmm64
INSTRUCTION: NP 0F 38 08 /r | PSIGNB mm1, mm2/m64 | SSSE3
	ops: rw=reg r=rm | Packed64_Int8
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Psignb_xmm_xmmm128
INSTRUCTION: 66 0F 38 08 /r | PSIGNB xmm1, xmm2/m128 | SSSE3
	ops: rw=reg r=rm | Packed128_Int8
END

# Code: VEX_Vpsignb_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG 08 /r | VPSIGNB xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int8
END

# Code: VEX_Vpsignb_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG 08 /r | VPSIGNB ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Int8
END

# Code: Psignw_mm_mmm64
INSTRUCTION: NP 0F 38 09 /r | PSIGNW mm1, mm2/m64 | SSSE3
	ops: rw=reg r=rm | Packed64_Int16
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Psignw_xmm_xmmm128
INSTRUCTION: 66 0F 38 09 /r | PSIGNW xmm1, xmm2/m128 | SSSE3
	ops: rw=reg r=rm | Packed128_Int16
END

# Code: VEX_Vpsignw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG 09 /r | VPSIGNW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int16
END

# Code: VEX_Vpsignw_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG 09 /r | VPSIGNW ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Int16
END

# Code: Psignd_mm_mmm64
INSTRUCTION: NP 0F 38 0A /r | PSIGND mm1, mm2/m64 | SSSE3
	ops: rw=reg r=rm | Packed64_Int32
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Psignd_xmm_xmmm128
INSTRUCTION: 66 0F 38 0A /r | PSIGND xmm1, xmm2/m128 | SSSE3
	ops: rw=reg r=rm | Packed128_Int32
END

# Code: VEX_Vpsignd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG 0A /r | VPSIGND xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int32
END

# Code: VEX_Vpsignd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG 0A /r | VPSIGND ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Int32
END

# Code: Pmulhrsw_mm_mmm64
INSTRUCTION: NP 0F 38 0B /r | PMULHRSW mm1, mm2/m64 | SSSE3
	ops: rw=reg r=rm | Packed64_Int16
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Pmulhrsw_xmm_xmmm128
INSTRUCTION: 66 0F 38 0B /r | PMULHRSW xmm1, xmm2/m128 | SSSE3
	ops: rw=reg r=rm | Packed128_Int16
END

# Code: VEX_Vpmulhrsw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG 0B /r | VPMULHRSW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int16
END

# Code: VEX_Vpmulhrsw_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG 0B /r | VPMULHRSW ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Int16
END

# Code: EVEX_Vpmulhrsw_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F38.WIG 0B /r | VPMULHRSW xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_Int16
END

# Code: EVEX_Vpmulhrsw_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F38.WIG 0B /r | VPMULHRSW ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_Int16
END

# Code: EVEX_Vpmulhrsw_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F38.WIG 0B /r | VPMULHRSW zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_Int16
END

# Code: VEX_Vpermilps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 0C /r | VPERMILPS xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vpermilps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 0C /r | VPERMILPS ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float32
END

# Code: EVEX_Vpermilps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 0C /r | VPERMILPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vpermilps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 0C /r | VPERMILPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vpermilps_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 0C /r | VPERMILPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: VEX_Vpermilpd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 0D /r | VPERMILPD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vpermilpd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 0D /r | VPERMILPD ymm1, ymm2, ymm3/m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vpermilpd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 0D /r | VPERMILPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vpermilpd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 0D /r | VPERMILPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vpermilpd_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 0D /r | VPERMILPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: VEX_Vtestps_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 0E /r | VTESTPS xmm1, xmm2/m128 | AVX
	ops: r=reg r=rm | Packed128_Float32
	rflags: w=zc 0=osap
END

# Code: VEX_Vtestps_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 0E /r | VTESTPS ymm1, ymm2/m256 | AVX
	ops: r=reg r=rm | Packed256_Float32
	rflags: w=zc 0=osap
END

# Code: VEX_Vtestpd_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 0F /r | VTESTPD xmm1, xmm2/m128 | AVX
	ops: r=reg r=rm | Packed128_Float64
	rflags: w=zc 0=osap
END

# Code: VEX_Vtestpd_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 0F /r | VTESTPD ymm1, ymm2/m256 | AVX
	ops: r=reg r=rm | Packed256_Float64
	rflags: w=zc 0=osap
END

# Code: Pblendvb_xmm_xmmm128
INSTRUCTION: 66 0F 38 10 /r | PBLENDVB xmm1, xmm2/m128, <XMM0> | SSE4_1
	ops: rw=reg r=rm | Packed128_UInt8
	implied: r=xmm0
	gas: xmm0
	masm: xmm0
	nasm: flags=mem-size=unknown xmm0
END

# Code: EVEX_Vpsrlvw_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F38.W1 10 /r | VPSRLVW xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: EVEX_Vpsrlvw_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F38.W1 10 /r | VPSRLVW ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: EVEX_Vpsrlvw_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F38.W1 10 /r | VPSRLVW zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt16
END

# Code: EVEX_Vpmovuswb_xmmm64_k1z_xmm
INSTRUCTION: EVEX.128.F3.0F38.W0 10 /r | VPMOVUSWB xmm1/m64 {k1}{z}, xmm2 | AVX512VL AVX512BW | N8
	ops: w=rm r=reg | Packed64_UInt8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovuswb_xmmm128_k1z_ymm
INSTRUCTION: EVEX.256.F3.0F38.W0 10 /r | VPMOVUSWB xmm1/m128 {k1}{z}, ymm2 | AVX512VL AVX512BW | N16
	ops: w=rm r=reg | Packed128_UInt8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovuswb_ymmm256_k1z_zmm
INSTRUCTION: EVEX.512.F3.0F38.W0 10 /r | VPMOVUSWB ymm1/m256 {k1}{z}, zmm2 | AVX512BW | N32
	ops: w=rm r=reg | Packed256_UInt8
	masm: flags=force-size=default
END

# Code: EVEX_Vpsravw_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F38.W1 11 /r | VPSRAVW xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: EVEX_Vpsravw_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F38.W1 11 /r | VPSRAVW ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: EVEX_Vpsravw_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F38.W1 11 /r | VPSRAVW zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt16
END

# Code: EVEX_Vpmovusdb_xmmm32_k1z_xmm
INSTRUCTION: EVEX.128.F3.0F38.W0 11 /r | VPMOVUSDB xmm1/m32 {k1}{z}, xmm2 | AVX512VL AVX512F | N4
	ops: w=rm r=reg | Packed32_UInt8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovusdb_xmmm64_k1z_ymm
INSTRUCTION: EVEX.256.F3.0F38.W0 11 /r | VPMOVUSDB xmm1/m64 {k1}{z}, ymm2 | AVX512VL AVX512F | N8
	ops: w=rm r=reg | Packed64_UInt8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovusdb_xmmm128_k1z_zmm
INSTRUCTION: EVEX.512.F3.0F38.W0 11 /r | VPMOVUSDB xmm1/m128 {k1}{z}, zmm2 | AVX512F | N16
	ops: w=rm r=reg | Packed128_UInt8
	masm: flags=force-size=default
END

# Code: EVEX_Vpsllvw_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F38.W1 12 /r | VPSLLVW xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: EVEX_Vpsllvw_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F38.W1 12 /r | VPSLLVW ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: EVEX_Vpsllvw_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F38.W1 12 /r | VPSLLVW zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt16
END

# Code: EVEX_Vpmovusqb_xmmm16_k1z_xmm
INSTRUCTION: EVEX.128.F3.0F38.W0 12 /r | VPMOVUSQB xmm1/m16 {k1}{z}, xmm2 | AVX512VL AVX512F | N2
	ops: w=rm r=reg | Packed16_UInt8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovusqb_xmmm32_k1z_ymm
INSTRUCTION: EVEX.256.F3.0F38.W0 12 /r | VPMOVUSQB xmm1/m32 {k1}{z}, ymm2 | AVX512VL AVX512F | N4
	ops: w=rm r=reg | Packed32_UInt8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovusqb_xmmm64_k1z_zmm
INSTRUCTION: EVEX.512.F3.0F38.W0 12 /r | VPMOVUSQB xmm1/m64 {k1}{z}, zmm2 | AVX512F | N8
	ops: w=rm r=reg | Packed64_UInt8
	masm: flags=force-size=default
END

# Code: VEX_Vcvtph2ps_xmm_xmmm64
INSTRUCTION: VEX.128.66.0F38.W0 13 /r | VCVTPH2PS xmm1, xmm2/m64 | F16C
	ops: w=reg r=rm | Packed64_Float16
	masm: flags=force-size=default
END

# Code: VEX_Vcvtph2ps_ymm_xmmm128
INSTRUCTION: VEX.256.66.0F38.W0 13 /r | VCVTPH2PS ymm1, xmm2/m128 | F16C
	ops: w=reg r=rm | Packed128_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtph2ps_xmm_k1z_xmmm64
INSTRUCTION: EVEX.128.66.0F38.W0 13 /r | VCVTPH2PS xmm1 {k1}{z}, xmm2/m64 | AVX512VL AVX512F | N8
	ops: w=reg r=rm | Packed64_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtph2ps_ymm_k1z_xmmm128
INSTRUCTION: EVEX.256.66.0F38.W0 13 /r | VCVTPH2PS ymm1 {k1}{z}, xmm2/m128 | AVX512VL AVX512F | N16
	ops: w=reg r=rm | Packed128_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtph2ps_zmm_k1z_ymmm256_sae
INSTRUCTION: EVEX.512.66.0F38.W0 13 /r | VCVTPH2PS zmm1 {k1}{z}, ymm2/m256{sae} | AVX512F | N32
	ops: wvmm=reg r=rm | Packed256_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovusdw_xmmm64_k1z_xmm
INSTRUCTION: EVEX.128.F3.0F38.W0 13 /r | VPMOVUSDW xmm1/m64 {k1}{z}, xmm2 | AVX512VL AVX512F | N8
	ops: w=rm r=reg | Packed64_UInt16
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovusdw_xmmm128_k1z_ymm
INSTRUCTION: EVEX.256.F3.0F38.W0 13 /r | VPMOVUSDW xmm1/m128 {k1}{z}, ymm2 | AVX512VL AVX512F | N16
	ops: w=rm r=reg | Packed128_UInt16
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovusdw_ymmm256_k1z_zmm
INSTRUCTION: EVEX.512.F3.0F38.W0 13 /r | VPMOVUSDW ymm1/m256 {k1}{z}, zmm2 | AVX512F | N32
	ops: w=rm r=reg | Packed256_UInt16
	masm: flags=force-size=default
END

# Code: Blendvps_xmm_xmmm128
INSTRUCTION: 66 0F 38 14 /r | BLENDVPS xmm1, xmm2/m128, <XMM0> | SSE4_1
	ops: rw=reg r=rm | Packed128_Float32
	implied: r=xmm0
	gas: xmm0
	masm: xmm0
	nasm: flags=mem-size=unknown xmm0
END

# Code: EVEX_Vprorvd_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 14 /r | VPRORVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_UInt32 Broadcast128_UInt32
END

# Code: EVEX_Vprorvd_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 14 /r | VPRORVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vprorvd_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 14 /r | VPRORVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: EVEX_Vprorvq_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 14 /r | VPRORVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Vprorvq_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 14 /r | VPRORVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vprorvq_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 14 /r | VPRORVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: EVEX_Vpmovusqw_xmmm32_k1z_xmm
INSTRUCTION: EVEX.128.F3.0F38.W0 14 /r | VPMOVUSQW xmm1/m32 {k1}{z}, xmm2 | AVX512VL AVX512F | N4
	ops: w=rm r=reg | Packed32_UInt16
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovusqw_xmmm64_k1z_ymm
INSTRUCTION: EVEX.256.F3.0F38.W0 14 /r | VPMOVUSQW xmm1/m64 {k1}{z}, ymm2 | AVX512VL AVX512F | N8
	ops: w=rm r=reg | Packed64_UInt16
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovusqw_xmmm128_k1z_zmm
INSTRUCTION: EVEX.512.F3.0F38.W0 14 /r | VPMOVUSQW xmm1/m128 {k1}{z}, zmm2 | AVX512F | N16
	ops: w=rm r=reg | Packed128_UInt16
	masm: flags=force-size=default
END

# Code: Blendvpd_xmm_xmmm128
INSTRUCTION: 66 0F 38 15 /r | BLENDVPD xmm1, xmm2/m128, <XMM0> | SSE4_1
	ops: rw=reg r=rm | Packed128_Float64
	implied: r=xmm0
	gas: xmm0
	masm: xmm0
	nasm: flags=mem-size=unknown xmm0
END

# Code: EVEX_Vprolvd_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 15 /r | VPROLVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_UInt32 Broadcast128_UInt32
END

# Code: EVEX_Vprolvd_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 15 /r | VPROLVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vprolvd_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 15 /r | VPROLVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: EVEX_Vprolvq_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 15 /r | VPROLVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Vprolvq_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 15 /r | VPROLVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vprolvq_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 15 /r | VPROLVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: EVEX_Vpmovusqd_xmmm64_k1z_xmm
INSTRUCTION: EVEX.128.F3.0F38.W0 15 /r | VPMOVUSQD xmm1/m64 {k1}{z}, xmm2 | AVX512VL AVX512F | N8
	ops: w=rm r=reg | Packed64_UInt32
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovusqd_xmmm128_k1z_ymm
INSTRUCTION: EVEX.256.F3.0F38.W0 15 /r | VPMOVUSQD xmm1/m128 {k1}{z}, ymm2 | AVX512VL AVX512F | N16
	ops: w=rm r=reg | Packed128_UInt32
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovusqd_ymmm256_k1z_zmm
INSTRUCTION: EVEX.512.F3.0F38.W0 15 /r | VPMOVUSQD ymm1/m256 {k1}{z}, zmm2 | AVX512F | N32
	ops: w=rm r=reg | Packed256_UInt32
	masm: flags=force-size=default
END

# Code: VEX_Vpermps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 16 /r | VPERMPS ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Float32
END

# Code: EVEX_Vpermps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 16 /r | VPERMPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vpermps_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 16 /r | VPERMPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vpermpd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 16 /r | VPERMPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vpermpd_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 16 /r | VPERMPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: Ptest_xmm_xmmm128
INSTRUCTION: 66 0F 38 17 /r | PTEST xmm1, xmm2/m128 | SSE4_1
	ops: r=reg r=rm | UInt128
	rflags: w=zc 0=osap
	masm: flags=force-size=default
END

# Code: VEX_Vptest_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG 17 /r | VPTEST xmm1, xmm2/m128 | AVX
	ops: r=reg r=rm | UInt128
	rflags: w=zc 0=osap
	masm: flags=force-size=default
END

# Code: VEX_Vptest_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG 17 /r | VPTEST ymm1, ymm2/m256 | AVX
	ops: r=reg r=rm | UInt256
	rflags: w=zc 0=osap
	masm: flags=force-size=default
END

# Code: VEX_Vbroadcastss_xmm_m32
INSTRUCTION: VEX.128.66.0F38.W0 18 /r | VBROADCASTSS xmm1, m32 | AVX
	ops: w=reg r=rm | Float32
	masm: flags=force-size=default
END

# Code: VEX_Vbroadcastss_ymm_m32
INSTRUCTION: VEX.256.66.0F38.W0 18 /r | VBROADCASTSS ymm1, m32 | AVX
	ops: w=reg r=rm | Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vbroadcastss_xmm_k1z_xmmm32
INSTRUCTION: EVEX.128.66.0F38.W0 18 /r | VBROADCASTSS xmm1 {k1}{z}, xmm2/m32 | AVX512VL AVX512F | N4
	ops: w=reg r=rm | Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vbroadcastss_ymm_k1z_xmmm32
INSTRUCTION: EVEX.256.66.0F38.W0 18 /r | VBROADCASTSS ymm1 {k1}{z}, xmm2/m32 | AVX512VL AVX512F | N4
	ops: w=reg r=rm | Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vbroadcastss_zmm_k1z_xmmm32
INSTRUCTION: EVEX.512.66.0F38.W0 18 /r | VBROADCASTSS zmm1 {k1}{z}, xmm2/m32 | AVX512F | N4
	ops: wvmm=reg r=rm | Float32
	masm: flags=force-size=default
END

# Code: VEX_Vbroadcastsd_ymm_m64
INSTRUCTION: VEX.256.66.0F38.W0 19 /r | VBROADCASTSD ymm1, m64 | AVX
	ops: w=reg r=rm | Float64
	masm: flags=force-size=default
END

# Code: EVEX_Vbroadcastf32x2_ymm_k1z_xmmm64
INSTRUCTION: EVEX.256.66.0F38.W0 19 /r | VBROADCASTF32X2 ymm1 {k1}{z}, xmm2/m64 | AVX512VL AVX512DQ | N8
	ops: w=reg r=rm | Packed64_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vbroadcastf32x2_zmm_k1z_xmmm64
INSTRUCTION: EVEX.512.66.0F38.W0 19 /r | VBROADCASTF32X2 zmm1 {k1}{z}, xmm2/m64 | AVX512DQ | N8
	ops: wvmm=reg r=rm | Packed64_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vbroadcastsd_ymm_k1z_xmmm64
INSTRUCTION: EVEX.256.66.0F38.W1 19 /r | VBROADCASTSD ymm1 {k1}{z}, xmm2/m64 | AVX512VL AVX512F | N8
	ops: w=reg r=rm | Float64
	masm: flags=force-size=default
END

# Code: EVEX_Vbroadcastsd_zmm_k1z_xmmm64
INSTRUCTION: EVEX.512.66.0F38.W1 19 /r | VBROADCASTSD zmm1 {k1}{z}, xmm2/m64 | AVX512F | N8
	ops: wvmm=reg r=rm | Float64
	masm: flags=force-size=default
END

# Code: VEX_Vbroadcastf128_ymm_m128
INSTRUCTION: VEX.256.66.0F38.W0 1A /r | VBROADCASTF128 ymm1, m128 | AVX
	ops: w=reg r=rm | Float128
	masm: flags=force-size=default
END

# Code: EVEX_Vbroadcastf32x4_ymm_k1z_m128
INSTRUCTION: EVEX.256.66.0F38.W0 1A /r | VBROADCASTF32X4 ymm1 {k1}{z}, m128 | AVX512VL AVX512F | N16
	ops: w=reg r=rm | Packed128_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vbroadcastf32x4_zmm_k1z_m128
INSTRUCTION: EVEX.512.66.0F38.W0 1A /r | VBROADCASTF32X4 zmm1 {k1}{z}, m128 | AVX512F | N16
	ops: wvmm=reg r=rm | Packed128_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vbroadcastf64x2_ymm_k1z_m128
INSTRUCTION: EVEX.256.66.0F38.W1 1A /r | VBROADCASTF64X2 ymm1 {k1}{z}, m128 | AVX512VL AVX512DQ | N16
	ops: w=reg r=rm | Packed128_Float64
	masm: flags=force-size=default
END

# Code: EVEX_Vbroadcastf64x2_zmm_k1z_m128
INSTRUCTION: EVEX.512.66.0F38.W1 1A /r | VBROADCASTF64X2 zmm1 {k1}{z}, m128 | AVX512DQ | N16
	ops: wvmm=reg r=rm | Packed128_Float64
	masm: flags=force-size=default
END

# Code: EVEX_Vbroadcastf32x8_zmm_k1z_m256
INSTRUCTION: EVEX.512.66.0F38.W0 1B /r | VBROADCASTF32X8 zmm1 {k1}{z}, m256 | AVX512DQ | N32
	ops: wvmm=reg r=rm | Packed256_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vbroadcastf64x4_zmm_k1z_m256
INSTRUCTION: EVEX.512.66.0F38.W1 1B /r | VBROADCASTF64X4 zmm1 {k1}{z}, m256 | AVX512F | N32
	ops: wvmm=reg r=rm | Packed256_Float64
	masm: flags=force-size=default
END

# Code: Pabsb_mm_mmm64
INSTRUCTION: NP 0F 38 1C /r | PABSB mm1, mm2/m64 | SSSE3
	ops: w=reg r=rm | Packed64_Int8
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Pabsb_xmm_xmmm128
INSTRUCTION: 66 0F 38 1C /r | PABSB xmm1, xmm2/m128 | SSSE3
	ops: w=reg r=rm | Packed128_Int8
END

# Code: VEX_Vpabsb_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG 1C /r | VPABSB xmm1, xmm2/m128 | AVX
	ops: w=reg r=rm | Packed128_Int8
END

# Code: VEX_Vpabsb_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG 1C /r | VPABSB ymm1, ymm2/m256 | AVX2
	ops: w=reg r=rm | Packed256_Int8
END

# Code: EVEX_Vpabsb_xmm_k1z_xmmm128
INSTRUCTION: EVEX.128.66.0F38.WIG 1C /r | VPABSB xmm1 {k1}{z}, xmm2/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=rm | Packed128_Int8
END

# Code: EVEX_Vpabsb_ymm_k1z_ymmm256
INSTRUCTION: EVEX.256.66.0F38.WIG 1C /r | VPABSB ymm1 {k1}{z}, ymm2/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=rm | Packed256_Int8
END

# Code: EVEX_Vpabsb_zmm_k1z_zmmm512
INSTRUCTION: EVEX.512.66.0F38.WIG 1C /r | VPABSB zmm1 {k1}{z}, zmm2/m512 | AVX512BW | N64
	ops: wvmm=reg r=rm | Packed512_Int8
END

# Code: Pabsw_mm_mmm64
INSTRUCTION: NP 0F 38 1D /r | PABSW mm1, mm2/m64 | SSSE3
	ops: w=reg r=rm | Packed64_Int16
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Pabsw_xmm_xmmm128
INSTRUCTION: 66 0F 38 1D /r | PABSW xmm1, xmm2/m128 | SSSE3
	ops: w=reg r=rm | Packed128_Int16
END

# Code: VEX_Vpabsw_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG 1D /r | VPABSW xmm1, xmm2/m128 | AVX
	ops: w=reg r=rm | Packed128_Int16
END

# Code: VEX_Vpabsw_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG 1D /r | VPABSW ymm1, ymm2/m256 | AVX2
	ops: w=reg r=rm | Packed256_Int16
END

# Code: EVEX_Vpabsw_xmm_k1z_xmmm128
INSTRUCTION: EVEX.128.66.0F38.WIG 1D /r | VPABSW xmm1 {k1}{z}, xmm2/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=rm | Packed128_Int16
END

# Code: EVEX_Vpabsw_ymm_k1z_ymmm256
INSTRUCTION: EVEX.256.66.0F38.WIG 1D /r | VPABSW ymm1 {k1}{z}, ymm2/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=rm | Packed256_Int16
END

# Code: EVEX_Vpabsw_zmm_k1z_zmmm512
INSTRUCTION: EVEX.512.66.0F38.WIG 1D /r | VPABSW zmm1 {k1}{z}, zmm2/m512 | AVX512BW | N64
	ops: wvmm=reg r=rm | Packed512_Int16
END

# Code: Pabsd_mm_mmm64
INSTRUCTION: NP 0F 38 1E /r | PABSD mm1, mm2/m64 | SSSE3
	ops: w=reg r=rm | Packed64_Int32
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Pabsd_xmm_xmmm128
INSTRUCTION: 66 0F 38 1E /r | PABSD xmm1, xmm2/m128 | SSSE3
	ops: w=reg r=rm | Packed128_Int32
END

# Code: VEX_Vpabsd_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG 1E /r | VPABSD xmm1, xmm2/m128 | AVX
	ops: w=reg r=rm | Packed128_Int32
END

# Code: VEX_Vpabsd_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG 1E /r | VPABSD ymm1, ymm2/m256 | AVX2
	ops: w=reg r=rm | Packed256_Int32
END

# Code: EVEX_Vpabsd_xmm_k1z_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 1E /r | VPABSD xmm1 {k1}{z}, xmm2/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=rm | Packed128_Int32 Broadcast128_Int32
END

# Code: EVEX_Vpabsd_ymm_k1z_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 1E /r | VPABSD ymm1 {k1}{z}, ymm2/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=rm | Packed256_Int32 Broadcast256_Int32
END

# Code: EVEX_Vpabsd_zmm_k1z_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 1E /r | VPABSD zmm1 {k1}{z}, zmm2/m512/m32bcst | AVX512F | N64b4
	ops: wvmm=reg r=rm | Packed512_Int32 Broadcast512_Int32
END

# Code: EVEX_Vpabsq_xmm_k1z_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 1F /r | VPABSQ xmm1 {k1}{z}, xmm2/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=rm | Packed128_Int64 Broadcast128_Int64
END

# Code: EVEX_Vpabsq_ymm_k1z_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 1F /r | VPABSQ ymm1 {k1}{z}, ymm2/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=rm | Packed256_Int64 Broadcast256_Int64
END

# Code: EVEX_Vpabsq_zmm_k1z_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 1F /r | VPABSQ zmm1 {k1}{z}, zmm2/m512/m64bcst | AVX512F | N64b8
	ops: wvmm=reg r=rm | Packed512_Int64 Broadcast512_Int64
END

# Code: Pmovsxbw_xmm_xmmm64
INSTRUCTION: 66 0F 38 20 /r | PMOVSXBW xmm1, xmm2/m64 | SSE4_1
	ops: w=reg r=rm | Packed64_Int8
END

# Code: VEX_Vpmovsxbw_xmm_xmmm64
INSTRUCTION: VEX.128.66.0F38.WIG 20 /r | VPMOVSXBW xmm1, xmm2/m64 | AVX
	ops: w=reg r=rm | Packed64_Int8
	masm: flags=force-size=default
END

# Code: VEX_Vpmovsxbw_ymm_xmmm128
INSTRUCTION: VEX.256.66.0F38.WIG 20 /r | VPMOVSXBW ymm1, xmm2/m128 | AVX2
	ops: w=reg r=rm | Packed128_Int8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsxbw_xmm_k1z_xmmm64
INSTRUCTION: EVEX.128.66.0F38.WIG 20 /r | VPMOVSXBW xmm1 {k1}{z}, xmm2/m64 | AVX512VL AVX512BW | N8
	ops: w=reg r=rm | Packed64_Int8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsxbw_ymm_k1z_xmmm128
INSTRUCTION: EVEX.256.66.0F38.WIG 20 /r | VPMOVSXBW ymm1 {k1}{z}, xmm2/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=rm | Packed128_Int8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsxbw_zmm_k1z_ymmm256
INSTRUCTION: EVEX.512.66.0F38.WIG 20 /r | VPMOVSXBW zmm1 {k1}{z}, ymm2/m256 | AVX512BW | N32
	ops: wvmm=reg r=rm | Packed256_Int8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovswb_xmmm64_k1z_xmm
INSTRUCTION: EVEX.128.F3.0F38.W0 20 /r | VPMOVSWB xmm1/m64 {k1}{z}, xmm2 | AVX512VL AVX512BW | N8
	ops: w=rm r=reg | Packed64_Int8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovswb_xmmm128_k1z_ymm
INSTRUCTION: EVEX.256.F3.0F38.W0 20 /r | VPMOVSWB xmm1/m128 {k1}{z}, ymm2 | AVX512VL AVX512BW | N16
	ops: w=rm r=reg | Packed128_Int8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovswb_ymmm256_k1z_zmm
INSTRUCTION: EVEX.512.F3.0F38.W0 20 /r | VPMOVSWB ymm1/m256 {k1}{z}, zmm2 | AVX512BW | N32
	ops: w=rm r=reg | Packed256_Int8
	masm: flags=force-size=default
END

# Code: Pmovsxbd_xmm_xmmm32
INSTRUCTION: 66 0F 38 21 /r | PMOVSXBD xmm1, xmm2/m32 | SSE4_1
	ops: w=reg r=rm | Packed32_Int8
END

# Code: VEX_Vpmovsxbd_xmm_xmmm32
INSTRUCTION: VEX.128.66.0F38.WIG 21 /r | VPMOVSXBD xmm1, xmm2/m32 | AVX
	ops: w=reg r=rm | Packed32_Int8
	masm: flags=force-size=default
END

# Code: VEX_Vpmovsxbd_ymm_xmmm64
INSTRUCTION: VEX.256.66.0F38.WIG 21 /r | VPMOVSXBD ymm1, xmm2/m64 | AVX2
	ops: w=reg r=rm | Packed64_Int8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsxbd_xmm_k1z_xmmm32
INSTRUCTION: EVEX.128.66.0F38.WIG 21 /r | VPMOVSXBD xmm1 {k1}{z}, xmm2/m32 | AVX512VL AVX512F | N4
	ops: w=reg r=rm | Packed32_Int8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsxbd_ymm_k1z_xmmm64
INSTRUCTION: EVEX.256.66.0F38.WIG 21 /r | VPMOVSXBD ymm1 {k1}{z}, xmm2/m64 | AVX512VL AVX512F | N8
	ops: w=reg r=rm | Packed64_Int8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsxbd_zmm_k1z_xmmm128
INSTRUCTION: EVEX.512.66.0F38.WIG 21 /r | VPMOVSXBD zmm1 {k1}{z}, xmm2/m128 | AVX512F | N16
	ops: wvmm=reg r=rm | Packed128_Int8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsdb_xmmm32_k1z_xmm
INSTRUCTION: EVEX.128.F3.0F38.W0 21 /r | VPMOVSDB xmm1/m32 {k1}{z}, xmm2 | AVX512VL AVX512F | N4
	ops: w=rm r=reg | Packed32_Int8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsdb_xmmm64_k1z_ymm
INSTRUCTION: EVEX.256.F3.0F38.W0 21 /r | VPMOVSDB xmm1/m64 {k1}{z}, ymm2 | AVX512VL AVX512F | N8
	ops: w=rm r=reg | Packed64_Int8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsdb_xmmm128_k1z_zmm
INSTRUCTION: EVEX.512.F3.0F38.W0 21 /r | VPMOVSDB xmm1/m128 {k1}{z}, zmm2 | AVX512F | N16
	ops: w=rm r=reg | Packed128_Int8
	masm: flags=force-size=default
END

# Code: Pmovsxbq_xmm_xmmm16
INSTRUCTION: 66 0F 38 22 /r | PMOVSXBQ xmm1, xmm2/m16 | SSE4_1
	ops: w=reg r=rm | Packed16_Int8
END

# Code: VEX_Vpmovsxbq_xmm_xmmm16
INSTRUCTION: VEX.128.66.0F38.WIG 22 /r | VPMOVSXBQ xmm1, xmm2/m16 | AVX
	ops: w=reg r=rm | Packed16_Int8
	masm: flags=force-size=default
END

# Code: VEX_Vpmovsxbq_ymm_xmmm32
INSTRUCTION: VEX.256.66.0F38.WIG 22 /r | VPMOVSXBQ ymm1, xmm2/m32 | AVX2
	ops: w=reg r=rm | Packed32_Int8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsxbq_xmm_k1z_xmmm16
INSTRUCTION: EVEX.128.66.0F38.WIG 22 /r | VPMOVSXBQ xmm1 {k1}{z}, xmm2/m16 | AVX512VL AVX512F | N2
	ops: w=reg r=rm | Packed16_Int8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsxbq_ymm_k1z_xmmm32
INSTRUCTION: EVEX.256.66.0F38.WIG 22 /r | VPMOVSXBQ ymm1 {k1}{z}, xmm2/m32 | AVX512VL AVX512F | N4
	ops: w=reg r=rm | Packed32_Int8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsxbq_zmm_k1z_xmmm64
INSTRUCTION: EVEX.512.66.0F38.WIG 22 /r | VPMOVSXBQ zmm1 {k1}{z}, xmm2/m64 | AVX512F | N8
	ops: wvmm=reg r=rm | Packed64_Int8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsqb_xmmm16_k1z_xmm
INSTRUCTION: EVEX.128.F3.0F38.W0 22 /r | VPMOVSQB xmm1/m16 {k1}{z}, xmm2 | AVX512VL AVX512F | N2
	ops: w=rm r=reg | Packed16_Int8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsqb_xmmm32_k1z_ymm
INSTRUCTION: EVEX.256.F3.0F38.W0 22 /r | VPMOVSQB xmm1/m32 {k1}{z}, ymm2 | AVX512VL AVX512F | N4
	ops: w=rm r=reg | Packed32_Int8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsqb_xmmm64_k1z_zmm
INSTRUCTION: EVEX.512.F3.0F38.W0 22 /r | VPMOVSQB xmm1/m64 {k1}{z}, zmm2 | AVX512F | N8
	ops: w=rm r=reg | Packed64_Int8
	masm: flags=force-size=default
END

# Code: Pmovsxwd_xmm_xmmm64
INSTRUCTION: 66 0F 38 23 /r | PMOVSXWD xmm1, xmm2/m64 | SSE4_1
	ops: w=reg r=rm | Packed64_Int16
END

# Code: VEX_Vpmovsxwd_xmm_xmmm64
INSTRUCTION: VEX.128.66.0F38.WIG 23 /r | VPMOVSXWD xmm1, xmm2/m64 | AVX
	ops: w=reg r=rm | Packed64_Int16
	masm: flags=force-size=default
END

# Code: VEX_Vpmovsxwd_ymm_xmmm128
INSTRUCTION: VEX.256.66.0F38.WIG 23 /r | VPMOVSXWD ymm1, xmm2/m128 | AVX2
	ops: w=reg r=rm | Packed128_Int16
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsxwd_xmm_k1z_xmmm64
INSTRUCTION: EVEX.128.66.0F38.WIG 23 /r | VPMOVSXWD xmm1 {k1}{z}, xmm2/m64 | AVX512VL AVX512F | N8
	ops: w=reg r=rm | Packed64_Int16
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsxwd_ymm_k1z_xmmm128
INSTRUCTION: EVEX.256.66.0F38.WIG 23 /r | VPMOVSXWD ymm1 {k1}{z}, xmm2/m128 | AVX512VL AVX512F | N16
	ops: w=reg r=rm | Packed128_Int16
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsxwd_zmm_k1z_ymmm256
INSTRUCTION: EVEX.512.66.0F38.WIG 23 /r | VPMOVSXWD zmm1 {k1}{z}, ymm2/m256 | AVX512F | N32
	ops: wvmm=reg r=rm | Packed256_Int16
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsdw_xmmm64_k1z_xmm
INSTRUCTION: EVEX.128.F3.0F38.W0 23 /r | VPMOVSDW xmm1/m64 {k1}{z}, xmm2 | AVX512VL AVX512F | N8
	ops: w=rm r=reg | Packed64_Int16
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsdw_xmmm128_k1z_ymm
INSTRUCTION: EVEX.256.F3.0F38.W0 23 /r | VPMOVSDW xmm1/m128 {k1}{z}, ymm2 | AVX512VL AVX512F | N16
	ops: w=rm r=reg | Packed128_Int16
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsdw_ymmm256_k1z_zmm
INSTRUCTION: EVEX.512.F3.0F38.W0 23 /r | VPMOVSDW ymm1/m256 {k1}{z}, zmm2 | AVX512F | N32
	ops: w=rm r=reg | Packed256_Int16
	masm: flags=force-size=default
END

# Code: Pmovsxwq_xmm_xmmm32
INSTRUCTION: 66 0F 38 24 /r | PMOVSXWQ xmm1, xmm2/m32 | SSE4_1
	ops: w=reg r=rm | Packed32_Int16
END

# Code: VEX_Vpmovsxwq_xmm_xmmm32
INSTRUCTION: VEX.128.66.0F38.WIG 24 /r | VPMOVSXWQ xmm1, xmm2/m32 | AVX
	ops: w=reg r=rm | Packed32_Int16
	masm: flags=force-size=default
END

# Code: VEX_Vpmovsxwq_ymm_xmmm64
INSTRUCTION: VEX.256.66.0F38.WIG 24 /r | VPMOVSXWQ ymm1, xmm2/m64 | AVX2
	ops: w=reg r=rm | Packed64_Int16
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsxwq_xmm_k1z_xmmm32
INSTRUCTION: EVEX.128.66.0F38.WIG 24 /r | VPMOVSXWQ xmm1 {k1}{z}, xmm2/m32 | AVX512VL AVX512F | N4
	ops: w=reg r=rm | Packed32_Int16
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsxwq_ymm_k1z_xmmm64
INSTRUCTION: EVEX.256.66.0F38.WIG 24 /r | VPMOVSXWQ ymm1 {k1}{z}, xmm2/m64 | AVX512VL AVX512F | N8
	ops: w=reg r=rm | Packed64_Int16
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsxwq_zmm_k1z_xmmm128
INSTRUCTION: EVEX.512.66.0F38.WIG 24 /r | VPMOVSXWQ zmm1 {k1}{z}, xmm2/m128 | AVX512F | N16
	ops: wvmm=reg r=rm | Packed128_Int16
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsqw_xmmm32_k1z_xmm
INSTRUCTION: EVEX.128.F3.0F38.W0 24 /r | VPMOVSQW xmm1/m32 {k1}{z}, xmm2 | AVX512VL AVX512F | N4
	ops: w=rm r=reg | Packed32_Int16
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsqw_xmmm64_k1z_ymm
INSTRUCTION: EVEX.256.F3.0F38.W0 24 /r | VPMOVSQW xmm1/m64 {k1}{z}, ymm2 | AVX512VL AVX512F | N8
	ops: w=rm r=reg | Packed64_Int16
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsqw_xmmm128_k1z_zmm
INSTRUCTION: EVEX.512.F3.0F38.W0 24 /r | VPMOVSQW xmm1/m128 {k1}{z}, zmm2 | AVX512F | N16
	ops: w=rm r=reg | Packed128_Int16
	masm: flags=force-size=default
END

# Code: Pmovsxdq_xmm_xmmm64
INSTRUCTION: 66 0F 38 25 /r | PMOVSXDQ xmm1, xmm2/m64 | SSE4_1
	ops: w=reg r=rm | Packed64_Int32
END

# Code: VEX_Vpmovsxdq_xmm_xmmm64
INSTRUCTION: VEX.128.66.0F38.WIG 25 /r | VPMOVSXDQ xmm1, xmm2/m64 | AVX
	ops: w=reg r=rm | Packed64_Int32
	masm: flags=force-size=default
END

# Code: VEX_Vpmovsxdq_ymm_xmmm128
INSTRUCTION: VEX.256.66.0F38.WIG 25 /r | VPMOVSXDQ ymm1, xmm2/m128 | AVX2
	ops: w=reg r=rm | Packed128_Int32
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsxdq_xmm_k1z_xmmm64
INSTRUCTION: EVEX.128.66.0F38.W0 25 /r | VPMOVSXDQ xmm1 {k1}{z}, xmm2/m64 | AVX512VL AVX512F | N8
	ops: w=reg r=rm | Packed64_Int32
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsxdq_ymm_k1z_xmmm128
INSTRUCTION: EVEX.256.66.0F38.W0 25 /r | VPMOVSXDQ ymm1 {k1}{z}, xmm2/m128 | AVX512VL AVX512F | N16
	ops: w=reg r=rm | Packed128_Int32
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsxdq_zmm_k1z_ymmm256
INSTRUCTION: EVEX.512.66.0F38.W0 25 /r | VPMOVSXDQ zmm1 {k1}{z}, ymm2/m256 | AVX512F | N32
	ops: wvmm=reg r=rm | Packed256_Int32
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsqd_xmmm64_k1z_xmm
INSTRUCTION: EVEX.128.F3.0F38.W0 25 /r | VPMOVSQD xmm1/m64 {k1}{z}, xmm2 | AVX512VL AVX512F | N8
	ops: w=rm r=reg | Packed64_Int32
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsqd_xmmm128_k1z_ymm
INSTRUCTION: EVEX.256.F3.0F38.W0 25 /r | VPMOVSQD xmm1/m128 {k1}{z}, ymm2 | AVX512VL AVX512F | N16
	ops: w=rm r=reg | Packed128_Int32
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovsqd_ymmm256_k1z_zmm
INSTRUCTION: EVEX.512.F3.0F38.W0 25 /r | VPMOVSQD ymm1/m256 {k1}{z}, zmm2 | AVX512F | N32
	ops: w=rm r=reg | Packed256_Int32
	masm: flags=force-size=default
END

# Code: EVEX_Vptestmb_kr_k1_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F38.W0 26 /r | VPTESTMB k2 {k1}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
	flags: implied-z
END

# Code: EVEX_Vptestmb_kr_k1_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F38.W0 26 /r | VPTESTMB k2 {k1}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
	flags: implied-z
END

# Code: EVEX_Vptestmb_kr_k1_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F38.W0 26 /r | VPTESTMB k2 {k1}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: w=reg r=vvvv r=rm | Packed512_UInt8
	flags: implied-z
END

# Code: EVEX_Vptestmw_kr_k1_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F38.W1 26 /r | VPTESTMW k2 {k1}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
	flags: implied-z
END

# Code: EVEX_Vptestmw_kr_k1_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F38.W1 26 /r | VPTESTMW k2 {k1}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
	flags: implied-z
END

# Code: EVEX_Vptestmw_kr_k1_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F38.W1 26 /r | VPTESTMW k2 {k1}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: w=reg r=vvvv r=rm | Packed512_UInt16
	flags: implied-z
END

# Code: EVEX_Vptestnmb_kr_k1_xmm_xmmm128
INSTRUCTION: EVEX.128.F3.0F38.W0 26 /r | VPTESTNMB k2 {k1}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
	flags: implied-z
END

# Code: EVEX_Vptestnmb_kr_k1_ymm_ymmm256
INSTRUCTION: EVEX.256.F3.0F38.W0 26 /r | VPTESTNMB k2 {k1}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
	flags: implied-z
END

# Code: EVEX_Vptestnmb_kr_k1_zmm_zmmm512
INSTRUCTION: EVEX.512.F3.0F38.W0 26 /r | VPTESTNMB k2 {k1}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: w=reg r=vvvv r=rm | Packed512_UInt8
	flags: implied-z
END

# Code: EVEX_Vptestnmw_kr_k1_xmm_xmmm128
INSTRUCTION: EVEX.128.F3.0F38.W1 26 /r | VPTESTNMW k2 {k1}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
	flags: implied-z
END

# Code: EVEX_Vptestnmw_kr_k1_ymm_ymmm256
INSTRUCTION: EVEX.256.F3.0F38.W1 26 /r | VPTESTNMW k2 {k1}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
	flags: implied-z
END

# Code: EVEX_Vptestnmw_kr_k1_zmm_zmmm512
INSTRUCTION: EVEX.512.F3.0F38.W1 26 /r | VPTESTNMW k2 {k1}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: w=reg r=vvvv r=rm | Packed512_UInt16
	flags: implied-z
END

# Code: EVEX_Vptestmd_kr_k1_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 27 /r | VPTESTMD k2 {k1}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_UInt32 Broadcast128_UInt32
	flags: implied-z
END

# Code: EVEX_Vptestmd_kr_k1_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 27 /r | VPTESTMD k2 {k1}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_UInt32 Broadcast256_UInt32
	flags: implied-z
END

# Code: EVEX_Vptestmd_kr_k1_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 27 /r | VPTESTMD k2 {k1}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: w=reg r=vvvv r=rm | Packed512_UInt32 Broadcast512_UInt32
	flags: implied-z
END

# Code: EVEX_Vptestmq_kr_k1_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 27 /r | VPTESTMQ k2 {k1}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_UInt64 Broadcast128_UInt64
	flags: implied-z
END

# Code: EVEX_Vptestmq_kr_k1_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 27 /r | VPTESTMQ k2 {k1}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_UInt64 Broadcast256_UInt64
	flags: implied-z
END

# Code: EVEX_Vptestmq_kr_k1_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 27 /r | VPTESTMQ k2 {k1}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: w=reg r=vvvv r=rm | Packed512_UInt64 Broadcast512_UInt64
	flags: implied-z
END

# Code: EVEX_Vptestnmd_kr_k1_xmm_xmmm128b32
INSTRUCTION: EVEX.128.F3.0F38.W0 27 /r | VPTESTNMD k2 {k1}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_UInt32 Broadcast128_UInt32
	flags: implied-z
END

# Code: EVEX_Vptestnmd_kr_k1_ymm_ymmm256b32
INSTRUCTION: EVEX.256.F3.0F38.W0 27 /r | VPTESTNMD k2 {k1}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_UInt32 Broadcast256_UInt32
	flags: implied-z
END

# Code: EVEX_Vptestnmd_kr_k1_zmm_zmmm512b32
INSTRUCTION: EVEX.512.F3.0F38.W0 27 /r | VPTESTNMD k2 {k1}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: w=reg r=vvvv r=rm | Packed512_UInt32 Broadcast512_UInt32
	flags: implied-z
END

# Code: EVEX_Vptestnmq_kr_k1_xmm_xmmm128b64
INSTRUCTION: EVEX.128.F3.0F38.W1 27 /r | VPTESTNMQ k2 {k1}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_UInt64 Broadcast128_UInt64
	flags: implied-z
END

# Code: EVEX_Vptestnmq_kr_k1_ymm_ymmm256b64
INSTRUCTION: EVEX.256.F3.0F38.W1 27 /r | VPTESTNMQ k2 {k1}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_UInt64 Broadcast256_UInt64
	flags: implied-z
END

# Code: EVEX_Vptestnmq_kr_k1_zmm_zmmm512b64
INSTRUCTION: EVEX.512.F3.0F38.W1 27 /r | VPTESTNMQ k2 {k1}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: w=reg r=vvvv r=rm | Packed512_UInt64 Broadcast512_UInt64
	flags: implied-z
END

# Code: Pmuldq_xmm_xmmm128
INSTRUCTION: 66 0F 38 28 /r | PMULDQ xmm1, xmm2/m128 | SSE4_1
	ops: rw=reg r=rm | Packed128_Int32
END

# Code: VEX_Vpmuldq_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG 28 /r | VPMULDQ xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int32
END

# Code: VEX_Vpmuldq_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG 28 /r | VPMULDQ ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Int32
END

# Code: EVEX_Vpmuldq_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 28 /r | VPMULDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_Int32 Broadcast128_2xInt32
END

# Code: EVEX_Vpmuldq_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 28 /r | VPMULDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_Int32 Broadcast256_2xInt32
END

# Code: EVEX_Vpmuldq_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 28 /r | VPMULDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_Int32 Broadcast512_2xInt32
END

# Code: EVEX_Vpmovm2b_xmm_kr
INSTRUCTION: EVEX.128.F3.0F38.W0 28 /r | VPMOVM2B xmm1, k1 | AVX512VL AVX512BW
	ops: w=reg r=rm
END

# Code: EVEX_Vpmovm2b_ymm_kr
INSTRUCTION: EVEX.256.F3.0F38.W0 28 /r | VPMOVM2B ymm1, k1 | AVX512VL AVX512BW
	ops: w=reg r=rm
END

# Code: EVEX_Vpmovm2b_zmm_kr
INSTRUCTION: EVEX.512.F3.0F38.W0 28 /r | VPMOVM2B zmm1, k1 | AVX512BW
	ops: w=reg r=rm
END

# Code: EVEX_Vpmovm2w_xmm_kr
INSTRUCTION: EVEX.128.F3.0F38.W1 28 /r | VPMOVM2W xmm1, k1 | AVX512VL AVX512BW
	ops: w=reg r=rm
END

# Code: EVEX_Vpmovm2w_ymm_kr
INSTRUCTION: EVEX.256.F3.0F38.W1 28 /r | VPMOVM2W ymm1, k1 | AVX512VL AVX512BW
	ops: w=reg r=rm
END

# Code: EVEX_Vpmovm2w_zmm_kr
INSTRUCTION: EVEX.512.F3.0F38.W1 28 /r | VPMOVM2W zmm1, k1 | AVX512BW
	ops: w=reg r=rm
END

# Code: Pcmpeqq_xmm_xmmm128
INSTRUCTION: 66 0F 38 29 /r | PCMPEQQ xmm1, xmm2/m128 | SSE4_1
	ops: rw=reg r=rm | Packed128_UInt64
END

# Code: VEX_Vpcmpeqq_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG 29 /r | VPCMPEQQ xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt64
END

# Code: VEX_Vpcmpeqq_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG 29 /r | VPCMPEQQ ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt64
END

# Code: EVEX_Vpcmpeqq_kr_k1_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 29 /r | VPCMPEQQ k1 {k2}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_UInt64 Broadcast128_UInt64
	flags: implied-z
END

# Code: EVEX_Vpcmpeqq_kr_k1_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 29 /r | VPCMPEQQ k1 {k2}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_UInt64 Broadcast256_UInt64
	flags: implied-z
END

# Code: EVEX_Vpcmpeqq_kr_k1_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 29 /r | VPCMPEQQ k1 {k2}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: w=reg r=vvvv r=rm | Packed512_UInt64 Broadcast512_UInt64
	flags: implied-z
END

# Code: EVEX_Vpmovb2m_kr_xmm
INSTRUCTION: EVEX.128.F3.0F38.W0 29 /r | VPMOVB2M k1, xmm1 | AVX512VL AVX512BW
	ops: w=reg r=rm
END

# Code: EVEX_Vpmovb2m_kr_ymm
INSTRUCTION: EVEX.256.F3.0F38.W0 29 /r | VPMOVB2M k1, ymm1 | AVX512VL AVX512BW
	ops: w=reg r=rm
END

# Code: EVEX_Vpmovb2m_kr_zmm
INSTRUCTION: EVEX.512.F3.0F38.W0 29 /r | VPMOVB2M k1, zmm1 | AVX512BW
	ops: w=reg r=rm
END

# Code: EVEX_Vpmovw2m_kr_xmm
INSTRUCTION: EVEX.128.F3.0F38.W1 29 /r | VPMOVW2M k1, xmm1 | AVX512VL AVX512BW
	ops: w=reg r=rm
END

# Code: EVEX_Vpmovw2m_kr_ymm
INSTRUCTION: EVEX.256.F3.0F38.W1 29 /r | VPMOVW2M k1, ymm1 | AVX512VL AVX512BW
	ops: w=reg r=rm
END

# Code: EVEX_Vpmovw2m_kr_zmm
INSTRUCTION: EVEX.512.F3.0F38.W1 29 /r | VPMOVW2M k1, zmm1 | AVX512BW
	ops: w=reg r=rm
END

# Code: Movntdqa_xmm_m128
INSTRUCTION: 66 0F 38 2A /r | MOVNTDQA xmm1, m128 | SSE4_1
	ops: w=reg r=rm | UInt128
	flags: tsx-impl-abort non-temporal
	masm: flags=force-size=default
END

# Code: VEX_Vmovntdqa_xmm_m128
INSTRUCTION: VEX.128.66.0F38.WIG 2A /r | VMOVNTDQA xmm1, m128 | AVX
	ops: w=reg r=rm | UInt128
	flags: tsx-impl-abort non-temporal
	masm: flags=force-size=default
END

# Code: VEX_Vmovntdqa_ymm_m256
INSTRUCTION: VEX.256.66.0F38.WIG 2A /r | VMOVNTDQA ymm1, m256 | AVX2
	ops: w=reg r=rm | UInt256
	flags: tsx-impl-abort non-temporal
	masm: flags=force-size=default
END

# Code: EVEX_Vmovntdqa_xmm_m128
INSTRUCTION: EVEX.128.66.0F38.W0 2A /r | VMOVNTDQA xmm1, m128 | AVX512VL AVX512F | N16
	ops: w=reg r=rm | UInt128
	flags: tsx-impl-abort non-temporal
	masm: flags=force-size=default
END

# Code: EVEX_Vmovntdqa_ymm_m256
INSTRUCTION: EVEX.256.66.0F38.W0 2A /r | VMOVNTDQA ymm1, m256 | AVX512VL AVX512F | N32
	ops: w=reg r=rm | UInt256
	flags: tsx-impl-abort non-temporal
	masm: flags=force-size=default
END

# Code: EVEX_Vmovntdqa_zmm_m512
INSTRUCTION: EVEX.512.66.0F38.W0 2A /r | VMOVNTDQA zmm1, m512 | AVX512F | N64
	ops: w=reg r=rm | UInt512
	flags: tsx-impl-abort non-temporal
	masm: flags=force-size=default
END

# Code: EVEX_Vpbroadcastmb2q_xmm_kr
INSTRUCTION: EVEX.128.F3.0F38.W1 2A /r | VPBROADCASTMB2Q xmm1, k1 | AVX512VL AVX512CD
	ops: w=reg r=rm
END

# Code: EVEX_Vpbroadcastmb2q_ymm_kr
INSTRUCTION: EVEX.256.F3.0F38.W1 2A /r | VPBROADCASTMB2Q ymm1, k1 | AVX512VL AVX512CD
	ops: w=reg r=rm
END

# Code: EVEX_Vpbroadcastmb2q_zmm_kr
INSTRUCTION: EVEX.512.F3.0F38.W1 2A /r | VPBROADCASTMB2Q zmm1, k1 | AVX512CD
	ops: w=reg r=rm
END

# Code: Packusdw_xmm_xmmm128
INSTRUCTION: 66 0F 38 2B /r | PACKUSDW xmm1, xmm2/m128 | SSE4_1
	ops: rw=reg r=rm | Packed128_Int32
END

# Code: VEX_Vpackusdw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG 2B /r | VPACKUSDW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int32
END

# Code: VEX_Vpackusdw_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG 2B /r | VPACKUSDW ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Int32
END

# Code: EVEX_Vpackusdw_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 2B /r | VPACKUSDW xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512BW | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_Int32 Broadcast128_Int32
END

# Code: EVEX_Vpackusdw_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 2B /r | VPACKUSDW ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512BW | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_Int32 Broadcast256_Int32
END

# Code: EVEX_Vpackusdw_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 2B /r | VPACKUSDW zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512BW | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_Int32 Broadcast512_Int32
END

# Code: VEX_Vmaskmovps_xmm_xmm_m128
INSTRUCTION: VEX.128.66.0F38.W0 2C /r | VMASKMOVPS xmm1, xmm2, m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vmaskmovps_ymm_ymm_m256
INSTRUCTION: VEX.256.66.0F38.W0 2C /r | VMASKMOVPS ymm1, ymm2, m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float32
END

# Code: EVEX_Vscalefps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 2C /r | VSCALEFPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vscalefps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 2C /r | VSCALEFPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vscalefps_zmm_k1z_zmm_zmmm512b32_er
INSTRUCTION: EVEX.512.66.0F38.W0 2C /r | VSCALEFPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er} | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vscalefpd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 2C /r | VSCALEFPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vscalefpd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 2C /r | VSCALEFPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vscalefpd_zmm_k1z_zmm_zmmm512b64_er
INSTRUCTION: EVEX.512.66.0F38.W1 2C /r | VSCALEFPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er} | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: VEX_Vmaskmovpd_xmm_xmm_m128
INSTRUCTION: VEX.128.66.0F38.W0 2D /r | VMASKMOVPD xmm1, xmm2, m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vmaskmovpd_ymm_ymm_m256
INSTRUCTION: VEX.256.66.0F38.W0 2D /r | VMASKMOVPD ymm1, ymm2, m256 | AVX
	ops: w=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vscalefss_xmm_k1z_xmm_xmmm32_er
INSTRUCTION: EVEX.LIG.66.0F38.W0 2D /r | VSCALEFSS xmm1 {k1}{z}, xmm2, xmm3/m32{er} | AVX512F | N4
	ops: w=reg r=vvvv r=rm | Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vscalefsd_xmm_k1z_xmm_xmmm64_er
INSTRUCTION: EVEX.LIG.66.0F38.W1 2D /r | VSCALEFSD xmm1 {k1}{z}, xmm2, xmm3/m64{er} | AVX512F | N8
	ops: w=reg r=vvvv r=rm | Float64
	masm: flags=force-size=default
END

# Code: VEX_Vmaskmovps_m128_xmm_xmm
INSTRUCTION: VEX.128.66.0F38.W0 2E /r | VMASKMOVPS m128, xmm1, xmm2 | AVX
	ops: w=rm r=vvvv r=reg | Packed128_Float32
END

# Code: VEX_Vmaskmovps_m256_ymm_ymm
INSTRUCTION: VEX.256.66.0F38.W0 2E /r | VMASKMOVPS m256, ymm1, ymm2 | AVX
	ops: w=rm r=vvvv r=reg | Packed256_Float32
END

# Code: VEX_Vmaskmovpd_m128_xmm_xmm
INSTRUCTION: VEX.128.66.0F38.W0 2F /r | VMASKMOVPD m128, xmm1, xmm2 | AVX
	ops: w=rm r=vvvv r=reg | Packed128_Float64
END

# Code: VEX_Vmaskmovpd_m256_ymm_ymm
INSTRUCTION: VEX.256.66.0F38.W0 2F /r | VMASKMOVPD m256, ymm1, ymm2 | AVX
	ops: w=rm r=vvvv r=reg | Packed256_Float64
END

# Code: Pmovzxbw_xmm_xmmm64
INSTRUCTION: 66 0F 38 30 /r | PMOVZXBW xmm1, xmm2/m64 | SSE4_1
	ops: w=reg r=rm | Packed64_UInt8
END

# Code: VEX_Vpmovzxbw_xmm_xmmm64
INSTRUCTION: VEX.128.66.0F38.WIG 30 /r | VPMOVZXBW xmm1, xmm2/m64 | AVX
	ops: w=reg r=rm | Packed64_UInt8
	masm: flags=force-size=default
END

# Code: VEX_Vpmovzxbw_ymm_xmmm128
INSTRUCTION: VEX.256.66.0F38.WIG 30 /r | VPMOVZXBW ymm1, xmm2/m128 | AVX2
	ops: w=reg r=rm | Packed128_UInt8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovzxbw_xmm_k1z_xmmm64
INSTRUCTION: EVEX.128.66.0F38.WIG 30 /r | VPMOVZXBW xmm1 {k1}{z}, xmm2/m64 | AVX512VL AVX512BW | N8
	ops: w=reg r=rm | Packed64_UInt8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovzxbw_ymm_k1z_xmmm128
INSTRUCTION: EVEX.256.66.0F38.WIG 30 /r | VPMOVZXBW ymm1 {k1}{z}, xmm2/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=rm | Packed128_UInt8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovzxbw_zmm_k1z_ymmm256
INSTRUCTION: EVEX.512.66.0F38.WIG 30 /r | VPMOVZXBW zmm1 {k1}{z}, ymm2/m256 | AVX512BW | N32
	ops: wvmm=reg r=rm | Packed256_UInt8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovwb_xmmm64_k1z_xmm
INSTRUCTION: EVEX.128.F3.0F38.W0 30 /r | VPMOVWB xmm1/m64 {k1}{z}, xmm2 | AVX512VL AVX512BW | N8
	ops: w=rm r=reg | Packed64_UInt8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovwb_xmmm128_k1z_ymm
INSTRUCTION: EVEX.256.F3.0F38.W0 30 /r | VPMOVWB xmm1/m128 {k1}{z}, ymm2 | AVX512VL AVX512BW | N16
	ops: w=rm r=reg | Packed128_UInt8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovwb_ymmm256_k1z_zmm
INSTRUCTION: EVEX.512.F3.0F38.W0 30 /r | VPMOVWB ymm1/m256 {k1}{z}, zmm2 | AVX512BW | N32
	ops: w=rm r=reg | Packed256_UInt8
	masm: flags=force-size=default
END

# Code: Pmovzxbd_xmm_xmmm32
INSTRUCTION: 66 0F 38 31 /r | PMOVZXBD xmm1, xmm2/m32 | SSE4_1
	ops: w=reg r=rm | Packed32_UInt8
END

# Code: VEX_Vpmovzxbd_xmm_xmmm32
INSTRUCTION: VEX.128.66.0F38.WIG 31 /r | VPMOVZXBD xmm1, xmm2/m32 | AVX
	ops: w=reg r=rm | Packed32_UInt8
	masm: flags=force-size=default
END

# Code: VEX_Vpmovzxbd_ymm_xmmm64
INSTRUCTION: VEX.256.66.0F38.WIG 31 /r | VPMOVZXBD ymm1, xmm2/m64 | AVX2
	ops: w=reg r=rm | Packed64_UInt8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovzxbd_xmm_k1z_xmmm32
INSTRUCTION: EVEX.128.66.0F38.WIG 31 /r | VPMOVZXBD xmm1 {k1}{z}, xmm2/m32 | AVX512VL AVX512F | N4
	ops: w=reg r=rm | Packed32_UInt8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovzxbd_ymm_k1z_xmmm64
INSTRUCTION: EVEX.256.66.0F38.WIG 31 /r | VPMOVZXBD ymm1 {k1}{z}, xmm2/m64 | AVX512VL AVX512F | N8
	ops: w=reg r=rm | Packed64_UInt8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovzxbd_zmm_k1z_xmmm128
INSTRUCTION: EVEX.512.66.0F38.WIG 31 /r | VPMOVZXBD zmm1 {k1}{z}, xmm2/m128 | AVX512F | N16
	ops: wvmm=reg r=rm | Packed128_UInt8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovdb_xmmm32_k1z_xmm
INSTRUCTION: EVEX.128.F3.0F38.W0 31 /r | VPMOVDB xmm1/m32 {k1}{z}, xmm2 | AVX512VL AVX512F | N4
	ops: w=rm r=reg | Packed32_UInt8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovdb_xmmm64_k1z_ymm
INSTRUCTION: EVEX.256.F3.0F38.W0 31 /r | VPMOVDB xmm1/m64 {k1}{z}, ymm2 | AVX512VL AVX512F | N8
	ops: w=rm r=reg | Packed64_UInt8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovdb_xmmm128_k1z_zmm
INSTRUCTION: EVEX.512.F3.0F38.W0 31 /r | VPMOVDB xmm1/m128 {k1}{z}, zmm2 | AVX512F | N16
	ops: w=rm r=reg | Packed128_UInt8
	masm: flags=force-size=default
END

# Code: Pmovzxbq_xmm_xmmm16
INSTRUCTION: 66 0F 38 32 /r | PMOVZXBQ xmm1, xmm2/m16 | SSE4_1
	ops: w=reg r=rm | Packed16_UInt8
END

# Code: VEX_Vpmovzxbq_xmm_xmmm16
INSTRUCTION: VEX.128.66.0F38.WIG 32 /r | VPMOVZXBQ xmm1, xmm2/m16 | AVX
	ops: w=reg r=rm | Packed16_UInt8
	masm: flags=force-size=default
END

# Code: VEX_Vpmovzxbq_ymm_xmmm32
INSTRUCTION: VEX.256.66.0F38.WIG 32 /r | VPMOVZXBQ ymm1, xmm2/m32 | AVX2
	ops: w=reg r=rm | Packed32_UInt8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovzxbq_xmm_k1z_xmmm16
INSTRUCTION: EVEX.128.66.0F38.WIG 32 /r | VPMOVZXBQ xmm1 {k1}{z}, xmm2/m16 | AVX512VL AVX512F | N2
	ops: w=reg r=rm | Packed16_UInt8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovzxbq_ymm_k1z_xmmm32
INSTRUCTION: EVEX.256.66.0F38.WIG 32 /r | VPMOVZXBQ ymm1 {k1}{z}, xmm2/m32 | AVX512VL AVX512F | N4
	ops: w=reg r=rm | Packed32_UInt8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovzxbq_zmm_k1z_xmmm64
INSTRUCTION: EVEX.512.66.0F38.WIG 32 /r | VPMOVZXBQ zmm1 {k1}{z}, xmm2/m64 | AVX512F | N8
	ops: wvmm=reg r=rm | Packed64_UInt8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovqb_xmmm16_k1z_xmm
INSTRUCTION: EVEX.128.F3.0F38.W0 32 /r | VPMOVQB xmm1/m16 {k1}{z}, xmm2 | AVX512VL AVX512F | N2
	ops: w=rm r=reg | Packed16_UInt8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovqb_xmmm32_k1z_ymm
INSTRUCTION: EVEX.256.F3.0F38.W0 32 /r | VPMOVQB xmm1/m32 {k1}{z}, ymm2 | AVX512VL AVX512F | N4
	ops: w=rm r=reg | Packed32_UInt8
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovqb_xmmm64_k1z_zmm
INSTRUCTION: EVEX.512.F3.0F38.W0 32 /r | VPMOVQB xmm1/m64 {k1}{z}, zmm2 | AVX512F | N8
	ops: w=rm r=reg | Packed64_UInt8
	masm: flags=force-size=default
END

# Code: Pmovzxwd_xmm_xmmm64
INSTRUCTION: 66 0F 38 33 /r | PMOVZXWD xmm1, xmm2/m64 | SSE4_1
	ops: w=reg r=rm | Packed64_UInt16
END

# Code: VEX_Vpmovzxwd_xmm_xmmm64
INSTRUCTION: VEX.128.66.0F38.WIG 33 /r | VPMOVZXWD xmm1, xmm2/m64 | AVX
	ops: w=reg r=rm | Packed64_UInt16
	masm: flags=force-size=default
END

# Code: VEX_Vpmovzxwd_ymm_xmmm128
INSTRUCTION: VEX.256.66.0F38.WIG 33 /r | VPMOVZXWD ymm1, xmm2/m128 | AVX2
	ops: w=reg r=rm | Packed128_UInt16
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovzxwd_xmm_k1z_xmmm64
INSTRUCTION: EVEX.128.66.0F38.WIG 33 /r | VPMOVZXWD xmm1 {k1}{z}, xmm2/m64 | AVX512VL AVX512F | N8
	ops: w=reg r=rm | Packed64_UInt16
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovzxwd_ymm_k1z_xmmm128
INSTRUCTION: EVEX.256.66.0F38.WIG 33 /r | VPMOVZXWD ymm1 {k1}{z}, xmm2/m128 | AVX512VL AVX512F | N16
	ops: w=reg r=rm | Packed128_UInt16
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovzxwd_zmm_k1z_ymmm256
INSTRUCTION: EVEX.512.66.0F38.WIG 33 /r | VPMOVZXWD zmm1 {k1}{z}, ymm2/m256 | AVX512F | N32
	ops: wvmm=reg r=rm | Packed256_UInt16
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovdw_xmmm64_k1z_xmm
INSTRUCTION: EVEX.128.F3.0F38.W0 33 /r | VPMOVDW xmm1/m64 {k1}{z}, xmm2 | AVX512VL AVX512F | N8
	ops: w=rm r=reg | Packed64_UInt16
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovdw_xmmm128_k1z_ymm
INSTRUCTION: EVEX.256.F3.0F38.W0 33 /r | VPMOVDW xmm1/m128 {k1}{z}, ymm2 | AVX512VL AVX512F | N16
	ops: w=rm r=reg | Packed128_UInt16
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovdw_ymmm256_k1z_zmm
INSTRUCTION: EVEX.512.F3.0F38.W0 33 /r | VPMOVDW ymm1/m256 {k1}{z}, zmm2 | AVX512F | N32
	ops: w=rm r=reg | Packed256_UInt16
	masm: flags=force-size=default
END

# Code: Pmovzxwq_xmm_xmmm32
INSTRUCTION: 66 0F 38 34 /r | PMOVZXWQ xmm1, xmm2/m32 | SSE4_1
	ops: w=reg r=rm | Packed32_UInt16
END

# Code: VEX_Vpmovzxwq_xmm_xmmm32
INSTRUCTION: VEX.128.66.0F38.WIG 34 /r | VPMOVZXWQ xmm1, xmm2/m32 | AVX
	ops: w=reg r=rm | Packed32_UInt16
	masm: flags=force-size=default
END

# Code: VEX_Vpmovzxwq_ymm_xmmm64
INSTRUCTION: VEX.256.66.0F38.WIG 34 /r | VPMOVZXWQ ymm1, xmm2/m64 | AVX2
	ops: w=reg r=rm | Packed64_UInt16
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovzxwq_xmm_k1z_xmmm32
INSTRUCTION: EVEX.128.66.0F38.WIG 34 /r | VPMOVZXWQ xmm1 {k1}{z}, xmm2/m32 | AVX512VL AVX512F | N4
	ops: w=reg r=rm | Packed32_UInt16
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovzxwq_ymm_k1z_xmmm64
INSTRUCTION: EVEX.256.66.0F38.WIG 34 /r | VPMOVZXWQ ymm1 {k1}{z}, xmm2/m64 | AVX512VL AVX512F | N8
	ops: w=reg r=rm | Packed64_UInt16
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovzxwq_zmm_k1z_xmmm128
INSTRUCTION: EVEX.512.66.0F38.WIG 34 /r | VPMOVZXWQ zmm1 {k1}{z}, xmm2/m128 | AVX512F | N16
	ops: wvmm=reg r=rm | Packed128_UInt16
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovqw_xmmm32_k1z_xmm
INSTRUCTION: EVEX.128.F3.0F38.W0 34 /r | VPMOVQW xmm1/m32 {k1}{z}, xmm2 | AVX512VL AVX512F | N4
	ops: w=rm r=reg | Packed32_UInt16
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovqw_xmmm64_k1z_ymm
INSTRUCTION: EVEX.256.F3.0F38.W0 34 /r | VPMOVQW xmm1/m64 {k1}{z}, ymm2 | AVX512VL AVX512F | N8
	ops: w=rm r=reg | Packed64_UInt16
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovqw_xmmm128_k1z_zmm
INSTRUCTION: EVEX.512.F3.0F38.W0 34 /r | VPMOVQW xmm1/m128 {k1}{z}, zmm2 | AVX512F | N16
	ops: w=rm r=reg | Packed128_UInt16
	masm: flags=force-size=default
END

# Code: Pmovzxdq_xmm_xmmm64
INSTRUCTION: 66 0F 38 35 /r | PMOVZXDQ xmm1, xmm2/m64 | SSE4_1
	ops: w=reg r=rm | Packed64_UInt32
END

# Code: VEX_Vpmovzxdq_xmm_xmmm64
INSTRUCTION: VEX.128.66.0F38.WIG 35 /r | VPMOVZXDQ xmm1, xmm2/m64 | AVX
	ops: w=reg r=rm | Packed64_UInt32
	masm: flags=force-size=default
END

# Code: VEX_Vpmovzxdq_ymm_xmmm128
INSTRUCTION: VEX.256.66.0F38.WIG 35 /r | VPMOVZXDQ ymm1, xmm2/m128 | AVX2
	ops: w=reg r=rm | Packed128_UInt32
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovzxdq_xmm_k1z_xmmm64
INSTRUCTION: EVEX.128.66.0F38.W0 35 /r | VPMOVZXDQ xmm1 {k1}{z}, xmm2/m64 | AVX512VL AVX512F | N8
	ops: w=reg r=rm | Packed64_UInt32
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovzxdq_ymm_k1z_xmmm128
INSTRUCTION: EVEX.256.66.0F38.W0 35 /r | VPMOVZXDQ ymm1 {k1}{z}, xmm2/m128 | AVX512VL AVX512F | N16
	ops: w=reg r=rm | Packed128_UInt32
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovzxdq_zmm_k1z_ymmm256
INSTRUCTION: EVEX.512.66.0F38.W0 35 /r | VPMOVZXDQ zmm1 {k1}{z}, ymm2/m256 | AVX512F | N32
	ops: wvmm=reg r=rm | Packed256_UInt32
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovqd_xmmm64_k1z_xmm
INSTRUCTION: EVEX.128.F3.0F38.W0 35 /r | VPMOVQD xmm1/m64 {k1}{z}, xmm2 | AVX512VL AVX512F | N8
	ops: w=rm r=reg | Packed64_UInt32
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovqd_xmmm128_k1z_ymm
INSTRUCTION: EVEX.256.F3.0F38.W0 35 /r | VPMOVQD xmm1/m128 {k1}{z}, ymm2 | AVX512VL AVX512F | N16
	ops: w=rm r=reg | Packed128_UInt32
	masm: flags=force-size=default
END

# Code: EVEX_Vpmovqd_ymmm256_k1z_zmm
INSTRUCTION: EVEX.512.F3.0F38.W0 35 /r | VPMOVQD ymm1/m256 {k1}{z}, zmm2 | AVX512F | N32
	ops: w=rm r=reg | Packed256_UInt32
	masm: flags=force-size=default
END

# Code: VEX_Vpermd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 36 /r | VPERMD ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt32
END

# Code: EVEX_Vpermd_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 36 /r | VPERMD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vpermd_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 36 /r | VPERMD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: EVEX_Vpermq_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 36 /r | VPERMQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vpermq_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 36 /r | VPERMQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: Pcmpgtq_xmm_xmmm128
INSTRUCTION: 66 0F 38 37 /r | PCMPGTQ xmm1, xmm2/m128 | SSE4_2
	ops: rw=reg r=rm | Packed128_Int64
END

# Code: VEX_Vpcmpgtq_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG 37 /r | VPCMPGTQ xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int64
END

# Code: VEX_Vpcmpgtq_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG 37 /r | VPCMPGTQ ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Int64
END

# Code: EVEX_Vpcmpgtq_kr_k1_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 37 /r | VPCMPGTQ k1 {k2}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_Int64 Broadcast128_Int64
	flags: implied-z
END

# Code: EVEX_Vpcmpgtq_kr_k1_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 37 /r | VPCMPGTQ k1 {k2}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_Int64 Broadcast256_Int64
	flags: implied-z
END

# Code: EVEX_Vpcmpgtq_kr_k1_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 37 /r | VPCMPGTQ k1 {k2}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: w=reg r=vvvv r=rm | Packed512_Int64 Broadcast512_Int64
	flags: implied-z
END

# Code: Pminsb_xmm_xmmm128
INSTRUCTION: 66 0F 38 38 /r | PMINSB xmm1, xmm2/m128 | SSE4_1
	ops: rw=reg r=rm | Packed128_Int8
END

# Code: VEX_Vpminsb_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG 38 /r | VPMINSB xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int8
END

# Code: VEX_Vpminsb_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG 38 /r | VPMINSB ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Int8
END

# Code: EVEX_Vpminsb_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F38.WIG 38 /r | VPMINSB xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_Int8
END

# Code: EVEX_Vpminsb_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F38.WIG 38 /r | VPMINSB ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_Int8
END

# Code: EVEX_Vpminsb_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F38.WIG 38 /r | VPMINSB zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_Int8
END

# Code: EVEX_Vpmovm2d_xmm_kr
INSTRUCTION: EVEX.128.F3.0F38.W0 38 /r | VPMOVM2D xmm1, k1 | AVX512VL AVX512DQ
	ops: w=reg r=rm
END

# Code: EVEX_Vpmovm2d_ymm_kr
INSTRUCTION: EVEX.256.F3.0F38.W0 38 /r | VPMOVM2D ymm1, k1 | AVX512VL AVX512DQ
	ops: w=reg r=rm
END

# Code: EVEX_Vpmovm2d_zmm_kr
INSTRUCTION: EVEX.512.F3.0F38.W0 38 /r | VPMOVM2D zmm1, k1 | AVX512DQ
	ops: w=reg r=rm
END

# Code: EVEX_Vpmovm2q_xmm_kr
INSTRUCTION: EVEX.128.F3.0F38.W1 38 /r | VPMOVM2Q xmm1, k1 | AVX512VL AVX512DQ
	ops: w=reg r=rm
END

# Code: EVEX_Vpmovm2q_ymm_kr
INSTRUCTION: EVEX.256.F3.0F38.W1 38 /r | VPMOVM2Q ymm1, k1 | AVX512VL AVX512DQ
	ops: w=reg r=rm
END

# Code: EVEX_Vpmovm2q_zmm_kr
INSTRUCTION: EVEX.512.F3.0F38.W1 38 /r | VPMOVM2Q zmm1, k1 | AVX512DQ
	ops: w=reg r=rm
END

# Code: Pminsd_xmm_xmmm128
INSTRUCTION: 66 0F 38 39 /r | PMINSD xmm1, xmm2/m128 | SSE4_1
	ops: rw=reg r=rm | Packed128_Int32
END

# Code: VEX_Vpminsd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG 39 /r | VPMINSD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int32
END

# Code: VEX_Vpminsd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG 39 /r | VPMINSD ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Int32
END

# Code: EVEX_Vpminsd_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 39 /r | VPMINSD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_Int32 Broadcast128_Int32
END

# Code: EVEX_Vpminsd_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 39 /r | VPMINSD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_Int32 Broadcast256_Int32
END

# Code: EVEX_Vpminsd_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 39 /r | VPMINSD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_Int32 Broadcast512_Int32
END

# Code: EVEX_Vpminsq_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 39 /r | VPMINSQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_Int64 Broadcast128_Int64
END

# Code: EVEX_Vpminsq_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 39 /r | VPMINSQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_Int64 Broadcast256_Int64
END

# Code: EVEX_Vpminsq_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 39 /r | VPMINSQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_Int64 Broadcast512_Int64
END

# Code: EVEX_Vpmovd2m_kr_xmm
INSTRUCTION: EVEX.128.F3.0F38.W0 39 /r | VPMOVD2M k1, xmm1 | AVX512VL AVX512DQ
	ops: w=reg r=rm
END

# Code: EVEX_Vpmovd2m_kr_ymm
INSTRUCTION: EVEX.256.F3.0F38.W0 39 /r | VPMOVD2M k1, ymm1 | AVX512VL AVX512DQ
	ops: w=reg r=rm
END

# Code: EVEX_Vpmovd2m_kr_zmm
INSTRUCTION: EVEX.512.F3.0F38.W0 39 /r | VPMOVD2M k1, zmm1 | AVX512DQ
	ops: w=reg r=rm
END

# Code: EVEX_Vpmovq2m_kr_xmm
INSTRUCTION: EVEX.128.F3.0F38.W1 39 /r | VPMOVQ2M k1, xmm1 | AVX512VL AVX512DQ
	ops: w=reg r=rm
END

# Code: EVEX_Vpmovq2m_kr_ymm
INSTRUCTION: EVEX.256.F3.0F38.W1 39 /r | VPMOVQ2M k1, ymm1 | AVX512VL AVX512DQ
	ops: w=reg r=rm
END

# Code: EVEX_Vpmovq2m_kr_zmm
INSTRUCTION: EVEX.512.F3.0F38.W1 39 /r | VPMOVQ2M k1, zmm1 | AVX512DQ
	ops: w=reg r=rm
END

# Code: Pminuw_xmm_xmmm128
INSTRUCTION: 66 0F 38 3A /r | PMINUW xmm1, xmm2/m128 | SSE4_1
	ops: rw=reg r=rm | Packed128_UInt16
END

# Code: VEX_Vpminuw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG 3A /r | VPMINUW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: VEX_Vpminuw_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG 3A /r | VPMINUW ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: EVEX_Vpminuw_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F38.WIG 3A /r | VPMINUW xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: EVEX_Vpminuw_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F38.WIG 3A /r | VPMINUW ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: EVEX_Vpminuw_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F38.WIG 3A /r | VPMINUW zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt16
END

# Code: EVEX_Vpbroadcastmw2d_xmm_kr
INSTRUCTION: EVEX.128.F3.0F38.W0 3A /r | VPBROADCASTMW2D xmm1, k1 | AVX512VL AVX512CD
	ops: w=reg r=rm
END

# Code: EVEX_Vpbroadcastmw2d_ymm_kr
INSTRUCTION: EVEX.256.F3.0F38.W0 3A /r | VPBROADCASTMW2D ymm1, k1 | AVX512VL AVX512CD
	ops: w=reg r=rm
END

# Code: EVEX_Vpbroadcastmw2d_zmm_kr
INSTRUCTION: EVEX.512.F3.0F38.W0 3A /r | VPBROADCASTMW2D zmm1, k1 | AVX512CD
	ops: w=reg r=rm
END

# Code: Pminud_xmm_xmmm128
INSTRUCTION: 66 0F 38 3B /r | PMINUD xmm1, xmm2/m128 | SSE4_1
	ops: rw=reg r=rm | Packed128_UInt32
END

# Code: VEX_Vpminud_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG 3B /r | VPMINUD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt32
END

# Code: VEX_Vpminud_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG 3B /r | VPMINUD ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt32
END

# Code: EVEX_Vpminud_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 3B /r | VPMINUD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_UInt32 Broadcast128_UInt32
END

# Code: EVEX_Vpminud_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 3B /r | VPMINUD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vpminud_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 3B /r | VPMINUD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: EVEX_Vpminuq_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 3B /r | VPMINUQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Vpminuq_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 3B /r | VPMINUQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vpminuq_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 3B /r | VPMINUQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: Pmaxsb_xmm_xmmm128
INSTRUCTION: 66 0F 38 3C /r | PMAXSB xmm1, xmm2/m128 | SSE4_1
	ops: rw=reg r=rm | Packed128_Int8
END

# Code: VEX_Vpmaxsb_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG 3C /r | VPMAXSB xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int8
END

# Code: VEX_Vpmaxsb_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG 3C /r | VPMAXSB ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Int8
END

# Code: EVEX_Vpmaxsb_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F38.WIG 3C /r | VPMAXSB xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_Int8
END

# Code: EVEX_Vpmaxsb_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F38.WIG 3C /r | VPMAXSB ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_Int8
END

# Code: EVEX_Vpmaxsb_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F38.WIG 3C /r | VPMAXSB zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_Int8
END

# Code: Pmaxsd_xmm_xmmm128
INSTRUCTION: 66 0F 38 3D /r | PMAXSD xmm1, xmm2/m128 | SSE4_1
	ops: rw=reg r=rm | Packed128_Int32
END

# Code: VEX_Vpmaxsd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG 3D /r | VPMAXSD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int32
END

# Code: VEX_Vpmaxsd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG 3D /r | VPMAXSD ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Int32
END

# Code: EVEX_Vpmaxsd_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 3D /r | VPMAXSD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_Int32 Broadcast128_Int32
END

# Code: EVEX_Vpmaxsd_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 3D /r | VPMAXSD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_Int32 Broadcast256_Int32
END

# Code: EVEX_Vpmaxsd_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 3D /r | VPMAXSD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_Int32 Broadcast512_Int32
END

# Code: EVEX_Vpmaxsq_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 3D /r | VPMAXSQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_Int64 Broadcast128_Int64
END

# Code: EVEX_Vpmaxsq_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 3D /r | VPMAXSQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_Int64 Broadcast256_Int64
END

# Code: EVEX_Vpmaxsq_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 3D /r | VPMAXSQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_Int64 Broadcast512_Int64
END

# Code: Pmaxuw_xmm_xmmm128
INSTRUCTION: 66 0F 38 3E /r | PMAXUW xmm1, xmm2/m128 | SSE4_1
	ops: rw=reg r=rm | Packed128_UInt16
END

# Code: VEX_Vpmaxuw_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG 3E /r | VPMAXUW xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: VEX_Vpmaxuw_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG 3E /r | VPMAXUW ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: EVEX_Vpmaxuw_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F38.WIG 3E /r | VPMAXUW xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: EVEX_Vpmaxuw_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F38.WIG 3E /r | VPMAXUW ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: EVEX_Vpmaxuw_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F38.WIG 3E /r | VPMAXUW zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt16
END

# Code: Pmaxud_xmm_xmmm128
INSTRUCTION: 66 0F 38 3F /r | PMAXUD xmm1, xmm2/m128 | SSE4_1
	ops: rw=reg r=rm | Packed128_UInt32
END

# Code: VEX_Vpmaxud_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG 3F /r | VPMAXUD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_UInt32
END

# Code: VEX_Vpmaxud_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG 3F /r | VPMAXUD ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt32
END

# Code: EVEX_Vpmaxud_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 3F /r | VPMAXUD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_UInt32 Broadcast128_UInt32
END

# Code: EVEX_Vpmaxud_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 3F /r | VPMAXUD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vpmaxud_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 3F /r | VPMAXUD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: EVEX_Vpmaxuq_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 3F /r | VPMAXUQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Vpmaxuq_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 3F /r | VPMAXUQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vpmaxuq_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 3F /r | VPMAXUQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: Pmulld_xmm_xmmm128
INSTRUCTION: 66 0F 38 40 /r | PMULLD xmm1, xmm2/m128 | SSE4_1
	ops: rw=reg r=rm | Packed128_Int32
END

# Code: VEX_Vpmulld_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG 40 /r | VPMULLD xmm1, xmm2, xmm3/m128 | AVX
	ops: w=reg r=vvvv r=rm | Packed128_Int32
END

# Code: VEX_Vpmulld_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG 40 /r | VPMULLD ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_Int32
END

# Code: EVEX_Vpmulld_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 40 /r | VPMULLD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_Int32 Broadcast128_Int32
END

# Code: EVEX_Vpmulld_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 40 /r | VPMULLD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_Int32 Broadcast256_Int32
END

# Code: EVEX_Vpmulld_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 40 /r | VPMULLD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_Int32 Broadcast512_Int32
END

# Code: EVEX_Vpmullq_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 40 /r | VPMULLQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512DQ | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_Int64 Broadcast128_Int64
END

# Code: EVEX_Vpmullq_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 40 /r | VPMULLQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512DQ | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_Int64 Broadcast256_Int64
END

# Code: EVEX_Vpmullq_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 40 /r | VPMULLQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512DQ | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_Int64 Broadcast512_Int64
END

# Code: Phminposuw_xmm_xmmm128
INSTRUCTION: 66 0F 38 41 /r | PHMINPOSUW xmm1, xmm2/m128 | SSE4_1
	ops: w=reg r=rm | Packed128_UInt16
END

# Code: VEX_Vphminposuw_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG 41 /r | VPHMINPOSUW xmm1, xmm2/m128 | AVX
	ops: w=reg r=rm | Packed128_UInt16
END

# Code: EVEX_Vgetexpps_xmm_k1z_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 42 /r | VGETEXPPS xmm1 {k1}{z}, xmm2/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vgetexpps_ymm_k1z_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 42 /r | VGETEXPPS ymm1 {k1}{z}, ymm2/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vgetexpps_zmm_k1z_zmmm512b32_sae
INSTRUCTION: EVEX.512.66.0F38.W0 42 /r | VGETEXPPS zmm1 {k1}{z}, zmm2/m512/m32bcst{sae} | AVX512F | N64b4
	ops: wvmm=reg r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vgetexppd_xmm_k1z_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 42 /r | VGETEXPPD xmm1 {k1}{z}, xmm2/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vgetexppd_ymm_k1z_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 42 /r | VGETEXPPD ymm1 {k1}{z}, ymm2/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vgetexppd_zmm_k1z_zmmm512b64_sae
INSTRUCTION: EVEX.512.66.0F38.W1 42 /r | VGETEXPPD zmm1 {k1}{z}, zmm2/m512/m64bcst{sae} | AVX512F | N64b8
	ops: wvmm=reg r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: EVEX_Vgetexpss_xmm_k1z_xmm_xmmm32_sae
INSTRUCTION: EVEX.LIG.66.0F38.W0 43 /r | VGETEXPSS xmm1 {k1}{z}, xmm2, xmm3/m32{sae} | AVX512F | N4
	ops: w=reg r=vvvv r=rm | Float32
END

# Code: EVEX_Vgetexpsd_xmm_k1z_xmm_xmmm64_sae
INSTRUCTION: EVEX.LIG.66.0F38.W1 43 /r | VGETEXPSD xmm1 {k1}{z}, xmm2, xmm3/m64{sae} | AVX512F | N8
	ops: w=reg r=vvvv r=rm | Float64
END

# Code: EVEX_Vplzcntd_xmm_k1z_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 44 /r | VPLZCNTD xmm1 {k1}{z}, xmm2/m128/m32bcst | AVX512VL AVX512CD | N16b4
	ops: w=reg r=rm | Packed128_UInt32 Broadcast128_UInt32
END

# Code: EVEX_Vplzcntd_ymm_k1z_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 44 /r | VPLZCNTD ymm1 {k1}{z}, ymm2/m256/m32bcst | AVX512VL AVX512CD | N32b4
	ops: w=reg r=rm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vplzcntd_zmm_k1z_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 44 /r | VPLZCNTD zmm1 {k1}{z}, zmm2/m512/m32bcst | AVX512CD | N64b4
	ops: wvmm=reg r=rm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: EVEX_Vplzcntq_xmm_k1z_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 44 /r | VPLZCNTQ xmm1 {k1}{z}, xmm2/m128/m64bcst | AVX512VL AVX512CD | N16b8
	ops: w=reg r=rm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Vplzcntq_ymm_k1z_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 44 /r | VPLZCNTQ ymm1 {k1}{z}, ymm2/m256/m64bcst | AVX512VL AVX512CD | N32b8
	ops: w=reg r=rm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vplzcntq_zmm_k1z_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 44 /r | VPLZCNTQ zmm1 {k1}{z}, zmm2/m512/m64bcst | AVX512CD | N64b8
	ops: wvmm=reg r=rm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: VEX_Vpsrlvd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 45 /r | VPSRLVD xmm1, xmm2, xmm3/m128 | AVX2
	ops: w=reg r=vvvv r=rm | Packed128_UInt32
END

# Code: VEX_Vpsrlvd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 45 /r | VPSRLVD ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt32
END

# Code: VEX_Vpsrlvq_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W1 45 /r | VPSRLVQ xmm1, xmm2, xmm3/m128 | AVX2
	ops: w=reg r=vvvv r=rm | Packed128_UInt64
END

# Code: VEX_Vpsrlvq_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W1 45 /r | VPSRLVQ ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt64
END

# Code: EVEX_Vpsrlvd_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 45 /r | VPSRLVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_UInt32 Broadcast128_UInt32
END

# Code: EVEX_Vpsrlvd_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 45 /r | VPSRLVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vpsrlvd_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 45 /r | VPSRLVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: EVEX_Vpsrlvq_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 45 /r | VPSRLVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Vpsrlvq_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 45 /r | VPSRLVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vpsrlvq_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 45 /r | VPSRLVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: VEX_Vpsravd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 46 /r | VPSRAVD xmm1, xmm2, xmm3/m128 | AVX2
	ops: w=reg r=vvvv r=rm | Packed128_UInt32
END

# Code: VEX_Vpsravd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 46 /r | VPSRAVD ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt32
END

# Code: EVEX_Vpsravd_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 46 /r | VPSRAVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_UInt32 Broadcast128_UInt32
END

# Code: EVEX_Vpsravd_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 46 /r | VPSRAVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vpsravd_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 46 /r | VPSRAVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: EVEX_Vpsravq_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 46 /r | VPSRAVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Vpsravq_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 46 /r | VPSRAVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vpsravq_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 46 /r | VPSRAVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: VEX_Vpsllvd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 47 /r | VPSLLVD xmm1, xmm2, xmm3/m128 | AVX2
	ops: w=reg r=vvvv r=rm | Packed128_UInt32
END

# Code: VEX_Vpsllvd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 47 /r | VPSLLVD ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt32
END

# Code: VEX_Vpsllvq_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W1 47 /r | VPSLLVQ xmm1, xmm2, xmm3/m128 | AVX2
	ops: w=reg r=vvvv r=rm | Packed128_UInt64
END

# Code: VEX_Vpsllvq_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W1 47 /r | VPSLLVQ ymm1, ymm2, ymm3/m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt64
END

# Code: EVEX_Vpsllvd_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 47 /r | VPSLLVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_UInt32 Broadcast128_UInt32
END

# Code: EVEX_Vpsllvd_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 47 /r | VPSLLVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vpsllvd_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 47 /r | VPSLLVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: EVEX_Vpsllvq_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 47 /r | VPSLLVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Vpsllvq_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 47 /r | VPSLLVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vpsllvq_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 47 /r | VPSLLVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: EVEX_Vrcp14ps_xmm_k1z_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 4C /r | VRCP14PS xmm1 {k1}{z}, xmm2/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vrcp14ps_ymm_k1z_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 4C /r | VRCP14PS ymm1 {k1}{z}, ymm2/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vrcp14ps_zmm_k1z_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 4C /r | VRCP14PS zmm1 {k1}{z}, zmm2/m512/m32bcst | AVX512F | N64b4
	ops: wvmm=reg r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vrcp14pd_xmm_k1z_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 4C /r | VRCP14PD xmm1 {k1}{z}, xmm2/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vrcp14pd_ymm_k1z_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 4C /r | VRCP14PD ymm1 {k1}{z}, ymm2/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vrcp14pd_zmm_k1z_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 4C /r | VRCP14PD zmm1 {k1}{z}, zmm2/m512/m64bcst | AVX512F | N64b8
	ops: wvmm=reg r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: EVEX_Vrcp14ss_xmm_k1z_xmm_xmmm32
INSTRUCTION: EVEX.LIG.66.0F38.W0 4D /r | VRCP14SS xmm1 {k1}{z}, xmm2, xmm3/m32 | AVX512F | N4
	ops: w=reg r=vvvv r=rm | Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vrcp14sd_xmm_k1z_xmm_xmmm64
INSTRUCTION: EVEX.LIG.66.0F38.W1 4D /r | VRCP14SD xmm1 {k1}{z}, xmm2, xmm3/m64 | AVX512F | N8
	ops: w=reg r=vvvv r=rm | Float64
	masm: flags=force-size=default
END

# Code: EVEX_Vrsqrt14ps_xmm_k1z_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 4E /r | VRSQRT14PS xmm1 {k1}{z}, xmm2/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vrsqrt14ps_ymm_k1z_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 4E /r | VRSQRT14PS ymm1 {k1}{z}, ymm2/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vrsqrt14ps_zmm_k1z_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 4E /r | VRSQRT14PS zmm1 {k1}{z}, zmm2/m512/m32bcst | AVX512F | N64b4
	ops: wvmm=reg r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vrsqrt14pd_xmm_k1z_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 4E /r | VRSQRT14PD xmm1 {k1}{z}, xmm2/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vrsqrt14pd_ymm_k1z_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 4E /r | VRSQRT14PD ymm1 {k1}{z}, ymm2/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vrsqrt14pd_zmm_k1z_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 4E /r | VRSQRT14PD zmm1 {k1}{z}, zmm2/m512/m64bcst | AVX512F | N64b8
	ops: wvmm=reg r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: EVEX_Vrsqrt14ss_xmm_k1z_xmm_xmmm32
INSTRUCTION: EVEX.LIG.66.0F38.W0 4F /r | VRSQRT14SS xmm1 {k1}{z}, xmm2, xmm3/m32 | AVX512F | N4
	ops: w=reg r=vvvv r=rm | Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vrsqrt14sd_xmm_k1z_xmm_xmmm64
INSTRUCTION: EVEX.LIG.66.0F38.W1 4F /r | VRSQRT14SD xmm1 {k1}{z}, xmm2, xmm3/m64 | AVX512F | N8
	ops: w=reg r=vvvv r=rm | Float64
	masm: flags=force-size=default
END

# Code: EVEX_Vpdpbusd_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 50 /r | VPDPBUSD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512_VNNI | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_Int8 Broadcast128_UInt32
END

# Code: EVEX_Vpdpbusd_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 50 /r | VPDPBUSD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512_VNNI | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_Int8 Broadcast256_UInt32
END

# Code: EVEX_Vpdpbusd_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 50 /r | VPDPBUSD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512_VNNI | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Int8 Broadcast512_UInt32
END

# Code: EVEX_Vpdpbusds_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 51 /r | VPDPBUSDS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512_VNNI | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_Int8 Broadcast128_UInt32
END

# Code: EVEX_Vpdpbusds_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 51 /r | VPDPBUSDS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512_VNNI | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_Int8 Broadcast256_UInt32
END

# Code: EVEX_Vpdpbusds_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 51 /r | VPDPBUSDS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512_VNNI | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Int8 Broadcast512_UInt32
END

# Code: EVEX_Vpdpwssd_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 52 /r | VPDPWSSD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512_VNNI | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_Int16 Broadcast128_2xInt16
END

# Code: EVEX_Vpdpwssd_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 52 /r | VPDPWSSD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512_VNNI | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_Int16 Broadcast256_2xInt16
END

# Code: EVEX_Vpdpwssd_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 52 /r | VPDPWSSD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512_VNNI | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Int16 Broadcast512_2xInt16
END

# Code: EVEX_Vdpbf16ps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.F3.0F38.W0 52 /r | VDPBF16PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512_BF16 | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_2xBFloat16 Broadcast128_2xBFloat16
END

# Code: EVEX_Vdpbf16ps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.F3.0F38.W0 52 /r | VDPBF16PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512_BF16 | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_2xBFloat16 Broadcast256_2xBFloat16
END

# Code: EVEX_Vdpbf16ps_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.F3.0F38.W0 52 /r | VDPBF16PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F AVX512_BF16 | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_2xBFloat16 Broadcast512_2xBFloat16
END

# Code: EVEX_Vp4dpwssd_zmm_k1z_zmmp3_m128
INSTRUCTION: EVEX.512.F2.0F38.W0 52 /r | VP4DPWSSD zmm1 {k1}{z}, zmm2+3, m128 | AVX512_4VNNIW | N16
	ops: rwvmm=reg r=vvvv;p3 r=rm | Packed128_Int16
	masm: flags=force-size=default
END

# Code: EVEX_Vpdpwssds_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 53 /r | VPDPWSSDS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512_VNNI | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_Int16 Broadcast128_2xInt16
END

# Code: EVEX_Vpdpwssds_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 53 /r | VPDPWSSDS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512_VNNI | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_Int16 Broadcast256_2xInt16
END

# Code: EVEX_Vpdpwssds_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 53 /r | VPDPWSSDS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512_VNNI | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Int16 Broadcast512_2xInt16
END

# Code: EVEX_Vp4dpwssds_zmm_k1z_zmmp3_m128
INSTRUCTION: EVEX.512.F2.0F38.W0 53 /r | VP4DPWSSDS zmm1 {k1}{z}, zmm2+3, m128 | AVX512_4VNNIW | N16
	ops: rwvmm=reg r=vvvv;p3 r=rm | Packed128_Int16
	masm: flags=force-size=default
END

# Code: EVEX_Vpopcntb_xmm_k1z_xmmm128
INSTRUCTION: EVEX.128.66.0F38.W0 54 /r | VPOPCNTB xmm1 {k1}{z}, xmm2/m128 | AVX512VL AVX512_BITALG | N16
	ops: w=reg r=rm | Packed128_UInt8
END

# Code: EVEX_Vpopcntb_ymm_k1z_ymmm256
INSTRUCTION: EVEX.256.66.0F38.W0 54 /r | VPOPCNTB ymm1 {k1}{z}, ymm2/m256 | AVX512VL AVX512_BITALG | N32
	ops: w=reg r=rm | Packed256_UInt8
END

# Code: EVEX_Vpopcntb_zmm_k1z_zmmm512
INSTRUCTION: EVEX.512.66.0F38.W0 54 /r | VPOPCNTB zmm1 {k1}{z}, zmm2/m512 | AVX512_BITALG | N64
	ops: wvmm=reg r=rm | Packed512_UInt8
END

# Code: EVEX_Vpopcntw_xmm_k1z_xmmm128
INSTRUCTION: EVEX.128.66.0F38.W1 54 /r | VPOPCNTW xmm1 {k1}{z}, xmm2/m128 | AVX512VL AVX512_BITALG | N16
	ops: w=reg r=rm | Packed128_UInt16
END

# Code: EVEX_Vpopcntw_ymm_k1z_ymmm256
INSTRUCTION: EVEX.256.66.0F38.W1 54 /r | VPOPCNTW ymm1 {k1}{z}, ymm2/m256 | AVX512VL AVX512_BITALG | N32
	ops: w=reg r=rm | Packed256_UInt16
END

# Code: EVEX_Vpopcntw_zmm_k1z_zmmm512
INSTRUCTION: EVEX.512.66.0F38.W1 54 /r | VPOPCNTW zmm1 {k1}{z}, zmm2/m512 | AVX512_BITALG | N64
	ops: wvmm=reg r=rm | Packed512_UInt16
END

# Code: EVEX_Vpopcntd_xmm_k1z_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 55 /r | VPOPCNTD xmm1 {k1}{z}, xmm2/m128/m32bcst | AVX512VL AVX512_VPOPCNTDQ | N16b4
	ops: w=reg r=rm | Packed128_UInt32 Broadcast128_UInt32
END

# Code: EVEX_Vpopcntd_ymm_k1z_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 55 /r | VPOPCNTD ymm1 {k1}{z}, ymm2/m256/m32bcst | AVX512VL AVX512_VPOPCNTDQ | N32b4
	ops: w=reg r=rm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vpopcntd_zmm_k1z_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 55 /r | VPOPCNTD zmm1 {k1}{z}, zmm2/m512/m32bcst | AVX512_VPOPCNTDQ | N64b4
	ops: wvmm=reg r=rm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: EVEX_Vpopcntq_xmm_k1z_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 55 /r | VPOPCNTQ xmm1 {k1}{z}, xmm2/m128/m64bcst | AVX512VL AVX512_VPOPCNTDQ | N16b8
	ops: w=reg r=rm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Vpopcntq_ymm_k1z_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 55 /r | VPOPCNTQ ymm1 {k1}{z}, ymm2/m256/m64bcst | AVX512VL AVX512_VPOPCNTDQ | N32b8
	ops: w=reg r=rm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vpopcntq_zmm_k1z_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 55 /r | VPOPCNTQ zmm1 {k1}{z}, zmm2/m512/m64bcst | AVX512_VPOPCNTDQ | N64b8
	ops: wvmm=reg r=rm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: VEX_Vpbroadcastd_xmm_xmmm32
INSTRUCTION: VEX.128.66.0F38.W0 58 /r | VPBROADCASTD xmm1, xmm2/m32 | AVX2
	ops: w=reg r=rm | Int32
	masm: flags=force-size=default
END

# Code: VEX_Vpbroadcastd_ymm_xmmm32
INSTRUCTION: VEX.256.66.0F38.W0 58 /r | VPBROADCASTD ymm1, xmm2/m32 | AVX2
	ops: w=reg r=rm | Int32
	masm: flags=force-size=default
END

# Code: EVEX_Vpbroadcastd_xmm_k1z_xmmm32
INSTRUCTION: EVEX.128.66.0F38.W0 58 /r | VPBROADCASTD xmm1 {k1}{z}, xmm2/m32 | AVX512VL AVX512F | N4
	ops: w=reg r=rm | Int32
	masm: flags=force-size=default
END

# Code: EVEX_Vpbroadcastd_ymm_k1z_xmmm32
INSTRUCTION: EVEX.256.66.0F38.W0 58 /r | VPBROADCASTD ymm1 {k1}{z}, xmm2/m32 | AVX512VL AVX512F | N4
	ops: w=reg r=rm | Int32
	masm: flags=force-size=default
END

# Code: EVEX_Vpbroadcastd_zmm_k1z_xmmm32
INSTRUCTION: EVEX.512.66.0F38.W0 58 /r | VPBROADCASTD zmm1 {k1}{z}, xmm2/m32 | AVX512F | N4
	ops: wvmm=reg r=rm | Int32
	masm: flags=force-size=default
END

# Code: VEX_Vpbroadcastq_xmm_xmmm64
INSTRUCTION: VEX.128.66.0F38.W0 59 /r | VPBROADCASTQ xmm1, xmm2/m64 | AVX2
	ops: w=reg r=rm | Int64
	masm: flags=force-size=default
END

# Code: VEX_Vpbroadcastq_ymm_xmmm64
INSTRUCTION: VEX.256.66.0F38.W0 59 /r | VPBROADCASTQ ymm1, xmm2/m64 | AVX2
	ops: w=reg r=rm | Int64
	masm: flags=force-size=default
END

# Code: EVEX_Vbroadcasti32x2_xmm_k1z_xmmm64
INSTRUCTION: EVEX.128.66.0F38.W0 59 /r | VBROADCASTI32X2 xmm1 {k1}{z}, xmm2/m64 | AVX512VL AVX512DQ | N8
	ops: w=reg r=rm | Packed64_UInt32
	masm: flags=force-size=default
END

# Code: EVEX_Vbroadcasti32x2_ymm_k1z_xmmm64
INSTRUCTION: EVEX.256.66.0F38.W0 59 /r | VBROADCASTI32X2 ymm1 {k1}{z}, xmm2/m64 | AVX512VL AVX512DQ | N8
	ops: w=reg r=rm | Packed64_UInt32
	masm: flags=force-size=default
END

# Code: EVEX_Vbroadcasti32x2_zmm_k1z_xmmm64
INSTRUCTION: EVEX.512.66.0F38.W0 59 /r | VBROADCASTI32X2 zmm1 {k1}{z}, xmm2/m64 | AVX512DQ | N8
	ops: wvmm=reg r=rm | Packed64_UInt32
	masm: flags=force-size=default
END

# Code: EVEX_Vpbroadcastq_xmm_k1z_xmmm64
INSTRUCTION: EVEX.128.66.0F38.W1 59 /r | VPBROADCASTQ xmm1 {k1}{z}, xmm2/m64 | AVX512VL AVX512F | N8
	ops: w=reg r=rm | Int64
	masm: flags=force-size=default
END

# Code: EVEX_Vpbroadcastq_ymm_k1z_xmmm64
INSTRUCTION: EVEX.256.66.0F38.W1 59 /r | VPBROADCASTQ ymm1 {k1}{z}, xmm2/m64 | AVX512VL AVX512F | N8
	ops: w=reg r=rm | Int64
	masm: flags=force-size=default
END

# Code: EVEX_Vpbroadcastq_zmm_k1z_xmmm64
INSTRUCTION: EVEX.512.66.0F38.W1 59 /r | VPBROADCASTQ zmm1 {k1}{z}, xmm2/m64 | AVX512F | N8
	ops: wvmm=reg r=rm | Int64
	masm: flags=force-size=default
END

# Code: VEX_Vbroadcasti128_ymm_m128
INSTRUCTION: VEX.256.66.0F38.W0 5A /r | VBROADCASTI128 ymm1, m128 | AVX2
	ops: w=reg r=rm | Int128
	masm: flags=force-size=default
END

# Code: EVEX_Vbroadcasti32x4_ymm_k1z_m128
INSTRUCTION: EVEX.256.66.0F38.W0 5A /r | VBROADCASTI32X4 ymm1 {k1}{z}, m128 | AVX512VL AVX512F | N16
	ops: w=reg r=rm | Packed128_UInt32
	masm: flags=force-size=default
END

# Code: EVEX_Vbroadcasti32x4_zmm_k1z_m128
INSTRUCTION: EVEX.512.66.0F38.W0 5A /r | VBROADCASTI32X4 zmm1 {k1}{z}, m128 | AVX512F | N16
	ops: wvmm=reg r=rm | Packed128_UInt32
	masm: flags=force-size=default
END

# Code: EVEX_Vbroadcasti64x2_ymm_k1z_m128
INSTRUCTION: EVEX.256.66.0F38.W1 5A /r | VBROADCASTI64X2 ymm1 {k1}{z}, m128 | AVX512VL AVX512DQ | N16
	ops: w=reg r=rm | Packed128_UInt64
	masm: flags=force-size=default
END

# Code: EVEX_Vbroadcasti64x2_zmm_k1z_m128
INSTRUCTION: EVEX.512.66.0F38.W1 5A /r | VBROADCASTI64X2 zmm1 {k1}{z}, m128 | AVX512DQ | N16
	ops: wvmm=reg r=rm | Packed128_UInt64
	masm: flags=force-size=default
END

# Code: EVEX_Vbroadcasti32x8_zmm_k1z_m256
INSTRUCTION: EVEX.512.66.0F38.W0 5B /r | VBROADCASTI32X8 zmm1 {k1}{z}, m256 | AVX512DQ | N32
	ops: wvmm=reg r=rm | Packed256_UInt32
	masm: flags=force-size=default
END

# Code: EVEX_Vbroadcasti64x4_zmm_k1z_m256
INSTRUCTION: EVEX.512.66.0F38.W1 5B /r | VBROADCASTI64X4 zmm1 {k1}{z}, m256 | AVX512F | N32
	ops: wvmm=reg r=rm | Packed256_UInt64
	masm: flags=force-size=default
END

# Code: EVEX_Vpexpandb_xmm_k1z_xmmm128
INSTRUCTION: EVEX.128.66.0F38.W0 62 /r | VPEXPANDB xmm1 {k1}{z}, xmm2/m128 | AVX512VL AVX512_VBMI2 | N1
	ops: w=reg r=rm | Packed128_UInt8
END

# Code: EVEX_Vpexpandb_ymm_k1z_ymmm256
INSTRUCTION: EVEX.256.66.0F38.W0 62 /r | VPEXPANDB ymm1 {k1}{z}, ymm2/m256 | AVX512VL AVX512_VBMI2 | N1
	ops: w=reg r=rm | Packed256_UInt8
END

# Code: EVEX_Vpexpandb_zmm_k1z_zmmm512
INSTRUCTION: EVEX.512.66.0F38.W0 62 /r | VPEXPANDB zmm1 {k1}{z}, zmm2/m512 | AVX512_VBMI2 | N1
	ops: wvmm=reg r=rm | Packed512_UInt8
END

# Code: EVEX_Vpexpandw_xmm_k1z_xmmm128
INSTRUCTION: EVEX.128.66.0F38.W1 62 /r | VPEXPANDW xmm1 {k1}{z}, xmm2/m128 | AVX512VL AVX512_VBMI2 | N2
	ops: w=reg r=rm | Packed128_UInt16
END

# Code: EVEX_Vpexpandw_ymm_k1z_ymmm256
INSTRUCTION: EVEX.256.66.0F38.W1 62 /r | VPEXPANDW ymm1 {k1}{z}, ymm2/m256 | AVX512VL AVX512_VBMI2 | N2
	ops: w=reg r=rm | Packed256_UInt16
END

# Code: EVEX_Vpexpandw_zmm_k1z_zmmm512
INSTRUCTION: EVEX.512.66.0F38.W1 62 /r | VPEXPANDW zmm1 {k1}{z}, zmm2/m512 | AVX512_VBMI2 | N2
	ops: wvmm=reg r=rm | Packed512_UInt16
END

# Code: EVEX_Vpcompressb_xmmm128_k1z_xmm
INSTRUCTION: EVEX.128.66.0F38.W0 63 /r | VPCOMPRESSB xmm1/m128 {k1}{z}, xmm2 | AVX512VL AVX512_VBMI2 | N1
	ops: w=rm r=reg | Packed128_UInt8
END

# Code: EVEX_Vpcompressb_ymmm256_k1z_ymm
INSTRUCTION: EVEX.256.66.0F38.W0 63 /r | VPCOMPRESSB ymm1/m256 {k1}{z}, ymm2 | AVX512VL AVX512_VBMI2 | N1
	ops: w=rm r=reg | Packed256_UInt8
END

# Code: EVEX_Vpcompressb_zmmm512_k1z_zmm
INSTRUCTION: EVEX.512.66.0F38.W0 63 /r | VPCOMPRESSB zmm1/m512 {k1}{z}, zmm2 | AVX512_VBMI2 | N1
	ops: wvmm=rm r=reg | Packed512_UInt8
END

# Code: EVEX_Vpcompressw_xmmm128_k1z_xmm
INSTRUCTION: EVEX.128.66.0F38.W1 63 /r | VPCOMPRESSW xmm1/m128 {k1}{z}, xmm2 | AVX512VL AVX512_VBMI2 | N2
	ops: w=rm r=reg | Packed128_UInt16
END

# Code: EVEX_Vpcompressw_ymmm256_k1z_ymm
INSTRUCTION: EVEX.256.66.0F38.W1 63 /r | VPCOMPRESSW ymm1/m256 {k1}{z}, ymm2 | AVX512VL AVX512_VBMI2 | N2
	ops: w=rm r=reg | Packed256_UInt16
END

# Code: EVEX_Vpcompressw_zmmm512_k1z_zmm
INSTRUCTION: EVEX.512.66.0F38.W1 63 /r | VPCOMPRESSW zmm1/m512 {k1}{z}, zmm2 | AVX512_VBMI2 | N2
	ops: wvmm=rm r=reg | Packed512_UInt16
END

# Code: EVEX_Vpblendmd_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 64 /r | VPBLENDMD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_UInt32 Broadcast128_UInt32
	flags: k-elem-selector
END

# Code: EVEX_Vpblendmd_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 64 /r | VPBLENDMD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_UInt32 Broadcast256_UInt32
	flags: k-elem-selector
END

# Code: EVEX_Vpblendmd_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 64 /r | VPBLENDMD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: w=reg r=vvvv r=rm | Packed512_UInt32 Broadcast512_UInt32
	flags: k-elem-selector
END

# Code: EVEX_Vpblendmq_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 64 /r | VPBLENDMQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_UInt64 Broadcast128_UInt64
	flags: k-elem-selector
END

# Code: EVEX_Vpblendmq_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 64 /r | VPBLENDMQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_UInt64 Broadcast256_UInt64
	flags: k-elem-selector
END

# Code: EVEX_Vpblendmq_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 64 /r | VPBLENDMQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: w=reg r=vvvv r=rm | Packed512_UInt64 Broadcast512_UInt64
	flags: k-elem-selector
END

# Code: EVEX_Vblendmps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 65 /r | VBLENDMPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
	flags: k-elem-selector
END

# Code: EVEX_Vblendmps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 65 /r | VBLENDMPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
	flags: k-elem-selector
END

# Code: EVEX_Vblendmps_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 65 /r | VBLENDMPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: w=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
	flags: k-elem-selector
END

# Code: EVEX_Vblendmpd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 65 /r | VBLENDMPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
	flags: k-elem-selector
END

# Code: EVEX_Vblendmpd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 65 /r | VBLENDMPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
	flags: k-elem-selector
END

# Code: EVEX_Vblendmpd_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 65 /r | VBLENDMPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: w=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
	flags: k-elem-selector
END

# Code: EVEX_Vpblendmb_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F38.W0 66 /r | VPBLENDMB xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
	flags: k-elem-selector
END

# Code: EVEX_Vpblendmb_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F38.W0 66 /r | VPBLENDMB ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
	flags: k-elem-selector
END

# Code: EVEX_Vpblendmb_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F38.W0 66 /r | VPBLENDMB zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: w=reg r=vvvv r=rm | Packed512_UInt8
	flags: k-elem-selector
END

# Code: EVEX_Vpblendmw_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F38.W1 66 /r | VPBLENDMW xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
	flags: k-elem-selector
END

# Code: EVEX_Vpblendmw_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F38.W1 66 /r | VPBLENDMW ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
	flags: k-elem-selector
END

# Code: EVEX_Vpblendmw_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F38.W1 66 /r | VPBLENDMW zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: w=reg r=vvvv r=rm | Packed512_UInt16
	flags: k-elem-selector
END

# Code: EVEX_Vp2intersectd_kp1_xmm_xmmm128b32
INSTRUCTION: EVEX.128.F2.0F38.W0 68 /r | VP2INTERSECTD k1+1, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512_VP2INTERSECT | N16b4
	ops: wf=reg;p1 r=vvvv r=rm | Packed128_UInt32 Broadcast128_UInt32
END

# Code: EVEX_Vp2intersectd_kp1_ymm_ymmm256b32
INSTRUCTION: EVEX.256.F2.0F38.W0 68 /r | VP2INTERSECTD k1+1, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512_VP2INTERSECT | N32b4
	ops: wf=reg;p1 r=vvvv r=rm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vp2intersectd_kp1_zmm_zmmm512b32
INSTRUCTION: EVEX.512.F2.0F38.W0 68 /r | VP2INTERSECTD k1+1, zmm2, zmm3/m512/m32bcst | AVX512F AVX512_VP2INTERSECT | N64b4
	ops: wf=reg;p1 r=vvvv r=rm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: EVEX_Vp2intersectq_kp1_xmm_xmmm128b64
INSTRUCTION: EVEX.128.F2.0F38.W1 68 /r | VP2INTERSECTQ k1+1, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512_VP2INTERSECT | N16b8
	ops: wf=reg;p1 r=vvvv r=rm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Vp2intersectq_kp1_ymm_ymmm256b64
INSTRUCTION: EVEX.256.F2.0F38.W1 68 /r | VP2INTERSECTQ k1+1, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512_VP2INTERSECT | N32b8
	ops: wf=reg;p1 r=vvvv r=rm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vp2intersectq_kp1_zmm_zmmm512b64
INSTRUCTION: EVEX.512.F2.0F38.W1 68 /r | VP2INTERSECTQ k1+1, zmm2, zmm3/m512/m64bcst | AVX512F AVX512_VP2INTERSECT | N64b8
	ops: wf=reg;p1 r=vvvv r=rm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: EVEX_Vpshldvw_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F38.W1 70 /r | VPSHLDVW xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512_VBMI2 | N16
	ops: rw=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: EVEX_Vpshldvw_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F38.W1 70 /r | VPSHLDVW ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512_VBMI2 | N32
	ops: rw=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: EVEX_Vpshldvw_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F38.W1 70 /r | VPSHLDVW zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512_VBMI2 | N64
	ops: rwvmm=reg r=vvvv r=rm | Packed512_UInt16
END

# Code: EVEX_Vpshldvd_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 71 /r | VPSHLDVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512_VBMI2 | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_UInt32 Broadcast128_UInt32
END

# Code: EVEX_Vpshldvd_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 71 /r | VPSHLDVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512_VBMI2 | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vpshldvd_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 71 /r | VPSHLDVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512_VBMI2 | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: EVEX_Vpshldvq_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 71 /r | VPSHLDVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512_VBMI2 | N16b8
	ops: rw=reg r=vvvv r=rm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Vpshldvq_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 71 /r | VPSHLDVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512_VBMI2 | N32b8
	ops: rw=reg r=vvvv r=rm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vpshldvq_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 71 /r | VPSHLDVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512_VBMI2 | N64b8
	ops: rwvmm=reg r=vvvv r=rm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: EVEX_Vpshrdvw_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F38.W1 72 /r | VPSHRDVW xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512_VBMI2 | N16
	ops: rw=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: EVEX_Vpshrdvw_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F38.W1 72 /r | VPSHRDVW ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512_VBMI2 | N32
	ops: rw=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: EVEX_Vpshrdvw_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F38.W1 72 /r | VPSHRDVW zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512_VBMI2 | N64
	ops: rwvmm=reg r=vvvv r=rm | Packed512_UInt16
END

# Code: EVEX_Vcvtneps2bf16_xmm_k1z_xmmm128b32
INSTRUCTION: EVEX.128.F3.0F38.W0 72 /r | VCVTNEPS2BF16 xmm1 {k1}{z}, xmm2/m128/m32bcst | AVX512VL AVX512_BF16 | N16b4
	ops: w=reg r=rm | Packed128_Float32 Broadcast128_Float32
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=x
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vcvtneps2bf16_xmm_k1z_ymmm256b32
INSTRUCTION: EVEX.256.F3.0F38.W0 72 /r | VCVTNEPS2BF16 xmm1 {k1}{z}, ymm2/m256/m32bcst | AVX512VL AVX512_BF16 | N32b4
	ops: w=reg r=rm | Packed256_Float32 Broadcast256_Float32
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=y
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vcvtneps2bf16_ymm_k1z_zmmm512b32
INSTRUCTION: EVEX.512.F3.0F38.W0 72 /r | VCVTNEPS2BF16 ymm1 {k1}{z}, zmm2/m512/m32bcst | AVX512F AVX512_BF16 | N64b4
	ops: w=reg r=rm | Packed512_Float32 Broadcast512_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtne2ps2bf16_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.F2.0F38.W0 72 /r | VCVTNE2PS2BF16 xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512_BF16 | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vcvtne2ps2bf16_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.F2.0F38.W0 72 /r | VCVTNE2PS2BF16 ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512_BF16 | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vcvtne2ps2bf16_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.F2.0F38.W0 72 /r | VCVTNE2PS2BF16 zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F AVX512_BF16 | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vpshrdvd_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 73 /r | VPSHRDVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512_VBMI2 | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_UInt32 Broadcast128_UInt32
END

# Code: EVEX_Vpshrdvd_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 73 /r | VPSHRDVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512_VBMI2 | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vpshrdvd_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 73 /r | VPSHRDVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512_VBMI2 | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: EVEX_Vpshrdvq_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 73 /r | VPSHRDVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512_VBMI2 | N16b8
	ops: rw=reg r=vvvv r=rm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Vpshrdvq_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 73 /r | VPSHRDVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512_VBMI2 | N32b8
	ops: rw=reg r=vvvv r=rm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vpshrdvq_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 73 /r | VPSHRDVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512_VBMI2 | N64b8
	ops: rwvmm=reg r=vvvv r=rm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: EVEX_Vpermi2b_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F38.W0 75 /r | VPERMI2B xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512_VBMI | N16
	ops: rw=reg r=vvvv r=rm | Packed128_UInt8
END

# Code: EVEX_Vpermi2b_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F38.W0 75 /r | VPERMI2B ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512_VBMI | N32
	ops: rw=reg r=vvvv r=rm | Packed256_UInt8
END

# Code: EVEX_Vpermi2b_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F38.W0 75 /r | VPERMI2B zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512_VBMI | N64
	ops: rwvmm=reg r=vvvv r=rm | Packed512_UInt8
END

# Code: EVEX_Vpermi2w_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F38.W1 75 /r | VPERMI2W xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: rw=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: EVEX_Vpermi2w_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F38.W1 75 /r | VPERMI2W ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: rw=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: EVEX_Vpermi2w_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F38.W1 75 /r | VPERMI2W zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: rwvmm=reg r=vvvv r=rm | Packed512_UInt16
END

# Code: EVEX_Vpermi2d_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 76 /r | VPERMI2D xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_UInt32 Broadcast128_UInt32
END

# Code: EVEX_Vpermi2d_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 76 /r | VPERMI2D ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vpermi2d_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 76 /r | VPERMI2D zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: EVEX_Vpermi2q_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 76 /r | VPERMI2Q xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: rw=reg r=vvvv r=rm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Vpermi2q_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 76 /r | VPERMI2Q ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: rw=reg r=vvvv r=rm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vpermi2q_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 76 /r | VPERMI2Q zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: rwvmm=reg r=vvvv r=rm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: EVEX_Vpermi2ps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 77 /r | VPERMI2PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vpermi2ps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 77 /r | VPERMI2PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vpermi2ps_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 77 /r | VPERMI2PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vpermi2pd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 77 /r | VPERMI2PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: rw=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vpermi2pd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 77 /r | VPERMI2PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: rw=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vpermi2pd_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 77 /r | VPERMI2PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: VEX_Vpbroadcastb_xmm_xmmm8
INSTRUCTION: VEX.128.66.0F38.W0 78 /r | VPBROADCASTB xmm1, xmm2/m8 | AVX2
	ops: w=reg r=rm | Int8
	masm: flags=force-size=default
END

# Code: VEX_Vpbroadcastb_ymm_xmmm8
INSTRUCTION: VEX.256.66.0F38.W0 78 /r | VPBROADCASTB ymm1, xmm2/m8 | AVX2
	ops: w=reg r=rm | Int8
	masm: flags=force-size=default
END

# Code: EVEX_Vpbroadcastb_xmm_k1z_xmmm8
INSTRUCTION: EVEX.128.66.0F38.W0 78 /r | VPBROADCASTB xmm1 {k1}{z}, xmm2/m8 | AVX512VL AVX512BW | N1
	ops: w=reg r=rm | Int8
	masm: flags=force-size=default
END

# Code: EVEX_Vpbroadcastb_ymm_k1z_xmmm8
INSTRUCTION: EVEX.256.66.0F38.W0 78 /r | VPBROADCASTB ymm1 {k1}{z}, xmm2/m8 | AVX512VL AVX512BW | N1
	ops: w=reg r=rm | Int8
	masm: flags=force-size=default
END

# Code: EVEX_Vpbroadcastb_zmm_k1z_xmmm8
INSTRUCTION: EVEX.512.66.0F38.W0 78 /r | VPBROADCASTB zmm1 {k1}{z}, xmm2/m8 | AVX512BW | N1
	ops: wvmm=reg r=rm | Int8
	masm: flags=force-size=default
END

# Code: VEX_Vpbroadcastw_xmm_xmmm16
INSTRUCTION: VEX.128.66.0F38.W0 79 /r | VPBROADCASTW xmm1, xmm2/m16 | AVX2
	ops: w=reg r=rm | Int16
	masm: flags=force-size=default
END

# Code: VEX_Vpbroadcastw_ymm_xmmm16
INSTRUCTION: VEX.256.66.0F38.W0 79 /r | VPBROADCASTW ymm1, xmm2/m16 | AVX2
	ops: w=reg r=rm | Int16
	masm: flags=force-size=default
END

# Code: EVEX_Vpbroadcastw_xmm_k1z_xmmm16
INSTRUCTION: EVEX.128.66.0F38.W0 79 /r | VPBROADCASTW xmm1 {k1}{z}, xmm2/m16 | AVX512VL AVX512BW | N2
	ops: w=reg r=rm | Int16
	masm: flags=force-size=default
END

# Code: EVEX_Vpbroadcastw_ymm_k1z_xmmm16
INSTRUCTION: EVEX.256.66.0F38.W0 79 /r | VPBROADCASTW ymm1 {k1}{z}, xmm2/m16 | AVX512VL AVX512BW | N2
	ops: w=reg r=rm | Int16
	masm: flags=force-size=default
END

# Code: EVEX_Vpbroadcastw_zmm_k1z_xmmm16
INSTRUCTION: EVEX.512.66.0F38.W0 79 /r | VPBROADCASTW zmm1 {k1}{z}, xmm2/m16 | AVX512BW | N2
	ops: wvmm=reg r=rm | Int16
	masm: flags=force-size=default
END

# Code: EVEX_Vpbroadcastb_xmm_k1z_r32
INSTRUCTION: EVEX.128.66.0F38.W0 7A /r | VPBROADCASTB xmm1 {k1}{z}, r32 | AVX512VL AVX512BW
	ops: w=reg r=rm
	implied: last-gpr-8
END

# Code: EVEX_Vpbroadcastb_ymm_k1z_r32
INSTRUCTION: EVEX.256.66.0F38.W0 7A /r | VPBROADCASTB ymm1 {k1}{z}, r32 | AVX512VL AVX512BW
	ops: w=reg r=rm
	implied: last-gpr-8
END

# Code: EVEX_Vpbroadcastb_zmm_k1z_r32
INSTRUCTION: EVEX.512.66.0F38.W0 7A /r | VPBROADCASTB zmm1 {k1}{z}, r32 | AVX512BW
	ops: wvmm=reg r=rm
	implied: last-gpr-8
END

# Code: EVEX_Vpbroadcastw_xmm_k1z_r32
INSTRUCTION: EVEX.128.66.0F38.W0 7B /r | VPBROADCASTW xmm1 {k1}{z}, r32 | AVX512VL AVX512BW
	ops: w=reg r=rm
	implied: last-gpr-16
END

# Code: EVEX_Vpbroadcastw_ymm_k1z_r32
INSTRUCTION: EVEX.256.66.0F38.W0 7B /r | VPBROADCASTW ymm1 {k1}{z}, r32 | AVX512VL AVX512BW
	ops: w=reg r=rm
	implied: last-gpr-16
END

# Code: EVEX_Vpbroadcastw_zmm_k1z_r32
INSTRUCTION: EVEX.512.66.0F38.W0 7B /r | VPBROADCASTW zmm1 {k1}{z}, r32 | AVX512BW
	ops: wvmm=reg r=rm
	implied: last-gpr-16
END

# Code: EVEX_Vpbroadcastd_xmm_k1z_r32
INSTRUCTION: EVEX.128.66.0F38.W0 7C /r | VPBROADCASTD xmm1 {k1}{z}, r32 | AVX512VL AVX512F
	ops: w=reg r=rm
	flags: wig32
END

# Code: EVEX_Vpbroadcastd_ymm_k1z_r32
INSTRUCTION: EVEX.256.66.0F38.W0 7C /r | VPBROADCASTD ymm1 {k1}{z}, r32 | AVX512VL AVX512F
	ops: w=reg r=rm
	flags: wig32
END

# Code: EVEX_Vpbroadcastd_zmm_k1z_r32
INSTRUCTION: EVEX.512.66.0F38.W0 7C /r | VPBROADCASTD zmm1 {k1}{z}, r32 | AVX512F
	ops: wvmm=reg r=rm
	flags: wig32
END

# Code: EVEX_Vpbroadcastq_xmm_k1z_r64
INSTRUCTION: EVEX.128.66.0F38.W1 7C /r | VPBROADCASTQ xmm1 {k1}{z}, r64 | AVX512VL AVX512F
	ops: w=reg r=rm
	flags: 64
END

# Code: EVEX_Vpbroadcastq_ymm_k1z_r64
INSTRUCTION: EVEX.256.66.0F38.W1 7C /r | VPBROADCASTQ ymm1 {k1}{z}, r64 | AVX512VL AVX512F
	ops: w=reg r=rm
	flags: 64
END

# Code: EVEX_Vpbroadcastq_zmm_k1z_r64
INSTRUCTION: EVEX.512.66.0F38.W1 7C /r | VPBROADCASTQ zmm1 {k1}{z}, r64 | AVX512F
	ops: wvmm=reg r=rm
	flags: 64
END

# Code: EVEX_Vpermt2b_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F38.W0 7D /r | VPERMT2B xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512_VBMI | N16
	ops: rw=reg r=vvvv r=rm | Packed128_UInt8
END

# Code: EVEX_Vpermt2b_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F38.W0 7D /r | VPERMT2B ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512_VBMI | N32
	ops: rw=reg r=vvvv r=rm | Packed256_UInt8
END

# Code: EVEX_Vpermt2b_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F38.W0 7D /r | VPERMT2B zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512_VBMI | N64
	ops: rwvmm=reg r=vvvv r=rm | Packed512_UInt8
END

# Code: EVEX_Vpermt2w_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F38.W1 7D /r | VPERMT2W xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: rw=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: EVEX_Vpermt2w_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F38.W1 7D /r | VPERMT2W ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: rw=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: EVEX_Vpermt2w_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F38.W1 7D /r | VPERMT2W zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: rwvmm=reg r=vvvv r=rm | Packed512_UInt16
END

# Code: EVEX_Vpermt2d_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 7E /r | VPERMT2D xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_UInt32 Broadcast128_UInt32
END

# Code: EVEX_Vpermt2d_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 7E /r | VPERMT2D ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vpermt2d_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 7E /r | VPERMT2D zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: EVEX_Vpermt2q_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 7E /r | VPERMT2Q xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: rw=reg r=vvvv r=rm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Vpermt2q_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 7E /r | VPERMT2Q ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: rw=reg r=vvvv r=rm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vpermt2q_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 7E /r | VPERMT2Q zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: rwvmm=reg r=vvvv r=rm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: EVEX_Vpermt2ps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 7F /r | VPERMT2PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vpermt2ps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 7F /r | VPERMT2PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vpermt2ps_zmm_k1z_zmm_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 7F /r | VPERMT2PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst | AVX512F | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vpermt2pd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 7F /r | VPERMT2PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: rw=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vpermt2pd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 7F /r | VPERMT2PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: rw=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vpermt2pd_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 7F /r | VPERMT2PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512F | N64b8
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: Invept_r32_m128
INSTRUCTION: 66 0F 38 80 /r | INVEPT r32, m128 | VMX INVEPT
	ops: r=reg r=rm | UInt128
	rflags: w=zc 0=osap
	flags: 16 32 cpl0 no-rm no-v86 no-cm serialize-intel vmx=op intel-vm-exit tdx-non-root-ud tsx-impl-abort
	masm: flags=mem-size=normal;force-size=default
END

# Code: Invept_r64_m128
INSTRUCTION: 66 0F 38 80 /r | INVEPT r64, m128 | VMX INVEPT
	ops: r=reg r=rm | UInt128
	rflags: w=zc 0=osap
	flags: 64 cpl0 no-rm no-v86 no-cm serialize-intel vmx=op intel-vm-exit tdx-non-root-ud tsx-impl-abort
	masm: flags=mem-size=normal;force-size=default
END

# Code: Invvpid_r32_m128
INSTRUCTION: 66 0F 38 81 /r | INVVPID r32, m128 | VMX INVVPID
	ops: r=reg r=rm | UInt128
	rflags: w=zc 0=osap
	flags: 16 32 cpl0 no-rm no-v86 no-cm serialize-intel vmx=op intel-vm-exit tdx-non-root-ud tsx-impl-abort
	masm: flags=mem-size=normal;force-size=default
END

# Code: Invvpid_r64_m128
INSTRUCTION: 66 0F 38 81 /r | INVVPID r64, m128 | VMX INVVPID
	ops: r=reg r=rm | UInt128
	rflags: w=zc 0=osap
	flags: 64 cpl0 no-rm no-v86 no-cm serialize-intel vmx=op intel-vm-exit tdx-non-root-ud tsx-impl-abort
	masm: flags=mem-size=normal;force-size=default
END

# Code: Invpcid_r32_m128
INSTRUCTION: 66 0F 38 82 /r | INVPCID r32, m128 | INVPCID
	ops: r=reg r=rm | UInt128
	# AMD: no-rm no-v86
	flags: 16 32 cpl0 serialize-intel serialize-amd intel-may-vm-exit amd-may-vm-exit tsx-impl-abort
	masm: flags=mem-size=normal;force-size=default
END

# Code: Invpcid_r64_m128
INSTRUCTION: 66 0F 38 82 /r | INVPCID r64, m128 | INVPCID
	ops: r=reg r=rm | UInt128
	# AMD: no-rm no-v86
	flags: 64 cpl0 serialize-intel serialize-amd intel-may-vm-exit amd-may-vm-exit tsx-impl-abort
	masm: flags=mem-size=normal;force-size=default
END

# Code: EVEX_Vpmultishiftqb_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 83 /r | VPMULTISHIFTQB xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512_VBMI | N16b8
	ops: w=reg r=vvvv r=rm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Vpmultishiftqb_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 83 /r | VPMULTISHIFTQB ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512_VBMI | N32b8
	ops: w=reg r=vvvv r=rm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vpmultishiftqb_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 83 /r | VPMULTISHIFTQB zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512_VBMI | N64b8
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: EVEX_Vexpandps_xmm_k1z_xmmm128
INSTRUCTION: EVEX.128.66.0F38.W0 88 /r | VEXPANDPS xmm1 {k1}{z}, xmm2/m128 | AVX512VL AVX512F | N4
	ops: w=reg r=rm | Packed128_Float32
END

# Code: EVEX_Vexpandps_ymm_k1z_ymmm256
INSTRUCTION: EVEX.256.66.0F38.W0 88 /r | VEXPANDPS ymm1 {k1}{z}, ymm2/m256 | AVX512VL AVX512F | N4
	ops: w=reg r=rm | Packed256_Float32
END

# Code: EVEX_Vexpandps_zmm_k1z_zmmm512
INSTRUCTION: EVEX.512.66.0F38.W0 88 /r | VEXPANDPS zmm1 {k1}{z}, zmm2/m512 | AVX512F | N4
	ops: wvmm=reg r=rm | Packed512_Float32
END

# Code: EVEX_Vexpandpd_xmm_k1z_xmmm128
INSTRUCTION: EVEX.128.66.0F38.W1 88 /r | VEXPANDPD xmm1 {k1}{z}, xmm2/m128 | AVX512VL AVX512F | N8
	ops: w=reg r=rm | Packed128_Float64
END

# Code: EVEX_Vexpandpd_ymm_k1z_ymmm256
INSTRUCTION: EVEX.256.66.0F38.W1 88 /r | VEXPANDPD ymm1 {k1}{z}, ymm2/m256 | AVX512VL AVX512F | N8
	ops: w=reg r=rm | Packed256_Float64
END

# Code: EVEX_Vexpandpd_zmm_k1z_zmmm512
INSTRUCTION: EVEX.512.66.0F38.W1 88 /r | VEXPANDPD zmm1 {k1}{z}, zmm2/m512 | AVX512F | N8
	ops: wvmm=reg r=rm | Packed512_Float64
END

# Code: EVEX_Vpexpandd_xmm_k1z_xmmm128
INSTRUCTION: EVEX.128.66.0F38.W0 89 /r | VPEXPANDD xmm1 {k1}{z}, xmm2/m128 | AVX512VL AVX512F | N4
	ops: w=reg r=rm | Packed128_UInt32
END

# Code: EVEX_Vpexpandd_ymm_k1z_ymmm256
INSTRUCTION: EVEX.256.66.0F38.W0 89 /r | VPEXPANDD ymm1 {k1}{z}, ymm2/m256 | AVX512VL AVX512F | N4
	ops: w=reg r=rm | Packed256_UInt32
END

# Code: EVEX_Vpexpandd_zmm_k1z_zmmm512
INSTRUCTION: EVEX.512.66.0F38.W0 89 /r | VPEXPANDD zmm1 {k1}{z}, zmm2/m512 | AVX512F | N4
	ops: wvmm=reg r=rm | Packed512_UInt32
END

# Code: EVEX_Vpexpandq_xmm_k1z_xmmm128
INSTRUCTION: EVEX.128.66.0F38.W1 89 /r | VPEXPANDQ xmm1 {k1}{z}, xmm2/m128 | AVX512VL AVX512F | N8
	ops: w=reg r=rm | Packed128_UInt64
END

# Code: EVEX_Vpexpandq_ymm_k1z_ymmm256
INSTRUCTION: EVEX.256.66.0F38.W1 89 /r | VPEXPANDQ ymm1 {k1}{z}, ymm2/m256 | AVX512VL AVX512F | N8
	ops: w=reg r=rm | Packed256_UInt64
END

# Code: EVEX_Vpexpandq_zmm_k1z_zmmm512
INSTRUCTION: EVEX.512.66.0F38.W1 89 /r | VPEXPANDQ zmm1 {k1}{z}, zmm2/m512 | AVX512F | N8
	ops: wvmm=reg r=rm | Packed512_UInt64
END

# Code: EVEX_Vcompressps_xmmm128_k1z_xmm
INSTRUCTION: EVEX.128.66.0F38.W0 8A /r | VCOMPRESSPS xmm1/m128 {k1}{z}, xmm2 | AVX512VL AVX512F | N4
	ops: w=rm r=reg | Packed128_Float32
END

# Code: EVEX_Vcompressps_ymmm256_k1z_ymm
INSTRUCTION: EVEX.256.66.0F38.W0 8A /r | VCOMPRESSPS ymm1/m256 {k1}{z}, ymm2 | AVX512VL AVX512F | N4
	ops: w=rm r=reg | Packed256_Float32
END

# Code: EVEX_Vcompressps_zmmm512_k1z_zmm
INSTRUCTION: EVEX.512.66.0F38.W0 8A /r | VCOMPRESSPS zmm1/m512 {k1}{z}, zmm2 | AVX512F | N4
	ops: wvmm=rm r=reg | Packed512_Float32
END

# Code: EVEX_Vcompresspd_xmmm128_k1z_xmm
INSTRUCTION: EVEX.128.66.0F38.W1 8A /r | VCOMPRESSPD xmm1/m128 {k1}{z}, xmm2 | AVX512VL AVX512F | N8
	ops: w=rm r=reg | Packed128_Float64
END

# Code: EVEX_Vcompresspd_ymmm256_k1z_ymm
INSTRUCTION: EVEX.256.66.0F38.W1 8A /r | VCOMPRESSPD ymm1/m256 {k1}{z}, ymm2 | AVX512VL AVX512F | N8
	ops: w=rm r=reg | Packed256_Float64
END

# Code: EVEX_Vcompresspd_zmmm512_k1z_zmm
INSTRUCTION: EVEX.512.66.0F38.W1 8A /r | VCOMPRESSPD zmm1/m512 {k1}{z}, zmm2 | AVX512F | N8
	ops: wvmm=rm r=reg | Packed512_Float64
END

# Code: EVEX_Vpcompressd_xmmm128_k1z_xmm
INSTRUCTION: EVEX.128.66.0F38.W0 8B /r | VPCOMPRESSD xmm1/m128 {k1}{z}, xmm2 | AVX512VL AVX512F | N4
	ops: w=rm r=reg | Packed128_UInt32
END

# Code: EVEX_Vpcompressd_ymmm256_k1z_ymm
INSTRUCTION: EVEX.256.66.0F38.W0 8B /r | VPCOMPRESSD ymm1/m256 {k1}{z}, ymm2 | AVX512VL AVX512F | N4
	ops: w=rm r=reg | Packed256_UInt32
END

# Code: EVEX_Vpcompressd_zmmm512_k1z_zmm
INSTRUCTION: EVEX.512.66.0F38.W0 8B /r | VPCOMPRESSD zmm1/m512 {k1}{z}, zmm2 | AVX512F | N4
	ops: wvmm=rm r=reg | Packed512_UInt32
END

# Code: EVEX_Vpcompressq_xmmm128_k1z_xmm
INSTRUCTION: EVEX.128.66.0F38.W1 8B /r | VPCOMPRESSQ xmm1/m128 {k1}{z}, xmm2 | AVX512VL AVX512F | N8
	ops: w=rm r=reg | Packed128_UInt64
END

# Code: EVEX_Vpcompressq_ymmm256_k1z_ymm
INSTRUCTION: EVEX.256.66.0F38.W1 8B /r | VPCOMPRESSQ ymm1/m256 {k1}{z}, ymm2 | AVX512VL AVX512F | N8
	ops: w=rm r=reg | Packed256_UInt64
END

# Code: EVEX_Vpcompressq_zmmm512_k1z_zmm
INSTRUCTION: EVEX.512.66.0F38.W1 8B /r | VPCOMPRESSQ zmm1/m512 {k1}{z}, zmm2 | AVX512F | N8
	ops: wvmm=rm r=reg | Packed512_UInt64
END

# Code: VEX_Vpmaskmovd_xmm_xmm_m128
INSTRUCTION: VEX.128.66.0F38.W0 8C /r | VPMASKMOVD xmm1, xmm2, m128 | AVX2
	ops: w=reg r=vvvv r=rm | Packed128_UInt32
END

# Code: VEX_Vpmaskmovd_ymm_ymm_m256
INSTRUCTION: VEX.256.66.0F38.W0 8C /r | VPMASKMOVD ymm1, ymm2, m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt32
END

# Code: VEX_Vpmaskmovq_xmm_xmm_m128
INSTRUCTION: VEX.128.66.0F38.W1 8C /r | VPMASKMOVQ xmm1, xmm2, m128 | AVX2
	ops: w=reg r=vvvv r=rm | Packed128_UInt64
END

# Code: VEX_Vpmaskmovq_ymm_ymm_m256
INSTRUCTION: VEX.256.66.0F38.W1 8C /r | VPMASKMOVQ ymm1, ymm2, m256 | AVX2
	ops: w=reg r=vvvv r=rm | Packed256_UInt64
END

# Code: EVEX_Vpermb_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F38.W0 8D /r | VPERMB xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512_VBMI | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
END

# Code: EVEX_Vpermb_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F38.W0 8D /r | VPERMB ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512_VBMI | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
END

# Code: EVEX_Vpermb_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F38.W0 8D /r | VPERMB zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512_VBMI | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt8
END

# Code: EVEX_Vpermw_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F38.W1 8D /r | VPERMW xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: EVEX_Vpermw_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F38.W1 8D /r | VPERMW ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: EVEX_Vpermw_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F38.W1 8D /r | VPERMW zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt16
END

# Code: VEX_Vpmaskmovd_m128_xmm_xmm
INSTRUCTION: VEX.128.66.0F38.W0 8E /r | VPMASKMOVD m128, xmm1, xmm2 | AVX2
	ops: w=rm r=vvvv r=reg | Packed128_UInt32
END

# Code: VEX_Vpmaskmovd_m256_ymm_ymm
INSTRUCTION: VEX.256.66.0F38.W0 8E /r | VPMASKMOVD m256, ymm1, ymm2 | AVX2
	ops: w=rm r=vvvv r=reg | Packed256_UInt32
END

# Code: VEX_Vpmaskmovq_m128_xmm_xmm
INSTRUCTION: VEX.128.66.0F38.W1 8E /r | VPMASKMOVQ m128, xmm1, xmm2 | AVX2
	ops: w=rm r=vvvv r=reg | Packed128_UInt64
END

# Code: VEX_Vpmaskmovq_m256_ymm_ymm
INSTRUCTION: VEX.256.66.0F38.W1 8E /r | VPMASKMOVQ m256, ymm1, ymm2 | AVX2
	ops: w=rm r=vvvv r=reg | Packed256_UInt64
END

# Code: EVEX_Vpshufbitqmb_kr_k1_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F38.W0 8F /r | VPSHUFBITQMB k1 {k2}, xmm2, xmm3/m128 | AVX512VL AVX512_BITALG | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
	flags: implied-z
END

# Code: EVEX_Vpshufbitqmb_kr_k1_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F38.W0 8F /r | VPSHUFBITQMB k1 {k2}, ymm2, ymm3/m256 | AVX512VL AVX512_BITALG | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
	flags: implied-z
END

# Code: EVEX_Vpshufbitqmb_kr_k1_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F38.W0 8F /r | VPSHUFBITQMB k1 {k2}, zmm2, zmm3/m512 | AVX512_BITALG | N64
	ops: w=reg r=vvvv r=rm | Packed512_UInt8
	flags: implied-z
END

# Code: VEX_Vpgatherdd_xmm_vm32x_xmm
INSTRUCTION: VEX.128.66.0F38.W0 90 /r | VPGATHERDD xmm1, vm32x, xmm2 | AVX2
	ops: rw=reg r=rm rw=vvvv | Int32
	flags: unique-reg-num
END

# Code: VEX_Vpgatherdd_ymm_vm32y_ymm
INSTRUCTION: VEX.256.66.0F38.W0 90 /r | VPGATHERDD ymm1, vm32y, ymm2 | AVX2
	ops: rw=reg r=rm rw=vvvv | Int32
	flags: unique-reg-num
END

# Code: VEX_Vpgatherdq_xmm_vm32x_xmm
INSTRUCTION: VEX.128.66.0F38.W1 90 /r | VPGATHERDQ xmm1, vm32x, xmm2 | AVX2
	ops: rw=reg r=rm rw=vvvv | Int64
	flags: unique-reg-num
END

# Code: VEX_Vpgatherdq_ymm_vm32x_ymm
INSTRUCTION: VEX.256.66.0F38.W1 90 /r | VPGATHERDQ ymm1, vm32x, ymm2 | AVX2
	ops: rw=reg r=rm rw=vvvv | Int64
	flags: unique-reg-num
END

# Code: EVEX_Vpgatherdd_xmm_k1_vm32x
INSTRUCTION: EVEX.128.66.0F38.W0 90 /vsib | VPGATHERDD xmm1 {k1}, vm32x | AVX512VL AVX512F | N4
	ops: w=reg r=rm | Int32
	flags: krw knz unique-reg-num
	intel: kmask-op
END

# Code: EVEX_Vpgatherdd_ymm_k1_vm32y
INSTRUCTION: EVEX.256.66.0F38.W0 90 /vsib | VPGATHERDD ymm1 {k1}, vm32y | AVX512VL AVX512F | N4
	ops: w=reg r=rm | Int32
	flags: krw knz unique-reg-num
	intel: kmask-op
END

# Code: EVEX_Vpgatherdd_zmm_k1_vm32z
INSTRUCTION: EVEX.512.66.0F38.W0 90 /vsib | VPGATHERDD zmm1 {k1}, vm32z | AVX512F | N4
	ops: wvmm=reg r=rm | Int32
	flags: krw knz unique-reg-num
	intel: kmask-op
END

# Code: EVEX_Vpgatherdq_xmm_k1_vm32x
INSTRUCTION: EVEX.128.66.0F38.W1 90 /vsib | VPGATHERDQ xmm1 {k1}, vm32x | AVX512VL AVX512F | N8
	ops: w=reg r=rm | Int64
	flags: krw knz unique-reg-num
	intel: kmask-op
END

# Code: EVEX_Vpgatherdq_ymm_k1_vm32x
INSTRUCTION: EVEX.256.66.0F38.W1 90 /vsib | VPGATHERDQ ymm1 {k1}, vm32x | AVX512VL AVX512F | N8
	ops: w=reg r=rm | Int64
	flags: krw knz unique-reg-num
	intel: kmask-op
END

# Code: EVEX_Vpgatherdq_zmm_k1_vm32y
INSTRUCTION: EVEX.512.66.0F38.W1 90 /vsib | VPGATHERDQ zmm1 {k1}, vm32y | AVX512F | N8
	ops: wvmm=reg r=rm | Int64
	flags: krw knz unique-reg-num
	intel: kmask-op
END

# Code: VEX_Vpgatherqd_xmm_vm64x_xmm
INSTRUCTION: VEX.128.66.0F38.W0 91 /r | VPGATHERQD xmm1, vm64x, xmm2 | AVX2
	ops: rw=reg r=rm rw=vvvv | Int32
	flags: unique-reg-num
END

# Code: VEX_Vpgatherqd_xmm_vm64y_xmm
INSTRUCTION: VEX.256.66.0F38.W0 91 /r | VPGATHERQD xmm1, vm64y, xmm2 | AVX2
	ops: rw=reg r=rm rw=vvvv | Int32
	flags: unique-reg-num
END

# Code: VEX_Vpgatherqq_xmm_vm64x_xmm
INSTRUCTION: VEX.128.66.0F38.W1 91 /r | VPGATHERQQ xmm1, vm64x, xmm2 | AVX2
	ops: rw=reg r=rm rw=vvvv | Int64
	flags: unique-reg-num
END

# Code: VEX_Vpgatherqq_ymm_vm64y_ymm
INSTRUCTION: VEX.256.66.0F38.W1 91 /r | VPGATHERQQ ymm1, vm64y, ymm2 | AVX2
	ops: rw=reg r=rm rw=vvvv | Int64
	flags: unique-reg-num
END

# Code: EVEX_Vpgatherqd_xmm_k1_vm64x
INSTRUCTION: EVEX.128.66.0F38.W0 91 /vsib | VPGATHERQD xmm1 {k1}, vm64x | AVX512VL AVX512F | N4
	ops: w=reg r=rm | Int32
	flags: krw knz unique-reg-num
	intel: kmask-op
END

# Code: EVEX_Vpgatherqd_xmm_k1_vm64y
INSTRUCTION: EVEX.256.66.0F38.W0 91 /vsib | VPGATHERQD xmm1 {k1}, vm64y | AVX512VL AVX512F | N4
	ops: w=reg r=rm | Int32
	flags: krw knz unique-reg-num
	intel: kmask-op
END

# Code: EVEX_Vpgatherqd_ymm_k1_vm64z
INSTRUCTION: EVEX.512.66.0F38.W0 91 /vsib | VPGATHERQD ymm1 {k1}, vm64z | AVX512F | N4
	ops: w=reg r=rm | Int32
	flags: krw knz unique-reg-num
	intel: kmask-op
END

# Code: EVEX_Vpgatherqq_xmm_k1_vm64x
INSTRUCTION: EVEX.128.66.0F38.W1 91 /vsib | VPGATHERQQ xmm1 {k1}, vm64x | AVX512VL AVX512F | N8
	ops: w=reg r=rm | Int64
	flags: krw knz unique-reg-num
	intel: kmask-op
END

# Code: EVEX_Vpgatherqq_ymm_k1_vm64y
INSTRUCTION: EVEX.256.66.0F38.W1 91 /vsib | VPGATHERQQ ymm1 {k1}, vm64y | AVX512VL AVX512F | N8
	ops: w=reg r=rm | Int64
	flags: krw knz unique-reg-num
	intel: kmask-op
END

# Code: EVEX_Vpgatherqq_zmm_k1_vm64z
INSTRUCTION: EVEX.512.66.0F38.W1 91 /vsib | VPGATHERQQ zmm1 {k1}, vm64z | AVX512F | N8
	ops: wvmm=reg r=rm | Int64
	flags: krw knz unique-reg-num
	intel: kmask-op
END

# Code: VEX_Vgatherdps_xmm_vm32x_xmm
INSTRUCTION: VEX.128.66.0F38.W0 92 /r | VGATHERDPS xmm1, vm32x, xmm2 | AVX2
	ops: rw=reg r=rm rw=vvvv | Float32
	flags: unique-reg-num
END

# Code: VEX_Vgatherdps_ymm_vm32y_ymm
INSTRUCTION: VEX.256.66.0F38.W0 92 /r | VGATHERDPS ymm1, vm32y, ymm2 | AVX2
	ops: rw=reg r=rm rw=vvvv | Float32
	flags: unique-reg-num
END

# Code: VEX_Vgatherdpd_xmm_vm32x_xmm
INSTRUCTION: VEX.128.66.0F38.W1 92 /r | VGATHERDPD xmm1, vm32x, xmm2 | AVX2
	ops: rw=reg r=rm rw=vvvv | Float64
	flags: unique-reg-num
END

# Code: VEX_Vgatherdpd_ymm_vm32x_ymm
INSTRUCTION: VEX.256.66.0F38.W1 92 /r | VGATHERDPD ymm1, vm32x, ymm2 | AVX2
	ops: rw=reg r=rm rw=vvvv | Float64
	flags: unique-reg-num
END

# Code: EVEX_Vgatherdps_xmm_k1_vm32x
INSTRUCTION: EVEX.128.66.0F38.W0 92 /vsib | VGATHERDPS xmm1 {k1}, vm32x | AVX512VL AVX512F | N4
	ops: rw=reg r=rm | Float32
	flags: krw knz unique-reg-num
	intel: kmask-op
END

# Code: EVEX_Vgatherdps_ymm_k1_vm32y
INSTRUCTION: EVEX.256.66.0F38.W0 92 /vsib | VGATHERDPS ymm1 {k1}, vm32y | AVX512VL AVX512F | N4
	ops: rw=reg r=rm | Float32
	flags: krw knz unique-reg-num
	intel: kmask-op
END

# Code: EVEX_Vgatherdps_zmm_k1_vm32z
INSTRUCTION: EVEX.512.66.0F38.W0 92 /vsib | VGATHERDPS zmm1 {k1}, vm32z | AVX512F | N4
	ops: rwvmm=reg r=rm | Float32
	flags: krw knz unique-reg-num
	intel: kmask-op
END

# Code: EVEX_Vgatherdpd_xmm_k1_vm32x
INSTRUCTION: EVEX.128.66.0F38.W1 92 /vsib | VGATHERDPD xmm1 {k1}, vm32x | AVX512VL AVX512F | N8
	ops: rw=reg r=rm | Float64
	flags: krw knz unique-reg-num
	intel: kmask-op
END

# Code: EVEX_Vgatherdpd_ymm_k1_vm32x
INSTRUCTION: EVEX.256.66.0F38.W1 92 /vsib | VGATHERDPD ymm1 {k1}, vm32x | AVX512VL AVX512F | N8
	ops: rw=reg r=rm | Float64
	flags: krw knz unique-reg-num
	intel: kmask-op
END

# Code: EVEX_Vgatherdpd_zmm_k1_vm32y
INSTRUCTION: EVEX.512.66.0F38.W1 92 /vsib | VGATHERDPD zmm1 {k1}, vm32y | AVX512F | N8
	ops: rwvmm=reg r=rm | Float64
	flags: krw knz unique-reg-num
	intel: kmask-op
END

# Code: VEX_Vgatherqps_xmm_vm64x_xmm
INSTRUCTION: VEX.128.66.0F38.W0 93 /r | VGATHERQPS xmm1, vm64x, xmm2 | AVX2
	ops: rw=reg r=rm rw=vvvv | Float32
	flags: unique-reg-num
END

# Code: VEX_Vgatherqps_xmm_vm64y_xmm
INSTRUCTION: VEX.256.66.0F38.W0 93 /r | VGATHERQPS xmm1, vm64y, xmm2 | AVX2
	ops: rw=reg r=rm rw=vvvv | Float32
	flags: unique-reg-num
END

# Code: VEX_Vgatherqpd_xmm_vm64x_xmm
INSTRUCTION: VEX.128.66.0F38.W1 93 /r | VGATHERQPD xmm1, vm64x, xmm2 | AVX2
	ops: rw=reg r=rm rw=vvvv | Float64
	flags: unique-reg-num
END

# Code: VEX_Vgatherqpd_ymm_vm64y_ymm
INSTRUCTION: VEX.256.66.0F38.W1 93 /r | VGATHERQPD ymm1, vm64y, ymm2 | AVX2
	ops: rw=reg r=rm rw=vvvv | Float64
	flags: unique-reg-num
END

# Code: EVEX_Vgatherqps_xmm_k1_vm64x
INSTRUCTION: EVEX.128.66.0F38.W0 93 /vsib | VGATHERQPS xmm1 {k1}, vm64x | AVX512VL AVX512F | N4
	ops: rw=reg r=rm | Float32
	flags: krw knz unique-reg-num
	intel: kmask-op
END

# Code: EVEX_Vgatherqps_xmm_k1_vm64y
INSTRUCTION: EVEX.256.66.0F38.W0 93 /vsib | VGATHERQPS xmm1 {k1}, vm64y | AVX512VL AVX512F | N4
	ops: rw=reg r=rm | Float32
	flags: krw knz unique-reg-num
	intel: kmask-op
END

# Code: EVEX_Vgatherqps_ymm_k1_vm64z
INSTRUCTION: EVEX.512.66.0F38.W0 93 /vsib | VGATHERQPS ymm1 {k1}, vm64z | AVX512F | N4
	ops: rw=reg r=rm | Float32
	flags: krw knz unique-reg-num
	intel: kmask-op
END

# Code: EVEX_Vgatherqpd_xmm_k1_vm64x
INSTRUCTION: EVEX.128.66.0F38.W1 93 /vsib | VGATHERQPD xmm1 {k1}, vm64x | AVX512VL AVX512F | N8
	ops: rw=reg r=rm | Float64
	flags: krw knz unique-reg-num
	intel: kmask-op
END

# Code: EVEX_Vgatherqpd_ymm_k1_vm64y
INSTRUCTION: EVEX.256.66.0F38.W1 93 /vsib | VGATHERQPD ymm1 {k1}, vm64y | AVX512VL AVX512F | N8
	ops: rw=reg r=rm | Float64
	flags: krw knz unique-reg-num
	intel: kmask-op
END

# Code: EVEX_Vgatherqpd_zmm_k1_vm64z
INSTRUCTION: EVEX.512.66.0F38.W1 93 /vsib | VGATHERQPD zmm1 {k1}, vm64z | AVX512F | N8
	ops: rwvmm=reg r=rm | Float64
	flags: krw knz unique-reg-num
	intel: kmask-op
END

# Code: VEX_Vfmaddsub132ps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 96 /r | VFMADDSUB132PS xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vfmaddsub132ps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 96 /r | VFMADDSUB132PS ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float32
END

# Code: VEX_Vfmaddsub132pd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W1 96 /r | VFMADDSUB132PD xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vfmaddsub132pd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W1 96 /r | VFMADDSUB132PD ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vfmaddsub132ps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 96 /r | VFMADDSUB132PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vfmaddsub132ps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 96 /r | VFMADDSUB132PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vfmaddsub132ps_zmm_k1z_zmm_zmmm512b32_er
INSTRUCTION: EVEX.512.66.0F38.W0 96 /r | VFMADDSUB132PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er} | AVX512F | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vfmaddsub132pd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 96 /r | VFMADDSUB132PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: rw=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vfmaddsub132pd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 96 /r | VFMADDSUB132PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: rw=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vfmaddsub132pd_zmm_k1z_zmm_zmmm512b64_er
INSTRUCTION: EVEX.512.66.0F38.W1 96 /r | VFMADDSUB132PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er} | AVX512F | N64b8
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: VEX_Vfmsubadd132ps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 97 /r | VFMSUBADD132PS xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vfmsubadd132ps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 97 /r | VFMSUBADD132PS ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float32
END

# Code: VEX_Vfmsubadd132pd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W1 97 /r | VFMSUBADD132PD xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vfmsubadd132pd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W1 97 /r | VFMSUBADD132PD ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vfmsubadd132ps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 97 /r | VFMSUBADD132PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vfmsubadd132ps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 97 /r | VFMSUBADD132PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vfmsubadd132ps_zmm_k1z_zmm_zmmm512b32_er
INSTRUCTION: EVEX.512.66.0F38.W0 97 /r | VFMSUBADD132PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er} | AVX512F | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vfmsubadd132pd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 97 /r | VFMSUBADD132PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: rw=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vfmsubadd132pd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 97 /r | VFMSUBADD132PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: rw=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vfmsubadd132pd_zmm_k1z_zmm_zmmm512b64_er
INSTRUCTION: EVEX.512.66.0F38.W1 97 /r | VFMSUBADD132PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er} | AVX512F | N64b8
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: VEX_Vfmadd132ps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 98 /r | VFMADD132PS xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vfmadd132ps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 98 /r | VFMADD132PS ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float32
END

# Code: VEX_Vfmadd132pd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W1 98 /r | VFMADD132PD xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vfmadd132pd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W1 98 /r | VFMADD132PD ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vfmadd132ps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 98 /r | VFMADD132PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vfmadd132ps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 98 /r | VFMADD132PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vfmadd132ps_zmm_k1z_zmm_zmmm512b32_er
INSTRUCTION: EVEX.512.66.0F38.W0 98 /r | VFMADD132PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er} | AVX512F | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vfmadd132pd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 98 /r | VFMADD132PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: rw=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vfmadd132pd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 98 /r | VFMADD132PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: rw=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vfmadd132pd_zmm_k1z_zmm_zmmm512b64_er
INSTRUCTION: EVEX.512.66.0F38.W1 98 /r | VFMADD132PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er} | AVX512F | N64b8
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: VEX_Vfmadd132ss_xmm_xmm_xmmm32
INSTRUCTION: VEX.LIG.66.0F38.W0 99 /r | VFMADD132SS xmm1, xmm2, xmm3/m32 | FMA
	ops: rw=reg r=vvvv r=rm | Float32
END

# Code: VEX_Vfmadd132sd_xmm_xmm_xmmm64
INSTRUCTION: VEX.LIG.66.0F38.W1 99 /r | VFMADD132SD xmm1, xmm2, xmm3/m64 | FMA
	ops: rw=reg r=vvvv r=rm | Float64
END

# Code: EVEX_Vfmadd132ss_xmm_k1z_xmm_xmmm32_er
INSTRUCTION: EVEX.LIG.66.0F38.W0 99 /r | VFMADD132SS xmm1 {k1}{z}, xmm2, xmm3/m32{er} | AVX512F | N4
	ops: rw=reg r=vvvv r=rm | Float32
END

# Code: EVEX_Vfmadd132sd_xmm_k1z_xmm_xmmm64_er
INSTRUCTION: EVEX.LIG.66.0F38.W1 99 /r | VFMADD132SD xmm1 {k1}{z}, xmm2, xmm3/m64{er} | AVX512F | N8
	ops: rw=reg r=vvvv r=rm | Float64
END

# Code: VEX_Vfmsub132ps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 9A /r | VFMSUB132PS xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vfmsub132ps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 9A /r | VFMSUB132PS ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float32
END

# Code: VEX_Vfmsub132pd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W1 9A /r | VFMSUB132PD xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vfmsub132pd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W1 9A /r | VFMSUB132PD ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vfmsub132ps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 9A /r | VFMSUB132PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vfmsub132ps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 9A /r | VFMSUB132PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vfmsub132ps_zmm_k1z_zmm_zmmm512b32_er
INSTRUCTION: EVEX.512.66.0F38.W0 9A /r | VFMSUB132PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er} | AVX512F | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vfmsub132pd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 9A /r | VFMSUB132PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: rw=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vfmsub132pd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 9A /r | VFMSUB132PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: rw=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vfmsub132pd_zmm_k1z_zmm_zmmm512b64_er
INSTRUCTION: EVEX.512.66.0F38.W1 9A /r | VFMSUB132PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er} | AVX512F | N64b8
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: EVEX_V4fmaddps_zmm_k1z_zmmp3_m128
INSTRUCTION: EVEX.512.F2.0F38.W0 9A /r | V4FMADDPS zmm1 {k1}{z}, zmm2+3, m128 | AVX512_4FMAPS | N16
	ops: rwvmm=reg r=vvvv;p3 r=rm | Packed128_Float32
	masm: flags=force-size=default
END

# Code: VEX_Vfmsub132ss_xmm_xmm_xmmm32
INSTRUCTION: VEX.LIG.66.0F38.W0 9B /r | VFMSUB132SS xmm1, xmm2, xmm3/m32 | FMA
	ops: rw=reg r=vvvv r=rm | Float32
END

# Code: VEX_Vfmsub132sd_xmm_xmm_xmmm64
INSTRUCTION: VEX.LIG.66.0F38.W1 9B /r | VFMSUB132SD xmm1, xmm2, xmm3/m64 | FMA
	ops: rw=reg r=vvvv r=rm | Float64
END

# Code: EVEX_Vfmsub132ss_xmm_k1z_xmm_xmmm32_er
INSTRUCTION: EVEX.LIG.66.0F38.W0 9B /r | VFMSUB132SS xmm1 {k1}{z}, xmm2, xmm3/m32{er} | AVX512F | N4
	ops: rw=reg r=vvvv r=rm | Float32
END

# Code: EVEX_Vfmsub132sd_xmm_k1z_xmm_xmmm64_er
INSTRUCTION: EVEX.LIG.66.0F38.W1 9B /r | VFMSUB132SD xmm1 {k1}{z}, xmm2, xmm3/m64{er} | AVX512F | N8
	ops: rw=reg r=vvvv r=rm | Float64
END

# Code: EVEX_V4fmaddss_xmm_k1z_xmmp3_m128
INSTRUCTION: EVEX.LIG.F2.0F38.W0 9B /r | V4FMADDSS xmm1 {k1}{z}, xmm2+3, m128 | AVX512_4FMAPS | N16
	ops: rw=reg r=vvvv;p3 r=rm | Packed128_Float32
	masm: flags=force-size=default
END

# Code: VEX_Vfnmadd132ps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 9C /r | VFNMADD132PS xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vfnmadd132ps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 9C /r | VFNMADD132PS ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float32
END

# Code: VEX_Vfnmadd132pd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W1 9C /r | VFNMADD132PD xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vfnmadd132pd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W1 9C /r | VFNMADD132PD ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vfnmadd132ps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 9C /r | VFNMADD132PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vfnmadd132ps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 9C /r | VFNMADD132PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vfnmadd132ps_zmm_k1z_zmm_zmmm512b32_er
INSTRUCTION: EVEX.512.66.0F38.W0 9C /r | VFNMADD132PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er} | AVX512F | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vfnmadd132pd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 9C /r | VFNMADD132PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: rw=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vfnmadd132pd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 9C /r | VFNMADD132PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: rw=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vfnmadd132pd_zmm_k1z_zmm_zmmm512b64_er
INSTRUCTION: EVEX.512.66.0F38.W1 9C /r | VFNMADD132PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er} | AVX512F | N64b8
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: VEX_Vfnmadd132ss_xmm_xmm_xmmm32
INSTRUCTION: VEX.LIG.66.0F38.W0 9D /r | VFNMADD132SS xmm1, xmm2, xmm3/m32 | FMA
	ops: rw=reg r=vvvv r=rm | Float32
END

# Code: VEX_Vfnmadd132sd_xmm_xmm_xmmm64
INSTRUCTION: VEX.LIG.66.0F38.W1 9D /r | VFNMADD132SD xmm1, xmm2, xmm3/m64 | FMA
	ops: rw=reg r=vvvv r=rm | Float64
END

# Code: EVEX_Vfnmadd132ss_xmm_k1z_xmm_xmmm32_er
INSTRUCTION: EVEX.LIG.66.0F38.W0 9D /r | VFNMADD132SS xmm1 {k1}{z}, xmm2, xmm3/m32{er} | AVX512F | N4
	ops: rw=reg r=vvvv r=rm | Float32
END

# Code: EVEX_Vfnmadd132sd_xmm_k1z_xmm_xmmm64_er
INSTRUCTION: EVEX.LIG.66.0F38.W1 9D /r | VFNMADD132SD xmm1 {k1}{z}, xmm2, xmm3/m64{er} | AVX512F | N8
	ops: rw=reg r=vvvv r=rm | Float64
END

# Code: VEX_Vfnmsub132ps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 9E /r | VFNMSUB132PS xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vfnmsub132ps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 9E /r | VFNMSUB132PS ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float32
END

# Code: VEX_Vfnmsub132pd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W1 9E /r | VFNMSUB132PD xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vfnmsub132pd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W1 9E /r | VFNMSUB132PD ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vfnmsub132ps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 9E /r | VFNMSUB132PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vfnmsub132ps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 9E /r | VFNMSUB132PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vfnmsub132ps_zmm_k1z_zmm_zmmm512b32_er
INSTRUCTION: EVEX.512.66.0F38.W0 9E /r | VFNMSUB132PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er} | AVX512F | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vfnmsub132pd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 9E /r | VFNMSUB132PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: rw=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vfnmsub132pd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 9E /r | VFNMSUB132PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: rw=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vfnmsub132pd_zmm_k1z_zmm_zmmm512b64_er
INSTRUCTION: EVEX.512.66.0F38.W1 9E /r | VFNMSUB132PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er} | AVX512F | N64b8
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: VEX_Vfnmsub132ss_xmm_xmm_xmmm32
INSTRUCTION: VEX.LIG.66.0F38.W0 9F /r | VFNMSUB132SS xmm1, xmm2, xmm3/m32 | FMA
	ops: rw=reg r=vvvv r=rm | Float32
END

# Code: VEX_Vfnmsub132sd_xmm_xmm_xmmm64
INSTRUCTION: VEX.LIG.66.0F38.W1 9F /r | VFNMSUB132SD xmm1, xmm2, xmm3/m64 | FMA
	ops: rw=reg r=vvvv r=rm | Float64
END

# Code: EVEX_Vfnmsub132ss_xmm_k1z_xmm_xmmm32_er
INSTRUCTION: EVEX.LIG.66.0F38.W0 9F /r | VFNMSUB132SS xmm1 {k1}{z}, xmm2, xmm3/m32{er} | AVX512F | N4
	ops: rw=reg r=vvvv r=rm | Float32
END

# Code: EVEX_Vfnmsub132sd_xmm_k1z_xmm_xmmm64_er
INSTRUCTION: EVEX.LIG.66.0F38.W1 9F /r | VFNMSUB132SD xmm1 {k1}{z}, xmm2, xmm3/m64{er} | AVX512F | N8
	ops: rw=reg r=vvvv r=rm | Float64
END

# Code: EVEX_Vpscatterdd_vm32x_k1_xmm
INSTRUCTION: EVEX.128.66.0F38.W0 A0 /vsib | VPSCATTERDD vm32x {k1}, xmm1 | AVX512VL AVX512F | N4
	ops: w=rm r=reg | Int32
	flags: krw knz
	intel: kmask-op
END

# Code: EVEX_Vpscatterdd_vm32y_k1_ymm
INSTRUCTION: EVEX.256.66.0F38.W0 A0 /vsib | VPSCATTERDD vm32y {k1}, ymm1 | AVX512VL AVX512F | N4
	ops: w=rm r=reg | Int32
	flags: krw knz
	intel: kmask-op
END

# Code: EVEX_Vpscatterdd_vm32z_k1_zmm
INSTRUCTION: EVEX.512.66.0F38.W0 A0 /vsib | VPSCATTERDD vm32z {k1}, zmm1 | AVX512F | N4
	ops: w=rm r=reg | Int32
	flags: krw knz
	intel: kmask-op
END

# Code: EVEX_Vpscatterdq_vm32x_k1_xmm
INSTRUCTION: EVEX.128.66.0F38.W1 A0 /vsib | VPSCATTERDQ vm32x {k1}, xmm1 | AVX512VL AVX512F | N8
	ops: w=rm r=reg | Int64
	flags: krw knz
	intel: kmask-op
END

# Code: EVEX_Vpscatterdq_vm32x_k1_ymm
INSTRUCTION: EVEX.256.66.0F38.W1 A0 /vsib | VPSCATTERDQ vm32x {k1}, ymm1 | AVX512VL AVX512F | N8
	ops: w=rm r=reg | Int64
	flags: krw knz
	intel: kmask-op
END

# Code: EVEX_Vpscatterdq_vm32y_k1_zmm
INSTRUCTION: EVEX.512.66.0F38.W1 A0 /vsib | VPSCATTERDQ vm32y {k1}, zmm1 | AVX512F | N8
	ops: w=rm r=reg | Int64
	flags: krw knz
	intel: kmask-op
END

# Code: EVEX_Vpscatterqd_vm64x_k1_xmm
INSTRUCTION: EVEX.128.66.0F38.W0 A1 /vsib | VPSCATTERQD vm64x {k1}, xmm1 | AVX512VL AVX512F | N4
	ops: w=rm r=reg | Int32
	flags: krw knz
	intel: kmask-op
END

# Code: EVEX_Vpscatterqd_vm64y_k1_xmm
INSTRUCTION: EVEX.256.66.0F38.W0 A1 /vsib | VPSCATTERQD vm64y {k1}, xmm1 | AVX512VL AVX512F | N4
	ops: w=rm r=reg | Int32
	flags: krw knz
	intel: kmask-op
END

# Code: EVEX_Vpscatterqd_vm64z_k1_ymm
INSTRUCTION: EVEX.512.66.0F38.W0 A1 /vsib | VPSCATTERQD vm64z {k1}, ymm1 | AVX512F | N4
	ops: w=rm r=reg | Int32
	flags: krw knz
	intel: kmask-op
END

# Code: EVEX_Vpscatterqq_vm64x_k1_xmm
INSTRUCTION: EVEX.128.66.0F38.W1 A1 /vsib | VPSCATTERQQ vm64x {k1}, xmm1 | AVX512VL AVX512F | N8
	ops: w=rm r=reg | Int64
	flags: krw knz
	intel: kmask-op
END

# Code: EVEX_Vpscatterqq_vm64y_k1_ymm
INSTRUCTION: EVEX.256.66.0F38.W1 A1 /vsib | VPSCATTERQQ vm64y {k1}, ymm1 | AVX512VL AVX512F | N8
	ops: w=rm r=reg | Int64
	flags: krw knz
	intel: kmask-op
END

# Code: EVEX_Vpscatterqq_vm64z_k1_zmm
INSTRUCTION: EVEX.512.66.0F38.W1 A1 /vsib | VPSCATTERQQ vm64z {k1}, zmm1 | AVX512F | N8
	ops: w=rm r=reg | Int64
	flags: krw knz
	intel: kmask-op
END

# Code: EVEX_Vscatterdps_vm32x_k1_xmm
INSTRUCTION: EVEX.128.66.0F38.W0 A2 /vsib | VSCATTERDPS vm32x {k1}, xmm1 | AVX512VL AVX512F | N4
	ops: w=rm r=reg | Float32
	flags: krw knz
	intel: kmask-op
END

# Code: EVEX_Vscatterdps_vm32y_k1_ymm
INSTRUCTION: EVEX.256.66.0F38.W0 A2 /vsib | VSCATTERDPS vm32y {k1}, ymm1 | AVX512VL AVX512F | N4
	ops: w=rm r=reg | Float32
	flags: krw knz
	intel: kmask-op
END

# Code: EVEX_Vscatterdps_vm32z_k1_zmm
INSTRUCTION: EVEX.512.66.0F38.W0 A2 /vsib | VSCATTERDPS vm32z {k1}, zmm1 | AVX512F | N4
	ops: w=rm r=reg | Float32
	flags: krw knz
	intel: kmask-op
END

# Code: EVEX_Vscatterdpd_vm32x_k1_xmm
INSTRUCTION: EVEX.128.66.0F38.W1 A2 /vsib | VSCATTERDPD vm32x {k1}, xmm1 | AVX512VL AVX512F | N8
	ops: w=rm r=reg | Float64
	flags: krw knz
	intel: kmask-op
END

# Code: EVEX_Vscatterdpd_vm32x_k1_ymm
INSTRUCTION: EVEX.256.66.0F38.W1 A2 /vsib | VSCATTERDPD vm32x {k1}, ymm1 | AVX512VL AVX512F | N8
	ops: w=rm r=reg | Float64
	flags: krw knz
	intel: kmask-op
END

# Code: EVEX_Vscatterdpd_vm32y_k1_zmm
INSTRUCTION: EVEX.512.66.0F38.W1 A2 /vsib | VSCATTERDPD vm32y {k1}, zmm1 | AVX512F | N8
	ops: w=rm r=reg | Float64
	flags: krw knz
	intel: kmask-op
END

# Code: EVEX_Vscatterqps_vm64x_k1_xmm
INSTRUCTION: EVEX.128.66.0F38.W0 A3 /vsib | VSCATTERQPS vm64x {k1}, xmm1 | AVX512VL AVX512F | N4
	ops: w=rm r=reg | Float32
	flags: krw knz
	intel: kmask-op
END

# Code: EVEX_Vscatterqps_vm64y_k1_xmm
INSTRUCTION: EVEX.256.66.0F38.W0 A3 /vsib | VSCATTERQPS vm64y {k1}, xmm1 | AVX512VL AVX512F | N4
	ops: w=rm r=reg | Float32
	flags: krw knz
	intel: kmask-op
END

# Code: EVEX_Vscatterqps_vm64z_k1_ymm
INSTRUCTION: EVEX.512.66.0F38.W0 A3 /vsib | VSCATTERQPS vm64z {k1}, ymm1 | AVX512F | N4
	ops: w=rm r=reg | Float32
	flags: krw knz
	intel: kmask-op
END

# Code: EVEX_Vscatterqpd_vm64x_k1_xmm
INSTRUCTION: EVEX.128.66.0F38.W1 A3 /vsib | VSCATTERQPD vm64x {k1}, xmm1 | AVX512VL AVX512F | N8
	ops: w=rm r=reg | Float64
	flags: krw knz
	intel: kmask-op
END

# Code: EVEX_Vscatterqpd_vm64y_k1_ymm
INSTRUCTION: EVEX.256.66.0F38.W1 A3 /vsib | VSCATTERQPD vm64y {k1}, ymm1 | AVX512VL AVX512F | N8
	ops: w=rm r=reg | Float64
	flags: krw knz
	intel: kmask-op
END

# Code: EVEX_Vscatterqpd_vm64z_k1_zmm
INSTRUCTION: EVEX.512.66.0F38.W1 A3 /vsib | VSCATTERQPD vm64z {k1}, zmm1 | AVX512F | N8
	ops: w=rm r=reg | Float64
	flags: krw knz
	intel: kmask-op
END

# Code: VEX_Vfmaddsub213ps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 A6 /r | VFMADDSUB213PS xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vfmaddsub213ps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 A6 /r | VFMADDSUB213PS ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float32
END

# Code: VEX_Vfmaddsub213pd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W1 A6 /r | VFMADDSUB213PD xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vfmaddsub213pd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W1 A6 /r | VFMADDSUB213PD ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vfmaddsub213ps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 A6 /r | VFMADDSUB213PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vfmaddsub213ps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 A6 /r | VFMADDSUB213PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vfmaddsub213ps_zmm_k1z_zmm_zmmm512b32_er
INSTRUCTION: EVEX.512.66.0F38.W0 A6 /r | VFMADDSUB213PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er} | AVX512F | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vfmaddsub213pd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 A6 /r | VFMADDSUB213PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: rw=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vfmaddsub213pd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 A6 /r | VFMADDSUB213PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: rw=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vfmaddsub213pd_zmm_k1z_zmm_zmmm512b64_er
INSTRUCTION: EVEX.512.66.0F38.W1 A6 /r | VFMADDSUB213PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er} | AVX512F | N64b8
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: VEX_Vfmsubadd213ps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 A7 /r | VFMSUBADD213PS xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vfmsubadd213ps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 A7 /r | VFMSUBADD213PS ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float32
END

# Code: VEX_Vfmsubadd213pd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W1 A7 /r | VFMSUBADD213PD xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vfmsubadd213pd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W1 A7 /r | VFMSUBADD213PD ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vfmsubadd213ps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 A7 /r | VFMSUBADD213PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vfmsubadd213ps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 A7 /r | VFMSUBADD213PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vfmsubadd213ps_zmm_k1z_zmm_zmmm512b32_er
INSTRUCTION: EVEX.512.66.0F38.W0 A7 /r | VFMSUBADD213PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er} | AVX512F | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vfmsubadd213pd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 A7 /r | VFMSUBADD213PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: rw=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vfmsubadd213pd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 A7 /r | VFMSUBADD213PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: rw=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vfmsubadd213pd_zmm_k1z_zmm_zmmm512b64_er
INSTRUCTION: EVEX.512.66.0F38.W1 A7 /r | VFMSUBADD213PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er} | AVX512F | N64b8
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: VEX_Vfmadd213ps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 A8 /r | VFMADD213PS xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vfmadd213ps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 A8 /r | VFMADD213PS ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float32
END

# Code: VEX_Vfmadd213pd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W1 A8 /r | VFMADD213PD xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vfmadd213pd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W1 A8 /r | VFMADD213PD ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vfmadd213ps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 A8 /r | VFMADD213PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vfmadd213ps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 A8 /r | VFMADD213PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vfmadd213ps_zmm_k1z_zmm_zmmm512b32_er
INSTRUCTION: EVEX.512.66.0F38.W0 A8 /r | VFMADD213PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er} | AVX512F | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vfmadd213pd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 A8 /r | VFMADD213PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: rw=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vfmadd213pd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 A8 /r | VFMADD213PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: rw=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vfmadd213pd_zmm_k1z_zmm_zmmm512b64_er
INSTRUCTION: EVEX.512.66.0F38.W1 A8 /r | VFMADD213PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er} | AVX512F | N64b8
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: VEX_Vfmadd213ss_xmm_xmm_xmmm32
INSTRUCTION: VEX.LIG.66.0F38.W0 A9 /r | VFMADD213SS xmm1, xmm2, xmm3/m32 | FMA
	ops: rw=reg r=vvvv r=rm | Float32
END

# Code: VEX_Vfmadd213sd_xmm_xmm_xmmm64
INSTRUCTION: VEX.LIG.66.0F38.W1 A9 /r | VFMADD213SD xmm1, xmm2, xmm3/m64 | FMA
	ops: rw=reg r=vvvv r=rm | Float64
END

# Code: EVEX_Vfmadd213ss_xmm_k1z_xmm_xmmm32_er
INSTRUCTION: EVEX.LIG.66.0F38.W0 A9 /r | VFMADD213SS xmm1 {k1}{z}, xmm2, xmm3/m32{er} | AVX512F | N4
	ops: rw=reg r=vvvv r=rm | Float32
END

# Code: EVEX_Vfmadd213sd_xmm_k1z_xmm_xmmm64_er
INSTRUCTION: EVEX.LIG.66.0F38.W1 A9 /r | VFMADD213SD xmm1 {k1}{z}, xmm2, xmm3/m64{er} | AVX512F | N8
	ops: rw=reg r=vvvv r=rm | Float64
END

# Code: VEX_Vfmsub213ps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 AA /r | VFMSUB213PS xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vfmsub213ps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 AA /r | VFMSUB213PS ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float32
END

# Code: VEX_Vfmsub213pd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W1 AA /r | VFMSUB213PD xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vfmsub213pd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W1 AA /r | VFMSUB213PD ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vfmsub213ps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 AA /r | VFMSUB213PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vfmsub213ps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 AA /r | VFMSUB213PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vfmsub213ps_zmm_k1z_zmm_zmmm512b32_er
INSTRUCTION: EVEX.512.66.0F38.W0 AA /r | VFMSUB213PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er} | AVX512F | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vfmsub213pd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 AA /r | VFMSUB213PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: rw=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vfmsub213pd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 AA /r | VFMSUB213PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: rw=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vfmsub213pd_zmm_k1z_zmm_zmmm512b64_er
INSTRUCTION: EVEX.512.66.0F38.W1 AA /r | VFMSUB213PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er} | AVX512F | N64b8
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: EVEX_V4fnmaddps_zmm_k1z_zmmp3_m128
INSTRUCTION: EVEX.512.F2.0F38.W0 AA /r | V4FNMADDPS zmm1 {k1}{z}, zmm2+3, m128 | AVX512_4FMAPS | N16
	ops: rwvmm=reg r=vvvv;p3 r=rm | Packed128_Float32
END

# Code: VEX_Vfmsub213ss_xmm_xmm_xmmm32
INSTRUCTION: VEX.LIG.66.0F38.W0 AB /r | VFMSUB213SS xmm1, xmm2, xmm3/m32 | FMA
	ops: rw=reg r=vvvv r=rm | Float32
END

# Code: VEX_Vfmsub213sd_xmm_xmm_xmmm64
INSTRUCTION: VEX.LIG.66.0F38.W1 AB /r | VFMSUB213SD xmm1, xmm2, xmm3/m64 | FMA
	ops: rw=reg r=vvvv r=rm | Float64
END

# Code: EVEX_Vfmsub213ss_xmm_k1z_xmm_xmmm32_er
INSTRUCTION: EVEX.LIG.66.0F38.W0 AB /r | VFMSUB213SS xmm1 {k1}{z}, xmm2, xmm3/m32{er} | AVX512F | N4
	ops: rw=reg r=vvvv r=rm | Float32
END

# Code: EVEX_Vfmsub213sd_xmm_k1z_xmm_xmmm64_er
INSTRUCTION: EVEX.LIG.66.0F38.W1 AB /r | VFMSUB213SD xmm1 {k1}{z}, xmm2, xmm3/m64{er} | AVX512F | N8
	ops: rw=reg r=vvvv r=rm | Float64
END

# Code: EVEX_V4fnmaddss_xmm_k1z_xmmp3_m128
INSTRUCTION: EVEX.LIG.F2.0F38.W0 AB /r | V4FNMADDSS xmm1 {k1}{z}, xmm2+3, m128 | AVX512_4FMAPS | N16
	ops: rw=reg r=vvvv;p3 r=rm | Packed128_Float32
	masm: flags=force-size=default
END

# Code: VEX_Vfnmadd213ps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 AC /r | VFNMADD213PS xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vfnmadd213ps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 AC /r | VFNMADD213PS ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float32
END

# Code: VEX_Vfnmadd213pd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W1 AC /r | VFNMADD213PD xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vfnmadd213pd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W1 AC /r | VFNMADD213PD ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vfnmadd213ps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 AC /r | VFNMADD213PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vfnmadd213ps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 AC /r | VFNMADD213PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vfnmadd213ps_zmm_k1z_zmm_zmmm512b32_er
INSTRUCTION: EVEX.512.66.0F38.W0 AC /r | VFNMADD213PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er} | AVX512F | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vfnmadd213pd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 AC /r | VFNMADD213PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: rw=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vfnmadd213pd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 AC /r | VFNMADD213PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: rw=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vfnmadd213pd_zmm_k1z_zmm_zmmm512b64_er
INSTRUCTION: EVEX.512.66.0F38.W1 AC /r | VFNMADD213PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er} | AVX512F | N64b8
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: VEX_Vfnmadd213ss_xmm_xmm_xmmm32
INSTRUCTION: VEX.LIG.66.0F38.W0 AD /r | VFNMADD213SS xmm1, xmm2, xmm3/m32 | FMA
	ops: rw=reg r=vvvv r=rm | Float32
END

# Code: VEX_Vfnmadd213sd_xmm_xmm_xmmm64
INSTRUCTION: VEX.LIG.66.0F38.W1 AD /r | VFNMADD213SD xmm1, xmm2, xmm3/m64 | FMA
	ops: rw=reg r=vvvv r=rm | Float64
END

# Code: EVEX_Vfnmadd213ss_xmm_k1z_xmm_xmmm32_er
INSTRUCTION: EVEX.LIG.66.0F38.W0 AD /r | VFNMADD213SS xmm1 {k1}{z}, xmm2, xmm3/m32{er} | AVX512F | N4
	ops: rw=reg r=vvvv r=rm | Float32
END

# Code: EVEX_Vfnmadd213sd_xmm_k1z_xmm_xmmm64_er
INSTRUCTION: EVEX.LIG.66.0F38.W1 AD /r | VFNMADD213SD xmm1 {k1}{z}, xmm2, xmm3/m64{er} | AVX512F | N8
	ops: rw=reg r=vvvv r=rm | Float64
END

# Code: VEX_Vfnmsub213ps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 AE /r | VFNMSUB213PS xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vfnmsub213ps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 AE /r | VFNMSUB213PS ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float32
END

# Code: VEX_Vfnmsub213pd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W1 AE /r | VFNMSUB213PD xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vfnmsub213pd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W1 AE /r | VFNMSUB213PD ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vfnmsub213ps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 AE /r | VFNMSUB213PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vfnmsub213ps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 AE /r | VFNMSUB213PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vfnmsub213ps_zmm_k1z_zmm_zmmm512b32_er
INSTRUCTION: EVEX.512.66.0F38.W0 AE /r | VFNMSUB213PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er} | AVX512F | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vfnmsub213pd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 AE /r | VFNMSUB213PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: rw=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vfnmsub213pd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 AE /r | VFNMSUB213PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: rw=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vfnmsub213pd_zmm_k1z_zmm_zmmm512b64_er
INSTRUCTION: EVEX.512.66.0F38.W1 AE /r | VFNMSUB213PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er} | AVX512F | N64b8
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: VEX_Vfnmsub213ss_xmm_xmm_xmmm32
INSTRUCTION: VEX.LIG.66.0F38.W0 AF /r | VFNMSUB213SS xmm1, xmm2, xmm3/m32 | FMA
	ops: rw=reg r=vvvv r=rm | Float32
END

# Code: VEX_Vfnmsub213sd_xmm_xmm_xmmm64
INSTRUCTION: VEX.LIG.66.0F38.W1 AF /r | VFNMSUB213SD xmm1, xmm2, xmm3/m64 | FMA
	ops: rw=reg r=vvvv r=rm | Float64
END

# Code: EVEX_Vfnmsub213ss_xmm_k1z_xmm_xmmm32_er
INSTRUCTION: EVEX.LIG.66.0F38.W0 AF /r | VFNMSUB213SS xmm1 {k1}{z}, xmm2, xmm3/m32{er} | AVX512F | N4
	ops: rw=reg r=vvvv r=rm | Float32
END

# Code: EVEX_Vfnmsub213sd_xmm_k1z_xmm_xmmm64_er
INSTRUCTION: EVEX.LIG.66.0F38.W1 AF /r | VFNMSUB213SD xmm1 {k1}{z}, xmm2, xmm3/m64{er} | AVX512F | N8
	ops: rw=reg r=vvvv r=rm | Float64
END

# Code: EVEX_Vpmadd52luq_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 B4 /r | VPMADD52LUQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512_IFMA | N16b8
	ops: rw=reg r=vvvv r=rm | Packed128_UInt52 Broadcast128_UInt52
END

# Code: EVEX_Vpmadd52luq_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 B4 /r | VPMADD52LUQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512_IFMA | N32b8
	ops: rw=reg r=vvvv r=rm | Packed256_UInt52 Broadcast256_UInt52
END

# Code: EVEX_Vpmadd52luq_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 B4 /r | VPMADD52LUQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512_IFMA | N64b8
	ops: rwvmm=reg r=vvvv r=rm | Packed512_UInt52 Broadcast512_UInt52
END

# Code: EVEX_Vpmadd52huq_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 B5 /r | VPMADD52HUQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512_IFMA | N16b8
	ops: rw=reg r=vvvv r=rm | Packed128_UInt52 Broadcast128_UInt52
END

# Code: EVEX_Vpmadd52huq_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 B5 /r | VPMADD52HUQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512_IFMA | N32b8
	ops: rw=reg r=vvvv r=rm | Packed256_UInt52 Broadcast256_UInt52
END

# Code: EVEX_Vpmadd52huq_zmm_k1z_zmm_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 B5 /r | VPMADD52HUQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst | AVX512_IFMA | N64b8
	ops: rwvmm=reg r=vvvv r=rm | Packed512_UInt52 Broadcast512_UInt52
END

# Code: VEX_Vfmaddsub231ps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 B6 /r | VFMADDSUB231PS xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vfmaddsub231ps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 B6 /r | VFMADDSUB231PS ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float32
END

# Code: VEX_Vfmaddsub231pd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W1 B6 /r | VFMADDSUB231PD xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vfmaddsub231pd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W1 B6 /r | VFMADDSUB231PD ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vfmaddsub231ps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 B6 /r | VFMADDSUB231PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vfmaddsub231ps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 B6 /r | VFMADDSUB231PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vfmaddsub231ps_zmm_k1z_zmm_zmmm512b32_er
INSTRUCTION: EVEX.512.66.0F38.W0 B6 /r | VFMADDSUB231PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er} | AVX512F | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vfmaddsub231pd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 B6 /r | VFMADDSUB231PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: rw=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vfmaddsub231pd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 B6 /r | VFMADDSUB231PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: rw=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vfmaddsub231pd_zmm_k1z_zmm_zmmm512b64_er
INSTRUCTION: EVEX.512.66.0F38.W1 B6 /r | VFMADDSUB231PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er} | AVX512F | N64b8
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: VEX_Vfmsubadd231ps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 B7 /r | VFMSUBADD231PS xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vfmsubadd231ps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 B7 /r | VFMSUBADD231PS ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float32
END

# Code: VEX_Vfmsubadd231pd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W1 B7 /r | VFMSUBADD231PD xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vfmsubadd231pd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W1 B7 /r | VFMSUBADD231PD ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vfmsubadd231ps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 B7 /r | VFMSUBADD231PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vfmsubadd231ps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 B7 /r | VFMSUBADD231PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vfmsubadd231ps_zmm_k1z_zmm_zmmm512b32_er
INSTRUCTION: EVEX.512.66.0F38.W0 B7 /r | VFMSUBADD231PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er} | AVX512F | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vfmsubadd231pd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 B7 /r | VFMSUBADD231PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: rw=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vfmsubadd231pd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 B7 /r | VFMSUBADD231PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: rw=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vfmsubadd231pd_zmm_k1z_zmm_zmmm512b64_er
INSTRUCTION: EVEX.512.66.0F38.W1 B7 /r | VFMSUBADD231PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er} | AVX512F | N64b8
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: VEX_Vfmadd231ps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 B8 /r | VFMADD231PS xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vfmadd231ps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 B8 /r | VFMADD231PS ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float32
END

# Code: VEX_Vfmadd231pd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W1 B8 /r | VFMADD231PD xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vfmadd231pd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W1 B8 /r | VFMADD231PD ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vfmadd231ps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 B8 /r | VFMADD231PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vfmadd231ps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 B8 /r | VFMADD231PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vfmadd231ps_zmm_k1z_zmm_zmmm512b32_er
INSTRUCTION: EVEX.512.66.0F38.W0 B8 /r | VFMADD231PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er} | AVX512F | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vfmadd231pd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 B8 /r | VFMADD231PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: rw=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vfmadd231pd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 B8 /r | VFMADD231PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: rw=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vfmadd231pd_zmm_k1z_zmm_zmmm512b64_er
INSTRUCTION: EVEX.512.66.0F38.W1 B8 /r | VFMADD231PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er} | AVX512F | N64b8
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: VEX_Vfmadd231ss_xmm_xmm_xmmm32
INSTRUCTION: VEX.LIG.66.0F38.W0 B9 /r | VFMADD231SS xmm1, xmm2, xmm3/m32 | FMA
	ops: rw=reg r=vvvv r=rm | Float32
END

# Code: VEX_Vfmadd231sd_xmm_xmm_xmmm64
INSTRUCTION: VEX.LIG.66.0F38.W1 B9 /r | VFMADD231SD xmm1, xmm2, xmm3/m64 | FMA
	ops: rw=reg r=vvvv r=rm | Float64
END

# Code: EVEX_Vfmadd231ss_xmm_k1z_xmm_xmmm32_er
INSTRUCTION: EVEX.LIG.66.0F38.W0 B9 /r | VFMADD231SS xmm1 {k1}{z}, xmm2, xmm3/m32{er} | AVX512F | N4
	ops: rw=reg r=vvvv r=rm | Float32
END

# Code: EVEX_Vfmadd231sd_xmm_k1z_xmm_xmmm64_er
INSTRUCTION: EVEX.LIG.66.0F38.W1 B9 /r | VFMADD231SD xmm1 {k1}{z}, xmm2, xmm3/m64{er} | AVX512F | N8
	ops: rw=reg r=vvvv r=rm | Float64
END

# Code: VEX_Vfmsub231ps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 BA /r | VFMSUB231PS xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vfmsub231ps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 BA /r | VFMSUB231PS ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float32
END

# Code: VEX_Vfmsub231pd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W1 BA /r | VFMSUB231PD xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vfmsub231pd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W1 BA /r | VFMSUB231PD ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vfmsub231ps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 BA /r | VFMSUB231PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vfmsub231ps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 BA /r | VFMSUB231PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vfmsub231ps_zmm_k1z_zmm_zmmm512b32_er
INSTRUCTION: EVEX.512.66.0F38.W0 BA /r | VFMSUB231PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er} | AVX512F | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vfmsub231pd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 BA /r | VFMSUB231PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: rw=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vfmsub231pd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 BA /r | VFMSUB231PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: rw=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vfmsub231pd_zmm_k1z_zmm_zmmm512b64_er
INSTRUCTION: EVEX.512.66.0F38.W1 BA /r | VFMSUB231PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er} | AVX512F | N64b8
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: VEX_Vfmsub231ss_xmm_xmm_xmmm32
INSTRUCTION: VEX.LIG.66.0F38.W0 BB /r | VFMSUB231SS xmm1, xmm2, xmm3/m32 | FMA
	ops: rw=reg r=vvvv r=rm | Float32
END

# Code: VEX_Vfmsub231sd_xmm_xmm_xmmm64
INSTRUCTION: VEX.LIG.66.0F38.W1 BB /r | VFMSUB231SD xmm1, xmm2, xmm3/m64 | FMA
	ops: rw=reg r=vvvv r=rm | Float64
END

# Code: EVEX_Vfmsub231ss_xmm_k1z_xmm_xmmm32_er
INSTRUCTION: EVEX.LIG.66.0F38.W0 BB /r | VFMSUB231SS xmm1 {k1}{z}, xmm2, xmm3/m32{er} | AVX512F | N4
	ops: rw=reg r=vvvv r=rm | Float32
END

# Code: EVEX_Vfmsub231sd_xmm_k1z_xmm_xmmm64_er
INSTRUCTION: EVEX.LIG.66.0F38.W1 BB /r | VFMSUB231SD xmm1 {k1}{z}, xmm2, xmm3/m64{er} | AVX512F | N8
	ops: rw=reg r=vvvv r=rm | Float64
END

# Code: VEX_Vfnmadd231ps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 BC /r | VFNMADD231PS xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vfnmadd231ps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 BC /r | VFNMADD231PS ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float32
END

# Code: VEX_Vfnmadd231pd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W1 BC /r | VFNMADD231PD xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vfnmadd231pd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W1 BC /r | VFNMADD231PD ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vfnmadd231ps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 BC /r | VFNMADD231PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vfnmadd231ps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 BC /r | VFNMADD231PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vfnmadd231ps_zmm_k1z_zmm_zmmm512b32_er
INSTRUCTION: EVEX.512.66.0F38.W0 BC /r | VFNMADD231PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er} | AVX512F | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vfnmadd231pd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 BC /r | VFNMADD231PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: rw=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vfnmadd231pd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 BC /r | VFNMADD231PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: rw=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vfnmadd231pd_zmm_k1z_zmm_zmmm512b64_er
INSTRUCTION: EVEX.512.66.0F38.W1 BC /r | VFNMADD231PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er} | AVX512F | N64b8
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: VEX_Vfnmadd231ss_xmm_xmm_xmmm32
INSTRUCTION: VEX.LIG.66.0F38.W0 BD /r | VFNMADD231SS xmm1, xmm2, xmm3/m32 | FMA
	ops: rw=reg r=vvvv r=rm | Float32
END

# Code: VEX_Vfnmadd231sd_xmm_xmm_xmmm64
INSTRUCTION: VEX.LIG.66.0F38.W1 BD /r | VFNMADD231SD xmm1, xmm2, xmm3/m64 | FMA
	ops: rw=reg r=vvvv r=rm | Float64
END

# Code: EVEX_Vfnmadd231ss_xmm_k1z_xmm_xmmm32_er
INSTRUCTION: EVEX.LIG.66.0F38.W0 BD /r | VFNMADD231SS xmm1 {k1}{z}, xmm2, xmm3/m32{er} | AVX512F | N4
	ops: rw=reg r=vvvv r=rm | Float32
END

# Code: EVEX_Vfnmadd231sd_xmm_k1z_xmm_xmmm64_er
INSTRUCTION: EVEX.LIG.66.0F38.W1 BD /r | VFNMADD231SD xmm1 {k1}{z}, xmm2, xmm3/m64{er} | AVX512F | N8
	ops: rw=reg r=vvvv r=rm | Float64
END

# Code: VEX_Vfnmsub231ps_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 BE /r | VFNMSUB231PS xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float32
END

# Code: VEX_Vfnmsub231ps_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 BE /r | VFNMSUB231PS ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float32
END

# Code: VEX_Vfnmsub231pd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W1 BE /r | VFNMSUB231PD xmm1, xmm2, xmm3/m128 | FMA
	ops: rw=reg r=vvvv r=rm | Packed128_Float64
END

# Code: VEX_Vfnmsub231pd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W1 BE /r | VFNMSUB231PD ymm1, ymm2, ymm3/m256 | FMA
	ops: rw=reg r=vvvv r=rm | Packed256_Float64
END

# Code: EVEX_Vfnmsub231ps_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 BE /r | VFNMSUB231PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512F | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vfnmsub231ps_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 BE /r | VFNMSUB231PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512F | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vfnmsub231ps_zmm_k1z_zmm_zmmm512b32_er
INSTRUCTION: EVEX.512.66.0F38.W0 BE /r | VFNMSUB231PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er} | AVX512F | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vfnmsub231pd_xmm_k1z_xmm_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 BE /r | VFNMSUB231PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst | AVX512VL AVX512F | N16b8
	ops: rw=reg r=vvvv r=rm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vfnmsub231pd_ymm_k1z_ymm_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 BE /r | VFNMSUB231PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst | AVX512VL AVX512F | N32b8
	ops: rw=reg r=vvvv r=rm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vfnmsub231pd_zmm_k1z_zmm_zmmm512b64_er
INSTRUCTION: EVEX.512.66.0F38.W1 BE /r | VFNMSUB231PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er} | AVX512F | N64b8
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: VEX_Vfnmsub231ss_xmm_xmm_xmmm32
INSTRUCTION: VEX.LIG.66.0F38.W0 BF /r | VFNMSUB231SS xmm1, xmm2, xmm3/m32 | FMA
	ops: rw=reg r=vvvv r=rm | Float32
END

# Code: VEX_Vfnmsub231sd_xmm_xmm_xmmm64
INSTRUCTION: VEX.LIG.66.0F38.W1 BF /r | VFNMSUB231SD xmm1, xmm2, xmm3/m64 | FMA
	ops: rw=reg r=vvvv r=rm | Float64
END

# Code: EVEX_Vfnmsub231ss_xmm_k1z_xmm_xmmm32_er
INSTRUCTION: EVEX.LIG.66.0F38.W0 BF /r | VFNMSUB231SS xmm1 {k1}{z}, xmm2, xmm3/m32{er} | AVX512F | N4
	ops: rw=reg r=vvvv r=rm | Float32
END

# Code: EVEX_Vfnmsub231sd_xmm_k1z_xmm_xmmm64_er
INSTRUCTION: EVEX.LIG.66.0F38.W1 BF /r | VFNMSUB231SD xmm1 {k1}{z}, xmm2, xmm3/m64{er} | AVX512F | N8
	ops: rw=reg r=vvvv r=rm | Float64
END

# Code: EVEX_Vpconflictd_xmm_k1z_xmmm128b32
INSTRUCTION: EVEX.128.66.0F38.W0 C4 /r | VPCONFLICTD xmm1 {k1}{z}, xmm2/m128/m32bcst | AVX512VL AVX512CD | N16b4
	ops: w=reg r=rm | Packed128_UInt32 Broadcast128_UInt32
END

# Code: EVEX_Vpconflictd_ymm_k1z_ymmm256b32
INSTRUCTION: EVEX.256.66.0F38.W0 C4 /r | VPCONFLICTD ymm1 {k1}{z}, ymm2/m256/m32bcst | AVX512VL AVX512CD | N32b4
	ops: w=reg r=rm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vpconflictd_zmm_k1z_zmmm512b32
INSTRUCTION: EVEX.512.66.0F38.W0 C4 /r | VPCONFLICTD zmm1 {k1}{z}, zmm2/m512/m32bcst | AVX512CD | N64b4
	ops: wvmm=reg r=rm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: EVEX_Vpconflictq_xmm_k1z_xmmm128b64
INSTRUCTION: EVEX.128.66.0F38.W1 C4 /r | VPCONFLICTQ xmm1 {k1}{z}, xmm2/m128/m64bcst | AVX512VL AVX512CD | N16b8
	ops: w=reg r=rm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Vpconflictq_ymm_k1z_ymmm256b64
INSTRUCTION: EVEX.256.66.0F38.W1 C4 /r | VPCONFLICTQ ymm1 {k1}{z}, ymm2/m256/m64bcst | AVX512VL AVX512CD | N32b8
	ops: w=reg r=rm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vpconflictq_zmm_k1z_zmmm512b64
INSTRUCTION: EVEX.512.66.0F38.W1 C4 /r | VPCONFLICTQ zmm1 {k1}{z}, zmm2/m512/m64bcst | AVX512CD | N64b8
	ops: wvmm=reg r=rm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: EVEX_Vgatherpf0dps_vm32z_k1
INSTRUCTION: EVEX.512.66.0F38.W0 C6 /1 /vsib | VGATHERPF0DPS vm32z {k1} | AVX512PF | N4
	ops: nma=rm | Float32
	flags: knz prefetch
	intel: kmask-op
END

# Code: EVEX_Vgatherpf0dpd_vm32y_k1
INSTRUCTION: EVEX.512.66.0F38.W1 C6 /1 /vsib | VGATHERPF0DPD vm32y {k1} | AVX512PF | N8
	ops: nma=rm | Float64
	flags: knz prefetch
	intel: kmask-op
END

# Code: EVEX_Vgatherpf1dps_vm32z_k1
INSTRUCTION: EVEX.512.66.0F38.W0 C6 /2 /vsib | VGATHERPF1DPS vm32z {k1} | AVX512PF | N4
	ops: nma=rm | Float32
	flags: knz prefetch
	intel: kmask-op
END

# Code: EVEX_Vgatherpf1dpd_vm32y_k1
INSTRUCTION: EVEX.512.66.0F38.W1 C6 /2 /vsib | VGATHERPF1DPD vm32y {k1} | AVX512PF | N8
	ops: nma=rm | Float64
	flags: knz prefetch
	intel: kmask-op
END

# Code: EVEX_Vscatterpf0dps_vm32z_k1
INSTRUCTION: EVEX.512.66.0F38.W0 C6 /5 /vsib | VSCATTERPF0DPS vm32z {k1} | AVX512PF | N4
	ops: nma=rm | Float32
	flags: knz prefetch
	intel: kmask-op
END

# Code: EVEX_Vscatterpf0dpd_vm32y_k1
INSTRUCTION: EVEX.512.66.0F38.W1 C6 /5 /vsib | VSCATTERPF0DPD vm32y {k1} | AVX512PF | N8
	ops: nma=rm | Float64
	flags: knz prefetch
	intel: kmask-op
END

# Code: EVEX_Vscatterpf1dps_vm32z_k1
INSTRUCTION: EVEX.512.66.0F38.W0 C6 /6 /vsib | VSCATTERPF1DPS vm32z {k1} | AVX512PF | N4
	ops: nma=rm | Float32
	flags: knz prefetch
	intel: kmask-op
END

# Code: EVEX_Vscatterpf1dpd_vm32y_k1
INSTRUCTION: EVEX.512.66.0F38.W1 C6 /6 /vsib | VSCATTERPF1DPD vm32y {k1} | AVX512PF | N8
	ops: nma=rm | Float64
	flags: knz prefetch
	intel: kmask-op
END

# Code: EVEX_Vgatherpf0qps_vm64z_k1
INSTRUCTION: EVEX.512.66.0F38.W0 C7 /1 /vsib | VGATHERPF0QPS vm64z {k1} | AVX512PF | N4
	ops: nma=rm | Float32
	flags: knz prefetch
	intel: kmask-op
END

# Code: EVEX_Vgatherpf0qpd_vm64z_k1
INSTRUCTION: EVEX.512.66.0F38.W1 C7 /1 /vsib | VGATHERPF0QPD vm64z {k1} | AVX512PF | N8
	ops: nma=rm | Float64
	flags: knz prefetch
	intel: kmask-op
END

# Code: EVEX_Vgatherpf1qps_vm64z_k1
INSTRUCTION: EVEX.512.66.0F38.W0 C7 /2 /vsib | VGATHERPF1QPS vm64z {k1} | AVX512PF | N4
	ops: nma=rm | Float32
	flags: knz prefetch
	intel: kmask-op
END

# Code: EVEX_Vgatherpf1qpd_vm64z_k1
INSTRUCTION: EVEX.512.66.0F38.W1 C7 /2 /vsib | VGATHERPF1QPD vm64z {k1} | AVX512PF | N8
	ops: nma=rm | Float64
	flags: knz prefetch
	intel: kmask-op
END

# Code: EVEX_Vscatterpf0qps_vm64z_k1
INSTRUCTION: EVEX.512.66.0F38.W0 C7 /5 /vsib | VSCATTERPF0QPS vm64z {k1} | AVX512PF | N4
	ops: nma=rm | Float32
	flags: knz prefetch
	intel: kmask-op
END

# Code: EVEX_Vscatterpf0qpd_vm64z_k1
INSTRUCTION: EVEX.512.66.0F38.W1 C7 /5 /vsib | VSCATTERPF0QPD vm64z {k1} | AVX512PF | N8
	ops: nma=rm | Float64
	flags: knz prefetch
	intel: kmask-op
END

# Code: EVEX_Vscatterpf1qps_vm64z_k1
INSTRUCTION: EVEX.512.66.0F38.W0 C7 /6 /vsib | VSCATTERPF1QPS vm64z {k1} | AVX512PF | N4
	ops: nma=rm | Float32
	flags: knz prefetch
	intel: kmask-op
END

# Code: EVEX_Vscatterpf1qpd_vm64z_k1
INSTRUCTION: EVEX.512.66.0F38.W1 C7 /6 /vsib | VSCATTERPF1QPD vm64z {k1} | AVX512PF | N8
	ops: nma=rm | Float64
	flags: knz prefetch
	intel: kmask-op
END

# Code: Sha1nexte_xmm_xmmm128
INSTRUCTION: NP 0F 38 C8 /r | SHA1NEXTE xmm1, xmm2/m128 | SHA
	ops: rw=reg r=rm | Packed128_UInt32
END

# Code: EVEX_Vexp2ps_zmm_k1z_zmmm512b32_sae
INSTRUCTION: EVEX.512.66.0F38.W0 C8 /r | VEXP2PS zmm1 {k1}{z}, zmm2/m512/m32bcst{sae} | AVX512ER | N64b4
	ops: wvmm=reg r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vexp2pd_zmm_k1z_zmmm512b64_sae
INSTRUCTION: EVEX.512.66.0F38.W1 C8 /r | VEXP2PD zmm1 {k1}{z}, zmm2/m512/m64bcst{sae} | AVX512ER | N64b8
	ops: wvmm=reg r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: Sha1msg1_xmm_xmmm128
INSTRUCTION: NP 0F 38 C9 /r | SHA1MSG1 xmm1, xmm2/m128 | SHA
	ops: rw=reg r=rm | Packed128_UInt32
END

# Code: Sha1msg2_xmm_xmmm128
INSTRUCTION: NP 0F 38 CA /r | SHA1MSG2 xmm1, xmm2/m128 | SHA
	ops: rw=reg r=rm | Packed128_UInt32
END

# Code: EVEX_Vrcp28ps_zmm_k1z_zmmm512b32_sae
INSTRUCTION: EVEX.512.66.0F38.W0 CA /r | VRCP28PS zmm1 {k1}{z}, zmm2/m512/m32bcst{sae} | AVX512ER | N64b4
	ops: wvmm=reg r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vrcp28pd_zmm_k1z_zmmm512b64_sae
INSTRUCTION: EVEX.512.66.0F38.W1 CA /r | VRCP28PD zmm1 {k1}{z}, zmm2/m512/m64bcst{sae} | AVX512ER | N64b8
	ops: wvmm=reg r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: Sha256rnds2_xmm_xmmm128
INSTRUCTION: NP 0F 38 CB /r | SHA256RNDS2 xmm1, xmm2/m128, <XMM0> | SHA
	ops: rw=reg r=rm | Packed128_UInt32
	implied: r=xmm0
	gas: xmm0
	masm: xmm0
	nasm: xmm0
END

# Code: EVEX_Vrcp28ss_xmm_k1z_xmm_xmmm32_sae
INSTRUCTION: EVEX.LIG.66.0F38.W0 CB /r | VRCP28SS xmm1 {k1}{z}, xmm2, xmm3/m32{sae} | AVX512ER | N4
	ops: w=reg r=vvvv r=rm | Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vrcp28sd_xmm_k1z_xmm_xmmm64_sae
INSTRUCTION: EVEX.LIG.66.0F38.W1 CB /r | VRCP28SD xmm1 {k1}{z}, xmm2, xmm3/m64{sae} | AVX512ER | N8
	ops: w=reg r=vvvv r=rm | Float64
	masm: flags=force-size=default
END

# Code: Sha256msg1_xmm_xmmm128
INSTRUCTION: NP 0F 38 CC /r | SHA256MSG1 xmm1, xmm2/m128 | SHA
	ops: rw=reg r=rm | Packed128_UInt32
END

# Code: EVEX_Vrsqrt28ps_zmm_k1z_zmmm512b32_sae
INSTRUCTION: EVEX.512.66.0F38.W0 CC /r | VRSQRT28PS zmm1 {k1}{z}, zmm2/m512/m32bcst{sae} | AVX512ER | N64b4
	ops: wvmm=reg r=rm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vrsqrt28pd_zmm_k1z_zmmm512b64_sae
INSTRUCTION: EVEX.512.66.0F38.W1 CC /r | VRSQRT28PD zmm1 {k1}{z}, zmm2/m512/m64bcst{sae} | AVX512ER | N64b8
	ops: wvmm=reg r=rm | Packed512_Float64 Broadcast512_Float64
END

# Code: Sha256msg2_xmm_xmmm128
INSTRUCTION: NP 0F 38 CD /r | SHA256MSG2 xmm1, xmm2/m128 | SHA
	ops: rw=reg r=rm | Packed128_UInt32
END

# Code: EVEX_Vrsqrt28ss_xmm_k1z_xmm_xmmm32_sae
INSTRUCTION: EVEX.LIG.66.0F38.W0 CD /r | VRSQRT28SS xmm1 {k1}{z}, xmm2, xmm3/m32{sae} | AVX512ER | N4
	ops: w=reg r=vvvv r=rm | Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vrsqrt28sd_xmm_k1z_xmm_xmmm64_sae
INSTRUCTION: EVEX.LIG.66.0F38.W1 CD /r | VRSQRT28SD xmm1 {k1}{z}, xmm2, xmm3/m64{sae} | AVX512ER | N8
	ops: w=reg r=vvvv r=rm | Float64
	masm: flags=force-size=default
END

# Code: Gf2p8mulb_xmm_xmmm128
INSTRUCTION: 66 0F 38 CF /r | GF2P8MULB xmm1, xmm2/m128 | GFNI
	ops: rw=reg r=rm | Packed128_UInt8
END

# Code: VEX_Vgf2p8mulb_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 CF /r | VGF2P8MULB xmm1, xmm2, xmm3/m128 | AVX GFNI
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
END

# Code: VEX_Vgf2p8mulb_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 CF /r | VGF2P8MULB ymm1, ymm2, ymm3/m256 | AVX GFNI
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
END

# Code: EVEX_Vgf2p8mulb_xmm_k1z_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F38.W0 CF /r | VGF2P8MULB xmm1 {k1}{z}, xmm2, xmm3/m128 | AVX512VL GFNI | N16
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
END

# Code: EVEX_Vgf2p8mulb_ymm_k1z_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F38.W0 CF /r | VGF2P8MULB ymm1 {k1}{z}, ymm2, ymm3/m256 | AVX512VL GFNI | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt8
END

# Code: EVEX_Vgf2p8mulb_zmm_k1z_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F38.W0 CF /r | VGF2P8MULB zmm1 {k1}{z}, zmm2, zmm3/m512 | AVX512F GFNI | N64
	ops: wvmm=reg r=vvvv r=rm | Packed512_UInt8
END

# Code: Aesimc_xmm_xmmm128
INSTRUCTION: 66 0F 38 DB /r | AESIMC xmm1, xmm2/m128 | AES
	ops: w=reg r=rm | UInt128
END

# Code: VEX_Vaesimc_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG DB /r | VAESIMC xmm1, xmm2/m128 | AES AVX
	ops: w=reg r=rm | UInt128
END

# Code: Aesenc_xmm_xmmm128
INSTRUCTION: 66 0F 38 DC /r | AESENC xmm1, xmm2/m128 | AES
	ops: rw=reg r=rm | UInt128
END

# Code: VEX_Vaesenc_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG DC /r | VAESENC xmm1, xmm2, xmm3/m128 | AES AVX
	ops: w=reg r=vvvv r=rm | UInt128
END

# Code: VEX_Vaesenc_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG DC /r | VAESENC ymm1, ymm2, ymm3/m256 | VAES
	ops: w=reg r=vvvv r=rm | Packed256_UInt128
END

# Code: EVEX_Vaesenc_xmm_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F38.WIG DC /r | VAESENC xmm1, xmm2, xmm3/m128 | AVX512VL VAES | N16
	ops: w=reg r=vvvv r=rm | UInt128
END

# Code: EVEX_Vaesenc_ymm_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F38.WIG DC /r | VAESENC ymm1, ymm2, ymm3/m256 | AVX512VL VAES | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt128
END

# Code: EVEX_Vaesenc_zmm_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F38.WIG DC /r | VAESENC zmm1, zmm2, zmm3/m512 | AVX512F VAES | N64
	ops: w=reg r=vvvv r=rm | Packed512_UInt128
END

# Code: Aesenclast_xmm_xmmm128
INSTRUCTION: 66 0F 38 DD /r | AESENCLAST xmm1, xmm2/m128 | AES
	ops: rw=reg r=rm | UInt128
END

# Code: VEX_Vaesenclast_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG DD /r | VAESENCLAST xmm1, xmm2, xmm3/m128 | AES AVX
	ops: w=reg r=vvvv r=rm | UInt128
END

# Code: VEX_Vaesenclast_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG DD /r | VAESENCLAST ymm1, ymm2, ymm3/m256 | VAES
	ops: w=reg r=vvvv r=rm | Packed256_UInt128
END

# Code: EVEX_Vaesenclast_xmm_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F38.WIG DD /r | VAESENCLAST xmm1, xmm2, xmm3/m128 | AVX512VL VAES | N16
	ops: w=reg r=vvvv r=rm | UInt128
END

# Code: EVEX_Vaesenclast_ymm_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F38.WIG DD /r | VAESENCLAST ymm1, ymm2, ymm3/m256 | AVX512VL VAES | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt128
END

# Code: EVEX_Vaesenclast_zmm_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F38.WIG DD /r | VAESENCLAST zmm1, zmm2, zmm3/m512 | AVX512F VAES | N64
	ops: w=reg r=vvvv r=rm | Packed512_UInt128
END

# Code: Aesdec_xmm_xmmm128
INSTRUCTION: 66 0F 38 DE /r | AESDEC xmm1, xmm2/m128 | AES
	ops: rw=reg r=rm | UInt128
END

# Code: VEX_Vaesdec_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG DE /r | VAESDEC xmm1, xmm2, xmm3/m128 | AES AVX
	ops: w=reg r=vvvv r=rm | UInt128
END

# Code: VEX_Vaesdec_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG DE /r | VAESDEC ymm1, ymm2, ymm3/m256 | VAES
	ops: w=reg r=vvvv r=rm | Packed256_UInt128
END

# Code: EVEX_Vaesdec_xmm_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F38.WIG DE /r | VAESDEC xmm1, xmm2, xmm3/m128 | AVX512VL VAES | N16
	ops: w=reg r=vvvv r=rm | UInt128
END

# Code: EVEX_Vaesdec_ymm_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F38.WIG DE /r | VAESDEC ymm1, ymm2, ymm3/m256 | AVX512VL VAES | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt128
END

# Code: EVEX_Vaesdec_zmm_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F38.WIG DE /r | VAESDEC zmm1, zmm2, zmm3/m512 | AVX512F VAES | N64
	ops: w=reg r=vvvv r=rm | Packed512_UInt128
END

# Code: Aesdeclast_xmm_xmmm128
INSTRUCTION: 66 0F 38 DF /r | AESDECLAST xmm1, xmm2/m128 | AES
	ops: rw=reg r=rm | UInt128
END

# Code: VEX_Vaesdeclast_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.WIG DF /r | VAESDECLAST xmm1, xmm2, xmm3/m128 | AES AVX
	ops: w=reg r=vvvv r=rm | UInt128
END

# Code: VEX_Vaesdeclast_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.WIG DF /r | VAESDECLAST ymm1, ymm2, ymm3/m256 | VAES
	ops: w=reg r=vvvv r=rm | Packed256_UInt128
END

# Code: EVEX_Vaesdeclast_xmm_xmm_xmmm128
INSTRUCTION: EVEX.128.66.0F38.WIG DF /r | VAESDECLAST xmm1, xmm2, xmm3/m128 | AVX512VL VAES | N16
	ops: w=reg r=vvvv r=rm | UInt128
END

# Code: EVEX_Vaesdeclast_ymm_ymm_ymmm256
INSTRUCTION: EVEX.256.66.0F38.WIG DF /r | VAESDECLAST ymm1, ymm2, ymm3/m256 | AVX512VL VAES | N32
	ops: w=reg r=vvvv r=rm | Packed256_UInt128
END

# Code: EVEX_Vaesdeclast_zmm_zmm_zmmm512
INSTRUCTION: EVEX.512.66.0F38.WIG DF /r | VAESDECLAST zmm1, zmm2, zmm3/m512 | AVX512F VAES | N64
	ops: w=reg r=vvvv r=rm | Packed512_UInt128
END

# Code: Movbe_r16_m16
INSTRUCTION: o16 0F 38 F0 /r | MOVBE r16, m16 | MOVBE
	ops: w=reg r=rm | UInt16
	flags: nfx
	gas: suffix=w
END

# Code: Movbe_r32_m32
INSTRUCTION: o32 0F 38 F0 /r | MOVBE r32, m32 | MOVBE
	ops: w=reg r=rm | UInt32
	flags: nfx
	gas: suffix=l
END

# Code: Movbe_r64_m64
INSTRUCTION: o64 0F 38 F0 /r | MOVBE r64, m64 | MOVBE
	ops: w=reg r=rm | UInt64
	flags: 64 nfx
	gas: suffix=q
END

# Code: Crc32_r32_rm8
INSTRUCTION: F2 0F 38 F0 /r | CRC32 r32, r/m8 | SSE4_2
	ops: rw=reg r=rm | UInt8
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Crc32_r64_rm8
INSTRUCTION: F2 o64 0F 38 F0 /r | CRC32 r64, r/m8 | SSE4_2
	ops: rw=reg r=rm | UInt8
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=b
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Movbe_m16_r16
INSTRUCTION: o16 0F 38 F1 /r | MOVBE m16, r16 | MOVBE
	ops: w=rm r=reg | UInt16
	flags: nfx
	gas: suffix=w
END

# Code: Movbe_m32_r32
INSTRUCTION: o32 0F 38 F1 /r | MOVBE m32, r32 | MOVBE
	ops: w=rm r=reg | UInt32
	flags: nfx
	gas: suffix=l
END

# Code: Movbe_m64_r64
INSTRUCTION: o64 0F 38 F1 /r | MOVBE m64, r64 | MOVBE
	ops: w=rm r=reg | UInt64
	flags: 64 nfx
	gas: suffix=q
END

# Code: Crc32_r32_rm16
INSTRUCTION: o16 F2 0F 38 F1 /r | CRC32 r32, r/m16 | SSE4_2
	ops: rw=reg r=rm | UInt16
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=w
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Crc32_r32_rm32
INSTRUCTION: o32 F2 0F 38 F1 /r | CRC32 r32, r/m32 | SSE4_2
	ops: rw=reg r=rm | UInt32
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: Crc32_r64_rm64
INSTRUCTION: F2 o64 0F 38 F1 /r | CRC32 r64, r/m64 | SSE4_2
	ops: rw=reg r=rm | UInt64
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: VEX_Andn_r32_r32_rm32
INSTRUCTION: VEX.LZ.0F38.W0 F2 /r | ANDN r32a, r32b, r/m32 | BMI1
	ops: w=reg r=vvvv r=rm | UInt32
	rflags: u=ap w=sz 0=oc
	flags: wig32
	gas: suffix=l
END

# Code: VEX_Andn_r64_r64_rm64
INSTRUCTION: VEX.LZ.0F38.W1 F2 /r | ANDN r64a, r64b, r/m64 | BMI1
	ops: w=reg r=vvvv r=rm | UInt64
	rflags: u=ap w=sz 0=oc
	flags: 64
	gas: suffix=q
END

# Code: VEX_Blsr_r32_rm32
INSTRUCTION: VEX.LZ.0F38.W0 F3 /1 | BLSR r32, r/m32 | BMI1
	ops: w=vvvv r=rm | UInt32
	rflags: u=ap w=szc 0=o
	flags: wig32
	gas: suffix=l
END

# Code: VEX_Blsr_r64_rm64
INSTRUCTION: VEX.LZ.0F38.W1 F3 /1 | BLSR r64, r/m64 | BMI1
	ops: w=vvvv r=rm | UInt64
	rflags: u=ap w=szc 0=o
	flags: 64
	gas: suffix=q
END

# Code: VEX_Blsmsk_r32_rm32
INSTRUCTION: VEX.LZ.0F38.W0 F3 /2 | BLSMSK r32, r/m32 | BMI1
	ops: w=vvvv r=rm | UInt32
	rflags: u=ap w=sc 0=oz
	flags: wig32
	gas: suffix=l
END

# Code: VEX_Blsmsk_r64_rm64
INSTRUCTION: VEX.LZ.0F38.W1 F3 /2 | BLSMSK r64, r/m64 | BMI1
	ops: w=vvvv r=rm | UInt64
	rflags: u=ap w=sc 0=oz
	flags: 64
	gas: suffix=q
END

# Code: VEX_Blsi_r32_rm32
INSTRUCTION: VEX.LZ.0F38.W0 F3 /3 | BLSI r32, r/m32 | BMI1
	ops: w=vvvv r=rm | UInt32
	rflags: u=ap w=szc 0=o
	flags: wig32
	gas: suffix=l
END

# Code: VEX_Blsi_r64_rm64
INSTRUCTION: VEX.LZ.0F38.W1 F3 /3 | BLSI r64, r/m64 | BMI1
	ops: w=vvvv r=rm | UInt64
	rflags: u=ap w=szc 0=o
	flags: 64
	gas: suffix=q
END

# Code: VEX_Bzhi_r32_rm32_r32
INSTRUCTION: VEX.LZ.0F38.W0 F5 /r | BZHI r32a, r/m32, r32b | BMI2
	ops: w=reg r=rm r=vvvv | UInt32
	implied: last-gpr-8
	rflags: u=ap w=szc 0=o
	flags: wig32
	gas: suffix=l
END

# Code: VEX_Bzhi_r64_rm64_r64
INSTRUCTION: VEX.LZ.0F38.W1 F5 /r | BZHI r64a, r/m64, r64b | BMI2
	ops: w=reg r=rm r=vvvv | UInt64
	implied: last-gpr-8
	rflags: u=ap w=szc 0=o
	flags: 64
	gas: suffix=q
END

# Code: Wrussd_m32_r32
INSTRUCTION: 66 0F 38 F5 /r | WRUSSD m32, r32 | CET_SS
	ops: w=rm r=reg | UInt32
	flags: cpl0 no-rm no-v86
END

# Code: Wrussq_m64_r64
INSTRUCTION: 66 o64 0F 38 F5 /r | WRUSSQ m64, r64 | CET_SS
	ops: w=rm r=reg | UInt64
	flags: 64 cpl0 no-rm no-v86
END

# Code: VEX_Pext_r32_r32_rm32
INSTRUCTION: VEX.LZ.F3.0F38.W0 F5 /r | PEXT r32a, r32b, r/m32 | BMI2
	ops: w=reg cr=vvvv r=rm | UInt32
	flags: wig32
	gas: suffix=l
END

# Code: VEX_Pext_r64_r64_rm64
INSTRUCTION: VEX.LZ.F3.0F38.W1 F5 /r | PEXT r64a, r64b, r/m64 | BMI2
	ops: w=reg cr=vvvv r=rm | UInt64
	flags: 64
	gas: suffix=q
END

# Code: VEX_Pdep_r32_r32_rm32
INSTRUCTION: VEX.LZ.F2.0F38.W0 F5 /r | PDEP r32a, r32b, r/m32 | BMI2
	ops: w=reg cr=vvvv r=rm | UInt32
	flags: wig32
	gas: suffix=l
END

# Code: VEX_Pdep_r64_r64_rm64
INSTRUCTION: VEX.LZ.F2.0F38.W1 F5 /r | PDEP r64a, r64b, r/m64 | BMI2
	ops: w=reg cr=vvvv r=rm | UInt64
	flags: 64
	gas: suffix=q
END

# Code: Wrssd_m32_r32
INSTRUCTION: NP 0F 38 F6 /r | WRSSD m32, r32 | CET_SS
	ops: w=rm r=reg | UInt32
	flags: no-rm no-v86
END

# Code: Wrssq_m64_r64
INSTRUCTION: NP o64 0F 38 F6 /r | WRSSQ m64, r64 | CET_SS
	ops: w=rm r=reg | UInt64
	flags: 64 no-rm no-v86
END

# Code: Adcx_r32_rm32
INSTRUCTION: 66 0F 38 F6 /r | ADCX r32, r/m32 | ADX
	ops: rw=reg r=rm | UInt32
	rflags: r=c w=c
	gas: suffix=l
END

# Code: Adcx_r64_rm64
INSTRUCTION: 66 o64 0F 38 F6 /r | ADCX r64, r/m64 | ADX
	ops: rw=reg r=rm | UInt64
	rflags: r=c w=c
	flags: 64
	gas: suffix=q
END

# Code: Adox_r32_rm32
INSTRUCTION: F3 0F 38 F6 /r | ADOX r32, r/m32 | ADX
	ops: rw=reg r=rm | UInt32
	rflags: r=o w=o
	gas: suffix=l
END

# Code: Adox_r64_rm64
INSTRUCTION: F3 o64 0F 38 F6 /r | ADOX r64, r/m64 | ADX
	ops: rw=reg r=rm | UInt64
	rflags: r=o w=o
	flags: 64
	gas: suffix=q
END

# Code: VEX_Mulx_r32_r32_rm32
INSTRUCTION: VEX.LZ.F2.0F38.W0 F6 /r | MULX r32a, r32b, r/m32 | BMI2
	ops: w=reg w=vvvv r=rm | UInt32
	implied: r=edx
	flags: wig32
	gas: suffix=l
END

# Code: VEX_Mulx_r64_r64_rm64
INSTRUCTION: VEX.LZ.F2.0F38.W1 F6 /r | MULX r64a, r64b, r/m64 | BMI2
	ops: w=reg w=vvvv r=rm | UInt64
	implied: r=rdx
	flags: 64
	gas: suffix=q
END

# Code: VEX_Bextr_r32_rm32_r32
INSTRUCTION: VEX.LZ.0F38.W0 F7 /r | BEXTR r32a, r/m32, r32b | BMI1
	ops: w=reg r=rm r=vvvv | UInt32
	implied: last-gpr-16
	rflags: u=sap w=z 0=oc
	flags: wig32
	gas: suffix=l
END

# Code: VEX_Bextr_r64_rm64_r64
INSTRUCTION: VEX.LZ.0F38.W1 F7 /r | BEXTR r64a, r/m64, r64b | BMI1
	ops: w=reg r=rm r=vvvv | UInt64
	implied: last-gpr-16
	rflags: u=sap w=z 0=oc
	flags: 64
	gas: suffix=q
END

# Code: VEX_Shlx_r32_rm32_r32
INSTRUCTION: VEX.LZ.66.0F38.W0 F7 /r | SHLX r32a, r/m32, r32b | BMI2
	ops: w=reg r=rm r=vvvv | UInt32
	implied: last-gpr-8
	flags: wig32
	gas: suffix=l
END

# Code: VEX_Shlx_r64_rm64_r64
INSTRUCTION: VEX.LZ.66.0F38.W1 F7 /r | SHLX r64a, r/m64, r64b | BMI2
	ops: w=reg r=rm r=vvvv | UInt64
	implied: last-gpr-8
	flags: 64
	gas: suffix=q
END

# Code: VEX_Sarx_r32_rm32_r32
INSTRUCTION: VEX.LZ.F3.0F38.W0 F7 /r | SARX r32a, r/m32, r32b | BMI2
	ops: w=reg r=rm r=vvvv | Int32
	implied: last-gpr-8
	flags: wig32
	gas: suffix=l
END

# Code: VEX_Sarx_r64_rm64_r64
INSTRUCTION: VEX.LZ.F3.0F38.W1 F7 /r | SARX r64a, r/m64, r64b | BMI2
	ops: w=reg r=rm r=vvvv | Int64
	implied: last-gpr-8
	flags: 64
	gas: suffix=q
END

# Code: VEX_Shrx_r32_rm32_r32
INSTRUCTION: VEX.LZ.F2.0F38.W0 F7 /r | SHRX r32a, r/m32, r32b | BMI2
	ops: w=reg r=rm r=vvvv | UInt32
	implied: last-gpr-8
	flags: wig32
	gas: suffix=l
END

# Code: VEX_Shrx_r64_rm64_r64
INSTRUCTION: VEX.LZ.F2.0F38.W1 F7 /r | SHRX r64a, r/m64, r64b | BMI2
	ops: w=reg r=rm r=vvvv | UInt64
	implied: last-gpr-8
	flags: 64
	gas: suffix=q
END

# Code: Movdir64b_r16_m512
INSTRUCTION: a16 66 0F 38 F8 /r | MOVDIR64B r16, m512 | MOVDIR64B
	ops: r=reg;mem r=rm | UInt512
	implied: w=[es:op0-reg=default]
	flags: 16 32
END

# Code: Movdir64b_r32_m512
INSTRUCTION: a32 66 0F 38 F8 /r | MOVDIR64B r32, m512 | MOVDIR64B
	ops: r=reg;mem r=rm | UInt512
	implied: w=[es:op0-reg=default]
END

# Code: Movdir64b_r64_m512
INSTRUCTION: a64 66 0F 38 F8 /r | MOVDIR64B r64, m512 | MOVDIR64B
	ops: r=reg;mem r=rm | UInt512
	implied: w=[es:op0-reg=default]
	flags: 64
END

# Code: Enqcmds_r16_m512
INSTRUCTION: a16 F3 0F 38 F8 !(11):rrr:bbb | ENQCMDS r16, m512 | ENQCMD
	ops: r=reg;mem r=rm | UInt512
	implied: w=[es:op0-reg=default]
	rflags: w=z 0=osacp
	# A VM exit may occur during the PASID translation process
	# May cause a TSX abort if VM exit
	flags: 16 32 cpl0 intel-may-vm-exit tdx-non-root-ud tsx-impl-abort
END

# Code: Enqcmds_r32_m512
INSTRUCTION: a32 F3 0F 38 F8 !(11):rrr:bbb | ENQCMDS r32, m512 | ENQCMD
	ops: r=reg;mem r=rm | UInt512
	implied: w=[es:op0-reg=default]
	rflags: w=z 0=osacp
	# A VM exit may occur during the PASID translation process
	# May cause a TSX abort if VM exit
	flags: cpl0 intel-may-vm-exit tdx-non-root-ud tsx-impl-abort
END

# Code: Enqcmds_r64_m512
INSTRUCTION: a64 F3 0F 38 F8 !(11):rrr:bbb | ENQCMDS r64, m512 | ENQCMD
	ops: r=reg;mem r=rm | UInt512
	implied: w=[es:op0-reg=default]
	rflags: w=z 0=osacp
	# A VM exit may occur during the PASID translation process
	# May cause a TSX abort if VM exit
	flags: 64 cpl0 intel-may-vm-exit tdx-non-root-ud tsx-impl-abort
END

# Code: Enqcmd_r16_m512
INSTRUCTION: a16 F2 0F 38 F8 !(11):rrr:bbb | ENQCMD r16, m512 | ENQCMD
	ops: r=reg;mem r=rm | UInt512
	implied: w=[es:op0-reg=default]
	rflags: w=z 0=osacp
	# A VM exit may occur during the PASID translation process
	# May cause a TSX abort if VM exit
	flags: 16 32 intel-may-vm-exit tdx-non-root-ud tsx-impl-abort
END

# Code: Enqcmd_r32_m512
INSTRUCTION: a32 F2 0F 38 F8 !(11):rrr:bbb | ENQCMD r32, m512 | ENQCMD
	ops: r=reg;mem r=rm | UInt512
	implied: w=[es:op0-reg=default]
	rflags: w=z 0=osacp
	# A VM exit may occur during the PASID translation process
	# May cause a TSX abort if VM exit
	flags: intel-may-vm-exit tdx-non-root-ud tsx-impl-abort
END

# Code: Enqcmd_r64_m512
INSTRUCTION: a64 F2 0F 38 F8 !(11):rrr:bbb | ENQCMD r64, m512 | ENQCMD
	ops: r=reg;mem r=rm | UInt512
	implied: w=[es:op0-reg=default]
	rflags: w=z 0=osacp
	# A VM exit may occur during the PASID translation process
	# May cause a TSX abort if VM exit
	flags: 64 intel-may-vm-exit tdx-non-root-ud tsx-impl-abort
END

# Code: Movdiri_m32_r32
INSTRUCTION: NP 0F 38 F9 /r | MOVDIRI m32, r32 | MOVDIRI
	ops: w=rm r=reg | UInt32
	gas: suffix=l
END

# Code: Movdiri_m64_r64
INSTRUCTION: NP o64 0F 38 F9 /r | MOVDIRI m64, r64 | MOVDIRI
	ops: w=rm r=reg | UInt64
	flags: 64
	gas: suffix=q
END

# Code: VEX_Vpermq_ymm_ymmm256_imm8
INSTRUCTION: VEX.256.66.0F3A.W1 00 /r ib | VPERMQ ymm1, ymm2/m256, imm8 | AVX2
	ops: w=reg r=rm r=imm | Packed256_UInt64
END

# Code: EVEX_Vpermq_ymm_k1z_ymmm256b64_imm8
INSTRUCTION: EVEX.256.66.0F3A.W1 00 /r ib | VPERMQ ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8 | AVX512VL AVX512F | N32b8
	ops: w=reg r=rm r=imm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vpermq_zmm_k1z_zmmm512b64_imm8
INSTRUCTION: EVEX.512.66.0F3A.W1 00 /r ib | VPERMQ zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8 | AVX512F | N64b8
	ops: wvmm=reg r=rm r=imm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: VEX_Vpermpd_ymm_ymmm256_imm8
INSTRUCTION: VEX.256.66.0F3A.W1 01 /r ib | VPERMPD ymm1, ymm2/m256, imm8 | AVX2
	ops: w=reg r=rm r=imm | Packed256_Float64
END

# Code: EVEX_Vpermpd_ymm_k1z_ymmm256b64_imm8
INSTRUCTION: EVEX.256.66.0F3A.W1 01 /r ib | VPERMPD ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8 | AVX512VL AVX512F | N32b8
	ops: w=reg r=rm r=imm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vpermpd_zmm_k1z_zmmm512b64_imm8
INSTRUCTION: EVEX.512.66.0F3A.W1 01 /r ib | VPERMPD zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8 | AVX512F | N64b8
	ops: wvmm=reg r=rm r=imm | Packed512_Float64 Broadcast512_Float64
END

# Code: VEX_Vpblendd_xmm_xmm_xmmm128_imm8
INSTRUCTION: VEX.128.66.0F3A.W0 02 /r ib | VPBLENDD xmm1, xmm2, xmm3/m128, imm8 | AVX2
	ops: w=reg r=vvvv r=rm r=imm | Packed128_UInt32
END

# Code: VEX_Vpblendd_ymm_ymm_ymmm256_imm8
INSTRUCTION: VEX.256.66.0F3A.W0 02 /r ib | VPBLENDD ymm1, ymm2, ymm3/m256, imm8 | AVX2
	ops: w=reg r=vvvv r=rm r=imm | Packed256_UInt32
END

# Code: EVEX_Valignd_xmm_k1z_xmm_xmmm128b32_imm8
INSTRUCTION: EVEX.128.66.0F3A.W0 03 /r ib | VALIGND xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst, imm8 | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm r=imm | Packed128_UInt32 Broadcast128_UInt32
END

# Code: EVEX_Valignd_ymm_k1z_ymm_ymmm256b32_imm8
INSTRUCTION: EVEX.256.66.0F3A.W0 03 /r ib | VALIGND ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst, imm8 | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm r=imm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Valignd_zmm_k1z_zmm_zmmm512b32_imm8
INSTRUCTION: EVEX.512.66.0F3A.W0 03 /r ib | VALIGND zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst, imm8 | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm r=imm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: EVEX_Valignq_xmm_k1z_xmm_xmmm128b64_imm8
INSTRUCTION: EVEX.128.66.0F3A.W1 03 /r ib | VALIGNQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst, imm8 | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm r=imm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Valignq_ymm_k1z_ymm_ymmm256b64_imm8
INSTRUCTION: EVEX.256.66.0F3A.W1 03 /r ib | VALIGNQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst, imm8 | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm r=imm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Valignq_zmm_k1z_zmm_zmmm512b64_imm8
INSTRUCTION: EVEX.512.66.0F3A.W1 03 /r ib | VALIGNQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst, imm8 | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm r=imm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: VEX_Vpermilps_xmm_xmmm128_imm8
INSTRUCTION: VEX.128.66.0F3A.W0 04 /r ib | VPERMILPS xmm1, xmm2/m128, imm8 | AVX
	ops: w=reg r=rm r=imm | Packed128_Float32
END

# Code: VEX_Vpermilps_ymm_ymmm256_imm8
INSTRUCTION: VEX.256.66.0F3A.W0 04 /r ib | VPERMILPS ymm1, ymm2/m256, imm8 | AVX
	ops: w=reg r=rm r=imm | Packed256_Float32
END

# Code: EVEX_Vpermilps_xmm_k1z_xmmm128b32_imm8
INSTRUCTION: EVEX.128.66.0F3A.W0 04 /r ib | VPERMILPS xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8 | AVX512VL AVX512F | N16b4
	ops: w=reg r=rm r=imm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vpermilps_ymm_k1z_ymmm256b32_imm8
INSTRUCTION: EVEX.256.66.0F3A.W0 04 /r ib | VPERMILPS ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8 | AVX512VL AVX512F | N32b4
	ops: w=reg r=rm r=imm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vpermilps_zmm_k1z_zmmm512b32_imm8
INSTRUCTION: EVEX.512.66.0F3A.W0 04 /r ib | VPERMILPS zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8 | AVX512F | N64b4
	ops: wvmm=reg r=rm r=imm | Packed512_Float32 Broadcast512_Float32
END

# Code: VEX_Vpermilpd_xmm_xmmm128_imm8
INSTRUCTION: VEX.128.66.0F3A.W0 05 /r ib | VPERMILPD xmm1, xmm2/m128, imm8 | AVX
	ops: w=reg r=rm r=imm | Packed128_Float64
END

# Code: VEX_Vpermilpd_ymm_ymmm256_imm8
INSTRUCTION: VEX.256.66.0F3A.W0 05 /r ib | VPERMILPD ymm1, ymm2/m256, imm8 | AVX
	ops: w=reg r=rm r=imm | Packed256_Float64
END

# Code: EVEX_Vpermilpd_xmm_k1z_xmmm128b64_imm8
INSTRUCTION: EVEX.128.66.0F3A.W1 05 /r ib | VPERMILPD xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8 | AVX512VL AVX512F | N16b8
	ops: w=reg r=rm r=imm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vpermilpd_ymm_k1z_ymmm256b64_imm8
INSTRUCTION: EVEX.256.66.0F3A.W1 05 /r ib | VPERMILPD ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8 | AVX512VL AVX512F | N32b8
	ops: w=reg r=rm r=imm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vpermilpd_zmm_k1z_zmmm512b64_imm8
INSTRUCTION: EVEX.512.66.0F3A.W1 05 /r ib | VPERMILPD zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8 | AVX512F | N64b8
	ops: wvmm=reg r=rm r=imm | Packed512_Float64 Broadcast512_Float64
END

# Code: VEX_Vperm2f128_ymm_ymm_ymmm256_imm8
INSTRUCTION: VEX.256.66.0F3A.W0 06 /r ib | VPERM2F128 ymm1, ymm2, ymm3/m256, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | Packed256_Float128
END

# Code: Roundps_xmm_xmmm128_imm8
INSTRUCTION: 66 0F 3A 08 /r ib | ROUNDPS xmm1, xmm2/m128, imm8 | SSE4_1
	ops: w=reg r=rm r=imm | Packed128_Float32
END

# Code: VEX_Vroundps_xmm_xmmm128_imm8
INSTRUCTION: VEX.128.66.0F3A.WIG 08 /r ib | VROUNDPS xmm1, xmm2/m128, imm8 | AVX
	ops: w=reg r=rm r=imm | Packed128_Float32
END

# Code: VEX_Vroundps_ymm_ymmm256_imm8
INSTRUCTION: VEX.256.66.0F3A.WIG 08 /r ib | VROUNDPS ymm1, ymm2/m256, imm8 | AVX
	ops: w=reg r=rm r=imm | Packed256_Float32
END

# Code: EVEX_Vrndscaleps_xmm_k1z_xmmm128b32_imm8
INSTRUCTION: EVEX.128.66.0F3A.W0 08 /r ib | VRNDSCALEPS xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8 | AVX512VL AVX512F | N16b4
	ops: w=reg r=rm r=imm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vrndscaleps_ymm_k1z_ymmm256b32_imm8
INSTRUCTION: EVEX.256.66.0F3A.W0 08 /r ib | VRNDSCALEPS ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8 | AVX512VL AVX512F | N32b4
	ops: w=reg r=rm r=imm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vrndscaleps_zmm_k1z_zmmm512b32_imm8_sae
INSTRUCTION: EVEX.512.66.0F3A.W0 08 /r ib | VRNDSCALEPS zmm1 {k1}{z}, zmm2/m512/m32bcst{sae}, imm8 | AVX512F | N64b4
	ops: wvmm=reg r=rm r=imm | Packed512_Float32 Broadcast512_Float32
END

# Code: Roundpd_xmm_xmmm128_imm8
INSTRUCTION: 66 0F 3A 09 /r ib | ROUNDPD xmm1, xmm2/m128, imm8 | SSE4_1
	ops: w=reg r=rm r=imm | Packed128_Float64
END

# Code: VEX_Vroundpd_xmm_xmmm128_imm8
INSTRUCTION: VEX.128.66.0F3A.WIG 09 /r ib | VROUNDPD xmm1, xmm2/m128, imm8 | AVX
	ops: w=reg r=rm r=imm | Packed128_Float64
END

# Code: VEX_Vroundpd_ymm_ymmm256_imm8
INSTRUCTION: VEX.256.66.0F3A.WIG 09 /r ib | VROUNDPD ymm1, ymm2/m256, imm8 | AVX
	ops: w=reg r=rm r=imm | Packed256_Float64
END

# Code: EVEX_Vrndscalepd_xmm_k1z_xmmm128b64_imm8
INSTRUCTION: EVEX.128.66.0F3A.W1 09 /r ib | VRNDSCALEPD xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8 | AVX512VL AVX512F | N16b8
	ops: w=reg r=rm r=imm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vrndscalepd_ymm_k1z_ymmm256b64_imm8
INSTRUCTION: EVEX.256.66.0F3A.W1 09 /r ib | VRNDSCALEPD ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8 | AVX512VL AVX512F | N32b8
	ops: w=reg r=rm r=imm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vrndscalepd_zmm_k1z_zmmm512b64_imm8_sae
INSTRUCTION: EVEX.512.66.0F3A.W1 09 /r ib | VRNDSCALEPD zmm1 {k1}{z}, zmm2/m512/m64bcst{sae}, imm8 | AVX512F | N64b8
	ops: wvmm=reg r=rm r=imm | Packed512_Float64 Broadcast512_Float64
END

# Code: Roundss_xmm_xmmm32_imm8
INSTRUCTION: 66 0F 3A 0A /r ib | ROUNDSS xmm1, xmm2/m32, imm8 | SSE4_1
	ops: rw=reg r=rm r=imm | Float32
END

# Code: VEX_Vroundss_xmm_xmm_xmmm32_imm8
INSTRUCTION: VEX.LIG.66.0F3A.WIG 0A /r ib | VROUNDSS xmm1, xmm2, xmm3/m32, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vrndscaless_xmm_k1z_xmm_xmmm32_imm8_sae
INSTRUCTION: EVEX.LIG.66.0F3A.W0 0A /r ib | VRNDSCALESS xmm1 {k1}{z}, xmm2, xmm3/m32{sae}, imm8 | AVX512F | N4
	ops: w=reg r=vvvv r=rm r=imm | Float32
END

# Code: Roundsd_xmm_xmmm64_imm8
INSTRUCTION: 66 0F 3A 0B /r ib | ROUNDSD xmm1, xmm2/m64, imm8 | SSE4_1
	ops: rw=reg r=rm r=imm | Float64
END

# Code: VEX_Vroundsd_xmm_xmm_xmmm64_imm8
INSTRUCTION: VEX.LIG.66.0F3A.WIG 0B /r ib | VROUNDSD xmm1, xmm2, xmm3/m64, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | Float64
	masm: flags=force-size=default
END

# Code: EVEX_Vrndscalesd_xmm_k1z_xmm_xmmm64_imm8_sae
INSTRUCTION: EVEX.LIG.66.0F3A.W1 0B /r ib | VRNDSCALESD xmm1 {k1}{z}, xmm2, xmm3/m64{sae}, imm8 | AVX512F | N8
	ops: w=reg r=vvvv r=rm r=imm | Float64
END

# Code: Blendps_xmm_xmmm128_imm8
INSTRUCTION: 66 0F 3A 0C /r ib | BLENDPS xmm1, xmm2/m128, imm8 | SSE4_1
	ops: rw=reg r=rm r=imm | Packed128_Float32
END

# Code: VEX_Vblendps_xmm_xmm_xmmm128_imm8
INSTRUCTION: VEX.128.66.0F3A.WIG 0C /r ib | VBLENDPS xmm1, xmm2, xmm3/m128, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | Packed128_Float32
END

# Code: VEX_Vblendps_ymm_ymm_ymmm256_imm8
INSTRUCTION: VEX.256.66.0F3A.WIG 0C /r ib | VBLENDPS ymm1, ymm2, ymm3/m256, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | Packed256_Float32
END

# Code: Blendpd_xmm_xmmm128_imm8
INSTRUCTION: 66 0F 3A 0D /r ib | BLENDPD xmm1, xmm2/m128, imm8 | SSE4_1
	ops: rw=reg r=rm r=imm | Packed128_Float64
END

# Code: VEX_Vblendpd_xmm_xmm_xmmm128_imm8
INSTRUCTION: VEX.128.66.0F3A.WIG 0D /r ib | VBLENDPD xmm1, xmm2, xmm3/m128, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | Packed128_Float64
END

# Code: VEX_Vblendpd_ymm_ymm_ymmm256_imm8
INSTRUCTION: VEX.256.66.0F3A.WIG 0D /r ib | VBLENDPD ymm1, ymm2, ymm3/m256, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | Packed256_Float64
END

# Code: Pblendw_xmm_xmmm128_imm8
INSTRUCTION: 66 0F 3A 0E /r ib | PBLENDW xmm1, xmm2/m128, imm8 | SSE4_1
	ops: rw=reg r=rm r=imm | Packed128_UInt16
END

# Code: VEX_Vpblendw_xmm_xmm_xmmm128_imm8
INSTRUCTION: VEX.128.66.0F3A.WIG 0E /r ib | VPBLENDW xmm1, xmm2, xmm3/m128, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | Packed128_UInt16
END

# Code: VEX_Vpblendw_ymm_ymm_ymmm256_imm8
INSTRUCTION: VEX.256.66.0F3A.WIG 0E /r ib | VPBLENDW ymm1, ymm2, ymm3/m256, imm8 | AVX2
	ops: w=reg r=vvvv r=rm r=imm | Packed256_UInt16
END

# Code: Palignr_mm_mmm64_imm8
INSTRUCTION: NP 0F 3A 0F /r ib | PALIGNR mm1, mm2/m64, imm8 | SSSE3
	ops: rw=reg r=rm r=imm | Packed64_UInt8
	flags: tsx-impl-abort
	masm: flags=mem-size=mmx
END

# Code: Palignr_xmm_xmmm128_imm8
INSTRUCTION: 66 0F 3A 0F /r ib | PALIGNR xmm1, xmm2/m128, imm8 | SSSE3
	ops: rw=reg r=rm r=imm | Packed128_UInt8
END

# Code: VEX_Vpalignr_xmm_xmm_xmmm128_imm8
INSTRUCTION: VEX.128.66.0F3A.WIG 0F /r ib | VPALIGNR xmm1, xmm2, xmm3/m128, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | Packed128_UInt8
END

# Code: VEX_Vpalignr_ymm_ymm_ymmm256_imm8
INSTRUCTION: VEX.256.66.0F3A.WIG 0F /r ib | VPALIGNR ymm1, ymm2, ymm3/m256, imm8 | AVX2
	ops: w=reg r=vvvv r=rm r=imm | Packed256_UInt8
END

# Code: EVEX_Vpalignr_xmm_k1z_xmm_xmmm128_imm8
INSTRUCTION: EVEX.128.66.0F3A.WIG 0F /r ib | VPALIGNR xmm1 {k1}{z}, xmm2, xmm3/m128, imm8 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm r=imm | Packed128_UInt8
END

# Code: EVEX_Vpalignr_ymm_k1z_ymm_ymmm256_imm8
INSTRUCTION: EVEX.256.66.0F3A.WIG 0F /r ib | VPALIGNR ymm1 {k1}{z}, ymm2, ymm3/m256, imm8 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm r=imm | Packed256_UInt8
END

# Code: EVEX_Vpalignr_zmm_k1z_zmm_zmmm512_imm8
INSTRUCTION: EVEX.512.66.0F3A.WIG 0F /r ib | VPALIGNR zmm1 {k1}{z}, zmm2, zmm3/m512, imm8 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm r=imm | Packed512_UInt8
END

# Code: Pextrb_r32m8_xmm_imm8
INSTRUCTION: 66 0F 3A 14 /r ib | PEXTRB r32/m8, xmm2, imm8 | SSE4_1
	ops: w=rm r=reg r=imm | UInt8
	masm: flags=force-size=default
END

# Code: Pextrb_r64m8_xmm_imm8
INSTRUCTION: 66 o64 0F 3A 14 /r ib | PEXTRB r64/m8, xmm2, imm8 | SSE4_1
	ops: w=rm r=reg r=imm | UInt8
	flags: 64 asm-ig-mem
	intel: reg32
	masm: flags=force-size=default
END

# Code: VEX_Vpextrb_r32m8_xmm_imm8
INSTRUCTION: VEX.128.66.0F3A.W0 14 /r ib | VPEXTRB r32/m8, xmm2, imm8 | AVX
	ops: w=rm r=reg r=imm | UInt8
	flags: wig32
	masm: flags=force-size=default
END

# Code: VEX_Vpextrb_r64m8_xmm_imm8
INSTRUCTION: VEX.128.66.0F3A.W1 14 /r ib | VPEXTRB r64/m8, xmm2, imm8 | AVX
	ops: w=rm r=reg r=imm | UInt8
	flags: 64 asm-ig-mem
	intel: reg32
	masm: flags=force-size=default
END

# Code: EVEX_Vpextrb_r32m8_xmm_imm8
INSTRUCTION: EVEX.128.66.0F3A.W0 14 /r ib | VPEXTRB r32/m8, xmm2, imm8 | AVX512BW | N1
	ops: w=rm r=reg r=imm | UInt8
	flags: wig32
	masm: flags=force-size=default
END

# Code: EVEX_Vpextrb_r64m8_xmm_imm8
INSTRUCTION: EVEX.128.66.0F3A.W1 14 /r ib | VPEXTRB r64/m8, xmm2, imm8 | AVX512BW | N1
	ops: w=rm r=reg r=imm | UInt8
	flags: 64 asm-ig-mem
	intel: reg32
	masm: flags=force-size=default
END

# Code: Pextrw_r32m16_xmm_imm8
INSTRUCTION: 66 0F 3A 15 /r ib | PEXTRW r32/m16, xmm, imm8 | SSE4_1
	ops: w=rm r=reg r=imm | UInt16
	masm: flags=force-size=default
END

# Code: Pextrw_r64m16_xmm_imm8
INSTRUCTION: 66 o64 0F 3A 15 /r ib | PEXTRW r64/m16, xmm, imm8 | SSE4_1
	ops: w=rm r=reg r=imm | UInt16
	flags: 64
	intel: reg32
	masm: flags=force-size=default
END

# Code: VEX_Vpextrw_r32m16_xmm_imm8
INSTRUCTION: VEX.128.66.0F3A.W0 15 /r ib | VPEXTRW r32/m16, xmm2, imm8 | AVX
	ops: w=rm r=reg r=imm | UInt16
	flags: wig32
	masm: flags=force-size=default
END

# Code: VEX_Vpextrw_r64m16_xmm_imm8
INSTRUCTION: VEX.128.66.0F3A.W1 15 /r ib | VPEXTRW r64/m16, xmm2, imm8 | AVX
	ops: w=rm r=reg r=imm | UInt16
	flags: 64 asm-ig-mem
	intel: reg32
	masm: flags=force-size=default
END

# Code: EVEX_Vpextrw_r32m16_xmm_imm8
INSTRUCTION: EVEX.128.66.0F3A.W0 15 /r ib | VPEXTRW r32/m16, xmm2, imm8 | AVX512BW | N2
	ops: w=rm r=reg r=imm | UInt16
	flags: wig32
	masm: flags=force-size=default
END

# Code: EVEX_Vpextrw_r64m16_xmm_imm8
INSTRUCTION: EVEX.128.66.0F3A.W1 15 /r ib | VPEXTRW r64/m16, xmm2, imm8 | AVX512BW | N2
	ops: w=rm r=reg r=imm | UInt16
	flags: 64 asm-ig-mem
	intel: reg32
	masm: flags=force-size=default
END

# Code: Pextrd_rm32_xmm_imm8
INSTRUCTION: 66 0F 3A 16 /r ib | PEXTRD r/m32, xmm2, imm8 | SSE4_1
	ops: w=rm r=reg r=imm | UInt32
	masm: flags=force-size=default
END

# Code: Pextrq_rm64_xmm_imm8
INSTRUCTION: 66 o64 0F 3A 16 /r ib | PEXTRQ r/m64, xmm2, imm8 | SSE4_1
	ops: w=rm r=reg r=imm | UInt64
	flags: 64
	masm: flags=force-size=default
END

# Code: VEX_Vpextrd_rm32_xmm_imm8
INSTRUCTION: VEX.128.66.0F3A.W0 16 /r ib | VPEXTRD r/m32, xmm2, imm8 | AVX
	ops: w=rm r=reg r=imm | UInt32
	flags: wig32
	masm: flags=force-size=default
END

# Code: VEX_Vpextrq_rm64_xmm_imm8
INSTRUCTION: VEX.128.66.0F3A.W1 16 /r ib | VPEXTRQ r/m64, xmm2, imm8 | AVX
	ops: w=rm r=reg r=imm | UInt64
	flags: 64
	masm: flags=force-size=default
END

# Code: EVEX_Vpextrd_rm32_xmm_imm8
INSTRUCTION: EVEX.128.66.0F3A.W0 16 /r ib | VPEXTRD r/m32, xmm2, imm8 | AVX512DQ | N4
	ops: w=rm r=reg r=imm | UInt32
	flags: wig32
	masm: flags=force-size=default
END

# Code: EVEX_Vpextrq_rm64_xmm_imm8
INSTRUCTION: EVEX.128.66.0F3A.W1 16 /r ib | VPEXTRQ r/m64, xmm2, imm8 | AVX512DQ | N8
	ops: w=rm r=reg r=imm | UInt64
	flags: 64
	masm: flags=force-size=default
END

# Code: Extractps_rm32_xmm_imm8
INSTRUCTION: 66 0F 3A 17 /r ib | EXTRACTPS r/m32, xmm1, imm8 | SSE4_1
	ops: w=rm r=reg r=imm | Float32
	masm: flags=force-size=always
END

# Code: Extractps_r64m32_xmm_imm8
INSTRUCTION: 66 o64 0F 3A 17 /r ib | EXTRACTPS r64/m32, xmm1, imm8 | SSE4_1
	ops: w=rm r=reg r=imm | Float32
	flags: 64 asm-ig-mem
	intel: reg32
	masm: flags=force-size=always reg32
END

# Code: VEX_Vextractps_rm32_xmm_imm8
INSTRUCTION: VEX.128.66.0F3A.W0 17 /r ib | VEXTRACTPS r/m32, xmm1, imm8 | AVX
	ops: w=rm r=reg r=imm | Float32
	flags: wig32
	masm: flags=force-size=always
END

# Code: VEX_Vextractps_r64m32_xmm_imm8
INSTRUCTION: VEX.128.66.0F3A.W1 17 /r ib | VEXTRACTPS r64/m32, xmm1, imm8 | AVX
	ops: w=rm r=reg r=imm | Float32
	flags: 64 asm-ig-mem
	intel: reg32
	masm: flags=force-size=always reg32
END

# Code: EVEX_Vextractps_rm32_xmm_imm8
INSTRUCTION: EVEX.128.66.0F3A.W0 17 /r ib | VEXTRACTPS r/m32, xmm1, imm8 | AVX512F | N4
	ops: w=rm r=reg r=imm | Float32
	flags: wig32
	masm: flags=force-size=always
END

# Code: EVEX_Vextractps_r64m32_xmm_imm8
INSTRUCTION: EVEX.128.66.0F3A.W1 17 /r ib | VEXTRACTPS r64/m32, xmm1, imm8 | AVX512F | N4
	ops: w=rm r=reg r=imm | Float32
	flags: 64 asm-ig-mem
	intel: reg32
	masm: flags=force-size=always reg32
END

# Code: VEX_Vinsertf128_ymm_ymm_xmmm128_imm8
INSTRUCTION: VEX.256.66.0F3A.W0 18 /r ib | VINSERTF128 ymm1, ymm2, xmm3/m128, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | Float128
	masm: flags=force-size=default
END

# Code: EVEX_Vinsertf32x4_ymm_k1z_ymm_xmmm128_imm8
INSTRUCTION: EVEX.256.66.0F3A.W0 18 /r ib | VINSERTF32X4 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8 | AVX512VL AVX512F | N16
	ops: w=reg r=vvvv r=rm r=imm | Packed128_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vinsertf32x4_zmm_k1z_zmm_xmmm128_imm8
INSTRUCTION: EVEX.512.66.0F3A.W0 18 /r ib | VINSERTF32X4 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8 | AVX512F | N16
	ops: wvmm=reg r=vvvv r=rm r=imm | Packed128_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vinsertf64x2_ymm_k1z_ymm_xmmm128_imm8
INSTRUCTION: EVEX.256.66.0F3A.W1 18 /r ib | VINSERTF64X2 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8 | AVX512VL AVX512DQ | N16
	ops: w=reg r=vvvv r=rm r=imm | Packed128_Float64
	masm: flags=force-size=default
END

# Code: EVEX_Vinsertf64x2_zmm_k1z_zmm_xmmm128_imm8
INSTRUCTION: EVEX.512.66.0F3A.W1 18 /r ib | VINSERTF64X2 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8 | AVX512DQ | N16
	ops: wvmm=reg r=vvvv r=rm r=imm | Packed128_Float64
	masm: flags=force-size=default
END

# Code: VEX_Vextractf128_xmmm128_ymm_imm8
INSTRUCTION: VEX.256.66.0F3A.W0 19 /r ib | VEXTRACTF128 xmm1/m128, ymm2, imm8 | AVX
	ops: w=rm r=reg r=imm | Float128
	masm: flags=force-size=default
END

# Code: EVEX_Vextractf32x4_xmmm128_k1z_ymm_imm8
INSTRUCTION: EVEX.256.66.0F3A.W0 19 /r ib | VEXTRACTF32X4 xmm1/m128 {k1}{z}, ymm2, imm8 | AVX512VL AVX512F | N16
	ops: w=rm r=reg r=imm | Packed128_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vextractf32x4_xmmm128_k1z_zmm_imm8
INSTRUCTION: EVEX.512.66.0F3A.W0 19 /r ib | VEXTRACTF32X4 xmm1/m128 {k1}{z}, zmm2, imm8 | AVX512F | N16
	ops: w=rm r=reg r=imm | Packed128_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vextractf64x2_xmmm128_k1z_ymm_imm8
INSTRUCTION: EVEX.256.66.0F3A.W1 19 /r ib | VEXTRACTF64X2 xmm1/m128 {k1}{z}, ymm2, imm8 | AVX512VL AVX512DQ | N16
	ops: w=rm r=reg r=imm | Packed128_Float64
	masm: flags=force-size=default
END

# Code: EVEX_Vextractf64x2_xmmm128_k1z_zmm_imm8
INSTRUCTION: EVEX.512.66.0F3A.W1 19 /r ib | VEXTRACTF64X2 xmm1/m128 {k1}{z}, zmm2, imm8 | AVX512DQ | N16
	ops: w=rm r=reg r=imm | Packed128_Float64
	masm: flags=force-size=default
END

# Code: EVEX_Vinsertf32x8_zmm_k1z_zmm_ymmm256_imm8
INSTRUCTION: EVEX.512.66.0F3A.W0 1A /r ib | VINSERTF32X8 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8 | AVX512DQ | N32
	ops: wvmm=reg r=vvvv r=rm r=imm | Packed256_Float32
END

# Code: EVEX_Vinsertf64x4_zmm_k1z_zmm_ymmm256_imm8
INSTRUCTION: EVEX.512.66.0F3A.W1 1A /r ib | VINSERTF64X4 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8 | AVX512F | N32
	ops: wvmm=reg r=vvvv r=rm r=imm | Packed256_Float64
END

# Code: EVEX_Vextractf32x8_ymmm256_k1z_zmm_imm8
INSTRUCTION: EVEX.512.66.0F3A.W0 1B /r ib | VEXTRACTF32X8 ymm1/m256 {k1}{z}, zmm2, imm8 | AVX512DQ | N32
	ops: w=rm r=reg r=imm | Packed256_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vextractf64x4_ymmm256_k1z_zmm_imm8
INSTRUCTION: EVEX.512.66.0F3A.W1 1B /r ib | VEXTRACTF64X4 ymm1/m256 {k1}{z}, zmm2, imm8 | AVX512F | N32
	ops: w=rm r=reg r=imm | Packed256_Float64
	masm: flags=force-size=default
END

# Code: VEX_Vcvtps2ph_xmmm64_xmm_imm8
INSTRUCTION: VEX.128.66.0F3A.W0 1D /r ib | VCVTPS2PH xmm1/m64, xmm2, imm8 | F16C
	ops: w=rm r=reg r=imm | Packed64_Float16
	masm: flags=force-size=default
END

# Code: VEX_Vcvtps2ph_xmmm128_ymm_imm8
INSTRUCTION: VEX.256.66.0F3A.W0 1D /r ib | VCVTPS2PH xmm1/m128, ymm2, imm8 | F16C
	ops: w=rm r=reg r=imm | Packed128_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtps2ph_xmmm64_k1z_xmm_imm8
INSTRUCTION: EVEX.128.66.0F3A.W0 1D /r ib | VCVTPS2PH xmm1/m64 {k1}{z}, xmm2, imm8 | AVX512VL AVX512F | N8
	ops: w=rm r=reg r=imm | Packed64_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtps2ph_xmmm128_k1z_ymm_imm8
INSTRUCTION: EVEX.256.66.0F3A.W0 1D /r ib | VCVTPS2PH xmm1/m128 {k1}{z}, ymm2, imm8 | AVX512VL AVX512F | N16
	ops: w=rm r=reg r=imm | Packed128_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtps2ph_ymmm256_k1z_zmm_imm8_sae
INSTRUCTION: EVEX.512.66.0F3A.W0 1D /r ib | VCVTPS2PH ymm1/m256 {k1}{z}, zmm2{sae}, imm8 | AVX512F | N32
	ops: w=rm r=reg r=imm | Packed256_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vpcmpud_kr_k1_xmm_xmmm128b32_imm8
INSTRUCTION: EVEX.128.66.0F3A.W0 1E /r ib | VPCMPUD k1 {k2}, xmm2, xmm3/m128/m32bcst, imm8 | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm r=imm | Packed128_UInt32 Broadcast128_UInt32
	flags: pseudo=vpcmpud implied-z
END

# Code: EVEX_Vpcmpud_kr_k1_ymm_ymmm256b32_imm8
INSTRUCTION: EVEX.256.66.0F3A.W0 1E /r ib | VPCMPUD k1 {k2}, ymm2, ymm3/m256/m32bcst, imm8 | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm r=imm | Packed256_UInt32 Broadcast256_UInt32
	flags: pseudo=vpcmpud implied-z
END

# Code: EVEX_Vpcmpud_kr_k1_zmm_zmmm512b32_imm8
INSTRUCTION: EVEX.512.66.0F3A.W0 1E /r ib | VPCMPUD k1 {k2}, zmm2, zmm3/m512/m32bcst, imm8 | AVX512F | N64b4
	ops: w=reg r=vvvv r=rm r=imm | Packed512_UInt32 Broadcast512_UInt32
	flags: pseudo=vpcmpud implied-z
END

# Code: EVEX_Vpcmpuq_kr_k1_xmm_xmmm128b64_imm8
INSTRUCTION: EVEX.128.66.0F3A.W1 1E /r ib | VPCMPUQ k1 {k2}, xmm2, xmm3/m128/m64bcst, imm8 | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm r=imm | Packed128_UInt64 Broadcast128_UInt64
	flags: pseudo=vpcmpuq implied-z
END

# Code: EVEX_Vpcmpuq_kr_k1_ymm_ymmm256b64_imm8
INSTRUCTION: EVEX.256.66.0F3A.W1 1E /r ib | VPCMPUQ k1 {k2}, ymm2, ymm3/m256/m64bcst, imm8 | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm r=imm | Packed256_UInt64 Broadcast256_UInt64
	flags: pseudo=vpcmpuq implied-z
END

# Code: EVEX_Vpcmpuq_kr_k1_zmm_zmmm512b64_imm8
INSTRUCTION: EVEX.512.66.0F3A.W1 1E /r ib | VPCMPUQ k1 {k2}, zmm2, zmm3/m512/m64bcst, imm8 | AVX512F | N64b8
	ops: w=reg r=vvvv r=rm r=imm | Packed512_UInt64 Broadcast512_UInt64
	flags: pseudo=vpcmpuq implied-z
END

# Code: EVEX_Vpcmpd_kr_k1_xmm_xmmm128b32_imm8
INSTRUCTION: EVEX.128.66.0F3A.W0 1F /r ib | VPCMPD k1 {k2}, xmm2, xmm3/m128/m32bcst, imm8 | AVX512VL AVX512F | N16b4
	ops: w=reg r=vvvv r=rm r=imm | Packed128_Int32 Broadcast128_Int32
	flags: pseudo=vpcmpd implied-z
END

# Code: EVEX_Vpcmpd_kr_k1_ymm_ymmm256b32_imm8
INSTRUCTION: EVEX.256.66.0F3A.W0 1F /r ib | VPCMPD k1 {k2}, ymm2, ymm3/m256/m32bcst, imm8 | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm r=imm | Packed256_Int32 Broadcast256_Int32
	flags: pseudo=vpcmpd implied-z
END

# Code: EVEX_Vpcmpd_kr_k1_zmm_zmmm512b32_imm8
INSTRUCTION: EVEX.512.66.0F3A.W0 1F /r ib | VPCMPD k1 {k2}, zmm2, zmm3/m512/m32bcst, imm8 | AVX512F | N64b4
	ops: w=reg r=vvvv r=rm r=imm | Packed512_Int32 Broadcast512_Int32
	flags: pseudo=vpcmpd implied-z
END

# Code: EVEX_Vpcmpq_kr_k1_xmm_xmmm128b64_imm8
INSTRUCTION: EVEX.128.66.0F3A.W1 1F /r ib | VPCMPQ k1 {k2}, xmm2, xmm3/m128/m64bcst, imm8 | AVX512VL AVX512F | N16b8
	ops: w=reg r=vvvv r=rm r=imm | Packed128_Int64 Broadcast128_Int64
	flags: pseudo=vpcmpq implied-z
END

# Code: EVEX_Vpcmpq_kr_k1_ymm_ymmm256b64_imm8
INSTRUCTION: EVEX.256.66.0F3A.W1 1F /r ib | VPCMPQ k1 {k2}, ymm2, ymm3/m256/m64bcst, imm8 | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm r=imm | Packed256_Int64 Broadcast256_Int64
	flags: pseudo=vpcmpq implied-z
END

# Code: EVEX_Vpcmpq_kr_k1_zmm_zmmm512b64_imm8
INSTRUCTION: EVEX.512.66.0F3A.W1 1F /r ib | VPCMPQ k1 {k2}, zmm2, zmm3/m512/m64bcst, imm8 | AVX512F | N64b8
	ops: w=reg r=vvvv r=rm r=imm | Packed512_Int64 Broadcast512_Int64
	flags: pseudo=vpcmpq implied-z
END

# Code: Pinsrb_xmm_r32m8_imm8
INSTRUCTION: 66 0F 3A 20 /r ib | PINSRB xmm1, r32/m8, imm8 | SSE4_1
	ops: rw=reg r=rm r=imm | UInt8
	implied: last-gpr-8
	masm: flags=force-size=default
END

# Code: Pinsrb_xmm_r64m8_imm8
INSTRUCTION: 66 o64 0F 3A 20 /r ib | PINSRB xmm1, r64/m8, imm8 | SSE4_1
	ops: rw=reg r=rm r=imm | UInt8
	implied: last-gpr-8
	flags: 64 asm-ig-mem
	intel: reg32
	masm: flags=force-size=default
	nasm: reg32
END

# Code: VEX_Vpinsrb_xmm_xmm_r32m8_imm8
INSTRUCTION: VEX.128.66.0F3A.W0 20 /r ib | VPINSRB xmm1, xmm2, r32/m8, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | UInt8
	implied: last-gpr-8
	flags: wig32
	masm: flags=force-size=default
END

# Code: VEX_Vpinsrb_xmm_xmm_r64m8_imm8
INSTRUCTION: VEX.128.66.0F3A.W1 20 /r ib | VPINSRB xmm1, xmm2, r64/m8, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | UInt8
	implied: last-gpr-8
	flags: 64 asm-ig-mem
	intel: reg32
	masm: flags=force-size=default reg32
	nasm: reg32
END

# Code: EVEX_Vpinsrb_xmm_xmm_r32m8_imm8
INSTRUCTION: EVEX.128.66.0F3A.W0 20 /r ib | VPINSRB xmm1, xmm2, r32/m8, imm8 | AVX512BW | N1
	ops: w=reg r=vvvv r=rm r=imm | UInt8
	implied: last-gpr-8
	flags: wig32
	masm: flags=force-size=default
END

# Code: EVEX_Vpinsrb_xmm_xmm_r64m8_imm8
INSTRUCTION: EVEX.128.66.0F3A.W1 20 /r ib | VPINSRB xmm1, xmm2, r64/m8, imm8 | AVX512BW | N1
	ops: w=reg r=vvvv r=rm r=imm | UInt8
	implied: last-gpr-8
	flags: 64 asm-ig-mem
	intel: reg32
	masm: flags=force-size=default reg32
	nasm: reg32
END

# Code: Insertps_xmm_xmmm32_imm8
INSTRUCTION: 66 0F 3A 21 /r ib | INSERTPS xmm1, xmm2/m32, imm8 | SSE4_1
	ops: rw=reg r=rm r=imm | Float32
	masm: flags=force-size=default
END

# Code: VEX_Vinsertps_xmm_xmm_xmmm32_imm8
INSTRUCTION: VEX.128.66.0F3A.WIG 21 /r ib | VINSERTPS xmm1, xmm2, xmm3/m32, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vinsertps_xmm_xmm_xmmm32_imm8
INSTRUCTION: EVEX.128.66.0F3A.W0 21 /r ib | VINSERTPS xmm1, xmm2, xmm3/m32, imm8 | AVX512F | N4
	ops: w=reg r=vvvv r=rm r=imm | Float32
	masm: flags=force-size=default
END

# Code: Pinsrd_xmm_rm32_imm8
INSTRUCTION: 66 0F 3A 22 /r ib | PINSRD xmm1, r/m32, imm8 | SSE4_1
	ops: rw=reg r=rm r=imm | UInt32
	masm: flags=force-size=default
END

# Code: Pinsrq_xmm_rm64_imm8
INSTRUCTION: 66 o64 0F 3A 22 /r ib | PINSRQ xmm1, r/m64, imm8 | SSE4_1
	ops: rw=reg r=rm r=imm | UInt64
	flags: 64
	masm: flags=force-size=default
END

# Code: VEX_Vpinsrd_xmm_xmm_rm32_imm8
INSTRUCTION: VEX.128.66.0F3A.W0 22 /r ib | VPINSRD xmm1, xmm2, r/m32, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | UInt32
	flags: wig32
	masm: flags=force-size=default
END

# Code: VEX_Vpinsrq_xmm_xmm_rm64_imm8
INSTRUCTION: VEX.128.66.0F3A.W1 22 /r ib | VPINSRQ xmm1, xmm2, r/m64, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | UInt64
	flags: 64
	masm: flags=force-size=default
END

# Code: EVEX_Vpinsrd_xmm_xmm_rm32_imm8
INSTRUCTION: EVEX.128.66.0F3A.W0 22 /r ib | VPINSRD xmm1, xmm2, r/m32, imm8 | AVX512DQ | N4
	ops: w=reg r=vvvv r=rm r=imm | UInt32
	flags: wig32
	masm: flags=force-size=default
END

# Code: EVEX_Vpinsrq_xmm_xmm_rm64_imm8
INSTRUCTION: EVEX.128.66.0F3A.W1 22 /r ib | VPINSRQ xmm1, xmm2, r/m64, imm8 | AVX512DQ | N8
	ops: w=reg r=vvvv r=rm r=imm | UInt64
	flags: 64
	masm: flags=force-size=default
END

# Code: EVEX_Vshuff32x4_ymm_k1z_ymm_ymmm256b32_imm8
INSTRUCTION: EVEX.256.66.0F3A.W0 23 /r ib | VSHUFF32X4 ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst, imm8 | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm r=imm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vshuff32x4_zmm_k1z_zmm_zmmm512b32_imm8
INSTRUCTION: EVEX.512.66.0F3A.W0 23 /r ib | VSHUFF32X4 zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst, imm8 | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm r=imm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vshuff64x2_ymm_k1z_ymm_ymmm256b64_imm8
INSTRUCTION: EVEX.256.66.0F3A.W1 23 /r ib | VSHUFF64X2 ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst, imm8 | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm r=imm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vshuff64x2_zmm_k1z_zmm_zmmm512b64_imm8
INSTRUCTION: EVEX.512.66.0F3A.W1 23 /r ib | VSHUFF64X2 zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst, imm8 | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm r=imm | Packed512_Float64 Broadcast512_Float64
END

# Code: EVEX_Vpternlogd_xmm_k1z_xmm_xmmm128b32_imm8
INSTRUCTION: EVEX.128.66.0F3A.W0 25 /r ib | VPTERNLOGD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst, imm8 | AVX512VL AVX512F | N16b4
	ops: rw=reg r=vvvv r=rm r=imm | Packed128_UInt32 Broadcast128_UInt32
END

# Code: EVEX_Vpternlogd_ymm_k1z_ymm_ymmm256b32_imm8
INSTRUCTION: EVEX.256.66.0F3A.W0 25 /r ib | VPTERNLOGD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst, imm8 | AVX512VL AVX512F | N32b4
	ops: rw=reg r=vvvv r=rm r=imm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vpternlogd_zmm_k1z_zmm_zmmm512b32_imm8
INSTRUCTION: EVEX.512.66.0F3A.W0 25 /r ib | VPTERNLOGD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst, imm8 | AVX512F | N64b4
	ops: rwvmm=reg r=vvvv r=rm r=imm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: EVEX_Vpternlogq_xmm_k1z_xmm_xmmm128b64_imm8
INSTRUCTION: EVEX.128.66.0F3A.W1 25 /r ib | VPTERNLOGQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst, imm8 | AVX512VL AVX512F | N16b8
	ops: rw=reg r=vvvv r=rm r=imm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Vpternlogq_ymm_k1z_ymm_ymmm256b64_imm8
INSTRUCTION: EVEX.256.66.0F3A.W1 25 /r ib | VPTERNLOGQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst, imm8 | AVX512VL AVX512F | N32b8
	ops: rw=reg r=vvvv r=rm r=imm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vpternlogq_zmm_k1z_zmm_zmmm512b64_imm8
INSTRUCTION: EVEX.512.66.0F3A.W1 25 /r ib | VPTERNLOGQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst, imm8 | AVX512F | N64b8
	ops: rwvmm=reg r=vvvv r=rm r=imm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: EVEX_Vgetmantps_xmm_k1z_xmmm128b32_imm8
INSTRUCTION: EVEX.128.66.0F3A.W0 26 /r ib | VGETMANTPS xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8 | AVX512VL AVX512F | N16b4
	ops: w=reg r=rm r=imm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vgetmantps_ymm_k1z_ymmm256b32_imm8
INSTRUCTION: EVEX.256.66.0F3A.W0 26 /r ib | VGETMANTPS ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8 | AVX512VL AVX512F | N32b4
	ops: w=reg r=rm r=imm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vgetmantps_zmm_k1z_zmmm512b32_imm8_sae
INSTRUCTION: EVEX.512.66.0F3A.W0 26 /r ib | VGETMANTPS zmm1 {k1}{z}, zmm2/m512/m32bcst{sae}, imm8 | AVX512F | N64b4
	ops: wvmm=reg r=rm r=imm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vgetmantpd_xmm_k1z_xmmm128b64_imm8
INSTRUCTION: EVEX.128.66.0F3A.W1 26 /r ib | VGETMANTPD xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8 | AVX512VL AVX512F | N16b8
	ops: w=reg r=rm r=imm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vgetmantpd_ymm_k1z_ymmm256b64_imm8
INSTRUCTION: EVEX.256.66.0F3A.W1 26 /r ib | VGETMANTPD ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8 | AVX512VL AVX512F | N32b8
	ops: w=reg r=rm r=imm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vgetmantpd_zmm_k1z_zmmm512b64_imm8_sae
INSTRUCTION: EVEX.512.66.0F3A.W1 26 /r ib | VGETMANTPD zmm1 {k1}{z}, zmm2/m512/m64bcst{sae}, imm8 | AVX512F | N64b8
	ops: wvmm=reg r=rm r=imm | Packed512_Float64 Broadcast512_Float64
END

# Code: EVEX_Vgetmantss_xmm_k1z_xmm_xmmm32_imm8_sae
INSTRUCTION: EVEX.LIG.66.0F3A.W0 27 /r ib | VGETMANTSS xmm1 {k1}{z}, xmm2, xmm3/m32{sae}, imm8 | AVX512F | N4
	ops: w=reg r=vvvv r=rm r=imm | Float32
END

# Code: EVEX_Vgetmantsd_xmm_k1z_xmm_xmmm64_imm8_sae
INSTRUCTION: EVEX.LIG.66.0F3A.W1 27 /r ib | VGETMANTSD xmm1 {k1}{z}, xmm2, xmm3/m64{sae}, imm8 | AVX512F | N8
	ops: w=reg r=vvvv r=rm r=imm | Float64
END

# Code: VEX_Kshiftrb_kr_kr_imm8
INSTRUCTION: VEX.L0.66.0F3A.W0 30 /r ib | KSHIFTRB k1, k2, imm8 | AVX512DQ
	ops: w=reg r=rm r=imm
END

# Code: VEX_Kshiftrw_kr_kr_imm8
INSTRUCTION: VEX.L0.66.0F3A.W1 30 /r ib | KSHIFTRW k1, k2, imm8 | AVX512F
	ops: w=reg r=rm r=imm
END

# Code: VEX_Kshiftrd_kr_kr_imm8
INSTRUCTION: VEX.L0.66.0F3A.W0 31 /r ib | KSHIFTRD k1, k2, imm8 | AVX512BW
	ops: w=reg r=rm r=imm
END

# Code: VEX_Kshiftrq_kr_kr_imm8
INSTRUCTION: VEX.L0.66.0F3A.W1 31 /r ib | KSHIFTRQ k1, k2, imm8 | AVX512BW
	ops: w=reg r=rm r=imm
END

# Code: VEX_Kshiftlb_kr_kr_imm8
INSTRUCTION: VEX.L0.66.0F3A.W0 32 /r ib | KSHIFTLB k1, k2, imm8 | AVX512DQ
	ops: w=reg r=rm r=imm
END

# Code: VEX_Kshiftlw_kr_kr_imm8
INSTRUCTION: VEX.L0.66.0F3A.W1 32 /r ib | KSHIFTLW k1, k2, imm8 | AVX512F
	ops: w=reg r=rm r=imm
END

# Code: VEX_Kshiftld_kr_kr_imm8
INSTRUCTION: VEX.L0.66.0F3A.W0 33 /r ib | KSHIFTLD k1, k2, imm8 | AVX512BW
	ops: w=reg r=rm r=imm
END

# Code: VEX_Kshiftlq_kr_kr_imm8
INSTRUCTION: VEX.L0.66.0F3A.W1 33 /r ib | KSHIFTLQ k1, k2, imm8 | AVX512BW
	ops: w=reg r=rm r=imm
END

# Code: VEX_Vinserti128_ymm_ymm_xmmm128_imm8
INSTRUCTION: VEX.256.66.0F3A.W0 38 /r ib | VINSERTI128 ymm1, ymm2, xmm3/m128, imm8 | AVX2
	ops: w=reg r=vvvv r=rm r=imm | Int128
	masm: flags=force-size=default
END

# Code: EVEX_Vinserti32x4_ymm_k1z_ymm_xmmm128_imm8
INSTRUCTION: EVEX.256.66.0F3A.W0 38 /r ib | VINSERTI32X4 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8 | AVX512VL AVX512F | N16
	ops: w=reg r=vvvv r=rm r=imm | Packed128_UInt32
	masm: flags=force-size=default
END

# Code: EVEX_Vinserti32x4_zmm_k1z_zmm_xmmm128_imm8
INSTRUCTION: EVEX.512.66.0F3A.W0 38 /r ib | VINSERTI32X4 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8 | AVX512F | N16
	ops: wvmm=reg r=vvvv r=rm r=imm | Packed128_UInt32
	masm: flags=force-size=default
END

# Code: EVEX_Vinserti64x2_ymm_k1z_ymm_xmmm128_imm8
INSTRUCTION: EVEX.256.66.0F3A.W1 38 /r ib | VINSERTI64X2 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8 | AVX512VL AVX512DQ | N16
	ops: w=reg r=vvvv r=rm r=imm | Packed128_UInt64
	masm: flags=force-size=default
END

# Code: EVEX_Vinserti64x2_zmm_k1z_zmm_xmmm128_imm8
INSTRUCTION: EVEX.512.66.0F3A.W1 38 /r ib | VINSERTI64X2 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8 | AVX512DQ | N16
	ops: wvmm=reg r=vvvv r=rm r=imm | Packed128_UInt64
	masm: flags=force-size=default
END

# Code: VEX_Vextracti128_xmmm128_ymm_imm8
INSTRUCTION: VEX.256.66.0F3A.W0 39 /r ib | VEXTRACTI128 xmm1/m128, ymm2, imm8 | AVX2
	ops: w=rm r=reg r=imm | Int128
	masm: flags=force-size=default
END

# Code: EVEX_Vextracti32x4_xmmm128_k1z_ymm_imm8
INSTRUCTION: EVEX.256.66.0F3A.W0 39 /r ib | VEXTRACTI32X4 xmm1/m128 {k1}{z}, ymm2, imm8 | AVX512VL AVX512F | N16
	ops: w=rm r=reg r=imm | Packed128_UInt32
	masm: flags=force-size=default
END

# Code: EVEX_Vextracti32x4_xmmm128_k1z_zmm_imm8
INSTRUCTION: EVEX.512.66.0F3A.W0 39 /r ib | VEXTRACTI32X4 xmm1/m128 {k1}{z}, zmm2, imm8 | AVX512F | N16
	ops: w=rm r=reg r=imm | Packed128_UInt32
	masm: flags=force-size=default
END

# Code: EVEX_Vextracti64x2_xmmm128_k1z_ymm_imm8
INSTRUCTION: EVEX.256.66.0F3A.W1 39 /r ib | VEXTRACTI64X2 xmm1/m128 {k1}{z}, ymm2, imm8 | AVX512VL AVX512DQ | N16
	ops: w=rm r=reg r=imm | Packed128_UInt64
	masm: flags=force-size=default
END

# Code: EVEX_Vextracti64x2_xmmm128_k1z_zmm_imm8
INSTRUCTION: EVEX.512.66.0F3A.W1 39 /r ib | VEXTRACTI64X2 xmm1/m128 {k1}{z}, zmm2, imm8 | AVX512DQ | N16
	ops: w=rm r=reg r=imm | Packed128_UInt64
	masm: flags=force-size=default
END

# Code: EVEX_Vinserti32x8_zmm_k1z_zmm_ymmm256_imm8
INSTRUCTION: EVEX.512.66.0F3A.W0 3A /r ib | VINSERTI32X8 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8 | AVX512DQ | N32
	ops: wvmm=reg r=vvvv r=rm r=imm | Packed256_UInt32
	masm: flags=force-size=default
END

# Code: EVEX_Vinserti64x4_zmm_k1z_zmm_ymmm256_imm8
INSTRUCTION: EVEX.512.66.0F3A.W1 3A /r ib | VINSERTI64X4 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8 | AVX512F | N32
	ops: wvmm=reg r=vvvv r=rm r=imm | Packed256_UInt64
	masm: flags=force-size=default
END

# Code: EVEX_Vextracti32x8_ymmm256_k1z_zmm_imm8
INSTRUCTION: EVEX.512.66.0F3A.W0 3B /r ib | VEXTRACTI32X8 ymm1/m256 {k1}{z}, zmm2, imm8 | AVX512DQ | N32
	ops: w=rm r=reg r=imm | Packed256_UInt32
	masm: flags=force-size=default
END

# Code: EVEX_Vextracti64x4_ymmm256_k1z_zmm_imm8
INSTRUCTION: EVEX.512.66.0F3A.W1 3B /r ib | VEXTRACTI64X4 ymm1/m256 {k1}{z}, zmm2, imm8 | AVX512F | N32
	ops: w=rm r=reg r=imm | Packed256_UInt64
	masm: flags=force-size=default
END

# Code: EVEX_Vpcmpub_kr_k1_xmm_xmmm128_imm8
INSTRUCTION: EVEX.128.66.0F3A.W0 3E /r ib | VPCMPUB k1 {k2}, xmm2, xmm3/m128, imm8 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm r=imm | Packed128_UInt8
	flags: pseudo=vpcmpub implied-z
END

# Code: EVEX_Vpcmpub_kr_k1_ymm_ymmm256_imm8
INSTRUCTION: EVEX.256.66.0F3A.W0 3E /r ib | VPCMPUB k1 {k2}, ymm2, ymm3/m256, imm8 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm r=imm | Packed256_UInt8
	flags: pseudo=vpcmpub implied-z
END

# Code: EVEX_Vpcmpub_kr_k1_zmm_zmmm512_imm8
INSTRUCTION: EVEX.512.66.0F3A.W0 3E /r ib | VPCMPUB k1 {k2}, zmm2, zmm3/m512, imm8 | AVX512BW | N64
	ops: w=reg r=vvvv r=rm r=imm | Packed512_UInt8
	flags: pseudo=vpcmpub implied-z
END

# Code: EVEX_Vpcmpuw_kr_k1_xmm_xmmm128_imm8
INSTRUCTION: EVEX.128.66.0F3A.W1 3E /r ib | VPCMPUW k1 {k2}, xmm2, xmm3/m128, imm8 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm r=imm | Packed128_UInt16
	flags: pseudo=vpcmpuw implied-z
END

# Code: EVEX_Vpcmpuw_kr_k1_ymm_ymmm256_imm8
INSTRUCTION: EVEX.256.66.0F3A.W1 3E /r ib | VPCMPUW k1 {k2}, ymm2, ymm3/m256, imm8 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm r=imm | Packed256_UInt16
	flags: pseudo=vpcmpuw implied-z
END

# Code: EVEX_Vpcmpuw_kr_k1_zmm_zmmm512_imm8
INSTRUCTION: EVEX.512.66.0F3A.W1 3E /r ib | VPCMPUW k1 {k2}, zmm2, zmm3/m512, imm8 | AVX512BW | N64
	ops: w=reg r=vvvv r=rm r=imm | Packed512_UInt16
	flags: pseudo=vpcmpuw implied-z
END

# Code: EVEX_Vpcmpb_kr_k1_xmm_xmmm128_imm8
INSTRUCTION: EVEX.128.66.0F3A.W0 3F /r ib | VPCMPB k1 {k2}, xmm2, xmm3/m128, imm8 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm r=imm | Packed128_Int8
	flags: pseudo=vpcmpb implied-z
END

# Code: EVEX_Vpcmpb_kr_k1_ymm_ymmm256_imm8
INSTRUCTION: EVEX.256.66.0F3A.W0 3F /r ib | VPCMPB k1 {k2}, ymm2, ymm3/m256, imm8 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm r=imm | Packed256_Int8
	flags: pseudo=vpcmpb implied-z
END

# Code: EVEX_Vpcmpb_kr_k1_zmm_zmmm512_imm8
INSTRUCTION: EVEX.512.66.0F3A.W0 3F /r ib | VPCMPB k1 {k2}, zmm2, zmm3/m512, imm8 | AVX512BW | N64
	ops: w=reg r=vvvv r=rm r=imm | Packed512_Int8
	flags: pseudo=vpcmpb implied-z
END

# Code: EVEX_Vpcmpw_kr_k1_xmm_xmmm128_imm8
INSTRUCTION: EVEX.128.66.0F3A.W1 3F /r ib | VPCMPW k1 {k2}, xmm2, xmm3/m128, imm8 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm r=imm | Packed128_Int16
	flags: pseudo=vpcmpw implied-z
END

# Code: EVEX_Vpcmpw_kr_k1_ymm_ymmm256_imm8
INSTRUCTION: EVEX.256.66.0F3A.W1 3F /r ib | VPCMPW k1 {k2}, ymm2, ymm3/m256, imm8 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm r=imm | Packed256_Int16
	flags: pseudo=vpcmpw implied-z
END

# Code: EVEX_Vpcmpw_kr_k1_zmm_zmmm512_imm8
INSTRUCTION: EVEX.512.66.0F3A.W1 3F /r ib | VPCMPW k1 {k2}, zmm2, zmm3/m512, imm8 | AVX512BW | N64
	ops: w=reg r=vvvv r=rm r=imm | Packed512_Int16
	flags: pseudo=vpcmpw implied-z
END

# Code: Dpps_xmm_xmmm128_imm8
INSTRUCTION: 66 0F 3A 40 /r ib | DPPS xmm1, xmm2/m128, imm8 | SSE4_1
	ops: rw=reg r=rm r=imm | Packed128_Float32
END

# Code: VEX_Vdpps_xmm_xmm_xmmm128_imm8
INSTRUCTION: VEX.128.66.0F3A.WIG 40 /r ib | VDPPS xmm1, xmm2, xmm3/m128, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | Packed128_Float32
END

# Code: VEX_Vdpps_ymm_ymm_ymmm256_imm8
INSTRUCTION: VEX.256.66.0F3A.WIG 40 /r ib | VDPPS ymm1, ymm2, ymm3/m256, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | Packed256_Float32
END

# Code: Dppd_xmm_xmmm128_imm8
INSTRUCTION: 66 0F 3A 41 /r ib | DPPD xmm1, xmm2/m128, imm8 | SSE4_1
	ops: rw=reg r=rm r=imm | Packed128_Float64
END

# Code: VEX_Vdppd_xmm_xmm_xmmm128_imm8
INSTRUCTION: VEX.128.66.0F3A.WIG 41 /r ib | VDPPD xmm1, xmm2, xmm3/m128, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | Packed128_Float64
END

# Code: Mpsadbw_xmm_xmmm128_imm8
INSTRUCTION: 66 0F 3A 42 /r ib | MPSADBW xmm1, xmm2/m128, imm8 | SSE4_1
	ops: rw=reg r=rm r=imm | Packed128_UInt8
END

# Code: VEX_Vmpsadbw_xmm_xmm_xmmm128_imm8
INSTRUCTION: VEX.128.66.0F3A.WIG 42 /r ib | VMPSADBW xmm1, xmm2, xmm3/m128, imm8 | AVX
	ops: w=reg r=vvvv r=rm r=imm | Packed128_UInt8
END

# Code: VEX_Vmpsadbw_ymm_ymm_ymmm256_imm8
INSTRUCTION: VEX.256.66.0F3A.WIG 42 /r ib | VMPSADBW ymm1, ymm2, ymm3/m256, imm8 | AVX2
	ops: w=reg r=vvvv r=rm r=imm | Packed256_UInt8
END

# Code: EVEX_Vdbpsadbw_xmm_k1z_xmm_xmmm128_imm8
INSTRUCTION: EVEX.128.66.0F3A.W0 42 /r ib | VDBPSADBW xmm1 {k1}{z}, xmm2, xmm3/m128, imm8 | AVX512VL AVX512BW | N16
	ops: w=reg r=vvvv r=rm r=imm | Packed128_UInt8
END

# Code: EVEX_Vdbpsadbw_ymm_k1z_ymm_ymmm256_imm8
INSTRUCTION: EVEX.256.66.0F3A.W0 42 /r ib | VDBPSADBW ymm1 {k1}{z}, ymm2, ymm3/m256, imm8 | AVX512VL AVX512BW | N32
	ops: w=reg r=vvvv r=rm r=imm | Packed256_UInt8
END

# Code: EVEX_Vdbpsadbw_zmm_k1z_zmm_zmmm512_imm8
INSTRUCTION: EVEX.512.66.0F3A.W0 42 /r ib | VDBPSADBW zmm1 {k1}{z}, zmm2, zmm3/m512, imm8 | AVX512BW | N64
	ops: wvmm=reg r=vvvv r=rm r=imm | Packed512_UInt8
END

# Code: EVEX_Vshufi32x4_ymm_k1z_ymm_ymmm256b32_imm8
INSTRUCTION: EVEX.256.66.0F3A.W0 43 /r ib | VSHUFI32X4 ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst, imm8 | AVX512VL AVX512F | N32b4
	ops: w=reg r=vvvv r=rm r=imm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vshufi32x4_zmm_k1z_zmm_zmmm512b32_imm8
INSTRUCTION: EVEX.512.66.0F3A.W0 43 /r ib | VSHUFI32X4 zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst, imm8 | AVX512F | N64b4
	ops: wvmm=reg r=vvvv r=rm r=imm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: EVEX_Vshufi64x2_ymm_k1z_ymm_ymmm256b64_imm8
INSTRUCTION: EVEX.256.66.0F3A.W1 43 /r ib | VSHUFI64X2 ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst, imm8 | AVX512VL AVX512F | N32b8
	ops: w=reg r=vvvv r=rm r=imm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vshufi64x2_zmm_k1z_zmm_zmmm512b64_imm8
INSTRUCTION: EVEX.512.66.0F3A.W1 43 /r ib | VSHUFI64X2 zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst, imm8 | AVX512F | N64b8
	ops: wvmm=reg r=vvvv r=rm r=imm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: Pclmulqdq_xmm_xmmm128_imm8
INSTRUCTION: 66 0F 3A 44 /r ib | PCLMULQDQ xmm1, xmm2/m128, imm8 | PCLMULQDQ
	ops: rw=reg r=rm r=imm | Packed128_UInt64
	flags: pseudo=pclmulqdq
END

# Code: VEX_Vpclmulqdq_xmm_xmm_xmmm128_imm8
INSTRUCTION: VEX.128.66.0F3A.WIG 44 /r ib | VPCLMULQDQ xmm1, xmm2, xmm3/m128, imm8 | PCLMULQDQ AVX
	ops: w=reg r=vvvv r=rm r=imm | Packed128_UInt64
	flags: pseudo=vpclmulqdq
END

# Code: VEX_Vpclmulqdq_ymm_ymm_ymmm256_imm8
INSTRUCTION: VEX.256.66.0F3A.WIG 44 /r ib | VPCLMULQDQ ymm1, ymm2, ymm3/m256, imm8 | VPCLMULQDQ
	ops: w=reg r=vvvv r=rm r=imm | Packed256_UInt64
	flags: pseudo=vpclmulqdq
END

# Code: EVEX_Vpclmulqdq_xmm_xmm_xmmm128_imm8
INSTRUCTION: EVEX.128.66.0F3A.WIG 44 /r ib | VPCLMULQDQ xmm1, xmm2, xmm3/m128, imm8 | AVX512VL VPCLMULQDQ | N16
	ops: w=reg r=vvvv r=rm r=imm | Packed128_UInt64
	flags: pseudo=vpclmulqdq
END

# Code: EVEX_Vpclmulqdq_ymm_ymm_ymmm256_imm8
INSTRUCTION: EVEX.256.66.0F3A.WIG 44 /r ib | VPCLMULQDQ ymm1, ymm2, ymm3/m256, imm8 | AVX512VL VPCLMULQDQ | N32
	ops: w=reg r=vvvv r=rm r=imm | Packed256_UInt64
	flags: pseudo=vpclmulqdq
END

# Code: EVEX_Vpclmulqdq_zmm_zmm_zmmm512_imm8
INSTRUCTION: EVEX.512.66.0F3A.WIG 44 /r ib | VPCLMULQDQ zmm1, zmm2, zmm3/m512, imm8 | AVX512F VPCLMULQDQ | N64
	ops: w=reg r=vvvv r=rm r=imm | Packed512_UInt64
	flags: pseudo=vpclmulqdq
END

# Code: VEX_Vperm2i128_ymm_ymm_ymmm256_imm8
INSTRUCTION: VEX.256.66.0F3A.W0 46 /r ib | VPERM2I128 ymm1, ymm2, ymm3/m256, imm8 | AVX2
	ops: w=reg r=vvvv r=rm r=imm | Packed256_UInt128
END

# Code: VEX_Vpermil2ps_xmm_xmm_xmmm128_xmm_imm4
INSTRUCTION: VEX.128.66.0F3A.W0 48 /r /is5 | VPERMIL2PS xmm1, xmm2, xmm3/m128, xmm4, imm4 | XOP
	ops: w=reg r=vvvv r=rm r=is r=imm | Packed128_Float32
END

# Code: VEX_Vpermil2ps_ymm_ymm_ymmm256_ymm_imm4
INSTRUCTION: VEX.256.66.0F3A.W0 48 /r /is5 | VPERMIL2PS ymm1, ymm2, ymm3/m256, ymm4, imm4 | XOP
	ops: w=reg r=vvvv r=rm r=is r=imm | Packed256_Float32
END

# Code: VEX_Vpermil2ps_xmm_xmm_xmm_xmmm128_imm4
INSTRUCTION: VEX.128.66.0F3A.W1 48 /r /is5 | VPERMIL2PS xmm1, xmm2, xmm3, xmm4/m128, imm4 | XOP
	ops: w=reg r=vvvv r=is r=rm r=imm | Packed128_Float32
END

# Code: VEX_Vpermil2ps_ymm_ymm_ymm_ymmm256_imm4
INSTRUCTION: VEX.256.66.0F3A.W1 48 /r /is5 | VPERMIL2PS ymm1, ymm2, ymm3, ymm4/m256, imm4 | XOP
	ops: w=reg r=vvvv r=is r=rm r=imm | Packed256_Float32
END

# Code: VEX_Vpermil2pd_xmm_xmm_xmmm128_xmm_imm4
INSTRUCTION: VEX.128.66.0F3A.W0 49 /r /is5 | VPERMIL2PD xmm1, xmm2, xmm3/m128, xmm4, imm4 | XOP
	ops: w=reg r=vvvv r=rm r=is r=imm | Packed128_Float64
END

# Code: VEX_Vpermil2pd_ymm_ymm_ymmm256_ymm_imm4
INSTRUCTION: VEX.256.66.0F3A.W0 49 /r /is5 | VPERMIL2PD ymm1, ymm2, ymm3/m256, ymm4, imm4 | XOP
	ops: w=reg r=vvvv r=rm r=is r=imm | Packed256_Float64
END

# Code: VEX_Vpermil2pd_xmm_xmm_xmm_xmmm128_imm4
INSTRUCTION: VEX.128.66.0F3A.W1 49 /r /is5 | VPERMIL2PD xmm1, xmm2, xmm3, xmm4/m128, imm4 | XOP
	ops: w=reg r=vvvv r=is r=rm r=imm | Packed128_Float64
END

# Code: VEX_Vpermil2pd_ymm_ymm_ymm_ymmm256_imm4
INSTRUCTION: VEX.256.66.0F3A.W1 49 /r /is5 | VPERMIL2PD ymm1, ymm2, ymm3, ymm4/m256, imm4 | XOP
	ops: w=reg r=vvvv r=is r=rm r=imm | Packed256_Float64
END

# Code: VEX_Vblendvps_xmm_xmm_xmmm128_xmm
INSTRUCTION: VEX.128.66.0F3A.W0 4A /r /is4 | VBLENDVPS xmm1, xmm2, xmm3/m128, xmm4 | AVX
	ops: w=reg r=vvvv r=rm r=is | Packed128_Float32
END

# Code: VEX_Vblendvps_ymm_ymm_ymmm256_ymm
INSTRUCTION: VEX.256.66.0F3A.W0 4A /r /is4 | VBLENDVPS ymm1, ymm2, ymm3/m256, ymm4 | AVX
	ops: w=reg r=vvvv r=rm r=is | Packed256_Float32
END

# Code: VEX_Vblendvpd_xmm_xmm_xmmm128_xmm
INSTRUCTION: VEX.128.66.0F3A.W0 4B /r /is4 | VBLENDVPD xmm1, xmm2, xmm3/m128, xmm4 | AVX
	ops: w=reg r=vvvv r=rm r=is | Packed128_Float64
END

# Code: VEX_Vblendvpd_ymm_ymm_ymmm256_ymm
INSTRUCTION: VEX.256.66.0F3A.W0 4B /r /is4 | VBLENDVPD ymm1, ymm2, ymm3/m256, ymm4 | AVX
	ops: w=reg r=vvvv r=rm r=is | Packed256_Float64
END

# Code: VEX_Vpblendvb_xmm_xmm_xmmm128_xmm
INSTRUCTION: VEX.128.66.0F3A.W0 4C /r /is4 | VPBLENDVB xmm1, xmm2, xmm3/m128, xmm4 | AVX
	ops: w=reg r=vvvv r=rm r=is | Packed128_UInt8
END

# Code: VEX_Vpblendvb_ymm_ymm_ymmm256_ymm
INSTRUCTION: VEX.256.66.0F3A.W0 4C /r /is4 | VPBLENDVB ymm1, ymm2, ymm3/m256, ymm4 | AVX2
	ops: w=reg r=vvvv r=rm r=is | Packed256_UInt8
END

# Code: EVEX_Vrangeps_xmm_k1z_xmm_xmmm128b32_imm8
INSTRUCTION: EVEX.128.66.0F3A.W0 50 /r ib | VRANGEPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst, imm8 | AVX512VL AVX512DQ | N16b4
	ops: w=reg r=vvvv r=rm r=imm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vrangeps_ymm_k1z_ymm_ymmm256b32_imm8
INSTRUCTION: EVEX.256.66.0F3A.W0 50 /r ib | VRANGEPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst, imm8 | AVX512VL AVX512DQ | N32b4
	ops: w=reg r=vvvv r=rm r=imm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vrangeps_zmm_k1z_zmm_zmmm512b32_imm8_sae
INSTRUCTION: EVEX.512.66.0F3A.W0 50 /r ib | VRANGEPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{sae}, imm8 | AVX512DQ | N64b4
	ops: wvmm=reg r=vvvv r=rm r=imm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vrangepd_xmm_k1z_xmm_xmmm128b64_imm8
INSTRUCTION: EVEX.128.66.0F3A.W1 50 /r ib | VRANGEPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst, imm8 | AVX512VL AVX512DQ | N16b8
	ops: w=reg r=vvvv r=rm r=imm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vrangepd_ymm_k1z_ymm_ymmm256b64_imm8
INSTRUCTION: EVEX.256.66.0F3A.W1 50 /r ib | VRANGEPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst, imm8 | AVX512VL AVX512DQ | N32b8
	ops: w=reg r=vvvv r=rm r=imm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vrangepd_zmm_k1z_zmm_zmmm512b64_imm8_sae
INSTRUCTION: EVEX.512.66.0F3A.W1 50 /r ib | VRANGEPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{sae}, imm8 | AVX512DQ | N64b8
	ops: wvmm=reg r=vvvv r=rm r=imm | Packed512_Float64 Broadcast512_Float64
END

# Code: EVEX_Vrangess_xmm_k1z_xmm_xmmm32_imm8_sae
INSTRUCTION: EVEX.LIG.66.0F3A.W0 51 /r ib | VRANGESS xmm1 {k1}{z}, xmm2, xmm3/m32{sae}, imm8 | AVX512DQ | N4
	ops: w=reg r=vvvv r=rm r=imm | Float32
END

# Code: EVEX_Vrangesd_xmm_k1z_xmm_xmmm64_imm8_sae
INSTRUCTION: EVEX.LIG.66.0F3A.W1 51 /r ib | VRANGESD xmm1 {k1}{z}, xmm2, xmm3/m64{sae}, imm8 | AVX512DQ | N8
	ops: w=reg r=vvvv r=rm r=imm | Float64
END

# Code: EVEX_Vfixupimmps_xmm_k1z_xmm_xmmm128b32_imm8
INSTRUCTION: EVEX.128.66.0F3A.W0 54 /r ib | VFIXUPIMMPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst, imm8 | AVX512VL AVX512F | N16b4
	ops: rw=reg r=vvvv r=rm r=imm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vfixupimmps_ymm_k1z_ymm_ymmm256b32_imm8
INSTRUCTION: EVEX.256.66.0F3A.W0 54 /r ib | VFIXUPIMMPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst, imm8 | AVX512VL AVX512F | N32b4
	ops: rw=reg r=vvvv r=rm r=imm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vfixupimmps_zmm_k1z_zmm_zmmm512b32_imm8_sae
INSTRUCTION: EVEX.512.66.0F3A.W0 54 /r ib | VFIXUPIMMPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{sae}, imm8 | AVX512F | N64b4
	ops: rwvmm=reg r=vvvv r=rm r=imm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vfixupimmpd_xmm_k1z_xmm_xmmm128b64_imm8
INSTRUCTION: EVEX.128.66.0F3A.W1 54 /r ib | VFIXUPIMMPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst, imm8 | AVX512VL AVX512F | N16b8
	ops: rw=reg r=vvvv r=rm r=imm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vfixupimmpd_ymm_k1z_ymm_ymmm256b64_imm8
INSTRUCTION: EVEX.256.66.0F3A.W1 54 /r ib | VFIXUPIMMPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst, imm8 | AVX512VL AVX512F | N32b8
	ops: rw=reg r=vvvv r=rm r=imm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vfixupimmpd_zmm_k1z_zmm_zmmm512b64_imm8_sae
INSTRUCTION: EVEX.512.66.0F3A.W1 54 /r ib | VFIXUPIMMPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{sae}, imm8 | AVX512F | N64b8
	ops: rwvmm=reg r=vvvv r=rm r=imm | Packed512_Float64 Broadcast512_Float64
END

# Code: EVEX_Vfixupimmss_xmm_k1z_xmm_xmmm32_imm8_sae
INSTRUCTION: EVEX.LIG.66.0F3A.W0 55 /r ib | VFIXUPIMMSS xmm1 {k1}{z}, xmm2, xmm3/m32{sae}, imm8 | AVX512F | N4
	ops: rw=reg r=vvvv r=rm r=imm | Float32
END

# Code: EVEX_Vfixupimmsd_xmm_k1z_xmm_xmmm64_imm8_sae
INSTRUCTION: EVEX.LIG.66.0F3A.W1 55 /r ib | VFIXUPIMMSD xmm1 {k1}{z}, xmm2, xmm3/m64{sae}, imm8 | AVX512F | N8
	ops: rw=reg r=vvvv r=rm r=imm | Float64
END

# Code: EVEX_Vreduceps_xmm_k1z_xmmm128b32_imm8
INSTRUCTION: EVEX.128.66.0F3A.W0 56 /r ib | VREDUCEPS xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8 | AVX512VL AVX512DQ | N16b4
	ops: w=reg r=rm r=imm | Packed128_Float32 Broadcast128_Float32
END

# Code: EVEX_Vreduceps_ymm_k1z_ymmm256b32_imm8
INSTRUCTION: EVEX.256.66.0F3A.W0 56 /r ib | VREDUCEPS ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8 | AVX512VL AVX512DQ | N32b4
	ops: w=reg r=rm r=imm | Packed256_Float32 Broadcast256_Float32
END

# Code: EVEX_Vreduceps_zmm_k1z_zmmm512b32_imm8_sae
INSTRUCTION: EVEX.512.66.0F3A.W0 56 /r ib | VREDUCEPS zmm1 {k1}{z}, zmm2/m512/m32bcst{sae}, imm8 | AVX512DQ | N64b4
	ops: wvmm=reg r=rm r=imm | Packed512_Float32 Broadcast512_Float32
END

# Code: EVEX_Vreducepd_xmm_k1z_xmmm128b64_imm8
INSTRUCTION: EVEX.128.66.0F3A.W1 56 /r ib | VREDUCEPD xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8 | AVX512VL AVX512DQ | N16b8
	ops: w=reg r=rm r=imm | Packed128_Float64 Broadcast128_Float64
END

# Code: EVEX_Vreducepd_ymm_k1z_ymmm256b64_imm8
INSTRUCTION: EVEX.256.66.0F3A.W1 56 /r ib | VREDUCEPD ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8 | AVX512VL AVX512DQ | N32b8
	ops: w=reg r=rm r=imm | Packed256_Float64 Broadcast256_Float64
END

# Code: EVEX_Vreducepd_zmm_k1z_zmmm512b64_imm8_sae
INSTRUCTION: EVEX.512.66.0F3A.W1 56 /r ib | VREDUCEPD zmm1 {k1}{z}, zmm2/m512/m64bcst{sae}, imm8 | AVX512DQ | N64b8
	ops: wvmm=reg r=rm r=imm | Packed512_Float64 Broadcast512_Float64
END

# Code: EVEX_Vreducess_xmm_k1z_xmm_xmmm32_imm8_sae
INSTRUCTION: EVEX.LIG.66.0F3A.W0 57 /r ib | VREDUCESS xmm1 {k1}{z}, xmm2, xmm3/m32{sae}, imm8 | AVX512DQ | N4
	ops: w=reg r=vvvv r=rm r=imm | Float32
END

# Code: EVEX_Vreducesd_xmm_k1z_xmm_xmmm64_imm8_sae
INSTRUCTION: EVEX.LIG.66.0F3A.W1 57 /r ib | VREDUCESD xmm1 {k1}{z}, xmm2, xmm3/m64{sae}, imm8 | AVX512DQ | N8
	ops: w=reg r=vvvv r=rm r=imm | Float64
END

# Code: VEX_Vfmaddsubps_xmm_xmm_xmmm128_xmm
INSTRUCTION: VEX.128.66.0F3A.W0 5C /r /is4 | VFMADDSUBPS xmm1, xmm2, xmm3/m128, xmm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Packed128_Float32
END

# Code: VEX_Vfmaddsubps_ymm_ymm_ymmm256_ymm
INSTRUCTION: VEX.256.66.0F3A.W0 5C /r /is4 | VFMADDSUBPS ymm1, ymm2, ymm3/m256, ymm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Packed256_Float32
END

# Code: VEX_Vfmaddsubps_xmm_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F3A.W1 5C /r /is4 | VFMADDSUBPS xmm1, xmm2, xmm3, xmm4/m128 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Packed128_Float32
END

# Code: VEX_Vfmaddsubps_ymm_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F3A.W1 5C /r /is4 | VFMADDSUBPS ymm1, ymm2, ymm3, ymm4/m256 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Packed256_Float32
END

# Code: VEX_Vfmaddsubpd_xmm_xmm_xmmm128_xmm
INSTRUCTION: VEX.128.66.0F3A.W0 5D /r /is4 | VFMADDSUBPD xmm1, xmm2, xmm3/m128, xmm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Packed128_Float64
END

# Code: VEX_Vfmaddsubpd_ymm_ymm_ymmm256_ymm
INSTRUCTION: VEX.256.66.0F3A.W0 5D /r /is4 | VFMADDSUBPD ymm1, ymm2, ymm3/m256, ymm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Packed256_Float64
END

# Code: VEX_Vfmaddsubpd_xmm_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F3A.W1 5D /r /is4 | VFMADDSUBPD xmm1, xmm2, xmm3, xmm4/m128 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Packed128_Float64
END

# Code: VEX_Vfmaddsubpd_ymm_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F3A.W1 5D /r /is4 | VFMADDSUBPD ymm1, ymm2, ymm3, ymm4/m256 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Packed256_Float64
END

# Code: VEX_Vfmsubaddps_xmm_xmm_xmmm128_xmm
INSTRUCTION: VEX.128.66.0F3A.W0 5E /r /is4 | VFMSUBADDPS xmm1, xmm2, xmm3/m128, xmm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Packed128_Float32
END

# Code: VEX_Vfmsubaddps_ymm_ymm_ymmm256_ymm
INSTRUCTION: VEX.256.66.0F3A.W0 5E /r /is4 | VFMSUBADDPS ymm1, ymm2, ymm3/m256, ymm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Packed256_Float32
END

# Code: VEX_Vfmsubaddps_xmm_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F3A.W1 5E /r /is4 | VFMSUBADDPS xmm1, xmm2, xmm3, xmm4/m128 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Packed128_Float32
END

# Code: VEX_Vfmsubaddps_ymm_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F3A.W1 5E /r /is4 | VFMSUBADDPS ymm1, ymm2, ymm3, ymm4/m256 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Packed256_Float32
END

# Code: VEX_Vfmsubaddpd_xmm_xmm_xmmm128_xmm
INSTRUCTION: VEX.128.66.0F3A.W0 5F /r /is4 | VFMSUBADDPD xmm1, xmm2, xmm3/m128, xmm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Packed128_Float64
END

# Code: VEX_Vfmsubaddpd_ymm_ymm_ymmm256_ymm
INSTRUCTION: VEX.256.66.0F3A.W0 5F /r /is4 | VFMSUBADDPD ymm1, ymm2, ymm3/m256, ymm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Packed256_Float64
END

# Code: VEX_Vfmsubaddpd_xmm_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F3A.W1 5F /r /is4 | VFMSUBADDPD xmm1, xmm2, xmm3, xmm4/m128 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Packed128_Float64
END

# Code: VEX_Vfmsubaddpd_ymm_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F3A.W1 5F /r /is4 | VFMSUBADDPD ymm1, ymm2, ymm3, ymm4/m256 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Packed256_Float64
END

# Code: Pcmpestrm_xmm_xmmm128_imm8
INSTRUCTION: 66 0F 3A 60 /r ib | PCMPESTRM xmm1, xmm2/m128, imm8 | SSE4_2
	ops: r=reg r=rm r=imm | Packed128_UInt8
	implied: r=eax;edx w=xmm0
	rflags: w=oszc 0=ap
END

# Code: Pcmpestrm64_xmm_xmmm128_imm8
INSTRUCTION: 66 o64 0F 3A 60 /r ib | PCMPESTRM64 xmm1, xmm2/m128, imm8 | SSE4_2
	ops: r=reg r=rm r=imm | Packed128_UInt8
	implied: r=rax;rdx w=xmm0
	rflags: w=oszc 0=ap
	flags: 64
	gas: mnemonic=pcmpestrm flags=force-suffix suffix=q
END

# Code: VEX_Vpcmpestrm_xmm_xmmm128_imm8
INSTRUCTION: VEX.128.66.0F3A.W0 60 /r ib | VPCMPESTRM xmm1, xmm2/m128, imm8 | AVX
	ops: r=reg r=rm r=imm | Packed128_UInt8
	implied: r=eax;edx w=xmm0
	rflags: w=oszc 0=ap
	flags: wig32
END

# Code: VEX_Vpcmpestrm64_xmm_xmmm128_imm8
INSTRUCTION: VEX.128.66.0F3A.W1 60 /r ib | VPCMPESTRM64 xmm1, xmm2/m128, imm8 | AVX
	ops: r=reg r=rm r=imm | Packed128_UInt8
	implied: r=rax;rdx w=xmm0
	rflags: w=oszc 0=ap
	flags: 64
	gas: mnemonic=vpcmpestrm flags=force-suffix suffix=q
END

# Code: Pcmpestri_xmm_xmmm128_imm8
INSTRUCTION: 66 0F 3A 61 /r ib | PCMPESTRI xmm1, xmm2/m128, imm8 | SSE4_2
	ops: r=reg r=rm r=imm | Packed128_UInt8
	implied: r=eax;edx w=ecx
	rflags: w=oszc 0=ap
END

# Code: Pcmpestri64_xmm_xmmm128_imm8
INSTRUCTION: 66 o64 0F 3A 61 /r ib | PCMPESTRI64 xmm1, xmm2/m128, imm8 | SSE4_2
	ops: r=reg r=rm r=imm | Packed128_UInt8
	implied: r=rax;rdx w=ecx
	rflags: w=oszc 0=ap
	flags: 64
	gas: mnemonic=pcmpestri flags=force-suffix suffix=q
END

# Code: VEX_Vpcmpestri_xmm_xmmm128_imm8
INSTRUCTION: VEX.128.66.0F3A.W0 61 /r ib | VPCMPESTRI xmm1, xmm2/m128, imm8 | AVX
	ops: r=reg r=rm r=imm | Packed128_UInt8
	implied: r=eax;edx w=ecx
	rflags: w=oszc 0=ap
	flags: wig32
END

# Code: VEX_Vpcmpestri64_xmm_xmmm128_imm8
INSTRUCTION: VEX.128.66.0F3A.W1 61 /r ib | VPCMPESTRI64 xmm1, xmm2/m128, imm8 | AVX
	ops: r=reg r=rm r=imm | Packed128_UInt8
	implied: r=rax;rdx w=ecx
	rflags: w=oszc 0=ap
	flags: 64
	gas: mnemonic=vpcmpestri flags=force-suffix suffix=q
END

# Code: Pcmpistrm_xmm_xmmm128_imm8
INSTRUCTION: 66 0F 3A 62 /r ib | PCMPISTRM xmm1, xmm2/m128, imm8 | SSE4_2
	ops: r=reg r=rm r=imm | Packed128_UInt8
	implied: w=xmm0
	rflags: w=oszc 0=ap
END

# Code: VEX_Vpcmpistrm_xmm_xmmm128_imm8
INSTRUCTION: VEX.128.66.0F3A.WIG 62 /r ib | VPCMPISTRM xmm1, xmm2/m128, imm8 | AVX
	ops: r=reg r=rm r=imm | Packed128_UInt8
	implied: w=xmm0
	rflags: w=oszc 0=ap
END

# Code: Pcmpistri_xmm_xmmm128_imm8
INSTRUCTION: 66 0F 3A 63 /r ib | PCMPISTRI xmm1, xmm2/m128, imm8 | SSE4_2
	ops: r=reg r=rm r=imm | Packed128_UInt8
	implied: w=ecx
	rflags: w=oszc 0=ap
END

# Code: VEX_Vpcmpistri_xmm_xmmm128_imm8
INSTRUCTION: VEX.128.66.0F3A.WIG 63 /r ib | VPCMPISTRI xmm1, xmm2/m128, imm8 | AVX
	ops: r=reg r=rm r=imm | Packed128_UInt8
	implied: w=ecx
	rflags: w=oszc 0=ap
END

# Code: EVEX_Vfpclassps_kr_k1_xmmm128b32_imm8
INSTRUCTION: EVEX.128.66.0F3A.W0 66 /r ib | VFPCLASSPS k2 {k1}, xmm2/m128/m32bcst, imm8 | AVX512VL AVX512DQ | N16b4
	ops: w=reg r=rm r=imm | Packed128_Float32 Broadcast128_Float32
	flags: implied-z
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=x
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vfpclassps_kr_k1_ymmm256b32_imm8
INSTRUCTION: EVEX.256.66.0F3A.W0 66 /r ib | VFPCLASSPS k2 {k1}, ymm2/m256/m32bcst, imm8 | AVX512VL AVX512DQ | N32b4
	ops: w=reg r=rm r=imm | Packed256_Float32 Broadcast256_Float32
	flags: implied-z
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=y
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vfpclassps_kr_k1_zmmm512b32_imm8
INSTRUCTION: EVEX.512.66.0F3A.W0 66 /r ib | VFPCLASSPS k2 {k1}, zmm2/m512/m32bcst, imm8 | AVX512DQ | N64b4
	ops: w=reg r=rm r=imm | Packed512_Float32 Broadcast512_Float32
	flags: implied-z
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=z
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vfpclasspd_kr_k1_xmmm128b64_imm8
INSTRUCTION: EVEX.128.66.0F3A.W1 66 /r ib | VFPCLASSPD k2 {k1}, xmm2/m128/m64bcst, imm8 | AVX512VL AVX512DQ | N16b8
	ops: w=reg r=rm r=imm | Packed128_Float64 Broadcast128_Float64
	flags: implied-z
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=x
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vfpclasspd_kr_k1_ymmm256b64_imm8
INSTRUCTION: EVEX.256.66.0F3A.W1 66 /r ib | VFPCLASSPD k2 {k1}, ymm2/m256/m64bcst, imm8 | AVX512VL AVX512DQ | N32b8
	ops: w=reg r=rm r=imm | Packed256_Float64 Broadcast256_Float64
	flags: implied-z
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=y
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vfpclasspd_kr_k1_zmmm512b64_imm8
INSTRUCTION: EVEX.512.66.0F3A.W1 66 /r ib | VFPCLASSPD k2 {k1}, zmm2/m512/m64bcst, imm8 | AVX512DQ | N64b8
	ops: w=reg r=rm r=imm | Packed512_Float64 Broadcast512_Float64
	flags: implied-z
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=z
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vfpclassss_kr_k1_xmmm32_imm8
INSTRUCTION: EVEX.LIG.66.0F3A.W0 67 /r ib | VFPCLASSSS k2 {k1}, xmm2/m32, imm8 | AVX512DQ | N4
	ops: w=reg r=rm r=imm | Float32
	flags: implied-z
	masm: flags=force-size=default
END

# Code: EVEX_Vfpclasssd_kr_k1_xmmm64_imm8
INSTRUCTION: EVEX.LIG.66.0F3A.W1 67 /r ib | VFPCLASSSD k2 {k1}, xmm2/m64, imm8 | AVX512DQ | N8
	ops: w=reg r=rm r=imm | Float64
	flags: implied-z
	masm: flags=force-size=default
END

# Code: VEX_Vfmaddps_xmm_xmm_xmmm128_xmm
INSTRUCTION: VEX.128.66.0F3A.W0 68 /r /is4 | VFMADDPS xmm1, xmm2, xmm3/m128, xmm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Packed128_Float32
END

# Code: VEX_Vfmaddps_ymm_ymm_ymmm256_ymm
INSTRUCTION: VEX.256.66.0F3A.W0 68 /r /is4 | VFMADDPS ymm1, ymm2, ymm3/m256, ymm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Packed256_Float32
END

# Code: VEX_Vfmaddps_xmm_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F3A.W1 68 /r /is4 | VFMADDPS xmm1, xmm2, xmm3, xmm4/m128 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Packed128_Float32
END

# Code: VEX_Vfmaddps_ymm_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F3A.W1 68 /r /is4 | VFMADDPS ymm1, ymm2, ymm3, ymm4/m256 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Packed256_Float32
END

# Code: VEX_Vfmaddpd_xmm_xmm_xmmm128_xmm
INSTRUCTION: VEX.128.66.0F3A.W0 69 /r /is4 | VFMADDPD xmm1, xmm2, xmm3/m128, xmm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Packed128_Float64
END

# Code: VEX_Vfmaddpd_ymm_ymm_ymmm256_ymm
INSTRUCTION: VEX.256.66.0F3A.W0 69 /r /is4 | VFMADDPD ymm1, ymm2, ymm3/m256, ymm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Packed256_Float64
END

# Code: VEX_Vfmaddpd_xmm_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F3A.W1 69 /r /is4 | VFMADDPD xmm1, xmm2, xmm3, xmm4/m128 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Packed128_Float64
END

# Code: VEX_Vfmaddpd_ymm_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F3A.W1 69 /r /is4 | VFMADDPD ymm1, ymm2, ymm3, ymm4/m256 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Packed256_Float64
END

# Code: VEX_Vfmaddss_xmm_xmm_xmmm32_xmm
INSTRUCTION: VEX.LIG.66.0F3A.W0 6A /r /is4 | VFMADDSS xmm1, xmm2, xmm3/m32, xmm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Float32
END

# Code: VEX_Vfmaddss_xmm_xmm_xmm_xmmm32
INSTRUCTION: VEX.LIG.66.0F3A.W1 6A /r /is4 | VFMADDSS xmm1, xmm2, xmm3, xmm4/m32 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Float32
END

# Code: VEX_Vfmaddsd_xmm_xmm_xmmm64_xmm
INSTRUCTION: VEX.LIG.66.0F3A.W0 6B /r /is4 | VFMADDSD xmm1, xmm2, xmm3/m64, xmm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Float64
END

# Code: VEX_Vfmaddsd_xmm_xmm_xmm_xmmm64
INSTRUCTION: VEX.LIG.66.0F3A.W1 6B /r /is4 | VFMADDSD xmm1, xmm2, xmm3, xmm4/m64 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Float64
END

# Code: VEX_Vfmsubps_xmm_xmm_xmmm128_xmm
INSTRUCTION: VEX.128.66.0F3A.W0 6C /r /is4 | VFMSUBPS xmm1, xmm2, xmm3/m128, xmm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Packed128_Float32
END

# Code: VEX_Vfmsubps_ymm_ymm_ymmm256_ymm
INSTRUCTION: VEX.256.66.0F3A.W0 6C /r /is4 | VFMSUBPS ymm1, ymm2, ymm3/m256, ymm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Packed256_Float32
END

# Code: VEX_Vfmsubps_xmm_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F3A.W1 6C /r /is4 | VFMSUBPS xmm1, xmm2, xmm3, xmm4/m128 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Packed128_Float32
END

# Code: VEX_Vfmsubps_ymm_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F3A.W1 6C /r /is4 | VFMSUBPS ymm1, ymm2, ymm3, ymm4/m256 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Packed256_Float32
END

# Code: VEX_Vfmsubpd_xmm_xmm_xmmm128_xmm
INSTRUCTION: VEX.128.66.0F3A.W0 6D /r /is4 | VFMSUBPD xmm1, xmm2, xmm3/m128, xmm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Packed128_Float64
END

# Code: VEX_Vfmsubpd_ymm_ymm_ymmm256_ymm
INSTRUCTION: VEX.256.66.0F3A.W0 6D /r /is4 | VFMSUBPD ymm1, ymm2, ymm3/m256, ymm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Packed256_Float64
END

# Code: VEX_Vfmsubpd_xmm_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F3A.W1 6D /r /is4 | VFMSUBPD xmm1, xmm2, xmm3, xmm4/m128 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Packed128_Float64
END

# Code: VEX_Vfmsubpd_ymm_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F3A.W1 6D /r /is4 | VFMSUBPD ymm1, ymm2, ymm3, ymm4/m256 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Packed256_Float64
END

# Code: VEX_Vfmsubss_xmm_xmm_xmmm32_xmm
INSTRUCTION: VEX.LIG.66.0F3A.W0 6E /r /is4 | VFMSUBSS xmm1, xmm2, xmm3/m32, xmm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Float32
END

# Code: VEX_Vfmsubss_xmm_xmm_xmm_xmmm32
INSTRUCTION: VEX.LIG.66.0F3A.W1 6E /r /is4 | VFMSUBSS xmm1, xmm2, xmm3, xmm4/m32 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Float32
END

# Code: VEX_Vfmsubsd_xmm_xmm_xmmm64_xmm
INSTRUCTION: VEX.LIG.66.0F3A.W0 6F /r /is4 | VFMSUBSD xmm1, xmm2, xmm3/m64, xmm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Float64
END

# Code: VEX_Vfmsubsd_xmm_xmm_xmm_xmmm64
INSTRUCTION: VEX.LIG.66.0F3A.W1 6F /r /is4 | VFMSUBSD xmm1, xmm2, xmm3, xmm4/m64 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Float64
END

# Code: EVEX_Vpshldw_xmm_k1z_xmm_xmmm128_imm8
INSTRUCTION: EVEX.128.66.0F3A.W1 70 /r ib | VPSHLDW xmm1 {k1}{z}, xmm2, xmm3/m128, imm8 | AVX512VL AVX512_VBMI2 | N16
	ops: w=reg r=vvvv r=rm r=imm | Packed128_UInt16
END

# Code: EVEX_Vpshldw_ymm_k1z_ymm_ymmm256_imm8
INSTRUCTION: EVEX.256.66.0F3A.W1 70 /r ib | VPSHLDW ymm1 {k1}{z}, ymm2, ymm3/m256, imm8 | AVX512VL AVX512_VBMI2 | N32
	ops: w=reg r=vvvv r=rm r=imm | Packed256_UInt16
END

# Code: EVEX_Vpshldw_zmm_k1z_zmm_zmmm512_imm8
INSTRUCTION: EVEX.512.66.0F3A.W1 70 /r ib | VPSHLDW zmm1 {k1}{z}, zmm2, zmm3/m512, imm8 | AVX512_VBMI2 | N64
	ops: wvmm=reg r=vvvv r=rm r=imm | Packed512_UInt16
END

# Code: EVEX_Vpshldd_xmm_k1z_xmm_xmmm128b32_imm8
INSTRUCTION: EVEX.128.66.0F3A.W0 71 /r ib | VPSHLDD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst, imm8 | AVX512VL AVX512_VBMI2 | N16b4
	ops: w=reg r=vvvv r=rm r=imm | Packed128_UInt32 Broadcast128_UInt32
END

# Code: EVEX_Vpshldd_ymm_k1z_ymm_ymmm256b32_imm8
INSTRUCTION: EVEX.256.66.0F3A.W0 71 /r ib | VPSHLDD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst, imm8 | AVX512VL AVX512_VBMI2 | N32b4
	ops: w=reg r=vvvv r=rm r=imm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vpshldd_zmm_k1z_zmm_zmmm512b32_imm8
INSTRUCTION: EVEX.512.66.0F3A.W0 71 /r ib | VPSHLDD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst, imm8 | AVX512_VBMI2 | N64b4
	ops: wvmm=reg r=vvvv r=rm r=imm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: EVEX_Vpshldq_xmm_k1z_xmm_xmmm128b64_imm8
INSTRUCTION: EVEX.128.66.0F3A.W1 71 /r ib | VPSHLDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst, imm8 | AVX512VL AVX512_VBMI2 | N16b8
	ops: w=reg r=vvvv r=rm r=imm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Vpshldq_ymm_k1z_ymm_ymmm256b64_imm8
INSTRUCTION: EVEX.256.66.0F3A.W1 71 /r ib | VPSHLDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst, imm8 | AVX512VL AVX512_VBMI2 | N32b8
	ops: w=reg r=vvvv r=rm r=imm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vpshldq_zmm_k1z_zmm_zmmm512b64_imm8
INSTRUCTION: EVEX.512.66.0F3A.W1 71 /r ib | VPSHLDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst, imm8 | AVX512_VBMI2 | N64b8
	ops: wvmm=reg r=vvvv r=rm r=imm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: EVEX_Vpshrdw_xmm_k1z_xmm_xmmm128_imm8
INSTRUCTION: EVEX.128.66.0F3A.W1 72 /r ib | VPSHRDW xmm1 {k1}{z}, xmm2, xmm3/m128, imm8 | AVX512VL AVX512_VBMI2 | N16
	ops: w=reg r=vvvv r=rm r=imm | Packed128_UInt16
END

# Code: EVEX_Vpshrdw_ymm_k1z_ymm_ymmm256_imm8
INSTRUCTION: EVEX.256.66.0F3A.W1 72 /r ib | VPSHRDW ymm1 {k1}{z}, ymm2, ymm3/m256, imm8 | AVX512VL AVX512_VBMI2 | N32
	ops: w=reg r=vvvv r=rm r=imm | Packed256_UInt16
END

# Code: EVEX_Vpshrdw_zmm_k1z_zmm_zmmm512_imm8
INSTRUCTION: EVEX.512.66.0F3A.W1 72 /r ib | VPSHRDW zmm1 {k1}{z}, zmm2, zmm3/m512, imm8 | AVX512_VBMI2 | N64
	ops: wvmm=reg r=vvvv r=rm r=imm | Packed512_UInt16
END

# Code: EVEX_Vpshrdd_xmm_k1z_xmm_xmmm128b32_imm8
INSTRUCTION: EVEX.128.66.0F3A.W0 73 /r ib | VPSHRDD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst, imm8 | AVX512VL AVX512_VBMI2 | N16b4
	ops: w=reg r=vvvv r=rm r=imm | Packed128_UInt32 Broadcast128_UInt32
END

# Code: EVEX_Vpshrdd_ymm_k1z_ymm_ymmm256b32_imm8
INSTRUCTION: EVEX.256.66.0F3A.W0 73 /r ib | VPSHRDD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst, imm8 | AVX512VL AVX512_VBMI2 | N32b4
	ops: w=reg r=vvvv r=rm r=imm | Packed256_UInt32 Broadcast256_UInt32
END

# Code: EVEX_Vpshrdd_zmm_k1z_zmm_zmmm512b32_imm8
INSTRUCTION: EVEX.512.66.0F3A.W0 73 /r ib | VPSHRDD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst, imm8 | AVX512_VBMI2 | N64b4
	ops: wvmm=reg r=vvvv r=rm r=imm | Packed512_UInt32 Broadcast512_UInt32
END

# Code: EVEX_Vpshrdq_xmm_k1z_xmm_xmmm128b64_imm8
INSTRUCTION: EVEX.128.66.0F3A.W1 73 /r ib | VPSHRDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst, imm8 | AVX512VL AVX512_VBMI2 | N16b8
	ops: w=reg r=vvvv r=rm r=imm | Packed128_UInt64 Broadcast128_UInt64
END

# Code: EVEX_Vpshrdq_ymm_k1z_ymm_ymmm256b64_imm8
INSTRUCTION: EVEX.256.66.0F3A.W1 73 /r ib | VPSHRDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst, imm8 | AVX512VL AVX512_VBMI2 | N32b8
	ops: w=reg r=vvvv r=rm r=imm | Packed256_UInt64 Broadcast256_UInt64
END

# Code: EVEX_Vpshrdq_zmm_k1z_zmm_zmmm512b64_imm8
INSTRUCTION: EVEX.512.66.0F3A.W1 73 /r ib | VPSHRDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst, imm8 | AVX512_VBMI2 | N64b8
	ops: wvmm=reg r=vvvv r=rm r=imm | Packed512_UInt64 Broadcast512_UInt64
END

# Code: VEX_Vfnmaddps_xmm_xmm_xmmm128_xmm
INSTRUCTION: VEX.128.66.0F3A.W0 78 /r /is4 | VFNMADDPS xmm1, xmm2, xmm3/m128, xmm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Packed128_Float32
END

# Code: VEX_Vfnmaddps_ymm_ymm_ymmm256_ymm
INSTRUCTION: VEX.256.66.0F3A.W0 78 /r /is4 | VFNMADDPS ymm1, ymm2, ymm3/m256, ymm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Packed256_Float32
END

# Code: VEX_Vfnmaddps_xmm_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F3A.W1 78 /r /is4 | VFNMADDPS xmm1, xmm2, xmm3, xmm4/m128 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Packed128_Float32
END

# Code: VEX_Vfnmaddps_ymm_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F3A.W1 78 /r /is4 | VFNMADDPS ymm1, ymm2, ymm3, ymm4/m256 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Packed256_Float32
END

# Code: VEX_Vfnmaddpd_xmm_xmm_xmmm128_xmm
INSTRUCTION: VEX.128.66.0F3A.W0 79 /r /is4 | VFNMADDPD xmm1, xmm2, xmm3/m128, xmm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Packed128_Float64
END

# Code: VEX_Vfnmaddpd_ymm_ymm_ymmm256_ymm
INSTRUCTION: VEX.256.66.0F3A.W0 79 /r /is4 | VFNMADDPD ymm1, ymm2, ymm3/m256, ymm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Packed256_Float64
END

# Code: VEX_Vfnmaddpd_xmm_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F3A.W1 79 /r /is4 | VFNMADDPD xmm1, xmm2, xmm3, xmm4/m128 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Packed128_Float64
END

# Code: VEX_Vfnmaddpd_ymm_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F3A.W1 79 /r /is4 | VFNMADDPD ymm1, ymm2, ymm3, ymm4/m256 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Packed256_Float64
END

# Code: VEX_Vfnmaddss_xmm_xmm_xmmm32_xmm
INSTRUCTION: VEX.LIG.66.0F3A.W0 7A /r /is4 | VFNMADDSS xmm1, xmm2, xmm3/m32, xmm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Float32
END

# Code: VEX_Vfnmaddss_xmm_xmm_xmm_xmmm32
INSTRUCTION: VEX.LIG.66.0F3A.W1 7A /r /is4 | VFNMADDSS xmm1, xmm2, xmm3, xmm4/m32 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Float32
END

# Code: VEX_Vfnmaddsd_xmm_xmm_xmmm64_xmm
INSTRUCTION: VEX.LIG.66.0F3A.W0 7B /r /is4 | VFNMADDSD xmm1, xmm2, xmm3/m64, xmm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Float64
END

# Code: VEX_Vfnmaddsd_xmm_xmm_xmm_xmmm64
INSTRUCTION: VEX.LIG.66.0F3A.W1 7B /r /is4 | VFNMADDSD xmm1, xmm2, xmm3, xmm4/m64 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Float64
END

# Code: VEX_Vfnmsubps_xmm_xmm_xmmm128_xmm
INSTRUCTION: VEX.128.66.0F3A.W0 7C /r /is4 | VFNMSUBPS xmm1, xmm2, xmm3/m128, xmm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Packed128_Float32
END

# Code: VEX_Vfnmsubps_ymm_ymm_ymmm256_ymm
INSTRUCTION: VEX.256.66.0F3A.W0 7C /r /is4 | VFNMSUBPS ymm1, ymm2, ymm3/m256, ymm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Packed256_Float32
END

# Code: VEX_Vfnmsubps_xmm_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F3A.W1 7C /r /is4 | VFNMSUBPS xmm1, xmm2, xmm3, xmm4/m128 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Packed128_Float32
END

# Code: VEX_Vfnmsubps_ymm_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F3A.W1 7C /r /is4 | VFNMSUBPS ymm1, ymm2, ymm3, ymm4/m256 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Packed256_Float32
END

# Code: VEX_Vfnmsubpd_xmm_xmm_xmmm128_xmm
INSTRUCTION: VEX.128.66.0F3A.W0 7D /r /is4 | VFNMSUBPD xmm1, xmm2, xmm3/m128, xmm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Packed128_Float64
END

# Code: VEX_Vfnmsubpd_ymm_ymm_ymmm256_ymm
INSTRUCTION: VEX.256.66.0F3A.W0 7D /r /is4 | VFNMSUBPD ymm1, ymm2, ymm3/m256, ymm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Packed256_Float64
END

# Code: VEX_Vfnmsubpd_xmm_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F3A.W1 7D /r /is4 | VFNMSUBPD xmm1, xmm2, xmm3, xmm4/m128 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Packed128_Float64
END

# Code: VEX_Vfnmsubpd_ymm_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F3A.W1 7D /r /is4 | VFNMSUBPD ymm1, ymm2, ymm3, ymm4/m256 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Packed256_Float64
END

# Code: VEX_Vfnmsubss_xmm_xmm_xmmm32_xmm
INSTRUCTION: VEX.LIG.66.0F3A.W0 7E /r /is4 | VFNMSUBSS xmm1, xmm2, xmm3/m32, xmm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Float32
END

# Code: VEX_Vfnmsubss_xmm_xmm_xmm_xmmm32
INSTRUCTION: VEX.LIG.66.0F3A.W1 7E /r /is4 | VFNMSUBSS xmm1, xmm2, xmm3, xmm4/m32 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Float32
END

# Code: VEX_Vfnmsubsd_xmm_xmm_xmmm64_xmm
INSTRUCTION: VEX.LIG.66.0F3A.W0 7F /r /is4 | VFNMSUBSD xmm1, xmm2, xmm3/m64, xmm4 | FMA4
	ops: w=reg r=vvvv r=rm r=is | Float64
END

# Code: VEX_Vfnmsubsd_xmm_xmm_xmm_xmmm64
INSTRUCTION: VEX.LIG.66.0F3A.W1 7F /r /is4 | VFNMSUBSD xmm1, xmm2, xmm3, xmm4/m64 | FMA4
	ops: w=reg r=vvvv r=is r=rm | Float64
END

# Code: Sha1rnds4_xmm_xmmm128_imm8
INSTRUCTION: NP 0F 3A CC /r ib | SHA1RNDS4 xmm1, xmm2/m128, imm8 | SHA
	ops: rw=reg r=rm r=imm | Packed128_UInt32
END

# Code: Gf2p8affineqb_xmm_xmmm128_imm8
INSTRUCTION: 66 0F 3A CE /r ib | GF2P8AFFINEQB xmm1, xmm2/m128, imm8 | GFNI
	ops: rw=reg r=rm r=imm | Packed128_UInt8
END

# Code: VEX_Vgf2p8affineqb_xmm_xmm_xmmm128_imm8
INSTRUCTION: VEX.128.66.0F3A.W1 CE /r ib | VGF2P8AFFINEQB xmm1, xmm2, xmm3/m128, imm8 | AVX GFNI
	ops: w=reg r=vvvv r=rm r=imm | Packed128_UInt8
END

# Code: VEX_Vgf2p8affineqb_ymm_ymm_ymmm256_imm8
INSTRUCTION: VEX.256.66.0F3A.W1 CE /r ib | VGF2P8AFFINEQB ymm1, ymm2, ymm3/m256, imm8 | AVX GFNI
	ops: w=reg r=vvvv r=rm r=imm | Packed256_UInt8
END

# Code: EVEX_Vgf2p8affineqb_xmm_k1z_xmm_xmmm128b64_imm8
INSTRUCTION: EVEX.128.66.0F3A.W1 CE /r ib | VGF2P8AFFINEQB xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst, imm8 | AVX512VL GFNI | N16b8
	ops: w=reg r=vvvv r=rm r=imm | Packed128_UInt8 Broadcast128_UInt64
END

# Code: EVEX_Vgf2p8affineqb_ymm_k1z_ymm_ymmm256b64_imm8
INSTRUCTION: EVEX.256.66.0F3A.W1 CE /r ib | VGF2P8AFFINEQB ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst, imm8 | AVX512VL GFNI | N32b8
	ops: w=reg r=vvvv r=rm r=imm | Packed256_UInt8 Broadcast256_UInt64
END

# Code: EVEX_Vgf2p8affineqb_zmm_k1z_zmm_zmmm512b64_imm8
INSTRUCTION: EVEX.512.66.0F3A.W1 CE /r ib | VGF2P8AFFINEQB zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst, imm8 | AVX512F GFNI | N64b8
	ops: wvmm=reg r=vvvv r=rm r=imm | Packed512_UInt8 Broadcast512_UInt64
END

# Code: Gf2p8affineinvqb_xmm_xmmm128_imm8
INSTRUCTION: 66 0F 3A CF /r ib | GF2P8AFFINEINVQB xmm1, xmm2/m128, imm8 | GFNI
	ops: rw=reg r=rm r=imm | Packed128_UInt8
END

# Code: VEX_Vgf2p8affineinvqb_xmm_xmm_xmmm128_imm8
INSTRUCTION: VEX.128.66.0F3A.W1 CF /r ib | VGF2P8AFFINEINVQB xmm1, xmm2, xmm3/m128, imm8 | AVX GFNI
	ops: w=reg r=vvvv r=rm r=imm | Packed128_UInt8
END

# Code: VEX_Vgf2p8affineinvqb_ymm_ymm_ymmm256_imm8
INSTRUCTION: VEX.256.66.0F3A.W1 CF /r ib | VGF2P8AFFINEINVQB ymm1, ymm2, ymm3/m256, imm8 | AVX GFNI
	ops: w=reg r=vvvv r=rm r=imm | Packed256_UInt8
END

# Code: EVEX_Vgf2p8affineinvqb_xmm_k1z_xmm_xmmm128b64_imm8
INSTRUCTION: EVEX.128.66.0F3A.W1 CF /r ib | VGF2P8AFFINEINVQB xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst, imm8 | AVX512VL GFNI | N16b8
	ops: w=reg r=vvvv r=rm r=imm | Packed128_UInt8 Broadcast128_UInt64
END

# Code: EVEX_Vgf2p8affineinvqb_ymm_k1z_ymm_ymmm256b64_imm8
INSTRUCTION: EVEX.256.66.0F3A.W1 CF /r ib | VGF2P8AFFINEINVQB ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst, imm8 | AVX512VL GFNI | N32b8
	ops: w=reg r=vvvv r=rm r=imm | Packed256_UInt8 Broadcast256_UInt64
END

# Code: EVEX_Vgf2p8affineinvqb_zmm_k1z_zmm_zmmm512b64_imm8
INSTRUCTION: EVEX.512.66.0F3A.W1 CF /r ib | VGF2P8AFFINEINVQB zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst, imm8 | AVX512F GFNI | N64b8
	ops: wvmm=reg r=vvvv r=rm r=imm | Packed512_UInt8 Broadcast512_UInt64
END

# Code: Aeskeygenassist_xmm_xmmm128_imm8
INSTRUCTION: 66 0F 3A DF /r ib | AESKEYGENASSIST xmm1, xmm2/m128, imm8 | AES
	ops: w=reg r=rm r=imm | UInt128
END

# Code: VEX_Vaeskeygenassist_xmm_xmmm128_imm8
INSTRUCTION: VEX.128.66.0F3A.WIG DF /r ib | VAESKEYGENASSIST xmm1, xmm2/m128, imm8 | AES AVX
	ops: w=reg r=rm r=imm | UInt128
END

# Code: VEX_Rorx_r32_rm32_imm8
INSTRUCTION: VEX.LZ.F2.0F3A.W0 F0 /r ib | RORX r32, r/m32, imm8 | BMI2
	ops: w=reg r=rm r=imm | UInt32
	flags: wig32
	gas: suffix=l
END

# Code: VEX_Rorx_r64_rm64_imm8
INSTRUCTION: VEX.LZ.F2.0F3A.W1 F0 /r ib | RORX r64, r/m64, imm8 | BMI2
	ops: w=reg r=rm r=imm | UInt64
	flags: 64
	gas: suffix=q
END

# Code: XOP_Vpmacssww_xmm_xmm_xmmm128_xmm
INSTRUCTION: XOP.128.X8.W0 85 /r /is4 | VPMACSSWW xmm1, xmm2, xmm3/m128, xmm4 | XOP
	ops: w=reg r=vvvv r=rm r=is | Packed128_Int16
END

# Code: XOP_Vpmacsswd_xmm_xmm_xmmm128_xmm
INSTRUCTION: XOP.128.X8.W0 86 /r /is4 | VPMACSSWD xmm1, xmm2, xmm3/m128, xmm4 | XOP
	ops: w=reg r=vvvv r=rm r=is | Packed128_Int16
END

# Code: XOP_Vpmacssdql_xmm_xmm_xmmm128_xmm
INSTRUCTION: XOP.128.X8.W0 87 /r /is4 | VPMACSSDQL xmm1, xmm2, xmm3/m128, xmm4 | XOP
	ops: w=reg r=vvvv r=rm r=is | Packed128_Int32
END

# Code: XOP_Vpmacssdd_xmm_xmm_xmmm128_xmm
INSTRUCTION: XOP.128.X8.W0 8E /r /is4 | VPMACSSDD xmm1, xmm2, xmm3/m128, xmm4 | XOP
	ops: w=reg r=vvvv r=rm r=is | Packed128_Int32
END

# Code: XOP_Vpmacssdqh_xmm_xmm_xmmm128_xmm
INSTRUCTION: XOP.128.X8.W0 8F /r /is4 | VPMACSSDQH xmm1, xmm2, xmm3/m128, xmm4 | XOP
	ops: w=reg r=vvvv r=rm r=is | Packed128_Int32
END

# Code: XOP_Vpmacsww_xmm_xmm_xmmm128_xmm
INSTRUCTION: XOP.128.X8.W0 95 /r /is4 | VPMACSWW xmm1, xmm2, xmm3/m128, xmm4 | XOP
	ops: w=reg r=vvvv r=rm r=is | Packed128_Int16
END

# Code: XOP_Vpmacswd_xmm_xmm_xmmm128_xmm
INSTRUCTION: XOP.128.X8.W0 96 /r /is4 | VPMACSWD xmm1, xmm2, xmm3/m128, xmm4 | XOP
	ops: w=reg r=vvvv r=rm r=is | Packed128_Int16
END

# Code: XOP_Vpmacsdql_xmm_xmm_xmmm128_xmm
INSTRUCTION: XOP.128.X8.W0 97 /r /is4 | VPMACSDQL xmm1, xmm2, xmm3/m128, xmm4 | XOP
	ops: w=reg r=vvvv r=rm r=is | Packed128_Int32
END

# Code: XOP_Vpmacsdd_xmm_xmm_xmmm128_xmm
INSTRUCTION: XOP.128.X8.W0 9E /r /is4 | VPMACSDD xmm1, xmm2, xmm3/m128, xmm4 | XOP
	ops: w=reg r=vvvv r=rm r=is | Packed128_Int32
END

# Code: XOP_Vpmacsdqh_xmm_xmm_xmmm128_xmm
INSTRUCTION: XOP.128.X8.W0 9F /r /is4 | VPMACSDQH xmm1, xmm2, xmm3/m128, xmm4 | XOP
	ops: w=reg r=vvvv r=rm r=is | Packed128_Int32
END

# Code: XOP_Vpcmov_xmm_xmm_xmmm128_xmm
INSTRUCTION: XOP.128.X8.W0 A2 /r /is4 | VPCMOV xmm1, xmm2, xmm3/m128, xmm4 | XOP
	ops: w=reg r=vvvv r=rm r=is | UInt128
END

# Code: XOP_Vpcmov_ymm_ymm_ymmm256_ymm
INSTRUCTION: XOP.256.X8.W0 A2 /r /is4 | VPCMOV ymm1, ymm2, ymm3/m256, ymm4 | XOP
	ops: w=reg r=vvvv r=rm r=is | UInt256
END

# Code: XOP_Vpcmov_xmm_xmm_xmm_xmmm128
INSTRUCTION: XOP.128.X8.W1 A2 /r /is4 | VPCMOV xmm1, xmm2, xmm3, xmm4/m128 | XOP
	ops: w=reg r=vvvv r=is r=rm | UInt128
END

# Code: XOP_Vpcmov_ymm_ymm_ymm_ymmm256
INSTRUCTION: XOP.256.X8.W1 A2 /r /is4 | VPCMOV ymm1, ymm2, ymm3, ymm4/m256 | XOP
	ops: w=reg r=vvvv r=is r=rm | UInt256
END

# Code: XOP_Vpperm_xmm_xmm_xmmm128_xmm
INSTRUCTION: XOP.128.X8.W0 A3 /r /is4 | VPPERM xmm1, xmm2, xmm3/m128, xmm4 | XOP
	ops: w=reg r=vvvv r=rm r=is | Packed128_UInt8
END

# Code: XOP_Vpperm_xmm_xmm_xmm_xmmm128
INSTRUCTION: XOP.128.X8.W1 A3 /r /is4 | VPPERM xmm1, xmm2, xmm3, xmm4/m128 | XOP
	ops: w=reg r=vvvv r=is r=rm | Packed128_UInt8
END

# Code: XOP_Vpmadcsswd_xmm_xmm_xmmm128_xmm
INSTRUCTION: XOP.128.X8.W0 A6 /r /is4 | VPMADCSSWD xmm1, xmm2, xmm3/m128, xmm4 | XOP
	ops: w=reg r=vvvv r=rm r=is | Packed128_Int16
END

# Code: XOP_Vpmadcswd_xmm_xmm_xmmm128_xmm
INSTRUCTION: XOP.128.X8.W0 B6 /r /is4 | VPMADCSWD xmm1, xmm2, xmm3/m128, xmm4 | XOP
	ops: w=reg r=vvvv r=rm r=is | Packed128_Int16
END

# Code: XOP_Vprotb_xmm_xmmm128_imm8
INSTRUCTION: XOP.128.X8.W0 C0 /r ib | VPROTB xmm1, xmm2/m128, imm8 | XOP
	ops: w=reg r=rm r=imm | Packed128_UInt8
END

# Code: XOP_Vprotw_xmm_xmmm128_imm8
INSTRUCTION: XOP.128.X8.W0 C1 /r ib | VPROTW xmm1, xmm2/m128, imm8 | XOP
	ops: w=reg r=rm r=imm | Packed128_UInt16
END

# Code: XOP_Vprotd_xmm_xmmm128_imm8
INSTRUCTION: XOP.128.X8.W0 C2 /r ib | VPROTD xmm1, xmm2/m128, imm8 | XOP
	ops: w=reg r=rm r=imm | Packed128_UInt32
END

# Code: XOP_Vprotq_xmm_xmmm128_imm8
INSTRUCTION: XOP.128.X8.W0 C3 /r ib | VPROTQ xmm1, xmm2/m128, imm8 | XOP
	ops: w=reg r=rm r=imm | Packed128_UInt64
END

# Code: XOP_Vpcomb_xmm_xmm_xmmm128_imm8
INSTRUCTION: XOP.128.X8.W0 CC /r ib | VPCOMB xmm1, xmm2, xmm3/m128, imm8 | XOP
	ops: w=reg r=vvvv r=rm r=imm | Packed128_Int8
	flags: pseudo=vpcomb
END

# Code: XOP_Vpcomw_xmm_xmm_xmmm128_imm8
INSTRUCTION: XOP.128.X8.W0 CD /r ib | VPCOMW xmm1, xmm2, xmm3/m128, imm8 | XOP
	ops: w=reg r=vvvv r=rm r=imm | Packed128_Int16
	flags: pseudo=vpcomw
END

# Code: XOP_Vpcomd_xmm_xmm_xmmm128_imm8
INSTRUCTION: XOP.128.X8.W0 CE /r ib | VPCOMD xmm1, xmm2, xmm3/m128, imm8 | XOP
	ops: w=reg r=vvvv r=rm r=imm | Packed128_Int32
	flags: pseudo=vpcomd
END

# Code: XOP_Vpcomq_xmm_xmm_xmmm128_imm8
INSTRUCTION: XOP.128.X8.W0 CF /r ib | VPCOMQ xmm1, xmm2, xmm3/m128, imm8 | XOP
	ops: w=reg r=vvvv r=rm r=imm | Packed128_Int64
	flags: pseudo=vpcomq
END

# Code: XOP_Vpcomub_xmm_xmm_xmmm128_imm8
INSTRUCTION: XOP.128.X8.W0 EC /r ib | VPCOMUB xmm1, xmm2, xmm3/m128, imm8 | XOP
	ops: w=reg r=vvvv r=rm r=imm | Packed128_UInt8
	flags: pseudo=vpcomub
END

# Code: XOP_Vpcomuw_xmm_xmm_xmmm128_imm8
INSTRUCTION: XOP.128.X8.W0 ED /r ib | VPCOMUW xmm1, xmm2, xmm3/m128, imm8 | XOP
	ops: w=reg r=vvvv r=rm r=imm | Packed128_UInt16
	flags: pseudo=vpcomuw
END

# Code: XOP_Vpcomud_xmm_xmm_xmmm128_imm8
INSTRUCTION: XOP.128.X8.W0 EE /r ib | VPCOMUD xmm1, xmm2, xmm3/m128, imm8 | XOP
	ops: w=reg r=vvvv r=rm r=imm | Packed128_UInt32
	flags: pseudo=vpcomud
END

# Code: XOP_Vpcomuq_xmm_xmm_xmmm128_imm8
INSTRUCTION: XOP.128.X8.W0 EF /r ib | VPCOMUQ xmm1, xmm2, xmm3/m128, imm8 | XOP
	ops: w=reg r=vvvv r=rm r=imm | Packed128_UInt64
	flags: pseudo=vpcomuq
END

# Code: XOP_Blcfill_r32_rm32
INSTRUCTION: XOP.L0.X9.W0 01 /1 | BLCFILL r32, r/m32 | TBM
	ops: w=vvvv r=rm | UInt32
	rflags: u=ap w=szc 0=o
	flags: wig32
	gas: suffix=l
END

# Code: XOP_Blcfill_r64_rm64
INSTRUCTION: XOP.L0.X9.W1 01 /1 | BLCFILL r64, r/m64 | TBM
	ops: w=vvvv r=rm | UInt64
	rflags: u=ap w=szc 0=o
	flags: 64
	gas: suffix=q
END

# Code: XOP_Blsfill_r32_rm32
INSTRUCTION: XOP.L0.X9.W0 01 /2 | BLSFILL r32, r/m32 | TBM
	ops: w=vvvv r=rm | UInt32
	rflags: u=ap w=szc 0=o
	flags: wig32
	gas: suffix=l
END

# Code: XOP_Blsfill_r64_rm64
INSTRUCTION: XOP.L0.X9.W1 01 /2 | BLSFILL r64, r/m64 | TBM
	ops: w=vvvv r=rm | UInt64
	rflags: u=ap w=szc 0=o
	flags: 64
	gas: suffix=q
END

# Code: XOP_Blcs_r32_rm32
INSTRUCTION: XOP.L0.X9.W0 01 /3 | BLCS r32, r/m32 | TBM
	ops: w=vvvv r=rm | UInt32
	rflags: u=ap w=szc 0=o
	flags: wig32
	gas: suffix=l
END

# Code: XOP_Blcs_r64_rm64
INSTRUCTION: XOP.L0.X9.W1 01 /3 | BLCS r64, r/m64 | TBM
	ops: w=vvvv r=rm | UInt64
	rflags: u=ap w=szc 0=o
	flags: 64
	gas: suffix=q
END

# Code: XOP_Tzmsk_r32_rm32
INSTRUCTION: XOP.L0.X9.W0 01 /4 | TZMSK r32, r/m32 | TBM
	ops: w=vvvv r=rm | UInt32
	rflags: u=ap w=szc 0=o
	flags: wig32
	gas: suffix=l
END

# Code: XOP_Tzmsk_r64_rm64
INSTRUCTION: XOP.L0.X9.W1 01 /4 | TZMSK r64, r/m64 | TBM
	ops: w=vvvv r=rm | UInt64
	rflags: u=ap w=szc 0=o
	flags: 64
	gas: suffix=q
END

# Code: XOP_Blcic_r32_rm32
INSTRUCTION: XOP.L0.X9.W0 01 /5 | BLCIC r32, r/m32 | TBM
	ops: w=vvvv r=rm | UInt32
	rflags: u=ap w=szc 0=o
	flags: wig32
	gas: suffix=l
END

# Code: XOP_Blcic_r64_rm64
INSTRUCTION: XOP.L0.X9.W1 01 /5 | BLCIC r64, r/m64 | TBM
	ops: w=vvvv r=rm | UInt64
	rflags: u=ap w=szc 0=o
	flags: 64
	gas: suffix=q
END

# Code: XOP_Blsic_r32_rm32
INSTRUCTION: XOP.L0.X9.W0 01 /6 | BLSIC r32, r/m32 | TBM
	ops: w=vvvv r=rm | UInt32
	rflags: u=ap w=szc 0=o
	flags: wig32
	gas: suffix=l
END

# Code: XOP_Blsic_r64_rm64
INSTRUCTION: XOP.L0.X9.W1 01 /6 | BLSIC r64, r/m64 | TBM
	ops: w=vvvv r=rm | UInt64
	rflags: u=ap w=szc 0=o
	flags: 64
	gas: suffix=q
END

# Code: XOP_T1mskc_r32_rm32
INSTRUCTION: XOP.L0.X9.W0 01 /7 | T1MSKC r32, r/m32 | TBM
	ops: w=vvvv r=rm | UInt32
	rflags: u=ap w=szc 0=o
	flags: wig32
	gas: suffix=l
END

# Code: XOP_T1mskc_r64_rm64
INSTRUCTION: XOP.L0.X9.W1 01 /7 | T1MSKC r64, r/m64 | TBM
	ops: w=vvvv r=rm | UInt64
	rflags: u=ap w=szc 0=o
	flags: 64
	gas: suffix=q
END

# Code: XOP_Blcmsk_r32_rm32
INSTRUCTION: XOP.L0.X9.W0 02 /1 | BLCMSK r32, r/m32 | TBM
	ops: w=vvvv r=rm | UInt32
	rflags: u=ap w=szc 0=o
	flags: wig32
	gas: suffix=l
END

# Code: XOP_Blcmsk_r64_rm64
INSTRUCTION: XOP.L0.X9.W1 02 /1 | BLCMSK r64, r/m64 | TBM
	ops: w=vvvv r=rm | UInt64
	rflags: u=ap w=szc 0=o
	flags: 64
	gas: suffix=q
END

# Code: XOP_Blci_r32_rm32
INSTRUCTION: XOP.L0.X9.W0 02 /6 | BLCI r32, r/m32 | TBM
	ops: w=vvvv r=rm | UInt32
	rflags: u=ap w=szc 0=o
	flags: wig32
	gas: suffix=l
END

# Code: XOP_Blci_r64_rm64
INSTRUCTION: XOP.L0.X9.W1 02 /6 | BLCI r64, r/m64 | TBM
	ops: w=vvvv r=rm | UInt64
	rflags: u=ap w=szc 0=o
	flags: 64
	gas: suffix=q
END

# Code: XOP_Llwpcb_r32
INSTRUCTION: XOP.L0.X9.W0 12 /0 | LLWPCB r32 | LWP
	ops: r=rm
	implied: r=[ds:op0-reg=Unknown]
	flags: wig32
END

# Code: XOP_Llwpcb_r64
INSTRUCTION: XOP.L0.X9.W1 12 /0 | LLWPCB r64 | LWP
	ops: r=rm
	implied: r=[ds:op0-reg=Unknown]
	flags: 64
END

# Code: XOP_Slwpcb_r32
INSTRUCTION: XOP.L0.X9.W0 12 /1 | SLWPCB r32 | LWP
	ops: w=rm
	flags: wig32
END

# Code: XOP_Slwpcb_r64
INSTRUCTION: XOP.L0.X9.W1 12 /1 | SLWPCB r64 | LWP
	ops: w=rm
	flags: 64
END

# Code: XOP_Vfrczps_xmm_xmmm128
INSTRUCTION: XOP.128.X9.W0 80 /r | VFRCZPS xmm1, xmm2/m128 | XOP
	ops: w=reg r=rm | Packed128_Float32
END

# Code: XOP_Vfrczps_ymm_ymmm256
INSTRUCTION: XOP.256.X9.W0 80 /r | VFRCZPS ymm1, ymm2/m256 | XOP
	ops: w=reg r=rm | Packed256_Float32
END

# Code: XOP_Vfrczpd_xmm_xmmm128
INSTRUCTION: XOP.128.X9.W0 81 /r | VFRCZPD xmm1, xmm2/m128 | XOP
	ops: w=reg r=rm | Packed128_Float64
END

# Code: XOP_Vfrczpd_ymm_ymmm256
INSTRUCTION: XOP.256.X9.W0 81 /r | VFRCZPD ymm1, ymm2/m256 | XOP
	ops: w=reg r=rm | Packed256_Float64
END

# Code: XOP_Vfrczss_xmm_xmmm32
INSTRUCTION: XOP.128.X9.W0 82 /r | VFRCZSS xmm1, xmm2/m32 | XOP
	ops: w=reg r=rm | Float32
END

# Code: XOP_Vfrczsd_xmm_xmmm64
INSTRUCTION: XOP.128.X9.W0 83 /r | VFRCZSD xmm1, xmm2/m64 | XOP
	ops: w=reg r=rm | Float64
END

# Code: XOP_Vprotb_xmm_xmmm128_xmm
INSTRUCTION: XOP.128.X9.W0 90 /r | VPROTB xmm1, xmm2/m128, xmm3 | XOP
	ops: w=reg r=rm r=vvvv | Packed128_UInt8
END

# Code: XOP_Vprotb_xmm_xmm_xmmm128
INSTRUCTION: XOP.128.X9.W1 90 /r | VPROTB xmm1, xmm2, xmm3/m128 | XOP
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
END

# Code: XOP_Vprotw_xmm_xmmm128_xmm
INSTRUCTION: XOP.128.X9.W0 91 /r | VPROTW xmm1, xmm2/m128, xmm3 | XOP
	ops: w=reg r=rm r=vvvv | Packed128_UInt16
END

# Code: XOP_Vprotw_xmm_xmm_xmmm128
INSTRUCTION: XOP.128.X9.W1 91 /r | VPROTW xmm1, xmm2, xmm3/m128 | XOP
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: XOP_Vprotd_xmm_xmmm128_xmm
INSTRUCTION: XOP.128.X9.W0 92 /r | VPROTD xmm1, xmm2/m128, xmm3 | XOP
	ops: w=reg r=rm r=vvvv | Packed128_UInt32
END

# Code: XOP_Vprotd_xmm_xmm_xmmm128
INSTRUCTION: XOP.128.X9.W1 92 /r | VPROTD xmm1, xmm2, xmm3/m128 | XOP
	ops: w=reg r=vvvv r=rm | Packed128_UInt32
END

# Code: XOP_Vprotq_xmm_xmmm128_xmm
INSTRUCTION: XOP.128.X9.W0 93 /r | VPROTQ xmm1, xmm2/m128, xmm3 | XOP
	ops: w=reg r=rm r=vvvv | Packed128_UInt64
END

# Code: XOP_Vprotq_xmm_xmm_xmmm128
INSTRUCTION: XOP.128.X9.W1 93 /r | VPROTQ xmm1, xmm2, xmm3/m128 | XOP
	ops: w=reg r=vvvv r=rm | Packed128_UInt64
END

# Code: XOP_Vpshlb_xmm_xmmm128_xmm
INSTRUCTION: XOP.128.X9.W0 94 /r | VPSHLB xmm1, xmm2/m128, xmm3 | XOP
	ops: w=reg r=rm r=vvvv | Packed128_UInt8
END

# Code: XOP_Vpshlb_xmm_xmm_xmmm128
INSTRUCTION: XOP.128.X9.W1 94 /r | VPSHLB xmm1, xmm2, xmm3/m128 | XOP
	ops: w=reg r=vvvv r=rm | Packed128_UInt8
END

# Code: XOP_Vpshlw_xmm_xmmm128_xmm
INSTRUCTION: XOP.128.X9.W0 95 /r | VPSHLW xmm1, xmm2/m128, xmm3 | XOP
	ops: w=reg r=rm r=vvvv | Packed128_UInt16
END

# Code: XOP_Vpshlw_xmm_xmm_xmmm128
INSTRUCTION: XOP.128.X9.W1 95 /r | VPSHLW xmm1, xmm2, xmm3/m128 | XOP
	ops: w=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: XOP_Vpshld_xmm_xmmm128_xmm
INSTRUCTION: XOP.128.X9.W0 96 /r | VPSHLD xmm1, xmm2/m128, xmm3 | XOP
	ops: w=reg r=rm r=vvvv | Packed128_UInt32
END

# Code: XOP_Vpshld_xmm_xmm_xmmm128
INSTRUCTION: XOP.128.X9.W1 96 /r | VPSHLD xmm1, xmm2, xmm3/m128 | XOP
	ops: w=reg r=vvvv r=rm | Packed128_UInt32
END

# Code: XOP_Vpshlq_xmm_xmmm128_xmm
INSTRUCTION: XOP.128.X9.W0 97 /r | VPSHLQ xmm1, xmm2/m128, xmm3 | XOP
	ops: w=reg r=rm r=vvvv | Packed128_UInt64
END

# Code: XOP_Vpshlq_xmm_xmm_xmmm128
INSTRUCTION: XOP.128.X9.W1 97 /r | VPSHLQ xmm1, xmm2, xmm3/m128 | XOP
	ops: w=reg r=vvvv r=rm | Packed128_UInt64
END

# Code: XOP_Vpshab_xmm_xmmm128_xmm
INSTRUCTION: XOP.128.X9.W0 98 /r | VPSHAB xmm1, xmm2/m128, xmm3 | XOP
	ops: w=reg r=rm r=vvvv | Packed128_Int8
END

# Code: XOP_Vpshab_xmm_xmm_xmmm128
INSTRUCTION: XOP.128.X9.W1 98 /r | VPSHAB xmm1, xmm2, xmm3/m128 | XOP
	ops: w=reg r=vvvv r=rm | Packed128_Int8
END

# Code: XOP_Vpshaw_xmm_xmmm128_xmm
INSTRUCTION: XOP.128.X9.W0 99 /r | VPSHAW xmm1, xmm2/m128, xmm3 | XOP
	ops: w=reg r=rm r=vvvv | Packed128_Int16
END

# Code: XOP_Vpshaw_xmm_xmm_xmmm128
INSTRUCTION: XOP.128.X9.W1 99 /r | VPSHAW xmm1, xmm2, xmm3/m128 | XOP
	ops: w=reg r=vvvv r=rm | Packed128_Int16
END

# Code: XOP_Vpshad_xmm_xmmm128_xmm
INSTRUCTION: XOP.128.X9.W0 9A /r | VPSHAD xmm1, xmm2/m128, xmm3 | XOP
	ops: w=reg r=rm r=vvvv | Packed128_Int32
END

# Code: XOP_Vpshad_xmm_xmm_xmmm128
INSTRUCTION: XOP.128.X9.W1 9A /r | VPSHAD xmm1, xmm2, xmm3/m128 | XOP
	ops: w=reg r=vvvv r=rm | Packed128_Int32
END

# Code: XOP_Vpshaq_xmm_xmmm128_xmm
INSTRUCTION: XOP.128.X9.W0 9B /r | VPSHAQ xmm1, xmm2/m128, xmm3 | XOP
	ops: w=reg r=rm r=vvvv | Packed128_Int64
END

# Code: XOP_Vpshaq_xmm_xmm_xmmm128
INSTRUCTION: XOP.128.X9.W1 9B /r | VPSHAQ xmm1, xmm2, xmm3/m128 | XOP
	ops: w=reg r=vvvv r=rm | Packed128_Int64
END

# Code: XOP_Vphaddbw_xmm_xmmm128
INSTRUCTION: XOP.128.X9.W0 C1 /r | VPHADDBW xmm1, xmm2/m128 | XOP
	ops: w=reg r=rm | Packed128_Int8
END

# Code: XOP_Vphaddbd_xmm_xmmm128
INSTRUCTION: XOP.128.X9.W0 C2 /r | VPHADDBD xmm1, xmm2/m128 | XOP
	ops: w=reg r=rm | Packed128_Int8
END

# Code: XOP_Vphaddbq_xmm_xmmm128
INSTRUCTION: XOP.128.X9.W0 C3 /r | VPHADDBQ xmm1, xmm2/m128 | XOP
	ops: w=reg r=rm | Packed128_Int8
END

# Code: XOP_Vphaddwd_xmm_xmmm128
INSTRUCTION: XOP.128.X9.W0 C6 /r | VPHADDWD xmm1, xmm2/m128 | XOP
	ops: w=reg r=rm | Packed128_Int16
END

# Code: XOP_Vphaddwq_xmm_xmmm128
INSTRUCTION: XOP.128.X9.W0 C7 /r | VPHADDWQ xmm1, xmm2/m128 | XOP
	ops: w=reg r=rm | Packed128_Int16
END

# Code: XOP_Vphadddq_xmm_xmmm128
INSTRUCTION: XOP.128.X9.W0 CB /r | VPHADDDQ xmm1, xmm2/m128 | XOP
	ops: w=reg r=rm | Packed128_Int32
END

# Code: XOP_Vphaddubw_xmm_xmmm128
INSTRUCTION: XOP.128.X9.W0 D1 /r | VPHADDUBW xmm1, xmm2/m128 | XOP
	ops: w=reg r=rm | Packed128_UInt8
END

# Code: XOP_Vphaddubd_xmm_xmmm128
INSTRUCTION: XOP.128.X9.W0 D2 /r | VPHADDUBD xmm1, xmm2/m128 | XOP
	ops: w=reg r=rm | Packed128_UInt8
END

# Code: XOP_Vphaddubq_xmm_xmmm128
INSTRUCTION: XOP.128.X9.W0 D3 /r | VPHADDUBQ xmm1, xmm2/m128 | XOP
	ops: w=reg r=rm | Packed128_UInt8
END

# Code: XOP_Vphadduwd_xmm_xmmm128
INSTRUCTION: XOP.128.X9.W0 D6 /r | VPHADDUWD xmm1, xmm2/m128 | XOP
	ops: w=reg r=rm | Packed128_UInt16
END

# Code: XOP_Vphadduwq_xmm_xmmm128
INSTRUCTION: XOP.128.X9.W0 D7 /r | VPHADDUWQ xmm1, xmm2/m128 | XOP
	ops: w=reg r=rm | Packed128_UInt16
END

# Code: XOP_Vphaddudq_xmm_xmmm128
INSTRUCTION: XOP.128.X9.W0 DB /r | VPHADDUDQ xmm1, xmm2/m128 | XOP
	ops: w=reg r=rm | Packed128_UInt32
END

# Code: XOP_Vphsubbw_xmm_xmmm128
INSTRUCTION: XOP.128.X9.W0 E1 /r | VPHSUBBW xmm1, xmm2/m128 | XOP
	ops: w=reg r=rm | Packed128_Int8
END

# Code: XOP_Vphsubwd_xmm_xmmm128
INSTRUCTION: XOP.128.X9.W0 E2 /r | VPHSUBWD xmm1, xmm2/m128 | XOP
	ops: w=reg r=rm | Packed128_Int16
END

# Code: XOP_Vphsubdq_xmm_xmmm128
INSTRUCTION: XOP.128.X9.W0 E3 /r | VPHSUBDQ xmm1, xmm2/m128 | XOP
	ops: w=reg r=rm | Packed128_Int32
END

# Code: XOP_Bextr_r32_rm32_imm32
INSTRUCTION: XOP.L0.XA.W0 10 /r id | BEXTR r32, r/m32, imm32 | TBM
	ops: w=reg r=rm r=imm | UInt32
	rflags: u=sap w=z 0=oc
	flags: wig32
	gas: suffix=l
END

# Code: XOP_Bextr_r64_rm64_imm32
INSTRUCTION: XOP.L0.XA.W1 10 /r id | BEXTR r64, r/m64, imm32 | TBM
	ops: w=reg r=rm r=imm | UInt64
	rflags: u=sap w=z 0=oc
	flags: 64
	gas: suffix=q
END

# Code: XOP_Lwpins_r32_rm32_imm32
INSTRUCTION: XOP.L0.XA.W0 12 /0 id | LWPINS r32, r/m32, imm32 | LWP
	ops: r=vvvv r=rm r=imm | UInt32
	rflags: w=c
	flags: wig32
	masm: flags=force-size=default
END

# Code: XOP_Lwpins_r64_rm32_imm32
INSTRUCTION: XOP.L0.XA.W1 12 /0 id | LWPINS r64, r/m32, imm32 | LWP
	ops: r=vvvv r=rm r=imm | UInt32
	rflags: w=c
	flags: 64
	masm: flags=force-size=default
END

# Code: XOP_Lwpval_r32_rm32_imm32
INSTRUCTION: XOP.L0.XA.W0 12 /1 id | LWPVAL r32, r/m32, imm32 | LWP
	ops: r=vvvv cr=rm r=imm | UInt32
	flags: wig32
	masm: flags=force-size=default
END

# Code: XOP_Lwpval_r64_rm32_imm32
INSTRUCTION: XOP.L0.XA.W1 12 /1 id | LWPVAL r64, r/m32, imm32 | LWP
	ops: r=vvvv cr=rm r=imm | UInt32
	flags: 64
	masm: flags=force-size=default
END

# Code: D3NOW_Pi2fw_mm_mmm64
INSTRUCTION: 0F 0F /r 0C | PI2FW mm, mm/m64 | D3NOWEXT
	ops: w=reg r=rm | Packed64_Int16
	masm: flags=mem-size=mmx
END

# Code: D3NOW_Pi2fd_mm_mmm64
INSTRUCTION: 0F 0F /r 0D | PI2FD mm, mm/m64 | D3NOW
	ops: w=reg r=rm | Packed64_Int32
	masm: flags=mem-size=mmx
END

# Code: D3NOW_Pf2iw_mm_mmm64
INSTRUCTION: 0F 0F /r 1C | PF2IW mm, mm/m64 | D3NOWEXT
	ops: w=reg r=rm | Packed64_Float32
	masm: flags=mem-size=mmx
END

# Code: D3NOW_Pf2id_mm_mmm64
INSTRUCTION: 0F 0F /r 1D | PF2ID mm, mm/m64 | D3NOW
	ops: w=reg r=rm | Packed64_Float32
	masm: flags=mem-size=mmx
END

# Code: D3NOW_Pfrcpv_mm_mmm64
INSTRUCTION: 0F 0F /r 86 | PFRCPV mm, mm/m64 | CYRIX_D3NOW
	ops: w=reg r=rm | Packed64_Float32
	flags: 16 32 dec-opt=Cyrix
	masm: flags=mem-size=mmx
END

# Code: D3NOW_Pfrsqrtv_mm_mmm64
INSTRUCTION: 0F 0F /r 87 | PFRSQRTV mm, mm/m64 | CYRIX_D3NOW
	ops: w=reg r=rm | Packed64_Float32
	flags: 16 32 dec-opt=Cyrix
	masm: flags=mem-size=mmx
END

# Code: D3NOW_Pfnacc_mm_mmm64
INSTRUCTION: 0F 0F /r 8A | PFNACC mm, mm/m64 | D3NOWEXT
	ops: rw=reg r=rm | Packed64_Float32
	masm: flags=mem-size=mmx
END

# Code: D3NOW_Pfpnacc_mm_mmm64
INSTRUCTION: 0F 0F /r 8E | PFPNACC mm, mm/m64 | D3NOWEXT
	ops: rw=reg r=rm | Packed64_Float32
	masm: flags=mem-size=mmx
END

# Code: D3NOW_Pfcmpge_mm_mmm64
INSTRUCTION: 0F 0F /r 90 | PFCMPGE mm, mm/m64 | D3NOW
	ops: rw=reg r=rm | Packed64_Float32
	masm: flags=mem-size=mmx
END

# Code: D3NOW_Pfmin_mm_mmm64
INSTRUCTION: 0F 0F /r 94 | PFMIN mm, mm/m64 | D3NOW
	ops: rw=reg r=rm | Packed64_Float32
	masm: flags=mem-size=mmx
END

# Code: D3NOW_Pfrcp_mm_mmm64
INSTRUCTION: 0F 0F /r 96 | PFRCP mm, mm/m64 | D3NOW
	ops: w=reg r=rm | Packed64_Float32
	masm: flags=mem-size=mmx
END

# Code: D3NOW_Pfrsqrt_mm_mmm64
INSTRUCTION: 0F 0F /r 97 | PFRSQRT mm, mm/m64 | D3NOW
	ops: w=reg r=rm | Packed64_Float32
	masm: flags=mem-size=mmx
END

# Code: D3NOW_Pfsub_mm_mmm64
INSTRUCTION: 0F 0F /r 9A | PFSUB mm, mm/m64 | D3NOW
	ops: rw=reg r=rm | Packed64_Float32
	masm: flags=mem-size=mmx
END

# Code: D3NOW_Pfadd_mm_mmm64
INSTRUCTION: 0F 0F /r 9E | PFADD mm, mm/m64 | D3NOW
	ops: rw=reg r=rm | Packed64_Float32
	masm: flags=mem-size=mmx
END

# Code: D3NOW_Pfcmpgt_mm_mmm64
INSTRUCTION: 0F 0F /r A0 | PFCMPGT mm, mm/m64 | D3NOW
	ops: rw=reg r=rm | Packed64_Float32
	masm: flags=mem-size=mmx
END

# Code: D3NOW_Pfmax_mm_mmm64
INSTRUCTION: 0F 0F /r A4 | PFMAX mm, mm/m64 | D3NOW
	ops: rw=reg r=rm | Packed64_Float32
	masm: flags=mem-size=mmx
END

# Code: D3NOW_Pfrcpit1_mm_mmm64
INSTRUCTION: 0F 0F /r A6 | PFRCPIT1 mm, mm/m64 | D3NOW
	ops: rw=reg r=rm | Packed64_Float32
	masm: flags=mem-size=mmx
END

# Code: D3NOW_Pfrsqit1_mm_mmm64
INSTRUCTION: 0F 0F /r A7 | PFRSQIT1 mm, mm/m64 | D3NOW
	ops: rw=reg r=rm | Packed64_Float32
	masm: flags=mem-size=mmx
END

# Code: D3NOW_Pfsubr_mm_mmm64
INSTRUCTION: 0F 0F /r AA | PFSUBR mm, mm/m64 | D3NOW
	ops: rw=reg r=rm | Packed64_Float32
	masm: flags=mem-size=mmx
END

# Code: D3NOW_Pfacc_mm_mmm64
INSTRUCTION: 0F 0F /r AE | PFACC mm, mm/m64 | D3NOW
	ops: rw=reg r=rm | Packed64_Float32
	masm: flags=mem-size=mmx
END

# Code: D3NOW_Pfcmpeq_mm_mmm64
INSTRUCTION: 0F 0F /r B0 | PFCMPEQ mm, mm/m64 | D3NOW
	ops: rw=reg r=rm | Packed64_Float32
	masm: flags=mem-size=mmx
END

# Code: D3NOW_Pfmul_mm_mmm64
INSTRUCTION: 0F 0F /r B4 | PFMUL mm, mm/m64 | D3NOW
	ops: rw=reg r=rm | Packed64_Float32
	masm: flags=mem-size=mmx
END

# Code: D3NOW_Pfrcpit2_mm_mmm64
INSTRUCTION: 0F 0F /r B6 | PFRCPIT2 mm, mm/m64 | D3NOW
	ops: rw=reg r=rm | Packed64_Float32
	masm: flags=mem-size=mmx
END

# Code: D3NOW_Pmulhrw_mm_mmm64
INSTRUCTION: 0F 0F /r B7 | PMULHRW mm, mm/m64 | D3NOW
	ops: rw=reg r=rm | Packed64_Int16
	masm: flags=mem-size=mmx
	nasm: mnemonic=pmulhrwa
END

# Code: D3NOW_Pswapd_mm_mmm64
INSTRUCTION: 0F 0F /r BB | PSWAPD mm, mm/m64 | D3NOWEXT
	ops: w=reg r=rm | Packed64_UInt32
	masm: flags=mem-size=mmx
END

# Code: D3NOW_Pavgusb_mm_mmm64
INSTRUCTION: 0F 0F /r BF | PAVGUSB mm, mm/m64 | D3NOW
	ops: rw=reg r=rm | Packed64_UInt8
	masm: flags=mem-size=mmx
END

# Code: Rmpadjust
INSTRUCTION: F3 0F 01 FE | RMPADJUST | SEV_SNP
	implied: rw=rax r=rcx;rdx
	rflags: w=oszap
	# #VMEXIT(NPF)
	flags: 64 cpl0 amd-may-vm-exit
END

# Code: Rmpupdate
INSTRUCTION: F2 0F 01 FE | RMPUPDATE | SEV_SNP
	implied: r=[seg:rcx=UInt128] rw=rax
	rflags: w=oszap
	flags: 64 cpl0
END

# Code: Psmash
INSTRUCTION: F3 0F 01 FF | PSMASH | SEV_SNP
	implied: rw=rax
	rflags: w=oszap
	flags: 64 cpl0
END

# Code: Pvalidatew
INSTRUCTION: a16 F2 0F 01 FF | PVALIDATE | SEV_SNP
	implied: r=ax w=eax r=ecx;edx
	code-mnemonic: pvalidatew
	rflags: w=oszacp
	# #VMEXIT(NPF)
	flags: 16 32 cpl0 amd-may-vm-exit
	gas: asz
	intel: reg ax
	nasm: asz
END

# Code: Pvalidated
INSTRUCTION: a32 F2 0F 01 FF | PVALIDATE | SEV_SNP
	implied: rw=eax r=ecx;edx
	code-mnemonic: pvalidated
	rflags: w=oszacp
	# #VMEXIT(NPF)
	flags: cpl0 amd-may-vm-exit
	gas: asz
	intel: reg eax
	nasm: asz
END

# Code: Pvalidateq
INSTRUCTION: a64 F2 0F 01 FF | PVALIDATE | SEV_SNP
	implied: rw=rax r=ecx;edx
	code-mnemonic: pvalidateq
	rflags: w=oszacp
	# #VMEXIT(NPF)
	flags: 64 cpl0 amd-may-vm-exit
	gas: asz
	intel: reg rax
	nasm: asz
END

# Code: Serialize
INSTRUCTION: NP 0F 01 E8 | SERIALIZE | SERIALIZE
	# AMD doesn't support this instruction yet
	flags: serialize-intel serialize-amd
END

# Code: Xsusldtrk
INSTRUCTION: F2 0F 01 E8 | XSUSLDTRK | TSXLDTRK
	flags: tsx-may-abort
END

# Code: Xresldtrk
INSTRUCTION: F2 0F 01 E9 | XRESLDTRK | TSXLDTRK
	flags: tsx-may-abort
END

# Code: Invlpgbw
INSTRUCTION: a16 NP 0F 01 FE | INVLPGB | INVLPGB
	implied: r=ax;ecx;edx
	code-mnemonic: invlpgbw
	flags: 16 32 cpl0 no-rm no-v86 amd-may-vm-exit
	gas: asz
	intel: reg ax
	nasm: asz
END

# Code: Invlpgbd
INSTRUCTION: a32 NP 0F 01 FE | INVLPGB | INVLPGB
	implied: r=eax;ecx;edx
	code-mnemonic: invlpgbd
	flags: cpl0 no-rm no-v86 amd-may-vm-exit
	gas: asz
	intel: reg eax
	nasm: asz
END

# Code: Invlpgbq
INSTRUCTION: a64 NP 0F 01 FE | INVLPGB | INVLPGB
	implied: r=rax;ecx;edx
	code-mnemonic: invlpgbq
	flags: 64 cpl0 no-rm no-v86 amd-may-vm-exit
	gas: asz
	intel: reg rax
	nasm: asz
END

# Code: Tlbsync
INSTRUCTION: NP 0F 01 FF | TLBSYNC | INVLPGB
	flags: cpl0 no-rm no-v86 serialize-amd amd-may-vm-exit
END

# Code: Prefetchreserved3_m8
INSTRUCTION: 0F 0D /3 | PREFETCHW m8 | PREFETCHW
	ops: nma=rm | UInt8
	code-mnemonic: prefetchreserved3
	flags: prefetch asm-ig
	nasm: flags=mem-size=ignore
END

# Code: Prefetchreserved4_m8
INSTRUCTION: 0F 0D /4 | PREFETCH m8 | PREFETCHW
	ops: nma=rm | UInt8
	code-mnemonic: prefetchreserved4
	flags: prefetch asm-ig
	intel: mnemonic=prefetch_reserved
	nasm: flags=mem-size=ignore
END

# Code: Prefetchreserved5_m8
INSTRUCTION: 0F 0D /5 | PREFETCH m8 | PREFETCHW
	ops: nma=rm | UInt8
	code-mnemonic: prefetchreserved5
	flags: prefetch asm-ig
	intel: mnemonic=prefetch_reserved
	nasm: flags=mem-size=ignore
END

# Code: Prefetchreserved6_m8
INSTRUCTION: 0F 0D /6 | PREFETCH m8 | PREFETCHW
	ops: nma=rm | UInt8
	code-mnemonic: prefetchreserved6
	flags: prefetch asm-ig
	intel: mnemonic=prefetch_reserved
	nasm: flags=mem-size=ignore
END

# Code: Prefetchreserved7_m8
INSTRUCTION: 0F 0D /7 | PREFETCH m8 | PREFETCHW
	ops: nma=rm | UInt8
	code-mnemonic: prefetchreserved7
	flags: prefetch asm-ig
	intel: mnemonic=prefetch_reserved
	nasm: flags=mem-size=ignore
END

# Code: Ud0
INSTRUCTION: 0F FF | UD0 | INTEL286
	flags: cflow=ex no-intel-dec
END

# Code: Vmgexit
INSTRUCTION: F3 0F 01 D9 | VMGEXIT | SEV_ES
	# This is VMGEXIT iff in guest mode and SEV-ES is active, else it's VMMCALL.
	flags: cflow=call amd-vm-exit
END

# Code: Vmgexit_F2
INSTRUCTION: F2 0F 01 D9 | VMGEXIT | SEV_ES
	code-suffix: F2
	# This is VMGEXIT iff in guest mode and SEV-ES is active, else it's VMMCALL.
	flags: cflow=call amd-vm-exit asm-ig
END

# Code: VEX_Ldtilecfg_m512
INSTRUCTION: VEX.128.0F38.W0 49 !(11):000:bbb | LDTILECFG m512 | AMX_TILE
	ops: r=rm | Tilecfg
	implied: w=tmm0-tmm_last
	flags: 64 tsx-abort
END

# Code: VEX_Tilerelease
INSTRUCTION: VEX.128.0F38.W0 49 C0 | TILERELEASE | AMX_TILE
	implied: w=tmm0-tmm_last
	flags: 64 tsx-abort
END

# Code: VEX_Sttilecfg_m512
INSTRUCTION: VEX.128.66.0F38.W0 49 !(11):000:bbb | STTILECFG m512 | AMX_TILE
	ops: w=rm | Tilecfg
	flags: 64 tsx-abort
END

# Code: VEX_Tilezero_tmm
INSTRUCTION: VEX.128.F2.0F38.W0 49 11:rrr:000 | TILEZERO tmm1 | AMX_TILE
	ops: w=reg
	flags: 64 tsx-abort
END

# Code: VEX_Tileloaddt1_tmm_sibmem
INSTRUCTION: VEX.128.66.0F38.W0 4B !(11):rrr:100 | TILELOADDT1 tmm1, sibmem | AMX_TILE
	ops: w=reg r=rm | Tile
	flags: 64 tile-stride-index tsx-abort
END

# Code: VEX_Tilestored_sibmem_tmm
INSTRUCTION: VEX.128.F3.0F38.W0 4B !(11):rrr:100 | TILESTORED sibmem, tmm1 | AMX_TILE
	ops: w=rm r=reg | Tile
	flags: 64 tile-stride-index tsx-abort
END

# Code: VEX_Tileloadd_tmm_sibmem
INSTRUCTION: VEX.128.F2.0F38.W0 4B !(11):rrr:100 | TILELOADD tmm1, sibmem | AMX_TILE
	ops: w=reg r=rm | Tile
	flags: 64 tile-stride-index tsx-abort
END

# Code: VEX_Tdpbf16ps_tmm_tmm_tmm
INSTRUCTION: VEX.128.F3.0F38.W0 5C 11:rrr:bbb | TDPBF16PS tmm1, tmm2, tmm3 | AMX_BF16
	ops: rw=reg r=rm r=vvvv
	flags: 64 unique-reg-num tsx-abort
END

# Code: VEX_Tdpbuud_tmm_tmm_tmm
INSTRUCTION: VEX.128.0F38.W0 5E 11:rrr:bbb | TDPBUUD tmm1, tmm2, tmm3 | AMX_INT8
	ops: rw=reg r=rm r=vvvv
	flags: 64 unique-reg-num tsx-abort
END

# Code: VEX_Tdpbusd_tmm_tmm_tmm
INSTRUCTION: VEX.128.66.0F38.W0 5E 11:rrr:bbb | TDPBUSD tmm1, tmm2, tmm3 | AMX_INT8
	ops: rw=reg r=rm r=vvvv
	flags: 64 unique-reg-num tsx-abort
END

# Code: VEX_Tdpbsud_tmm_tmm_tmm
INSTRUCTION: VEX.128.F3.0F38.W0 5E 11:rrr:bbb | TDPBSUD tmm1, tmm2, tmm3 | AMX_INT8
	ops: rw=reg r=rm r=vvvv
	flags: 64 unique-reg-num tsx-abort
END

# Code: VEX_Tdpbssd_tmm_tmm_tmm
INSTRUCTION: VEX.128.F2.0F38.W0 5E 11:rrr:bbb | TDPBSSD tmm1, tmm2, tmm3 | AMX_INT8
	ops: rw=reg r=rm r=vvvv
	flags: 64 unique-reg-num tsx-abort
END

# Code: Fnstdw_AX
INSTRUCTION: DF E1 | FNSTDW AX | FPU387SL_ONLY
	ops: w=r:ax
	#TODO: assume c0,c1,c2,c3 == undefined
	rflags: u=0123
	flags: 16 32 dec-opt=OldFpu tsx-impl-abort no-wait
END

# Code: Fnstsg_AX
INSTRUCTION: DF E2 | FNSTSG AX | FPU387SL_ONLY
	ops: w=r:ax
	#TODO: assume c0,c1,c2,c3 == undefined
	rflags: u=0123
	flags: 16 32 dec-opt=OldFpu tsx-impl-abort no-wait
END

# Code: Rdshr_rm32
INSTRUCTION: 0F 36 /0 | RDSHR r/m32 | CYRIX_SHR
	ops: w=rm | UInt32
	flags: 16 32 dec-opt=Cyrix cpl0 no-outside-smm
	gas: suffix=l
END

# Code: Wrshr_rm32
INSTRUCTION: 0F 37 /0 | WRSHR r/m32 | CYRIX_SHR
	ops: r=rm | UInt32
	flags: 16 32 dec-opt=Cyrix cpl0 no-outside-smm
	gas: suffix=l
END

# Code: Smint
INSTRUCTION: 0F 38 | SMINT | CYRIX_SMINT
	flags: 16 32 dec-opt=Cyrix cpl0 cflow=int
END

# Code: Dmint
INSTRUCTION: 0F 39 | DMINT | CYRIX_DMI
	flags: 16 32 dec-opt=Cyrix_DMI cpl0 cflow=int
END

# Code: Rdm
INSTRUCTION: 0F 3A | RDM | CYRIX_DMI
	rflags: w=oszacpdiA
	flags: 16 32 dec-opt=Cyrix_DMI cpl0 save-restore cflow=ret
END

# Code: Svdc_m80_Sreg
INSTRUCTION: 0F 78 /r | SVDC m80, Sreg | CYRIX_SMM
	# Some CPUs only allow this instruction when in SMM (eg. Cyrix 6x86, Cyrix III)
	ops: w=rm r=reg | SegmentDescSelector
	flags: 16 32 dec-opt=Cyrix cpl0
END

# Code: Rsdc_Sreg_m80
INSTRUCTION: 0F 79 /r | RSDC Sreg, m80 | CYRIX_SMM
	# Some CPUs don't allow CS (#UD) as a target register (eg. Cyrix 6x86, Cyrix III), others allow it (eg. Geode LX)
	# Some CPUs only allow this instruction when in SMM (eg. Cyrix 6x86, Cyrix III)
	ops: w=reg r=rm | SegmentDescSelector
	flags: 16 32 dec-opt=Cyrix cpl0
END

# Code: Svldt_m80
INSTRUCTION: 0F 7A /0 | SVLDT m80 | CYRIX_SMM
	# Some CPUs only allow this instruction when in SMM (eg. Cyrix 6x86, Cyrix III)
	ops: w=rm | SegmentDescSelector
	flags: 16 32 dec-opt=Cyrix cpl0
END

# Code: Rsldt_m80
INSTRUCTION: 0F 7B /0 | RSLDT m80 | CYRIX_SMM
	# Some CPUs only allow this instruction when in SMM (eg. Cyrix 6x86, Cyrix III)
	ops: r=rm | SegmentDescSelector
	flags: 16 32 dec-opt=Cyrix cpl0
END

# Code: Svts_m80
INSTRUCTION: 0F 7C /0 | SVTS m80 | CYRIX_SMM
	# Some CPUs only allow this instruction when in SMM (eg. Cyrix 6x86, Cyrix III)
	ops: w=rm | SegmentDescSelector
	flags: 16 32 dec-opt=Cyrix cpl0
END

# Code: Rsts_m80
INSTRUCTION: 0F 7D /0 | RSTS m80 | CYRIX_SMM
	# Some CPUs only allow this instruction when in SMM (eg. Cyrix 6x86, Cyrix III)
	ops: r=rm | SegmentDescSelector
	flags: 16 32 dec-opt=Cyrix cpl0
END

# Code: Smint_0F7E
INSTRUCTION: 0F 7E | SMINT | CYRIX_SMINT_0F7E
	code-suffix: 0F7E
	flags: 16 32 dec-opt=Cyrix_SMINT_0F7E cpl0 cflow=int asm=smint_0f7e
	nasm: mnemonic=smintold
END

# Code: Bb0_reset
INSTRUCTION: 0F 3A | BB0_RESET | CYRIX_DDI
	flags: 16 32 dec-opt=Cyrix cpl0
END

# Code: Bb1_reset
INSTRUCTION: 0F 3B | BB1_RESET | CYRIX_DDI
	flags: 16 32 dec-opt=Cyrix cpl0
END

# Code: Cpu_write
INSTRUCTION: 0F 3C | CPU_WRITE | CYRIX_DDI
	implied: r=eax;ebx
	flags: 16 32 dec-opt=Cyrix cpl0
END

# Code: Cpu_read
INSTRUCTION: 0F 3D | CPU_READ | CYRIX_DDI
	implied: w=eax r=ebx
	flags: 16 32 dec-opt=Cyrix cpl0
END

# Code: Altinst
INSTRUCTION: 0F 3F | ALTINST | CENTAUR_AIS
	implied: r=eax
	flags: 16 32 dec-opt=ALTINST cflow=br-ind
END

# Code: Paveb_mm_mmm64
INSTRUCTION: 0F 50 /r | PAVEB mm, mm/m64 | CYRIX_EMMI
	ops: rw=reg r=rm | Packed64_UInt8
	flags: 16 32 dec-opt=Cyrix
END

# Code: Paddsiw_mm_mmm64
INSTRUCTION: 0F 51 /r | PADDSIW mm, mm/m64 | CYRIX_EMMI
	ops: r=reg r=rm | Packed64_Int16
	implied: emmi-reg=w
	flags: 16 32 dec-opt=Cyrix
END

# Code: Pmagw_mm_mmm64
INSTRUCTION: 0F 52 /r | PMAGW mm, mm/m64 | CYRIX_EMMI
	ops: rcw=reg r=rm | Packed64_UInt16
	flags: 16 32 dec-opt=Cyrix
END

# Code: Pdistib_mm_m64
INSTRUCTION: 0F 54 /r | PDISTIB mm, m64 | CYRIX_EMMI
	ops: r=reg r=rm | Packed64_UInt8
	implied: emmi-reg=rw
	flags: 16 32 dec-opt=Cyrix
END

# Code: Psubsiw_mm_mmm64
INSTRUCTION: 0F 55 /r | PSUBSIW mm, mm/m64 | CYRIX_EMMI
	ops: r=reg r=rm | Packed64_Int16
	implied: emmi-reg=w
	flags: 16 32 dec-opt=Cyrix
END

# Code: Pmvzb_mm_m64
INSTRUCTION: 0F 58 /r | PMVZB mm, m64 | CYRIX_EMMI
	ops: rcw=reg r=rm | Packed64_UInt8
	implied: emmi-reg=r
	flags: 16 32 dec-opt=Cyrix
END

# Code: Pmulhrw_mm_mmm64
INSTRUCTION: 0F 59 /r | PMULHRW mm, mm/m64 | CYRIX_EMMI
	ops: rw=reg r=rm | Packed64_Int16
	flags: 16 32 dec-opt=Cyrix asm=pmulhrw_cyrix
	nasm: mnemonic=pmulhrwc
END

# Code: Pmvnzb_mm_m64
INSTRUCTION: 0F 5A /r | PMVNZB mm, m64 | CYRIX_EMMI
	ops: rcw=reg r=rm | Packed64_UInt8
	implied: emmi-reg=r
	flags: 16 32 dec-opt=Cyrix
END

# Code: Pmvlzb_mm_m64
INSTRUCTION: 0F 5B /r | PMVLZB mm, m64 | CYRIX_EMMI
	ops: rcw=reg r=rm | Packed64_Int8
	implied: emmi-reg=r
	flags: 16 32 dec-opt=Cyrix
END

# Code: Pmvgezb_mm_m64
INSTRUCTION: 0F 5C /r | PMVGEZB mm, m64 | CYRIX_EMMI
	ops: rcw=reg r=rm | Packed64_Int8
	implied: emmi-reg=r
	flags: 16 32 dec-opt=Cyrix
END

# Code: Pmulhriw_mm_mmm64
INSTRUCTION: 0F 5D /r | PMULHRIW mm, mm/m64 | CYRIX_EMMI
	ops: r=reg r=rm | Packed64_Int16
	implied: emmi-reg=w
	flags: 16 32 dec-opt=Cyrix
END

# Code: Pmachriw_mm_m64
INSTRUCTION: 0F 5E /r | PMACHRIW mm, m64 | CYRIX_EMMI
	ops: r=reg r=rm | Packed64_UInt16
	implied: emmi-reg=rw
	flags: 16 32 dec-opt=Cyrix
END

# Code: Cyrix_D9D7
INSTRUCTION: D9 D7 | UNDOC | CYRIX_FPU
	code-mnemonic: cyrix
	code-suffix: D9D7
	rflags: u=0123
	flags: 16 32 dec-opt=Cyrix asm-ig
END

# Code: Cyrix_D9E2
INSTRUCTION: D9 E2 | UNDOC | CYRIX_FPU
	code-mnemonic: cyrix
	code-suffix: D9E2
	rflags: u=0123
	flags: 16 32 dec-opt=Cyrix asm-ig
END

# Code: Ftstp
INSTRUCTION: D9 E6 | FTSTP | CYRIX_FPU
	implied: r=st0
	# Assume it uses the same flags as FTST
	rflags: 0=1 w=023
	flags: 16 32 dec-opt=Cyrix fpu-pop=1 asm-ig
END

# Code: Cyrix_D9E7
INSTRUCTION: D9 E7 | UNDOC | CYRIX_FPU
	code-mnemonic: cyrix
	code-suffix: D9E7
	rflags: u=0123
	flags: 16 32 dec-opt=Cyrix asm-ig
END

# Code: Frint2
INSTRUCTION: DB FC | FRINT2 | CYRIX_FPU
	implied: rw=st0
	# Assume it uses the same flags as FRNDINT
	rflags: w=1 u=023
	flags: 16 32 dec-opt=Cyrix asm-ig
END

# Code: Frichop
INSTRUCTION: DD FC | FRICHOP | CYRIX_FPU
	implied: rw=st0
	# Assume it uses the same flags as FRNDINT
	rflags: w=1 u=023
	flags: 16 32 dec-opt=Cyrix asm-ig
END

# Code: Cyrix_DED8
INSTRUCTION: DE D8 | UNDOC | CYRIX_FPU
	code-mnemonic: cyrix
	code-suffix: DED8
	rflags: u=0123
	flags: 16 32 dec-opt=Cyrix asm-ig
END

# Code: Cyrix_DEDA
INSTRUCTION: DE DA | UNDOC | CYRIX_FPU
	code-mnemonic: cyrix
	code-suffix: DEDA
	rflags: u=0123
	flags: 16 32 dec-opt=Cyrix asm-ig
END

# Code: Cyrix_DEDC
INSTRUCTION: DE DC | UNDOC | CYRIX_FPU
	code-mnemonic: cyrix
	code-suffix: DEDC
	rflags: u=0123
	flags: 16 32 dec-opt=Cyrix asm-ig
END

# Code: Cyrix_DEDD
INSTRUCTION: DE DD | UNDOC | CYRIX_FPU
	code-mnemonic: cyrix
	code-suffix: DEDD
	rflags: u=0123
	flags: 16 32 dec-opt=Cyrix asm-ig
END

# Code: Cyrix_DEDE
INSTRUCTION: DE DE | UNDOC | CYRIX_FPU
	code-mnemonic: cyrix
	code-suffix: DEDE
	rflags: u=0123
	flags: 16 32 dec-opt=Cyrix asm-ig
END

# Code: Frinear
INSTRUCTION: DF FC | FRINEAR | CYRIX_FPU
	implied: rw=st0
	# Assume it uses the same flags as FRNDINT
	rflags: w=1 u=023
	flags: 16 32 dec-opt=Cyrix asm-ig
END

# Code: Tdcall
INSTRUCTION: 66 0F 01 CC | TDCALL | TDX
	# VMX instrs have tsx-impl-abort, it's probably the same for all TDX instructions
	flags: cpl0 cflow=call vmx=non-root intel-vm-exit tsx-impl-abort
END

# Code: Seamret
INSTRUCTION: 66 0F 01 CD | SEAMRET | TDX
	rflags: w=zc 0=osap
	# VMX instrs have tsx-impl-abort, it's probably the same for all TDX instructions
	# Continues from the next instruction on failure
	flags: 64 cpl0 cflow=call vmx=root no-outside-seam tsx-impl-abort
END

# Code: Seamops
INSTRUCTION: 66 0F 01 CE | SEAMOPS | TDX
	implied: rw=rax cr=rcx;rdx;r8;r9
	#TODO: should be cond-write (no flags are written if rax==0)
	rflags: w=z 0=osacp
	# VMX instrs have tsx-impl-abort, it's probably the same for all TDX instructions
	flags: 64 cpl0 vmx=root no-outside-seam tsx-impl-abort
END

# Code: Seamcall
INSTRUCTION: 66 0F 01 CF | SEAMCALL | TDX
	implied: r=rax
	rflags: w=c 0=oszap
	# VMX instrs have tsx-impl-abort, it's probably the same for all TDX instructions
	flags: 64 cpl0 cflow=call vmx=op intel-vm-exit no-in-smm no-in-seam tsx-impl-abort
END

# Code: Aesencwide128kl_m384
INSTRUCTION: F3 0F 38 D8 !(11):000:bbb | AESENCWIDE128KL m384, <XMM0-7> | AESKLE WIDE_KL
	ops: r=rm | KLHandleAes128
	implied: rw=xmm0-xmm7
	rflags: w=z 0=osacp
	# All Key Locker instructions may cause a TSX abort
	flags: tsx-impl-abort
END

# Code: Aesdecwide128kl_m384
INSTRUCTION: F3 0F 38 D8 !(11):001:bbb | AESDECWIDE128KL m384, <XMM0-7> | AESKLE WIDE_KL
	ops: r=rm | KLHandleAes128
	implied: rw=xmm0-xmm7
	rflags: w=z 0=osacp
	# All Key Locker instructions may cause a TSX abort
	flags: tsx-impl-abort
END

# Code: Aesencwide256kl_m512
INSTRUCTION: F3 0F 38 D8 !(11):010:bbb | AESENCWIDE256KL m512, <XMM0-7> | AESKLE WIDE_KL
	ops: r=rm | KLHandleAes256
	implied: rw=xmm0-xmm7
	rflags: w=z 0=osacp
	# All Key Locker instructions may cause a TSX abort
	flags: tsx-impl-abort
END

# Code: Aesdecwide256kl_m512
INSTRUCTION: F3 0F 38 D8 !(11):011:bbb | AESDECWIDE256KL m512, <XMM0-7> | AESKLE WIDE_KL
	ops: r=rm | KLHandleAes256
	implied: rw=xmm0-xmm7
	rflags: w=z 0=osacp
	# All Key Locker instructions may cause a TSX abort
	flags: tsx-impl-abort
END

# Code: Loadiwkey_xmm_xmm
INSTRUCTION: F3 0F 38 DC 11:rrr:bbb | LOADIWKEY xmm1, xmm2, <EAX>, <XMM0> | KL
	ops: r=reg r=rm
	implied: r=eax;xmm0
	rflags: w=z 0=osacp
	# All Key Locker instructions may cause a TSX abort
	flags: cpl0 tsx-impl-abort intel-may-vm-exit
END

# Code: Aesenc128kl_xmm_m384
INSTRUCTION: F3 0F 38 DC !(11):rrr:bbb | AESENC128KL xmm, m384 | AESKLE
	ops: rw=reg r=rm | KLHandleAes128
	rflags: w=z 0=osacp
	# All Key Locker instructions may cause a TSX abort
	flags: tsx-impl-abort
END

# Code: Aesdec128kl_xmm_m384
INSTRUCTION: F3 0F 38 DD !(11):rrr:bbb | AESDEC128KL xmm, m384 | AESKLE
	ops: rw=reg r=rm | KLHandleAes128
	rflags: w=z 0=osacp
	# All Key Locker instructions may cause a TSX abort
	flags: tsx-impl-abort
END

# Code: Aesenc256kl_xmm_m512
INSTRUCTION: F3 0F 38 DE !(11):rrr:bbb | AESENC256KL xmm, m512 | AESKLE
	ops: rw=reg r=rm | KLHandleAes256
	rflags: w=z 0=osacp
	# All Key Locker instructions may cause a TSX abort
	flags: tsx-impl-abort
END

# Code: Aesdec256kl_xmm_m512
INSTRUCTION: F3 0F 38 DF !(11):rrr:bbb | AESDEC256KL xmm, m512 | AESKLE
	ops: rw=reg r=rm | KLHandleAes256
	rflags: w=z 0=osacp
	# All Key Locker instructions may cause a TSX abort
	flags: tsx-impl-abort
END

# Code: Encodekey128_r32_r32
INSTRUCTION: F3 0F 38 FA 11:rrr:bbb | ENCODEKEY128 r32, r32, <XMM0-2>, <XMM4-6> | AESKLE
	ops: w=reg r=rm
	implied: rw=xmm0 w=xmm1;xmm2;xmm4-xmm6
	# Future extensions may write non-zero values to the flags
	rflags: 0=oszacp
	# All Key Locker instructions may cause a TSX abort
	flags: tsx-impl-abort
END

# Code: Encodekey256_r32_r32
INSTRUCTION: F3 0F 38 FB 11:rrr:bbb | ENCODEKEY256 r32, r32, <XMM0-6> | AESKLE
	ops: w=reg r=rm
	implied: rw=xmm0;xmm1 w=xmm2-xmm6
	# Future extensions may write non-zero values to the flags
	rflags: 0=oszacp
	# All Key Locker instructions may cause a TSX abort
	flags: tsx-impl-abort
END

# Code: VEX_Vbroadcastss_xmm_xmm
INSTRUCTION: VEX.128.66.0F38.W0 18 /r | VBROADCASTSS xmm1, xmm2 | AVX2
	ops: w=reg r=rm
END

# Code: VEX_Vbroadcastss_ymm_xmm
INSTRUCTION: VEX.256.66.0F38.W0 18 /r | VBROADCASTSS ymm1, xmm2 | AVX2
	ops: w=reg r=rm
END

# Code: VEX_Vbroadcastsd_ymm_xmm
INSTRUCTION: VEX.256.66.0F38.W0 19 /r | VBROADCASTSD ymm1, xmm2 | AVX2
	ops: w=reg r=rm
END

# Code: Uiret
INSTRUCTION: F3 0F 01 EC | UIRET | UINTR
	implied: pop=3x8
	rflags: w=cpazsdoA 1=u
	flags: 64 sp=pop;24 cflow=ret no-in-sgx tsx-abort
END

# Code: Testui
INSTRUCTION: F3 0F 01 ED | TESTUI | UINTR
	rflags: r=u w=c 0=zaops
	# It can be executed inside a transactional region
	flags: 64 no-in-sgx
END

# Code: Clui
INSTRUCTION: F3 0F 01 EE | CLUI | UINTR
	rflags: 0=u
	flags: 64 no-in-sgx tsx-abort
END

# Code: Stui
INSTRUCTION: F3 0F 01 EF | STUI | UINTR
	rflags: 1=u
	flags: 64 no-in-sgx tsx-abort
END

# Code: Senduipi_r64
INSTRUCTION: F3 0F C7 /6 | SENDUIPI r64 | UINTR
	ops: r=rm
	# APIC-write VM exit
	#TODO: is this tsx-abort?
	flags: 64 fo64 intel-may-vm-exit no-in-sgx
END

# Code: Hreset_imm8
INSTRUCTION: F3 0F 3A F0 C0 ib | HRESET imm8, <EAX> | HRESET
	# The CPU ignores op0 (imm8)
	ops: n=imm
	implied: r=eax
	flags: cpl0 tsx-abort
END

# Code: VEX_Vpdpbusd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 50 /r | VPDPBUSD xmm1, xmm2, xmm3/m128 | AVX_VNNI
	ops: rw=reg r=vvvv r=rm | Packed128_Int8
END

# Code: VEX_Vpdpbusd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 50 /r | VPDPBUSD ymm1, ymm2, ymm3/m256 | AVX_VNNI
	ops: rw=reg r=vvvv r=rm | Packed256_Int8
END

# Code: VEX_Vpdpbusds_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 51 /r | VPDPBUSDS xmm1, xmm2, xmm3/m128 | AVX_VNNI
	ops: rw=reg r=vvvv r=rm | Packed128_Int8
END

# Code: VEX_Vpdpbusds_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 51 /r | VPDPBUSDS ymm1, ymm2, ymm3/m256 | AVX_VNNI
	ops: rw=reg r=vvvv r=rm | Packed256_Int8
END

# Code: VEX_Vpdpwssd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 52 /r | VPDPWSSD xmm1, xmm2, xmm3/m128 | AVX_VNNI
	ops: rw=reg r=vvvv r=rm | Packed128_Int16
END

# Code: VEX_Vpdpwssd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 52 /r | VPDPWSSD ymm1, ymm2, ymm3/m256 | AVX_VNNI
	ops: rw=reg r=vvvv r=rm | Packed256_Int16
END

# Code: VEX_Vpdpwssds_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 53 /r | VPDPWSSDS xmm1, xmm2, xmm3/m128 | AVX_VNNI
	ops: rw=reg r=vvvv r=rm | Packed128_Int16
END

# Code: VEX_Vpdpwssds_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 53 /r | VPDPWSSDS ymm1, ymm2, ymm3/m256 | AVX_VNNI
	ops: rw=reg r=vvvv r=rm | Packed256_Int16
END

# Code: Ccs_hash_16
INSTRUCTION: a16 F3 0F A6 E8 | CCS_HASH | PADLOCK_GMI
	# Some Zhaoxin CPUs support GMI, eg. ZX-C+, KX, KH
	# GMI = GuoMi Instruction

	# https://github.com/ZXOpenSource/OpenSSL-ZX-GMI/blob/master/GMI%20User%20Manual%20V1.0.pdf
	# OpenSSL PR: https://github.com/openssl/openssl/pull/8706

	# SM3 instruction
	implied: cr=[es:si=Unknown] crcw=[es:di=Unknown] cw=si rcw=ax;cx cr=bx
	code-suffix: 16
	flags: 16 32 ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Ccs_hash_32
INSTRUCTION: a32 F3 0F A6 E8 | CCS_HASH | PADLOCK_GMI
	# See a16 version above for more info
	implied: cr=[es:esi=Unknown] crcw=[es:edi=Unknown] cw=esi rcw=eax;ecx cr=ebx
	code-suffix: 32
	flags: ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Ccs_hash_64
INSTRUCTION: a64 F3 0F A6 E8 | CCS_HASH | PADLOCK_GMI
	# See a16 version above for more info
	implied: cr=[es:rsi=Unknown] crcw=[es:rdi=Unknown] cw=rsi rcw=rax;rcx cr=rbx
	code-suffix: 64
	flags: 64 ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Via_undoc_F30FA6F0_16
INSTRUCTION: a16 F3 0F A6 F0 | UNDOC | PADLOCK_UNDOC
	# Undocumented instruction (Zhaoxin KX-6580 CPU, tested by @tremalrik)
	code-mnemonic: via_undoc
	code-suffix: F30FA6F0_16
	flags: 16 32 ig-modrm-low3 save-restore asm-ig
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Via_undoc_F30FA6F0_32
INSTRUCTION: a32 F3 0F A6 F0 | UNDOC | PADLOCK_UNDOC
	code-mnemonic: via_undoc
	code-suffix: F30FA6F0_32
	flags: ig-modrm-low3 save-restore asm-ig
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Via_undoc_F30FA6F0_64
INSTRUCTION: a64 F3 0F A6 F0 | UNDOC | PADLOCK_UNDOC
	code-mnemonic: via_undoc
	code-suffix: F30FA6F0_64
	flags: 64 ig-modrm-low3 save-restore asm-ig
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Via_undoc_F30FA6F8_16
INSTRUCTION: a16 F3 0F A6 F8 | UNDOC | PADLOCK_UNDOC
	# Undocumented instruction (Zhaoxin KX-6580 CPU, tested by @tremalrik)
	code-mnemonic: via_undoc
	code-suffix: F30FA6F8_16
	flags: 16 32 ig-modrm-low3 save-restore asm-ig
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Via_undoc_F30FA6F8_32
INSTRUCTION: a32 F3 0F A6 F8 | UNDOC | PADLOCK_UNDOC
	code-mnemonic: via_undoc
	code-suffix: F30FA6F8_32
	flags: ig-modrm-low3 save-restore asm-ig
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Via_undoc_F30FA6F8_64
INSTRUCTION: a64 F3 0F A6 F8 | UNDOC | PADLOCK_UNDOC
	code-mnemonic: via_undoc
	code-suffix: F30FA6F8_64
	flags: 64 ig-modrm-low3 save-restore asm-ig
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Ccs_encrypt_16
INSTRUCTION: a16 F3 0F A7 F0 | CCS_ENCRYPT | PADLOCK_GMI
	# https://github.com/ZXOpenSource/OpenSSL-ZX-GMI/blob/master/GMI%20User%20Manual%20V1.0.pdf
	# OpenSSL PR: https://github.com/openssl/openssl/pull/8706

	# SM4 instruction
	implied: cr=[es:dx=Unknown];[es:bx=Unknown];[es:si=Unknown] cw=[es:di=Unknown] rcw=cx cw=si;di cr=ax
	code-suffix: 16
	flags: 16 32 ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Ccs_encrypt_32
INSTRUCTION: a32 F3 0F A7 F0 | CCS_ENCRYPT | PADLOCK_GMI
	# See a16 version above for more info
	implied: cr=[es:edx=Unknown];[es:ebx=Unknown];[es:esi=Unknown] cw=[es:edi=Unknown] rcw=ecx cw=esi;edi cr=eax
	code-suffix: 32
	flags: ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Ccs_encrypt_64
INSTRUCTION: a64 F3 0F A7 F0 | CCS_ENCRYPT | PADLOCK_GMI
	# See a16 version above for more info
	implied: cr=[es:rdx=Unknown];[es:rbx=Unknown];[es:rsi=Unknown] cw=[es:rdi=Unknown] rcw=rcx cw=rsi;rdi cr=rax
	code-suffix: 64
	flags: 64 ig-modrm-low3
	gas: asz
	intel: asz
	nasm: asz
END

# Code: Lkgs_rm16
INSTRUCTION: o16 F2 0F 00 /6 | LKGS r/m16 | LKGS
	ops: r=rm | UInt16
	implied: w=gs
	flags: 64 cpl0
	gas: reg16
	masm: flags=force-size=default
	nasm: osz-reg16
END

# Code: Lkgs_r32m16
INSTRUCTION: o32 F2 0F 00 /6 | LKGS r32/m16 | LKGS
	ops: r=rm | UInt16
	implied: last-gpr-16 w=gs
	flags: 64 cpl0
	gas: reg16
	masm: flags=force-size=default
	nasm: osz-reg16
END

# Code: Lkgs_r64m16
INSTRUCTION: F2 o64 0F 00 /6 | LKGS r64/m16 | LKGS
	ops: r=rm | UInt16
	implied: last-gpr-16 w=gs
	flags: 64 cpl0
	gas: reg16
	masm: flags=force-size=default
	nasm: osz-reg16
END

# Code: Eretu
INSTRUCTION: F3 0F 01 CA | ERETU | FRED
	# Also loads GS.base (but not GS (selector))
	# The first 8 bytes (error code) aren't read
	implied: pop=6x8 w=rsp;cs;ss
	rflags: w=oszacpdiA
	flags: 64 cpl0 sp=pop;48 cflow=ret
END

# Code: Erets
INSTRUCTION: F2 0F 01 CA | ERETS | FRED
	# The first 8 bytes (error code) aren't read
	implied: pop=6x8 w=rsp r=cs;ss
	rflags: w=oszacpdiA
	flags: 64 cpl0 sp=pop;48 cflow=ret
END

# Code: EVEX_Vaddph_xmm_k1z_xmm_xmmm128b16
INSTRUCTION: EVEX.128.MAP5.W0 58 /r | VADDPH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: w=reg r=vvvv r=rm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vaddph_ymm_k1z_ymm_ymmm256b16
INSTRUCTION: EVEX.256.MAP5.W0 58 /r | VADDPH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: w=reg r=vvvv r=rm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vaddph_zmm_k1z_zmm_zmmm512b16_er
INSTRUCTION: EVEX.512.MAP5.W0 58 /r | VADDPH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er} | AVX512_FP16 | N64b2
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vaddsh_xmm_k1z_xmm_xmmm16_er
INSTRUCTION: EVEX.LIG.F3.MAP5.W0 58 /r | VADDSH xmm1 {k1}{z}, xmm2, xmm3/m16{er} | AVX512_FP16 | N2
	ops: w=reg r=vvvv r=rm | Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcmpph_kr_k1_xmm_xmmm128b16_imm8
INSTRUCTION: EVEX.128.0F3A.W0 C2 /r ib | VCMPPH k1 {k2}, xmm2, xmm3/m128/m16bcst, imm8 | AVX512VL AVX512_FP16 | N16b2
	ops: w=reg r=vvvv r=rm r=imm | Packed128_Float16 Broadcast128_Float16
	flags: pseudo=vcmpph implied-z
END

# Code: EVEX_Vcmpph_kr_k1_ymm_ymmm256b16_imm8
INSTRUCTION: EVEX.256.0F3A.W0 C2 /r ib | VCMPPH k1 {k2}, ymm2, ymm3/m256/m16bcst, imm8 | AVX512VL AVX512_FP16 | N32b2
	ops: w=reg r=vvvv r=rm r=imm | Packed256_Float16 Broadcast256_Float16
	flags: pseudo=vcmpph implied-z
END

# Code: EVEX_Vcmpph_kr_k1_zmm_zmmm512b16_imm8_sae
INSTRUCTION: EVEX.512.0F3A.W0 C2 /r ib | VCMPPH k1 {k2}, zmm2, zmm3/m512/m16bcst{sae}, imm8 | AVX512_FP16 | N64b2
	ops: w=reg r=vvvv r=rm r=imm | Packed512_Float16 Broadcast512_Float16
	flags: pseudo=vcmpph implied-z
END

# Code: EVEX_Vcmpsh_kr_k1_xmm_xmmm16_imm8_sae
INSTRUCTION: EVEX.LIG.F3.0F3A.W0 C2 /r ib | VCMPSH k1 {k2}, xmm2, xmm3/m16{sae}, imm8 | AVX512_FP16 | N2
	ops: w=reg r=vvvv r=rm r=imm | Float16
	flags: pseudo=vcmpsh implied-z
	masm: flags=force-size=default
END

# Code: EVEX_Vcomish_xmm_xmmm16_sae
INSTRUCTION: EVEX.LIG.MAP5.W0 2F /r | VCOMISH xmm1, xmm2/m16{sae} | AVX512_FP16 | N2
	ops: r=reg r=rm | Float16
	rflags: w=zcp 0=osa
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtdq2ph_xmm_k1z_xmmm128b32
INSTRUCTION: EVEX.128.MAP5.W0 5B /r | VCVTDQ2PH xmm1 {k1}{z}, xmm2/m128/m32bcst | AVX512VL AVX512_FP16 | N16b4
	ops: w=reg r=rm | Packed128_Int32 Broadcast128_Int32
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=x
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vcvtdq2ph_xmm_k1z_ymmm256b32
INSTRUCTION: EVEX.256.MAP5.W0 5B /r | VCVTDQ2PH xmm1 {k1}{z}, ymm2/m256/m32bcst | AVX512VL AVX512_FP16 | N32b4
	ops: w=reg r=rm | Packed256_Int32 Broadcast256_Int32
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=y
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vcvtdq2ph_ymm_k1z_zmmm512b32_er
INSTRUCTION: EVEX.512.MAP5.W0 5B /r | VCVTDQ2PH ymm1 {k1}{z}, zmm2/m512/m32bcst{er} | AVX512_FP16 | N64b4
	ops: w=reg r=rm | Packed512_Int32 Broadcast512_Int32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtpd2ph_xmm_k1z_xmmm128b64
INSTRUCTION: EVEX.128.66.MAP5.W1 5A /r | VCVTPD2PH xmm1 {k1}{z}, xmm2/m128/m64bcst | AVX512VL AVX512_FP16 | N16b8
	ops: w=reg r=rm | Packed128_Float64 Broadcast128_Float64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=x
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vcvtpd2ph_xmm_k1z_ymmm256b64
INSTRUCTION: EVEX.256.66.MAP5.W1 5A /r | VCVTPD2PH xmm1 {k1}{z}, ymm2/m256/m64bcst | AVX512VL AVX512_FP16 | N32b8
	ops: w=reg r=rm | Packed256_Float64 Broadcast256_Float64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=y
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vcvtpd2ph_xmm_k1z_zmmm512b64_er
INSTRUCTION: EVEX.512.66.MAP5.W1 5A /r | VCVTPD2PH xmm1 {k1}{z}, zmm2/m512/m64bcst{er} | AVX512_FP16 | N64b8
	ops: w=reg r=rm | Packed512_Float64 Broadcast512_Float64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=z
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: EVEX_Vcvtph2dq_xmm_k1z_xmmm64b16
INSTRUCTION: EVEX.128.66.MAP5.W0 5B /r | VCVTPH2DQ xmm1 {k1}{z}, xmm2/m64/m16bcst | AVX512VL AVX512_FP16 | N8b2
	ops: w=reg r=rm | Packed64_Float16 Broadcast64_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtph2dq_ymm_k1z_xmmm128b16
INSTRUCTION: EVEX.256.66.MAP5.W0 5B /r | VCVTPH2DQ ymm1 {k1}{z}, xmm2/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: w=reg r=rm | Packed128_Float16 Broadcast128_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtph2dq_zmm_k1z_ymmm256b16_er
INSTRUCTION: EVEX.512.66.MAP5.W0 5B /r | VCVTPH2DQ zmm1 {k1}{z}, ymm2/m256/m16bcst{er} | AVX512_FP16 | N32b2
	ops: wvmm=reg r=rm | Packed256_Float16 Broadcast256_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtph2pd_xmm_k1z_xmmm32b16
INSTRUCTION: EVEX.128.MAP5.W0 5A /r | VCVTPH2PD xmm1 {k1}{z}, xmm2/m32/m16bcst | AVX512VL AVX512_FP16 | N4b2
	ops: w=reg r=rm | Packed32_Float16 Broadcast32_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtph2pd_ymm_k1z_xmmm64b16
INSTRUCTION: EVEX.256.MAP5.W0 5A /r | VCVTPH2PD ymm1 {k1}{z}, xmm2/m64/m16bcst | AVX512VL AVX512_FP16 | N8b2
	ops: w=reg r=rm | Packed64_Float16 Broadcast64_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtph2pd_zmm_k1z_xmmm128b16_sae
INSTRUCTION: EVEX.512.MAP5.W0 5A /r | VCVTPH2PD zmm1 {k1}{z}, xmm2/m128/m16bcst{sae} | AVX512_FP16 | N16b2
	ops: wvmm=reg r=rm | Packed128_Float16 Broadcast128_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtph2psx_xmm_k1z_xmmm64b16
INSTRUCTION: EVEX.128.66.MAP6.W0 13 /r | VCVTPH2PSX xmm1 {k1}{z}, xmm2/m64/m16bcst | AVX512VL AVX512_FP16 | N8b2
	ops: w=reg r=rm | Packed64_Float16 Broadcast64_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtph2psx_ymm_k1z_xmmm128b16
INSTRUCTION: EVEX.256.66.MAP6.W0 13 /r | VCVTPH2PSX ymm1 {k1}{z}, xmm2/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: w=reg r=rm | Packed128_Float16 Broadcast128_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtph2psx_zmm_k1z_ymmm256b16_sae
INSTRUCTION: EVEX.512.66.MAP6.W0 13 /r | VCVTPH2PSX zmm1 {k1}{z}, ymm2/m256/m16bcst{sae} | AVX512_FP16 | N32b2
	ops: wvmm=reg r=rm | Packed256_Float16 Broadcast256_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtph2qq_xmm_k1z_xmmm32b16
INSTRUCTION: EVEX.128.66.MAP5.W0 7B /r | VCVTPH2QQ xmm1 {k1}{z}, xmm2/m32/m16bcst | AVX512VL AVX512_FP16 | N4b2
	ops: w=reg r=rm | Packed32_Float16 Broadcast32_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtph2qq_ymm_k1z_xmmm64b16
INSTRUCTION: EVEX.256.66.MAP5.W0 7B /r | VCVTPH2QQ ymm1 {k1}{z}, xmm2/m64/m16bcst | AVX512VL AVX512_FP16 | N8b2
	ops: w=reg r=rm | Packed64_Float16 Broadcast64_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtph2qq_zmm_k1z_xmmm128b16_er
INSTRUCTION: EVEX.512.66.MAP5.W0 7B /r | VCVTPH2QQ zmm1 {k1}{z}, xmm2/m128/m16bcst{er} | AVX512_FP16 | N16b2
	ops: wvmm=reg r=rm | Packed128_Float16 Broadcast128_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtph2udq_xmm_k1z_xmmm64b16
INSTRUCTION: EVEX.128.MAP5.W0 79 /r | VCVTPH2UDQ xmm1 {k1}{z}, xmm2/m64/m16bcst | AVX512VL AVX512_FP16 | N8b2
	ops: w=reg r=rm | Packed64_Float16 Broadcast64_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtph2udq_ymm_k1z_xmmm128b16
INSTRUCTION: EVEX.256.MAP5.W0 79 /r | VCVTPH2UDQ ymm1 {k1}{z}, xmm2/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: w=reg r=rm | Packed128_Float16 Broadcast128_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtph2udq_zmm_k1z_ymmm256b16_er
INSTRUCTION: EVEX.512.MAP5.W0 79 /r | VCVTPH2UDQ zmm1 {k1}{z}, ymm2/m256/m16bcst{er} | AVX512_FP16 | N32b2
	ops: wvmm=reg r=rm | Packed256_Float16 Broadcast256_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtph2uqq_xmm_k1z_xmmm32b16
INSTRUCTION: EVEX.128.66.MAP5.W0 79 /r | VCVTPH2UQQ xmm1 {k1}{z}, xmm2/m32/m16bcst | AVX512VL AVX512_FP16 | N4b2
	ops: w=reg r=rm | Packed32_Float16 Broadcast32_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtph2uqq_ymm_k1z_xmmm64b16
INSTRUCTION: EVEX.256.66.MAP5.W0 79 /r | VCVTPH2UQQ ymm1 {k1}{z}, xmm2/m64/m16bcst | AVX512VL AVX512_FP16 | N8b2
	ops: w=reg r=rm | Packed64_Float16 Broadcast64_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtph2uqq_zmm_k1z_xmmm128b16_er
INSTRUCTION: EVEX.512.66.MAP5.W0 79 /r | VCVTPH2UQQ zmm1 {k1}{z}, xmm2/m128/m16bcst{er} | AVX512_FP16 | N16b2
	ops: wvmm=reg r=rm | Packed128_Float16 Broadcast128_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtph2uw_xmm_k1z_xmmm128b16
INSTRUCTION: EVEX.128.MAP5.W0 7D /r | VCVTPH2UW xmm1 {k1}{z}, xmm2/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: w=reg r=rm | Packed128_Float16 Broadcast128_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtph2uw_ymm_k1z_ymmm256b16
INSTRUCTION: EVEX.256.MAP5.W0 7D /r | VCVTPH2UW ymm1 {k1}{z}, ymm2/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: w=reg r=rm | Packed256_Float16 Broadcast256_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtph2uw_zmm_k1z_zmmm512b16_er
INSTRUCTION: EVEX.512.MAP5.W0 7D /r | VCVTPH2UW zmm1 {k1}{z}, zmm2/m512/m16bcst{er} | AVX512_FP16 | N64b2
	ops: wvmm=reg r=rm | Packed512_Float16 Broadcast512_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtph2w_xmm_k1z_xmmm128b16
INSTRUCTION: EVEX.128.66.MAP5.W0 7D /r | VCVTPH2W xmm1 {k1}{z}, xmm2/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: w=reg r=rm | Packed128_Float16 Broadcast128_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtph2w_ymm_k1z_ymmm256b16
INSTRUCTION: EVEX.256.66.MAP5.W0 7D /r | VCVTPH2W ymm1 {k1}{z}, ymm2/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: w=reg r=rm | Packed256_Float16 Broadcast256_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtph2w_zmm_k1z_zmmm512b16_er
INSTRUCTION: EVEX.512.66.MAP5.W0 7D /r | VCVTPH2W zmm1 {k1}{z}, zmm2/m512/m16bcst{er} | AVX512_FP16 | N64b2
	ops: wvmm=reg r=rm | Packed512_Float16 Broadcast512_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtps2phx_xmm_k1z_xmmm128b32
INSTRUCTION: EVEX.128.66.MAP5.W0 1D /r | VCVTPS2PHX xmm1 {k1}{z}, xmm2/m128/m32bcst | AVX512VL AVX512_FP16 | N16b4
	ops: w=reg r=rm | Packed128_Float32 Broadcast128_Float32
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=x
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vcvtps2phx_xmm_k1z_ymmm256b32
INSTRUCTION: EVEX.256.66.MAP5.W0 1D /r | VCVTPS2PHX xmm1 {k1}{z}, ymm2/m256/m32bcst | AVX512VL AVX512_FP16 | N32b4
	ops: w=reg r=rm | Packed256_Float32 Broadcast256_Float32
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=y
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vcvtps2phx_ymm_k1z_zmmm512b32_er
INSTRUCTION: EVEX.512.66.MAP5.W0 1D /r | VCVTPS2PHX ymm1 {k1}{z}, zmm2/m512/m32bcst{er} | AVX512_FP16 | N64b4
	ops: w=reg r=rm | Packed512_Float32 Broadcast512_Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtqq2ph_xmm_k1z_xmmm128b64
INSTRUCTION: EVEX.128.MAP5.W1 5B /r | VCVTQQ2PH xmm1 {k1}{z}, xmm2/m128/m64bcst | AVX512VL AVX512_FP16 | N16b8
	ops: w=reg r=rm | Packed128_Int64 Broadcast128_Int64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=x
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vcvtqq2ph_xmm_k1z_ymmm256b64
INSTRUCTION: EVEX.256.MAP5.W1 5B /r | VCVTQQ2PH xmm1 {k1}{z}, ymm2/m256/m64bcst | AVX512VL AVX512_FP16 | N32b8
	ops: w=reg r=rm | Packed256_Int64 Broadcast256_Int64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=y
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vcvtqq2ph_xmm_k1z_zmmm512b64_er
INSTRUCTION: EVEX.512.MAP5.W1 5B /r | VCVTQQ2PH xmm1 {k1}{z}, zmm2/m512/m64bcst{er} | AVX512_FP16 | N64b8
	ops: w=reg r=rm | Packed512_Int64 Broadcast512_Int64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=z
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: EVEX_Vcvtsd2sh_xmm_k1z_xmm_xmmm64_er
INSTRUCTION: EVEX.LIG.F2.MAP5.W1 5A /r | VCVTSD2SH xmm1 {k1}{z}, xmm2, xmm3/m64{er} | AVX512_FP16 | N8
	ops: w=reg r=vvvv r=rm | Float64
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtsh2sd_xmm_k1z_xmm_xmmm16_sae
INSTRUCTION: EVEX.LIG.F3.MAP5.W0 5A /r | VCVTSH2SD xmm1 {k1}{z}, xmm2, xmm3/m16{sae} | AVX512_FP16 | N2
	ops: w=reg r=vvvv r=rm | Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtsh2si_r32_xmmm16_er
INSTRUCTION: EVEX.LIG.F3.MAP5.W0 2D /r | VCVTSH2SI r32, xmm1/m16{er} | AVX512_FP16 | N2
	ops: w=reg r=rm | Float16
	flags: wig32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtsh2si_r64_xmmm16_er
INSTRUCTION: EVEX.LIG.F3.MAP5.W1 2D /r | VCVTSH2SI r64, xmm1/m16{er} | AVX512_FP16 | N2
	ops: w=reg r=rm | Float16
	flags: 64
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtsh2ss_xmm_k1z_xmm_xmmm16_sae
INSTRUCTION: EVEX.LIG.MAP6.W0 13 /r | VCVTSH2SS xmm1 {k1}{z}, xmm2, xmm3/m16{sae} | AVX512_FP16 | N2
	ops: w=reg r=vvvv r=rm | Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtsh2usi_r32_xmmm16_er
INSTRUCTION: EVEX.LIG.F3.MAP5.W0 79 /r | VCVTSH2USI r32, xmm1/m16{er} | AVX512_FP16 | N2
	ops: w=reg r=rm | Float16
	flags: wig32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtsh2usi_r64_xmmm16_er
INSTRUCTION: EVEX.LIG.F3.MAP5.W1 79 /r | VCVTSH2USI r64, xmm1/m16{er} | AVX512_FP16 | N2
	ops: w=reg r=rm | Float16
	flags: 64
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtsi2sh_xmm_xmm_rm32_er
INSTRUCTION: EVEX.LIG.F3.MAP5.W0 2A /r | VCVTSI2SH xmm1, xmm2, r/m32{er} | AVX512_FP16 | N4
	ops: w=reg r=vvvv r=rm | Int32
	flags: wig32
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: EVEX_Vcvtsi2sh_xmm_xmm_rm64_er
INSTRUCTION: EVEX.LIG.F3.MAP5.W1 2A /r | VCVTSI2SH xmm1, xmm2, r/m64{er} | AVX512_FP16 | N8
	ops: w=reg r=vvvv r=rm | Int64
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: EVEX_Vcvtss2sh_xmm_k1z_xmm_xmmm32_er
INSTRUCTION: EVEX.LIG.MAP5.W0 1D /r | VCVTSS2SH xmm1 {k1}{z}, xmm2, xmm3/m32{er} | AVX512_FP16 | N4
	ops: w=reg r=vvvv r=rm | Float32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttph2dq_xmm_k1z_xmmm64b16
INSTRUCTION: EVEX.128.F3.MAP5.W0 5B /r | VCVTTPH2DQ xmm1 {k1}{z}, xmm2/m64/m16bcst | AVX512VL AVX512_FP16 | N8b2
	ops: w=reg r=rm | Packed64_Float16 Broadcast64_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttph2dq_ymm_k1z_xmmm128b16
INSTRUCTION: EVEX.256.F3.MAP5.W0 5B /r | VCVTTPH2DQ ymm1 {k1}{z}, xmm2/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: w=reg r=rm | Packed128_Float16 Broadcast128_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttph2dq_zmm_k1z_ymmm256b16_sae
INSTRUCTION: EVEX.512.F3.MAP5.W0 5B /r | VCVTTPH2DQ zmm1 {k1}{z}, ymm2/m256/m16bcst{sae} | AVX512_FP16 | N32b2
	ops: wvmm=reg r=rm | Packed256_Float16 Broadcast256_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttph2qq_xmm_k1z_xmmm32b16
INSTRUCTION: EVEX.128.66.MAP5.W0 7A /r | VCVTTPH2QQ xmm1 {k1}{z}, xmm2/m32/m16bcst | AVX512VL AVX512_FP16 | N4b2
	ops: w=reg r=rm | Packed32_Float16 Broadcast32_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttph2qq_ymm_k1z_xmmm64b16
INSTRUCTION: EVEX.256.66.MAP5.W0 7A /r | VCVTTPH2QQ ymm1 {k1}{z}, xmm2/m64/m16bcst | AVX512VL AVX512_FP16 | N8b2
	ops: w=reg r=rm | Packed64_Float16 Broadcast64_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttph2qq_zmm_k1z_xmmm128b16_sae
INSTRUCTION: EVEX.512.66.MAP5.W0 7A /r | VCVTTPH2QQ zmm1 {k1}{z}, xmm2/m128/m16bcst{sae} | AVX512_FP16 | N16b2
	ops: wvmm=reg r=rm | Packed128_Float16 Broadcast128_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttph2udq_xmm_k1z_xmmm64b16
INSTRUCTION: EVEX.128.MAP5.W0 78 /r | VCVTTPH2UDQ xmm1 {k1}{z}, xmm2/m64/m16bcst | AVX512VL AVX512_FP16 | N8b2
	ops: w=reg r=rm | Packed64_Float16 Broadcast64_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttph2udq_ymm_k1z_xmmm128b16
INSTRUCTION: EVEX.256.MAP5.W0 78 /r | VCVTTPH2UDQ ymm1 {k1}{z}, xmm2/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: w=reg r=rm | Packed128_Float16 Broadcast128_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttph2udq_zmm_k1z_ymmm256b16_sae
INSTRUCTION: EVEX.512.MAP5.W0 78 /r | VCVTTPH2UDQ zmm1 {k1}{z}, ymm2/m256/m16bcst{sae} | AVX512_FP16 | N32b2
	ops: wvmm=reg r=rm | Packed256_Float16 Broadcast256_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttph2uqq_xmm_k1z_xmmm32b16
INSTRUCTION: EVEX.128.66.MAP5.W0 78 /r | VCVTTPH2UQQ xmm1 {k1}{z}, xmm2/m32/m16bcst | AVX512VL AVX512_FP16 | N4b2
	ops: w=reg r=rm | Packed32_Float16 Broadcast32_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttph2uqq_ymm_k1z_xmmm64b16
INSTRUCTION: EVEX.256.66.MAP5.W0 78 /r | VCVTTPH2UQQ ymm1 {k1}{z}, xmm2/m64/m16bcst | AVX512VL AVX512_FP16 | N8b2
	ops: w=reg r=rm | Packed64_Float16 Broadcast64_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttph2uqq_zmm_k1z_xmmm128b16_sae
INSTRUCTION: EVEX.512.66.MAP5.W0 78 /r | VCVTTPH2UQQ zmm1 {k1}{z}, xmm2/m128/m16bcst{sae} | AVX512_FP16 | N16b2
	ops: wvmm=reg r=rm | Packed128_Float16 Broadcast128_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttph2uw_xmm_k1z_xmmm128b16
INSTRUCTION: EVEX.128.MAP5.W0 7C /r | VCVTTPH2UW xmm1 {k1}{z}, xmm2/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: w=reg r=rm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vcvttph2uw_ymm_k1z_ymmm256b16
INSTRUCTION: EVEX.256.MAP5.W0 7C /r | VCVTTPH2UW ymm1 {k1}{z}, ymm2/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: w=reg r=rm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vcvttph2uw_zmm_k1z_zmmm512b16_sae
INSTRUCTION: EVEX.512.MAP5.W0 7C /r | VCVTTPH2UW zmm1 {k1}{z}, zmm2/m512/m16bcst{sae} | AVX512_FP16 | N64b2
	ops: wvmm=reg r=rm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vcvttph2w_xmm_k1z_xmmm128b16
INSTRUCTION: EVEX.128.66.MAP5.W0 7C /r | VCVTTPH2W xmm1 {k1}{z}, xmm2/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: w=reg r=rm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vcvttph2w_ymm_k1z_ymmm256b16
INSTRUCTION: EVEX.256.66.MAP5.W0 7C /r | VCVTTPH2W ymm1 {k1}{z}, ymm2/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: w=reg r=rm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vcvttph2w_zmm_k1z_zmmm512b16_sae
INSTRUCTION: EVEX.512.66.MAP5.W0 7C /r | VCVTTPH2W zmm1 {k1}{z}, zmm2/m512/m16bcst{sae} | AVX512_FP16 | N64b2
	ops: wvmm=reg r=rm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vcvttsh2si_r32_xmmm16_sae
INSTRUCTION: EVEX.LIG.F3.MAP5.W0 2C /r | VCVTTSH2SI r32, xmm1/m16{sae} | AVX512_FP16 | N2
	ops: w=reg r=rm | Float16
	flags: wig32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttsh2si_r64_xmmm16_sae
INSTRUCTION: EVEX.LIG.F3.MAP5.W1 2C /r | VCVTTSH2SI r64, xmm1/m16{sae} | AVX512_FP16 | N2
	ops: w=reg r=rm | Float16
	flags: 64
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttsh2usi_r32_xmmm16_sae
INSTRUCTION: EVEX.LIG.F3.MAP5.W0 78 /r | VCVTTSH2USI r32, xmm1/m16{sae} | AVX512_FP16 | N2
	ops: w=reg r=rm | Float16
	flags: wig32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvttsh2usi_r64_xmmm16_sae
INSTRUCTION: EVEX.LIG.F3.MAP5.W1 78 /r | VCVTTSH2USI r64, xmm1/m16{sae} | AVX512_FP16 | N2
	ops: w=reg r=rm | Float16
	flags: 64
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtudq2ph_xmm_k1z_xmmm128b32
INSTRUCTION: EVEX.128.F2.MAP5.W0 7A /r | VCVTUDQ2PH xmm1 {k1}{z}, xmm2/m128/m32bcst | AVX512VL AVX512_FP16 | N16b4
	ops: w=reg r=rm | Packed128_UInt32 Broadcast128_UInt32
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=x
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vcvtudq2ph_xmm_k1z_ymmm256b32
INSTRUCTION: EVEX.256.F2.MAP5.W0 7A /r | VCVTUDQ2PH xmm1 {k1}{z}, ymm2/m256/m32bcst | AVX512VL AVX512_FP16 | N32b4
	ops: w=reg r=rm | Packed256_UInt32 Broadcast256_UInt32
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=y
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vcvtudq2ph_ymm_k1z_zmmm512b32_er
INSTRUCTION: EVEX.512.F2.MAP5.W0 7A /r | VCVTUDQ2PH ymm1 {k1}{z}, zmm2/m512/m32bcst{er} | AVX512_FP16 | N64b4
	ops: w=reg r=rm | Packed512_UInt32 Broadcast512_UInt32
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtuqq2ph_xmm_k1z_xmmm128b64
INSTRUCTION: EVEX.128.F2.MAP5.W1 7A /r | VCVTUQQ2PH xmm1 {k1}{z}, xmm2/m128/m64bcst | AVX512VL AVX512_FP16 | N16b8
	ops: w=reg r=rm | Packed128_UInt64 Broadcast128_UInt64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=x
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vcvtuqq2ph_xmm_k1z_ymmm256b64
INSTRUCTION: EVEX.256.F2.MAP5.W1 7A /r | VCVTUQQ2PH xmm1 {k1}{z}, ymm2/m256/m64bcst | AVX512VL AVX512_FP16 | N32b8
	ops: w=reg r=rm | Packed256_UInt64 Broadcast256_UInt64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=y
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vcvtuqq2ph_xmm_k1z_zmmm512b64_er
INSTRUCTION: EVEX.512.F2.MAP5.W1 7A /r | VCVTUQQ2PH xmm1 {k1}{z}, zmm2/m512/m64bcst{er} | AVX512_FP16 | N64b8
	ops: w=reg r=rm | Packed512_UInt64 Broadcast512_UInt64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=z
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: EVEX_Vcvtusi2sh_xmm_xmm_rm32_er
INSTRUCTION: EVEX.LIG.F3.MAP5.W0 7B /r | VCVTUSI2SH xmm1, xmm2, r/m32{er} | AVX512_FP16 | N4
	ops: w=reg r=vvvv r=rm | UInt32
	flags: wig32
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=l
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: EVEX_Vcvtusi2sh_xmm_xmm_rm64_er
INSTRUCTION: EVEX.LIG.F3.MAP5.W1 7B /r | VCVTUSI2SH xmm1, xmm2, r/m64{er} | AVX512_FP16 | N8
	ops: w=reg r=vvvv r=rm | UInt64
	flags: 64
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=q
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: EVEX_Vcvtuw2ph_xmm_k1z_xmmm128b16
INSTRUCTION: EVEX.128.F2.MAP5.W0 7D /r | VCVTUW2PH xmm1 {k1}{z}, xmm2/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: w=reg r=rm | Packed128_UInt16 Broadcast128_UInt16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtuw2ph_ymm_k1z_ymmm256b16
INSTRUCTION: EVEX.256.F2.MAP5.W0 7D /r | VCVTUW2PH ymm1 {k1}{z}, ymm2/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: w=reg r=rm | Packed256_UInt16 Broadcast256_UInt16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtuw2ph_zmm_k1z_zmmm512b16_er
INSTRUCTION: EVEX.512.F2.MAP5.W0 7D /r | VCVTUW2PH zmm1 {k1}{z}, zmm2/m512/m16bcst{er} | AVX512_FP16 | N64b2
	ops: wvmm=reg r=rm | Packed512_UInt16 Broadcast512_UInt16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtw2ph_xmm_k1z_xmmm128b16
INSTRUCTION: EVEX.128.F3.MAP5.W0 7D /r | VCVTW2PH xmm1 {k1}{z}, xmm2/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: w=reg r=rm | Packed128_Int16 Broadcast128_Int16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtw2ph_ymm_k1z_ymmm256b16
INSTRUCTION: EVEX.256.F3.MAP5.W0 7D /r | VCVTW2PH ymm1 {k1}{z}, ymm2/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: w=reg r=rm | Packed256_Int16 Broadcast256_Int16
	masm: flags=force-size=default
END

# Code: EVEX_Vcvtw2ph_zmm_k1z_zmmm512b16_er
INSTRUCTION: EVEX.512.F3.MAP5.W0 7D /r | VCVTW2PH zmm1 {k1}{z}, zmm2/m512/m16bcst{er} | AVX512_FP16 | N64b2
	ops: wvmm=reg r=rm | Packed512_Int16 Broadcast512_Int16
	masm: flags=force-size=default
END

# Code: EVEX_Vdivph_xmm_k1z_xmm_xmmm128b16
INSTRUCTION: EVEX.128.MAP5.W0 5E /r | VDIVPH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: w=reg r=vvvv r=rm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vdivph_ymm_k1z_ymm_ymmm256b16
INSTRUCTION: EVEX.256.MAP5.W0 5E /r | VDIVPH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: w=reg r=vvvv r=rm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vdivph_zmm_k1z_zmm_zmmm512b16_er
INSTRUCTION: EVEX.512.MAP5.W0 5E /r | VDIVPH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er} | AVX512_FP16 | N64b2
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vdivsh_xmm_k1z_xmm_xmmm16_er
INSTRUCTION: EVEX.LIG.F3.MAP5.W0 5E /r | VDIVSH xmm1 {k1}{z}, xmm2, xmm3/m16{er} | AVX512_FP16 | N2
	ops: w=reg r=vvvv r=rm | Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vfcmaddcph_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.F2.MAP6.W0 56 /r | VFCMADDCPH xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512_FP16 | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_2xFloat16 Broadcast128_2xFloat16
	flags: unique-dest-reg-num
END

# Code: EVEX_Vfcmaddcph_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.F2.MAP6.W0 56 /r | VFCMADDCPH ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512_FP16 | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_2xFloat16 Broadcast256_2xFloat16
	flags: unique-dest-reg-num
END

# Code: EVEX_Vfcmaddcph_zmm_k1z_zmm_zmmm512b32_er
INSTRUCTION: EVEX.512.F2.MAP6.W0 56 /r | VFCMADDCPH zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er} | AVX512_FP16 | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_2xFloat16 Broadcast512_2xFloat16
	flags: unique-dest-reg-num
END

# Code: EVEX_Vfmaddcph_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.F3.MAP6.W0 56 /r | VFMADDCPH xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512_FP16 | N16b4
	ops: rw=reg r=vvvv r=rm | Packed128_2xFloat16 Broadcast128_2xFloat16
	flags: unique-dest-reg-num
END

# Code: EVEX_Vfmaddcph_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.F3.MAP6.W0 56 /r | VFMADDCPH ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512_FP16 | N32b4
	ops: rw=reg r=vvvv r=rm | Packed256_2xFloat16 Broadcast256_2xFloat16
	flags: unique-dest-reg-num
END

# Code: EVEX_Vfmaddcph_zmm_k1z_zmm_zmmm512b32_er
INSTRUCTION: EVEX.512.F3.MAP6.W0 56 /r | VFMADDCPH zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er} | AVX512_FP16 | N64b4
	ops: rwvmm=reg r=vvvv r=rm | Packed512_2xFloat16 Broadcast512_2xFloat16
	flags: unique-dest-reg-num
END

# Code: EVEX_Vfcmaddcsh_xmm_k1z_xmm_xmmm32_er
INSTRUCTION: EVEX.LIG.F2.MAP6.W0 57 /r | VFCMADDCSH xmm1 {k1}{z}, xmm2, xmm3/m32{er} | AVX512_FP16 | N4
	ops: rw=reg r=vvvv r=rm | Packed32_Float16
	flags: unique-dest-reg-num
END

# Code: EVEX_Vfmaddcsh_xmm_k1z_xmm_xmmm32_er
INSTRUCTION: EVEX.LIG.F3.MAP6.W0 57 /r | VFMADDCSH xmm1 {k1}{z}, xmm2, xmm3/m32{er} | AVX512_FP16 | N4
	ops: rw=reg r=vvvv r=rm | Packed32_Float16
	flags: unique-dest-reg-num
END

# Code: EVEX_Vfcmulcph_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.F2.MAP6.W0 D6 /r | VFCMULCPH xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512_FP16 | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_2xFloat16 Broadcast128_2xFloat16
	flags: unique-dest-reg-num
END

# Code: EVEX_Vfcmulcph_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.F2.MAP6.W0 D6 /r | VFCMULCPH ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512_FP16 | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_2xFloat16 Broadcast256_2xFloat16
	flags: unique-dest-reg-num
END

# Code: EVEX_Vfcmulcph_zmm_k1z_zmm_zmmm512b32_er
INSTRUCTION: EVEX.512.F2.MAP6.W0 D6 /r | VFCMULCPH zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er} | AVX512_FP16 | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_2xFloat16 Broadcast512_2xFloat16
	flags: unique-dest-reg-num
END

# Code: EVEX_Vfmulcph_xmm_k1z_xmm_xmmm128b32
INSTRUCTION: EVEX.128.F3.MAP6.W0 D6 /r | VFMULCPH xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst | AVX512VL AVX512_FP16 | N16b4
	ops: w=reg r=vvvv r=rm | Packed128_2xFloat16 Broadcast128_2xFloat16
	flags: unique-dest-reg-num
END

# Code: EVEX_Vfmulcph_ymm_k1z_ymm_ymmm256b32
INSTRUCTION: EVEX.256.F3.MAP6.W0 D6 /r | VFMULCPH ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst | AVX512VL AVX512_FP16 | N32b4
	ops: w=reg r=vvvv r=rm | Packed256_2xFloat16 Broadcast256_2xFloat16
	flags: unique-dest-reg-num
END

# Code: EVEX_Vfmulcph_zmm_k1z_zmm_zmmm512b32_er
INSTRUCTION: EVEX.512.F3.MAP6.W0 D6 /r | VFMULCPH zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er} | AVX512_FP16 | N64b4
	ops: wvmm=reg r=vvvv r=rm | Packed512_2xFloat16 Broadcast512_2xFloat16
	flags: unique-dest-reg-num
END

# Code: EVEX_Vfcmulcsh_xmm_k1z_xmm_xmmm32_er
INSTRUCTION: EVEX.LIG.F2.MAP6.W0 D7 /r | VFCMULCSH xmm1 {k1}{z}, xmm2, xmm3/m32{er} | AVX512_FP16 | N4
	ops: w=reg r=vvvv r=rm | Packed32_Float16
	flags: unique-dest-reg-num
END

# Code: EVEX_Vfmulcsh_xmm_k1z_xmm_xmmm32_er
INSTRUCTION: EVEX.LIG.F3.MAP6.W0 D7 /r | VFMULCSH xmm1 {k1}{z}, xmm2, xmm3/m32{er} | AVX512_FP16 | N4
	ops: w=reg r=vvvv r=rm | Packed32_Float16
	flags: unique-dest-reg-num
END

# Code: EVEX_Vfmaddsub132ph_xmm_k1z_xmm_xmmm128b16
INSTRUCTION: EVEX.128.66.MAP6.W0 96 /r | VFMADDSUB132PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: rw=reg r=vvvv r=rm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vfmaddsub132ph_ymm_k1z_ymm_ymmm256b16
INSTRUCTION: EVEX.256.66.MAP6.W0 96 /r | VFMADDSUB132PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: rw=reg r=vvvv r=rm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vfmaddsub132ph_zmm_k1z_zmm_zmmm512b16_er
INSTRUCTION: EVEX.512.66.MAP6.W0 96 /r | VFMADDSUB132PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er} | AVX512_FP16 | N64b2
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vfmaddsub213ph_xmm_k1z_xmm_xmmm128b16
INSTRUCTION: EVEX.128.66.MAP6.W0 A6 /r | VFMADDSUB213PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: rw=reg r=vvvv r=rm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vfmaddsub213ph_ymm_k1z_ymm_ymmm256b16
INSTRUCTION: EVEX.256.66.MAP6.W0 A6 /r | VFMADDSUB213PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: rw=reg r=vvvv r=rm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vfmaddsub213ph_zmm_k1z_zmm_zmmm512b16_er
INSTRUCTION: EVEX.512.66.MAP6.W0 A6 /r | VFMADDSUB213PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er} | AVX512_FP16 | N64b2
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vfmaddsub231ph_xmm_k1z_xmm_xmmm128b16
INSTRUCTION: EVEX.128.66.MAP6.W0 B6 /r | VFMADDSUB231PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: rw=reg r=vvvv r=rm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vfmaddsub231ph_ymm_k1z_ymm_ymmm256b16
INSTRUCTION: EVEX.256.66.MAP6.W0 B6 /r | VFMADDSUB231PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: rw=reg r=vvvv r=rm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vfmaddsub231ph_zmm_k1z_zmm_zmmm512b16_er
INSTRUCTION: EVEX.512.66.MAP6.W0 B6 /r | VFMADDSUB231PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er} | AVX512_FP16 | N64b2
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vfmsubadd132ph_xmm_k1z_xmm_xmmm128b16
INSTRUCTION: EVEX.128.66.MAP6.W0 97 /r | VFMSUBADD132PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: rw=reg r=vvvv r=rm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vfmsubadd132ph_ymm_k1z_ymm_ymmm256b16
INSTRUCTION: EVEX.256.66.MAP6.W0 97 /r | VFMSUBADD132PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: rw=reg r=vvvv r=rm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vfmsubadd132ph_zmm_k1z_zmm_zmmm512b16_er
INSTRUCTION: EVEX.512.66.MAP6.W0 97 /r | VFMSUBADD132PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er} | AVX512_FP16 | N64b2
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vfmsubadd213ph_xmm_k1z_xmm_xmmm128b16
INSTRUCTION: EVEX.128.66.MAP6.W0 A7 /r | VFMSUBADD213PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: rw=reg r=vvvv r=rm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vfmsubadd213ph_ymm_k1z_ymm_ymmm256b16
INSTRUCTION: EVEX.256.66.MAP6.W0 A7 /r | VFMSUBADD213PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: rw=reg r=vvvv r=rm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vfmsubadd213ph_zmm_k1z_zmm_zmmm512b16_er
INSTRUCTION: EVEX.512.66.MAP6.W0 A7 /r | VFMSUBADD213PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er} | AVX512_FP16 | N64b2
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vfmsubadd231ph_xmm_k1z_xmm_xmmm128b16
INSTRUCTION: EVEX.128.66.MAP6.W0 B7 /r | VFMSUBADD231PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: rw=reg r=vvvv r=rm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vfmsubadd231ph_ymm_k1z_ymm_ymmm256b16
INSTRUCTION: EVEX.256.66.MAP6.W0 B7 /r | VFMSUBADD231PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: rw=reg r=vvvv r=rm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vfmsubadd231ph_zmm_k1z_zmm_zmmm512b16_er
INSTRUCTION: EVEX.512.66.MAP6.W0 B7 /r | VFMSUBADD231PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er} | AVX512_FP16 | N64b2
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vfmadd132ph_xmm_k1z_xmm_xmmm128b16
INSTRUCTION: EVEX.128.66.MAP6.W0 98 /r | VFMADD132PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: rw=reg r=vvvv r=rm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vfmadd132ph_ymm_k1z_ymm_ymmm256b16
INSTRUCTION: EVEX.256.66.MAP6.W0 98 /r | VFMADD132PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: rw=reg r=vvvv r=rm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vfmadd132ph_zmm_k1z_zmm_zmmm512b16_er
INSTRUCTION: EVEX.512.66.MAP6.W0 98 /r | VFMADD132PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er} | AVX512_FP16 | N64b2
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vfmadd213ph_xmm_k1z_xmm_xmmm128b16
INSTRUCTION: EVEX.128.66.MAP6.W0 A8 /r | VFMADD213PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: rw=reg r=vvvv r=rm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vfmadd213ph_ymm_k1z_ymm_ymmm256b16
INSTRUCTION: EVEX.256.66.MAP6.W0 A8 /r | VFMADD213PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: rw=reg r=vvvv r=rm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vfmadd213ph_zmm_k1z_zmm_zmmm512b16_er
INSTRUCTION: EVEX.512.66.MAP6.W0 A8 /r | VFMADD213PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er} | AVX512_FP16 | N64b2
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vfmadd231ph_xmm_k1z_xmm_xmmm128b16
INSTRUCTION: EVEX.128.66.MAP6.W0 B8 /r | VFMADD231PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: rw=reg r=vvvv r=rm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vfmadd231ph_ymm_k1z_ymm_ymmm256b16
INSTRUCTION: EVEX.256.66.MAP6.W0 B8 /r | VFMADD231PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: rw=reg r=vvvv r=rm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vfmadd231ph_zmm_k1z_zmm_zmmm512b16_er
INSTRUCTION: EVEX.512.66.MAP6.W0 B8 /r | VFMADD231PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er} | AVX512_FP16 | N64b2
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vfnmadd132ph_xmm_k1z_xmm_xmmm128b16
INSTRUCTION: EVEX.128.66.MAP6.W0 9C /r | VFNMADD132PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: rw=reg r=vvvv r=rm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vfnmadd132ph_ymm_k1z_ymm_ymmm256b16
INSTRUCTION: EVEX.256.66.MAP6.W0 9C /r | VFNMADD132PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: rw=reg r=vvvv r=rm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vfnmadd132ph_zmm_k1z_zmm_zmmm512b16_er
INSTRUCTION: EVEX.512.66.MAP6.W0 9C /r | VFNMADD132PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er} | AVX512_FP16 | N64b2
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vfnmadd213ph_xmm_k1z_xmm_xmmm128b16
INSTRUCTION: EVEX.128.66.MAP6.W0 AC /r | VFNMADD213PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: rw=reg r=vvvv r=rm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vfnmadd213ph_ymm_k1z_ymm_ymmm256b16
INSTRUCTION: EVEX.256.66.MAP6.W0 AC /r | VFNMADD213PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: rw=reg r=vvvv r=rm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vfnmadd213ph_zmm_k1z_zmm_zmmm512b16_er
INSTRUCTION: EVEX.512.66.MAP6.W0 AC /r | VFNMADD213PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er} | AVX512_FP16 | N64b2
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vfnmadd231ph_xmm_k1z_xmm_xmmm128b16
INSTRUCTION: EVEX.128.66.MAP6.W0 BC /r | VFNMADD231PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: rw=reg r=vvvv r=rm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vfnmadd231ph_ymm_k1z_ymm_ymmm256b16
INSTRUCTION: EVEX.256.66.MAP6.W0 BC /r | VFNMADD231PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: rw=reg r=vvvv r=rm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vfnmadd231ph_zmm_k1z_zmm_zmmm512b16_er
INSTRUCTION: EVEX.512.66.MAP6.W0 BC /r | VFNMADD231PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er} | AVX512_FP16 | N64b2
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vfmadd132sh_xmm_k1z_xmm_xmmm16_er
INSTRUCTION: EVEX.LIG.66.MAP6.W0 99 /r | VFMADD132SH xmm1 {k1}{z}, xmm2, xmm3/m16{er} | AVX512_FP16 | N2
	ops: rw=reg r=vvvv r=rm | Float16
END

# Code: EVEX_Vfmadd213sh_xmm_k1z_xmm_xmmm16_er
INSTRUCTION: EVEX.LIG.66.MAP6.W0 A9 /r | VFMADD213SH xmm1 {k1}{z}, xmm2, xmm3/m16{er} | AVX512_FP16 | N2
	ops: rw=reg r=vvvv r=rm | Float16
END

# Code: EVEX_Vfmadd231sh_xmm_k1z_xmm_xmmm16_er
INSTRUCTION: EVEX.LIG.66.MAP6.W0 B9 /r | VFMADD231SH xmm1 {k1}{z}, xmm2, xmm3/m16{er} | AVX512_FP16 | N2
	ops: rw=reg r=vvvv r=rm | Float16
END

# Code: EVEX_Vfnmadd132sh_xmm_k1z_xmm_xmmm16_er
INSTRUCTION: EVEX.LIG.66.MAP6.W0 9D /r | VFNMADD132SH xmm1 {k1}{z}, xmm2, xmm3/m16{er} | AVX512_FP16 | N2
	ops: rw=reg r=vvvv r=rm | Float16
END

# Code: EVEX_Vfnmadd213sh_xmm_k1z_xmm_xmmm16_er
INSTRUCTION: EVEX.LIG.66.MAP6.W0 AD /r | VFNMADD213SH xmm1 {k1}{z}, xmm2, xmm3/m16{er} | AVX512_FP16 | N2
	ops: rw=reg r=vvvv r=rm | Float16
END

# Code: EVEX_Vfnmadd231sh_xmm_k1z_xmm_xmmm16_er
INSTRUCTION: EVEX.LIG.66.MAP6.W0 BD /r | VFNMADD231SH xmm1 {k1}{z}, xmm2, xmm3/m16{er} | AVX512_FP16 | N2
	ops: rw=reg r=vvvv r=rm | Float16
END

# Code: EVEX_Vfmsub132ph_xmm_k1z_xmm_xmmm128b16
INSTRUCTION: EVEX.128.66.MAP6.W0 9A /r | VFMSUB132PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: rw=reg r=vvvv r=rm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vfmsub132ph_ymm_k1z_ymm_ymmm256b16
INSTRUCTION: EVEX.256.66.MAP6.W0 9A /r | VFMSUB132PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: rw=reg r=vvvv r=rm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vfmsub132ph_zmm_k1z_zmm_zmmm512b16_er
INSTRUCTION: EVEX.512.66.MAP6.W0 9A /r | VFMSUB132PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er} | AVX512_FP16 | N64b2
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vfmsub213ph_xmm_k1z_xmm_xmmm128b16
INSTRUCTION: EVEX.128.66.MAP6.W0 AA /r | VFMSUB213PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: rw=reg r=vvvv r=rm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vfmsub213ph_ymm_k1z_ymm_ymmm256b16
INSTRUCTION: EVEX.256.66.MAP6.W0 AA /r | VFMSUB213PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: rw=reg r=vvvv r=rm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vfmsub213ph_zmm_k1z_zmm_zmmm512b16_er
INSTRUCTION: EVEX.512.66.MAP6.W0 AA /r | VFMSUB213PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er} | AVX512_FP16 | N64b2
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vfmsub231ph_xmm_k1z_xmm_xmmm128b16
INSTRUCTION: EVEX.128.66.MAP6.W0 BA /r | VFMSUB231PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: rw=reg r=vvvv r=rm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vfmsub231ph_ymm_k1z_ymm_ymmm256b16
INSTRUCTION: EVEX.256.66.MAP6.W0 BA /r | VFMSUB231PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: rw=reg r=vvvv r=rm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vfmsub231ph_zmm_k1z_zmm_zmmm512b16_er
INSTRUCTION: EVEX.512.66.MAP6.W0 BA /r | VFMSUB231PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er} | AVX512_FP16 | N64b2
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vfnmsub132ph_xmm_k1z_xmm_xmmm128b16
INSTRUCTION: EVEX.128.66.MAP6.W0 9E /r | VFNMSUB132PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: rw=reg r=vvvv r=rm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vfnmsub132ph_ymm_k1z_ymm_ymmm256b16
INSTRUCTION: EVEX.256.66.MAP6.W0 9E /r | VFNMSUB132PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: rw=reg r=vvvv r=rm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vfnmsub132ph_zmm_k1z_zmm_zmmm512b16_er
INSTRUCTION: EVEX.512.66.MAP6.W0 9E /r | VFNMSUB132PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er} | AVX512_FP16 | N64b2
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vfnmsub213ph_xmm_k1z_xmm_xmmm128b16
INSTRUCTION: EVEX.128.66.MAP6.W0 AE /r | VFNMSUB213PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: rw=reg r=vvvv r=rm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vfnmsub213ph_ymm_k1z_ymm_ymmm256b16
INSTRUCTION: EVEX.256.66.MAP6.W0 AE /r | VFNMSUB213PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: rw=reg r=vvvv r=rm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vfnmsub213ph_zmm_k1z_zmm_zmmm512b16_er
INSTRUCTION: EVEX.512.66.MAP6.W0 AE /r | VFNMSUB213PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er} | AVX512_FP16 | N64b2
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vfnmsub231ph_xmm_k1z_xmm_xmmm128b16
INSTRUCTION: EVEX.128.66.MAP6.W0 BE /r | VFNMSUB231PH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: rw=reg r=vvvv r=rm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vfnmsub231ph_ymm_k1z_ymm_ymmm256b16
INSTRUCTION: EVEX.256.66.MAP6.W0 BE /r | VFNMSUB231PH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: rw=reg r=vvvv r=rm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vfnmsub231ph_zmm_k1z_zmm_zmmm512b16_er
INSTRUCTION: EVEX.512.66.MAP6.W0 BE /r | VFNMSUB231PH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er} | AVX512_FP16 | N64b2
	ops: rwvmm=reg r=vvvv r=rm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vfmsub132sh_xmm_k1z_xmm_xmmm16_er
INSTRUCTION: EVEX.LIG.66.MAP6.W0 9B /r | VFMSUB132SH xmm1 {k1}{z}, xmm2, xmm3/m16{er} | AVX512_FP16 | N2
	ops: rw=reg r=vvvv r=rm | Float16
END

# Code: EVEX_Vfmsub213sh_xmm_k1z_xmm_xmmm16_er
INSTRUCTION: EVEX.LIG.66.MAP6.W0 AB /r | VFMSUB213SH xmm1 {k1}{z}, xmm2, xmm3/m16{er} | AVX512_FP16 | N2
	ops: rw=reg r=vvvv r=rm | Float16
END

# Code: EVEX_Vfmsub231sh_xmm_k1z_xmm_xmmm16_er
INSTRUCTION: EVEX.LIG.66.MAP6.W0 BB /r | VFMSUB231SH xmm1 {k1}{z}, xmm2, xmm3/m16{er} | AVX512_FP16 | N2
	ops: rw=reg r=vvvv r=rm | Float16
END

# Code: EVEX_Vfnmsub132sh_xmm_k1z_xmm_xmmm16_er
INSTRUCTION: EVEX.LIG.66.MAP6.W0 9F /r | VFNMSUB132SH xmm1 {k1}{z}, xmm2, xmm3/m16{er} | AVX512_FP16 | N2
	ops: rw=reg r=vvvv r=rm | Float16
END

# Code: EVEX_Vfnmsub213sh_xmm_k1z_xmm_xmmm16_er
INSTRUCTION: EVEX.LIG.66.MAP6.W0 AF /r | VFNMSUB213SH xmm1 {k1}{z}, xmm2, xmm3/m16{er} | AVX512_FP16 | N2
	ops: rw=reg r=vvvv r=rm | Float16
END

# Code: EVEX_Vfnmsub231sh_xmm_k1z_xmm_xmmm16_er
INSTRUCTION: EVEX.LIG.66.MAP6.W0 BF /r | VFNMSUB231SH xmm1 {k1}{z}, xmm2, xmm3/m16{er} | AVX512_FP16 | N2
	ops: rw=reg r=vvvv r=rm | Float16
END

# Code: EVEX_Vfpclassph_kr_k1_xmmm128b16_imm8
INSTRUCTION: EVEX.128.0F3A.W0 66 /r ib | VFPCLASSPH k1 {k2}, xmm2/m128/m16bcst, imm8 | AVX512VL AVX512_FP16 | N16b2
	ops: w=reg r=rm r=imm | Packed128_Float16 Broadcast128_Float16
	flags: implied-z
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=x
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vfpclassph_kr_k1_ymmm256b16_imm8
INSTRUCTION: EVEX.256.0F3A.W0 66 /r ib | VFPCLASSPH k1 {k2}, ymm2/m256/m16bcst, imm8 | AVX512VL AVX512_FP16 | N32b2
	ops: w=reg r=rm r=imm | Packed256_Float16 Broadcast256_Float16
	flags: implied-z
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=y
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vfpclassph_kr_k1_zmmm512b16_imm8
INSTRUCTION: EVEX.512.0F3A.W0 66 /r ib | VFPCLASSPH k1 {k2}, zmm2/m512/m16bcst, imm8 | AVX512_FP16 | N64b2
	ops: w=reg r=rm r=imm | Packed512_Float16 Broadcast512_Float16
	flags: implied-z
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=z
	intel: flags=force-size=always bcst
	masm: flags=force-size=always
	nasm: flags=force-size=always bcst
END

# Code: EVEX_Vfpclasssh_kr_k1_xmmm16_imm8
INSTRUCTION: EVEX.LIG.0F3A.W0 67 /r ib | VFPCLASSSH k1 {k2}, xmm2/m16, imm8 | AVX512_FP16 | N2
	ops: w=reg r=rm r=imm | Float16
	flags: implied-z
	masm: flags=force-size=default
END

# Code: EVEX_Vgetexpph_xmm_k1z_xmmm128b16
INSTRUCTION: EVEX.128.66.MAP6.W0 42 /r | VGETEXPPH xmm1 {k1}{z}, xmm2/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: w=reg r=rm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vgetexpph_ymm_k1z_ymmm256b16
INSTRUCTION: EVEX.256.66.MAP6.W0 42 /r | VGETEXPPH ymm1 {k1}{z}, ymm2/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: w=reg r=rm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vgetexpph_zmm_k1z_zmmm512b16_sae
INSTRUCTION: EVEX.512.66.MAP6.W0 42 /r | VGETEXPPH zmm1 {k1}{z}, zmm2/m512/m16bcst{sae} | AVX512_FP16 | N64b2
	ops: wvmm=reg r=rm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vgetexpsh_xmm_k1z_xmm_xmmm16_sae
INSTRUCTION: EVEX.LIG.66.MAP6.W0 43 /r | VGETEXPSH xmm1 {k1}{z}, xmm2, xmm3/m16{sae} | AVX512_FP16 | N2
	ops: w=reg r=vvvv r=rm | Float16
END

# Code: EVEX_Vgetmantph_xmm_k1z_xmmm128b16_imm8
INSTRUCTION: EVEX.128.0F3A.W0 26 /r ib | VGETMANTPH xmm1 {k1}{z}, xmm2/m128/m16bcst, imm8 | AVX512VL AVX512_FP16 | N16b2
	ops: w=reg r=rm r=imm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vgetmantph_ymm_k1z_ymmm256b16_imm8
INSTRUCTION: EVEX.256.0F3A.W0 26 /r ib | VGETMANTPH ymm1 {k1}{z}, ymm2/m256/m16bcst, imm8 | AVX512VL AVX512_FP16 | N32b2
	ops: w=reg r=rm r=imm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vgetmantph_zmm_k1z_zmmm512b16_imm8_sae
INSTRUCTION: EVEX.512.0F3A.W0 26 /r ib | VGETMANTPH zmm1 {k1}{z}, zmm2/m512/m16bcst{sae}, imm8 | AVX512_FP16 | N64b2
	ops: wvmm=reg r=rm r=imm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vgetmantsh_xmm_k1z_xmm_xmmm16_imm8_sae
INSTRUCTION: EVEX.LIG.0F3A.W0 27 /r ib | VGETMANTSH xmm1 {k1}{z}, xmm2, xmm3/m16{sae}, imm8 | AVX512_FP16 | N2
	ops: w=reg r=vvvv r=rm r=imm | Float16
END

# Code: EVEX_Vmaxph_xmm_k1z_xmm_xmmm128b16
INSTRUCTION: EVEX.128.MAP5.W0 5F /r | VMAXPH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: w=reg r=vvvv r=rm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vmaxph_ymm_k1z_ymm_ymmm256b16
INSTRUCTION: EVEX.256.MAP5.W0 5F /r | VMAXPH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: w=reg r=vvvv r=rm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vmaxph_zmm_k1z_zmm_zmmm512b16_sae
INSTRUCTION: EVEX.512.MAP5.W0 5F /r | VMAXPH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{sae} | AVX512_FP16 | N64b2
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vmaxsh_xmm_k1z_xmm_xmmm16_sae
INSTRUCTION: EVEX.LIG.F3.MAP5.W0 5F /r | VMAXSH xmm1 {k1}{z}, xmm2, xmm3/m16{sae} | AVX512_FP16 | N2
	ops: w=reg r=vvvv r=rm | Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vminph_xmm_k1z_xmm_xmmm128b16
INSTRUCTION: EVEX.128.MAP5.W0 5D /r | VMINPH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: w=reg r=vvvv r=rm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vminph_ymm_k1z_ymm_ymmm256b16
INSTRUCTION: EVEX.256.MAP5.W0 5D /r | VMINPH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: w=reg r=vvvv r=rm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vminph_zmm_k1z_zmm_zmmm512b16_sae
INSTRUCTION: EVEX.512.MAP5.W0 5D /r | VMINPH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{sae} | AVX512_FP16 | N64b2
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vminsh_xmm_k1z_xmm_xmmm16_sae
INSTRUCTION: EVEX.LIG.F3.MAP5.W0 5D /r | VMINSH xmm1 {k1}{z}, xmm2, xmm3/m16{sae} | AVX512_FP16 | N2
	ops: w=reg r=vvvv r=rm | Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vmovsh_xmm_k1z_m16
INSTRUCTION: EVEX.LIG.F3.MAP5.W0 10 /r | VMOVSH xmm1 {k1}{z}, m16 | AVX512_FP16 | N2
	ops: w=reg r=rm | Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vmovsh_m16_k1_xmm
INSTRUCTION: EVEX.LIG.F3.MAP5.W0 11 /r | VMOVSH m16 {k1}, xmm1 | AVX512_FP16 | N2
	ops: w=rm r=reg | Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vmovsh_xmm_k1z_xmm_xmm
INSTRUCTION: EVEX.LIG.F3.MAP5.W0 10 /r | VMOVSH xmm1 {k1}{z}, xmm2, xmm3 | AVX512_FP16
	ops: w=reg r=vvvv r=rm
	masm: flags=force-size=default
END

# Code: EVEX_Vmovsh_xmm_k1z_xmm_xmm_MAP5_11
INSTRUCTION: EVEX.LIG.F3.MAP5.W0 11 /r | VMOVSH xmm1 {k1}{z}, xmm2, xmm3 | AVX512_FP16
	ops: w=rm r=vvvv r=reg
	code-suffix: MAP5_11
	flags: asm-ig
END

# Code: EVEX_Vmovw_xmm_r32m16
INSTRUCTION: EVEX.128.66.MAP5.W0 6E /r | VMOVW xmm1, r32/m16 | AVX512_FP16 | N2
	ops: w=reg r=rm | UInt16
	implied: last-gpr-16
	flags: wig32
	gas: reg32
	intel: reg32
	masm: flags=force-size=default reg32
	nasm: reg32
END

# Code: EVEX_Vmovw_xmm_r64m16
INSTRUCTION: EVEX.128.66.MAP5.W1 6E /r | VMOVW xmm1, r64/m16 | AVX512_FP16 | N2
	ops: w=reg r=rm | UInt16
	implied: last-gpr-16
	flags: 64
	gas: reg32
	intel: reg32
	masm: flags=force-size=default reg32
	nasm: reg32
END

# Code: EVEX_Vmovw_r32m16_xmm
INSTRUCTION: EVEX.128.66.MAP5.W0 7E /r | VMOVW r32/m16, xmm1 | AVX512_FP16 | N2
	ops: w=rm r=reg | UInt16
	flags: wig32
	gas: reg32
	intel: reg32
	masm: flags=force-size=default reg32
	nasm: reg32
END

# Code: EVEX_Vmovw_r64m16_xmm
INSTRUCTION: EVEX.128.66.MAP5.W1 7E /r | VMOVW r64/m16, xmm1 | AVX512_FP16 | N2
	ops: w=rm r=reg | UInt16
	flags: 64
	gas: reg32
	intel: reg32
	masm: flags=force-size=default reg32
	nasm: reg32
END

# Code: EVEX_Vmulph_xmm_k1z_xmm_xmmm128b16
INSTRUCTION: EVEX.128.MAP5.W0 59 /r | VMULPH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: w=reg r=vvvv r=rm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vmulph_ymm_k1z_ymm_ymmm256b16
INSTRUCTION: EVEX.256.MAP5.W0 59 /r | VMULPH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: w=reg r=vvvv r=rm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vmulph_zmm_k1z_zmm_zmmm512b16_er
INSTRUCTION: EVEX.512.MAP5.W0 59 /r | VMULPH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er} | AVX512_FP16 | N64b2
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vmulsh_xmm_k1z_xmm_xmmm16_er
INSTRUCTION: EVEX.LIG.F3.MAP5.W0 59 /r | VMULSH xmm1 {k1}{z}, xmm2, xmm3/m16{er} | AVX512_FP16 | N2
	ops: w=reg r=vvvv r=rm | Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vrcpph_xmm_k1z_xmmm128b16
INSTRUCTION: EVEX.128.66.MAP6.W0 4C /r | VRCPPH xmm1 {k1}{z}, xmm2/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: w=reg r=rm | Packed128_Float16 Broadcast128_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vrcpph_ymm_k1z_ymmm256b16
INSTRUCTION: EVEX.256.66.MAP6.W0 4C /r | VRCPPH ymm1 {k1}{z}, ymm2/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: w=reg r=rm | Packed256_Float16 Broadcast256_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vrcpph_zmm_k1z_zmmm512b16
INSTRUCTION: EVEX.512.66.MAP6.W0 4C /r | VRCPPH zmm1 {k1}{z}, zmm2/m512/m16bcst | AVX512_FP16 | N64b2
	ops: wvmm=reg r=rm | Packed512_Float16 Broadcast512_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vrcpsh_xmm_k1z_xmm_xmmm16
INSTRUCTION: EVEX.LIG.66.MAP6.W0 4D /r | VRCPSH xmm1 {k1}{z}, xmm2, xmm3/m16 | AVX512_FP16 | N2
	ops: w=reg r=vvvv r=rm | Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vreduceph_xmm_k1z_xmmm128b16_imm8
INSTRUCTION: EVEX.128.0F3A.W0 56 /r ib | VREDUCEPH xmm1 {k1}{z}, xmm2/m128/m16bcst, imm8 | AVX512VL AVX512_FP16 | N16b2
	ops: w=reg r=rm r=imm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vreduceph_ymm_k1z_ymmm256b16_imm8
INSTRUCTION: EVEX.256.0F3A.W0 56 /r ib | VREDUCEPH ymm1 {k1}{z}, ymm2/m256/m16bcst, imm8 | AVX512VL AVX512_FP16 | N32b2
	ops: w=reg r=rm r=imm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vreduceph_zmm_k1z_zmmm512b16_imm8_sae
INSTRUCTION: EVEX.512.0F3A.W0 56 /r ib | VREDUCEPH zmm1 {k1}{z}, zmm2/m512/m16bcst{sae}, imm8 | AVX512_FP16 | N64b2
	ops: wvmm=reg r=rm r=imm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vreducesh_xmm_k1z_xmm_xmmm16_imm8_sae
INSTRUCTION: EVEX.LIG.0F3A.W0 57 /r ib | VREDUCESH xmm1 {k1}{z}, xmm2, xmm3/m16{sae}, imm8 | AVX512_FP16 | N2
	ops: w=reg r=vvvv r=rm r=imm | Float16
END

# Code: EVEX_Vrndscaleph_xmm_k1z_xmmm128b16_imm8
INSTRUCTION: EVEX.128.0F3A.W0 08 /r ib | VRNDSCALEPH xmm1 {k1}{z}, xmm2/m128/m16bcst, imm8 | AVX512VL AVX512_FP16 | N16b2
	ops: w=reg r=rm r=imm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vrndscaleph_ymm_k1z_ymmm256b16_imm8
INSTRUCTION: EVEX.256.0F3A.W0 08 /r ib | VRNDSCALEPH ymm1 {k1}{z}, ymm2/m256/m16bcst, imm8 | AVX512VL AVX512_FP16 | N32b2
	ops: w=reg r=rm r=imm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vrndscaleph_zmm_k1z_zmmm512b16_imm8_sae
INSTRUCTION: EVEX.512.0F3A.W0 08 /r ib | VRNDSCALEPH zmm1 {k1}{z}, zmm2/m512/m16bcst{sae}, imm8 | AVX512_FP16 | N64b2
	ops: wvmm=reg r=rm r=imm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vrndscalesh_xmm_k1z_xmm_xmmm16_imm8_sae
INSTRUCTION: EVEX.LIG.0F3A.W0 0A /r ib | VRNDSCALESH xmm1 {k1}{z}, xmm2, xmm3/m16{sae}, imm8 | AVX512_FP16 | N2
	ops: w=reg r=vvvv r=rm r=imm | Float16
END

# Code: EVEX_Vrsqrtph_xmm_k1z_xmmm128b16
INSTRUCTION: EVEX.128.66.MAP6.W0 4E /r | VRSQRTPH xmm1 {k1}{z}, xmm2/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: w=reg r=rm | Packed128_Float16 Broadcast128_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vrsqrtph_ymm_k1z_ymmm256b16
INSTRUCTION: EVEX.256.66.MAP6.W0 4E /r | VRSQRTPH ymm1 {k1}{z}, ymm2/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: w=reg r=rm | Packed256_Float16 Broadcast256_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vrsqrtph_zmm_k1z_zmmm512b16
INSTRUCTION: EVEX.512.66.MAP6.W0 4E /r | VRSQRTPH zmm1 {k1}{z}, zmm2/m512/m16bcst | AVX512_FP16 | N64b2
	ops: wvmm=reg r=rm | Packed512_Float16 Broadcast512_Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vrsqrtsh_xmm_k1z_xmm_xmmm16
INSTRUCTION: EVEX.LIG.66.MAP6.W0 4F /r | VRSQRTSH xmm1 {k1}{z}, xmm2, xmm3/m16 | AVX512_FP16 | N2
	ops: w=reg r=vvvv r=rm | Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vscalefph_xmm_k1z_xmm_xmmm128b16
INSTRUCTION: EVEX.128.66.MAP6.W0 2C /r | VSCALEFPH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: w=reg r=vvvv r=rm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vscalefph_ymm_k1z_ymm_ymmm256b16
INSTRUCTION: EVEX.256.66.MAP6.W0 2C /r | VSCALEFPH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: w=reg r=vvvv r=rm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vscalefph_zmm_k1z_zmm_zmmm512b16_er
INSTRUCTION: EVEX.512.66.MAP6.W0 2C /r | VSCALEFPH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er} | AVX512_FP16 | N64b2
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vscalefsh_xmm_k1z_xmm_xmmm16_er
INSTRUCTION: EVEX.LIG.66.MAP6.W0 2D /r | VSCALEFSH xmm1 {k1}{z}, xmm2, xmm3/m16{er} | AVX512_FP16 | N2
	ops: w=reg r=vvvv r=rm | Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vsqrtph_xmm_k1z_xmmm128b16
INSTRUCTION: EVEX.128.MAP5.W0 51 /r | VSQRTPH xmm1 {k1}{z}, xmm2/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: w=reg r=rm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vsqrtph_ymm_k1z_ymmm256b16
INSTRUCTION: EVEX.256.MAP5.W0 51 /r | VSQRTPH ymm1 {k1}{z}, ymm2/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: w=reg r=rm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vsqrtph_zmm_k1z_zmmm512b16_er
INSTRUCTION: EVEX.512.MAP5.W0 51 /r | VSQRTPH zmm1 {k1}{z}, zmm2/m512/m16bcst{er} | AVX512_FP16 | N64b2
	ops: wvmm=reg r=rm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vsqrtsh_xmm_k1z_xmm_xmmm16_er
INSTRUCTION: EVEX.LIG.F3.MAP5.W0 51 /r | VSQRTSH xmm1 {k1}{z}, xmm2, xmm3/m16{er} | AVX512_FP16 | N2
	ops: w=reg r=vvvv r=rm | Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vsubph_xmm_k1z_xmm_xmmm128b16
INSTRUCTION: EVEX.128.MAP5.W0 5C /r | VSUBPH xmm1 {k1}{z}, xmm2, xmm3/m128/m16bcst | AVX512VL AVX512_FP16 | N16b2
	ops: w=reg r=vvvv r=rm | Packed128_Float16 Broadcast128_Float16
END

# Code: EVEX_Vsubph_ymm_k1z_ymm_ymmm256b16
INSTRUCTION: EVEX.256.MAP5.W0 5C /r | VSUBPH ymm1 {k1}{z}, ymm2, ymm3/m256/m16bcst | AVX512VL AVX512_FP16 | N32b2
	ops: w=reg r=vvvv r=rm | Packed256_Float16 Broadcast256_Float16
END

# Code: EVEX_Vsubph_zmm_k1z_zmm_zmmm512b16_er
INSTRUCTION: EVEX.512.MAP5.W0 5C /r | VSUBPH zmm1 {k1}{z}, zmm2, zmm3/m512/m16bcst{er} | AVX512_FP16 | N64b2
	ops: wvmm=reg r=vvvv r=rm | Packed512_Float16 Broadcast512_Float16
END

# Code: EVEX_Vsubsh_xmm_k1z_xmm_xmmm16_er
INSTRUCTION: EVEX.LIG.F3.MAP5.W0 5C /r | VSUBSH xmm1 {k1}{z}, xmm2, xmm3/m16{er} | AVX512_FP16 | N2
	ops: w=reg r=vvvv r=rm | Float16
	masm: flags=force-size=default
END

# Code: EVEX_Vucomish_xmm_xmmm16_sae
INSTRUCTION: EVEX.LIG.MAP5.W0 2E /r | VUCOMISH xmm1, xmm2/m16{sae} | AVX512_FP16 | N2
	ops: r=reg r=rm | Float16
	rflags: w=zcp 0=osa
	masm: flags=force-size=default
END

# Code: Rdudbg
INSTRUCTION: 0F 0E | RDUDBG | UDBG
	# https://raw.githubusercontent.com/chip-red-pill/udbgInstr/main/paper/undocumented_x86_insts_for_uarch_control.pdf
	implied: r=eax;ecx w=edx;ebx
	# Doesn't seem to require CPL0 to execute but it does require a special CPU mode to execute so they're privileged
	flags: dec-opt=Udbg privileged 
END

# Code: Wrudbg
INSTRUCTION: 0F 0F | WRUDBG | UDBG
	implied: r=eax;ecx;edx cr=ebx cw=edx;ebx
	flags: dec-opt=Udbg privileged 
END

# Code: VEX_KNC_Jkzd_kr_rel8_64
INSTRUCTION: VEX.128.W0 74 cb | JKZD k1, rel8 | KNC
	ops: r=vvvv r=br64
	code-suffix: 64
	flags: cc=jk;e;d br=jkcc-short cflow=br-cond intel-fo64 do64
END

# Code: VEX_KNC_Jknzd_kr_rel8_64
INSTRUCTION: VEX.128.W0 75 cb | JKNZD k1, rel8 | KNC
	ops: r=vvvv r=br64
	code-suffix: 64
	flags: cc=jk;ne;d br=jkcc-short cflow=br-cond intel-fo64 do64
END

# Code: VEX_KNC_Vprefetchnta_m8
INSTRUCTION: VEX.128.0F.WIG 18 /0 | VPREFETCHNTA m8 | KNC
	ops: nma=rm | UInt8
	flags: prefetch non-temporal
END

# Code: VEX_KNC_Vprefetch0_m8
INSTRUCTION: VEX.128.0F.WIG 18 /1 | VPREFETCH0 m8 | KNC
	ops: nma=rm | UInt8
	flags: prefetch
END

# Code: VEX_KNC_Vprefetch1_m8
INSTRUCTION: VEX.128.0F.WIG 18 /2 | VPREFETCH1 m8 | KNC
	ops: nma=rm | UInt8
	flags: prefetch
END

# Code: VEX_KNC_Vprefetch2_m8
INSTRUCTION: VEX.128.0F.WIG 18 /3 | VPREFETCH2 m8 | KNC
	ops: nma=rm | UInt8
	flags: prefetch non-temporal
END

# Code: VEX_KNC_Vprefetchenta_m8
INSTRUCTION: VEX.128.0F.WIG 18 /4 | VPREFETCHENTA m8 | KNC
	ops: nma=rm | UInt8
	flags: prefetch non-temporal
END

# Code: VEX_KNC_Vprefetche0_m8
INSTRUCTION: VEX.128.0F.WIG 18 /5 | VPREFETCHE0 m8 | KNC
	ops: nma=rm | UInt8
	flags: prefetch
END

# Code: VEX_KNC_Vprefetche1_m8
INSTRUCTION: VEX.128.0F.WIG 18 /6 | VPREFETCHE1 m8 | KNC
	ops: nma=rm | UInt8
	flags: prefetch
END

# Code: VEX_KNC_Vprefetche2_m8
INSTRUCTION: VEX.128.0F.WIG 18 /7 | VPREFETCHE2 m8 | KNC
	ops: nma=rm | UInt8
	flags: prefetch non-temporal
END

# Code: VEX_KNC_Kand_kr_kr
INSTRUCTION: VEX.128.0F.W0 41 /r | KAND k1, k2 | KNC
	ops: rw=reg r=rm
END

# Code: VEX_KNC_Kandn_kr_kr
INSTRUCTION: VEX.128.0F.W0 42 /r | KANDN k1, k2 | KNC
	ops: rw=reg r=rm
END

# Code: VEX_KNC_Kandnr_kr_kr
INSTRUCTION: VEX.128.0F.W0 43 /r | KANDNR k1, k2 | KNC
	ops: rw=reg r=rm
END

# Code: VEX_KNC_Knot_kr_kr
INSTRUCTION: VEX.128.0F.W0 44 /r | KNOT k1, k2 | KNC
	ops: w=reg r=rm
END

# Code: VEX_KNC_Kor_kr_kr
INSTRUCTION: VEX.128.0F.W0 45 /r | KOR k1, k2 | KNC
	ops: rw=reg r=rm
END

# Code: VEX_KNC_Kxnor_kr_kr
INSTRUCTION: VEX.128.0F.W0 46 /r | KXNOR k1, k2 | KNC
	ops: rw=reg r=rm
END

# Code: VEX_KNC_Kxor_kr_kr
INSTRUCTION: VEX.128.0F.W0 47 /r | KXOR k1, k2 | KNC
	ops: rw=reg r=rm
END

# Code: VEX_KNC_Kmerge2l1h_kr_kr
INSTRUCTION: VEX.128.0F.W0 48 /r | KMERGE2L1H k1, k2 | KNC
	ops: rw=reg r=rm
END

# Code: VEX_KNC_Kmerge2l1l_kr_kr
INSTRUCTION: VEX.128.0F.W0 49 /r | KMERGE2L1L k1, k2 | KNC
	ops: rw=reg r=rm
END

# Code: VEX_KNC_Jkzd_kr_rel32_64
INSTRUCTION: VEX.128.0F.W0 84 cd | JKZD k1, rel32 | KNC
	ops: r=vvvv r=br64
	code-suffix: 64
	flags: cc=jk;e;d br=jkcc-near cflow=br-cond intel-fo64 do64
END

# Code: VEX_KNC_Jknzd_kr_rel32_64
INSTRUCTION: VEX.128.0F.W0 85 cd | JKNZD k1, rel32 | KNC
	ops: r=vvvv r=br64
	code-suffix: 64
	flags: cc=jk;ne;d br=jkcc-near cflow=br-cond intel-fo64 do64
END

# Code: VEX_KNC_Kmov_kr_kr
INSTRUCTION: VEX.128.0F.W0 90 /r | KMOV k1, k2 | KNC
	ops: w=reg r=rm
END

# Code: VEX_KNC_Kmov_kr_r32
INSTRUCTION: VEX.128.0F.W0 92 /r | KMOV k1, r32 | KNC
	ops: w=reg r=rm
END

# Code: VEX_KNC_Kmov_r32_kr
INSTRUCTION: VEX.128.0F.W0 93 /r | KMOV r32, k1 | KNC
	ops: w=reg r=rm
END

# Code: VEX_KNC_Kconcath_r64_kr_kr
INSTRUCTION: VEX.128.0F.W0 95 /r | KCONCATH r64, k1, k2 | KNC
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_KNC_Kconcatl_r64_kr_kr
INSTRUCTION: VEX.128.0F.W0 97 /r | KCONCATL r64, k1, k2 | KNC
	ops: w=reg r=vvvv r=rm
END

# Code: VEX_KNC_Kortest_kr_kr
INSTRUCTION: VEX.128.0F.W0 98 /r | KORTEST k1, k2 | KNC
	ops: r=reg r=rm
	rflags: w=zc 0=osap
END

# Code: VEX_KNC_Delay_r32
INSTRUCTION: VEX.128.F3.0F.W0 AE /6 | DELAY r32 | KNC
	ops: r=rm
	flags: wig32
	gas: suffix=l
END

# Code: VEX_KNC_Delay_r64
INSTRUCTION: VEX.128.F3.0F.W1 AE /6 | DELAY r64 | KNC
	ops: r=rm
	gas: suffix=q
END

# Code: VEX_KNC_Spflt_r32
INSTRUCTION: VEX.128.F2.0F.W0 AE /6 | SPFLT r32 | KNC
	ops: r=rm
	flags: wig32
	gas: suffix=l
END

# Code: VEX_KNC_Spflt_r64
INSTRUCTION: VEX.128.F2.0F.W1 AE /6 | SPFLT r64 | KNC
	ops: r=rm
	gas: suffix=q
END

# Code: VEX_KNC_Clevict1_m8
INSTRUCTION: VEX.128.F3.0F.WIG AE /7 | CLEVICT1 m8 | KNC
	ops: nma=rm | UInt8
END

# Code: VEX_KNC_Clevict0_m8
INSTRUCTION: VEX.128.F2.0F.WIG AE /7 | CLEVICT0 m8 | KNC
	ops: nma=rm | UInt8
END

# Code: VEX_KNC_Popcnt_r32_r32
INSTRUCTION: VEX.128.F3.0F.W0 B8 /r | POPCNT r32, r32 | KNC
	ops: w=reg r=rm
	flags: wig32
	rflags: w=z 0=osacp
	gas: suffix=l
END

# Code: VEX_KNC_Popcnt_r64_r64
INSTRUCTION: VEX.128.F3.0F.W1 B8 /r | POPCNT r64, r64 | KNC
	ops: w=reg r=rm
	rflags: w=z 0=osacp
	gas: suffix=q
END

# Code: VEX_KNC_Tzcnt_r32_r32
INSTRUCTION: VEX.128.F3.0F.W0 BC /r | TZCNT r32, r32 | KNC
	ops: w=reg r=rm
	flags: wig32
	rflags: u=osap w=zc
	gas: suffix=l
END

# Code: VEX_KNC_Tzcnt_r64_r64
INSTRUCTION: VEX.128.F3.0F.W1 BC /r | TZCNT r64, r64 | KNC
	ops: w=reg r=rm
	rflags: u=osap w=zc
	gas: suffix=q
END

# Code: VEX_KNC_Tzcnti_r32_r32
INSTRUCTION: VEX.128.F2.0F.W0 BC /r | TZCNTI r32, r32 | KNC
	ops: rw=reg r=rm
	flags: wig32
	rflags: u=osap w=zc
	gas: suffix=l
END

# Code: VEX_KNC_Tzcnti_r64_r64
INSTRUCTION: VEX.128.F2.0F.W1 BC /r | TZCNTI r64, r64 | KNC
	ops: rw=reg r=rm
	rflags: u=osap w=zc
	gas: suffix=q
END

# Code: VEX_KNC_Lzcnt_r32_r32
INSTRUCTION: VEX.128.F3.0F.W0 BD /r | LZCNT r32, r32 | KNC
	ops: w=reg r=rm
	flags: wig32
	rflags: u=osap w=zc
	gas: suffix=l
END

# Code: VEX_KNC_Lzcnt_r64_r64
INSTRUCTION: VEX.128.F3.0F.W1 BD /r | LZCNT r64, r64 | KNC
	ops: w=reg r=rm
	rflags: u=osap w=zc
	gas: suffix=q
END

# Code: VEX_KNC_Undoc_r32_rm32_128_F3_0F38_W0_F0
INSTRUCTION: VEX.128.F3.0F38.W0 F0 /r | UNDOC r32, r/m32 | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 128_F3_0F38_W0_F0
	ops: n=reg n=rm | UInt32
	flags: save-restore asm-ig
END

# Code: VEX_KNC_Undoc_r64_rm64_128_F3_0F38_W1_F0
INSTRUCTION: VEX.128.F3.0F38.W1 F0 /r | UNDOC r64, r/m64 | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 128_F3_0F38_W1_F0
	ops: n=reg n=rm | UInt64
	flags: save-restore asm-ig
END

# Code: VEX_KNC_Undoc_r32_rm32_128_F2_0F38_W0_F0
INSTRUCTION: VEX.128.F2.0F38.W0 F0 /r | UNDOC r32, r/m32 | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 128_F2_0F38_W0_F0
	ops: n=reg n=rm | UInt32
	flags: save-restore asm-ig
END

# Code: VEX_KNC_Undoc_r64_rm64_128_F2_0F38_W1_F0
INSTRUCTION: VEX.128.F2.0F38.W1 F0 /r | UNDOC r64, r/m64 | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 128_F2_0F38_W1_F0
	ops: n=reg n=rm | UInt64
	flags: save-restore asm-ig
END

# Code: VEX_KNC_Undoc_r32_rm32_128_F2_0F38_W0_F1
INSTRUCTION: VEX.128.F2.0F38.W0 F1 /r | UNDOC r32, r/m32 | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 128_F2_0F38_W0_F1
	ops: n=reg n=rm | UInt32
	flags: save-restore asm-ig
END

# Code: VEX_KNC_Undoc_r64_rm64_128_F2_0F38_W1_F1
INSTRUCTION: VEX.128.F2.0F38.W1 F1 /r | UNDOC r64, r/m64 | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 128_F2_0F38_W1_F1
	ops: n=reg n=rm | UInt64
	flags: save-restore asm-ig
END

# Code: VEX_KNC_Kextract_kr_r64_imm8
INSTRUCTION: VEX.128.66.0F3A.W0 3E /r ib | KEXTRACT k1, r64, imm8 | KNC
	ops: w=reg r=rm r=imm
END

# Code: MVEX_Vprefetchnta_m
INSTRUCTION: MVEX.512.0F.WIG 18 /0 | VPREFETCHNTA m | KNC
	# v9 template (page 722) shows {k1} is allowed but it seems to be ignored
	# Embedded {eh} is ignored, see page 51
	ops: nma=rm | mem=1000_0000 i32 ignore-opmask ignore-eh
	flags: prefetch non-temporal
END

# Code: MVEX_Vprefetch0_m
INSTRUCTION: MVEX.512.0F.WIG 18 /1 | VPREFETCH0 m | KNC
	ops: nma=rm | mem=1000_0000 i32 ignore-opmask ignore-eh
	flags: prefetch
END

# Code: MVEX_Vprefetch1_m
INSTRUCTION: MVEX.512.0F.WIG 18 /2 | VPREFETCH1 m | KNC
	ops: nma=rm | mem=1000_0000 i32 ignore-opmask ignore-eh
	flags: prefetch
END

# Code: MVEX_Vprefetch2_m
INSTRUCTION: MVEX.512.0F.WIG 18 /3 | VPREFETCH2 m | KNC
	ops: nma=rm | mem=1000_0000 i32 ignore-opmask ignore-eh
	flags: prefetch non-temporal
END

# Code: MVEX_Vprefetchenta_m
INSTRUCTION: MVEX.512.0F.WIG 18 /4 | VPREFETCHENTA m | KNC
	ops: nma=rm | mem=1000_0000 i32 ignore-opmask ignore-eh
	flags: prefetch non-temporal
END

# Code: MVEX_Vprefetche0_m
INSTRUCTION: MVEX.512.0F.WIG 18 /5 | VPREFETCHE0 m | KNC
	ops: nma=rm | mem=1000_0000 i32 ignore-opmask ignore-eh
	flags: prefetch
END

# Code: MVEX_Vprefetche1_m
INSTRUCTION: MVEX.512.0F.WIG 18 /6 | VPREFETCHE1 m | KNC
	ops: nma=rm | mem=1000_0000 i32 ignore-opmask ignore-eh
	flags: prefetch
END

# Code: MVEX_Vprefetche2_m
INSTRUCTION: MVEX.512.0F.WIG 18 /7 | VPREFETCHE2 m | KNC
	ops: nma=rm | mem=1000_0000 i32 ignore-opmask ignore-eh
	flags: prefetch non-temporal
END

# Code: MVEX_Vmovaps_zmm_k1_zmmmt
INSTRUCTION: MVEX.512.0F.W0 28 /r | VMOVAPS zmm1 {k1}, Sf32(zmm2/mt) | KNC
	ops: wvmm=reg r=rm | no-er-sae swizz mem=1001_1111
END

# Code: MVEX_Vmovapd_zmm_k1_zmmmt
INSTRUCTION: MVEX.512.66.0F.W1 28 /r | VMOVAPD zmm1 {k1}, Sf64(zmm2/mt) | KNC
	ops: wvmm=reg r=rm | no-er-sae swizz mem=1000_0000
END

# Code: MVEX_Vmovaps_mt_k1_zmm
INSTRUCTION: MVEX.512.0F.W0 29 /r | VMOVAPS mt {k1}, Df32(zmm1) | KNC
	ops: wvmm=rm r=reg | mem=1001_1111
END

# Code: MVEX_Vmovapd_mt_k1_zmm
INSTRUCTION: MVEX.512.66.0F.W1 29 /r | VMOVAPD mt {k1}, Df64(zmm1) | KNC
	ops: wvmm=rm r=reg | mem=1000_0000
END

# Code: MVEX_Vmovnrapd_m_k1_zmm
INSTRUCTION: MVEX.512.F3.0F.W1.EH0 29 /r | VMOVNRAPD m {k1}, Df64(zmm1) | KNC
	ops: wvmm=rm r=reg | mem=1000_0000
END

# Code: MVEX_Vmovnrngoapd_m_k1_zmm
INSTRUCTION: MVEX.512.F3.0F.W1.EH1 29 /r | VMOVNRNGOAPD m {k1}, Df64(zmm1) | KNC
	ops: wvmm=rm r=reg | mem=1000_0000
END

# Code: MVEX_Vmovnraps_m_k1_zmm
INSTRUCTION: MVEX.512.F2.0F.W0.EH0 29 /r | VMOVNRAPS m {k1}, Df32(zmm1) | KNC
	ops: wvmm=rm r=reg | mem=1001_1111
END

# Code: MVEX_Vmovnrngoaps_m_k1_zmm
INSTRUCTION: MVEX.512.F2.0F.W0.EH1 29 /r | VMOVNRNGOAPS m {k1}, Df32(zmm1) | KNC
	ops: wvmm=rm r=reg | mem=1001_1111
END

# Code: MVEX_Vaddps_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.0F.W0 58 /r | VADDPS zmm1 {k1}, zmm2, Sf32(zmm3/mt) | KNC
	# The docs say that {sint8} is invalid but XED seems to think it's valid.
	# It's possible that the docs are wrong because it doesn't make any sense
	# for {sint8} to be invalid when {sint16} and {uint8} are valid.
	ops: wvmm=reg r=vvvv r=rm | sae er swizz mem=1111_1111
END

# Code: MVEX_Vaddpd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F.W1 58 /r | VADDPD zmm1 {k1}, zmm2, Sf64(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | sae er swizz mem=1110_0000
END

# Code: MVEX_Vmulps_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.0F.W0 59 /r | VMULPS zmm1 {k1}, zmm2, Sf32(zmm3/mt) | KNC
	# For the reason why {sint8} (101b) is valid, see MVEX_Vaddps_zmm_k1_zmm_zmmmt
	ops: wvmm=reg r=vvvv r=rm | sae er swizz mem=1111_1111
END

# Code: MVEX_Vmulpd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F.W1 59 /r | VMULPD zmm1 {k1}, zmm2, Sf64(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | sae er swizz mem=1110_0000
END

# Code: MVEX_Vcvtps2pd_zmm_k1_zmmmt
INSTRUCTION: MVEX.512.0F.W0 5A /r | VCVTPS2PD zmm1 {k1}, Sf32(zmm2/mt) | KNC
	ops: wvmm=reg r=rm | sae swizz mem=1110_0000 f32-half
END

# Code: MVEX_Vcvtpd2ps_zmm_k1_zmmmt
INSTRUCTION: MVEX.512.66.0F.W1 5A /r | VCVTPD2PS zmm1 {k1}, Sf64(zmm2/mt) | KNC
	ops: wvmm=reg r=rm | sae er swizz mem=1110_0000
END

# Code: MVEX_Vsubps_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.0F.W0 5C /r | VSUBPS zmm1 {k1}, zmm2, Sf32(zmm3/mt) | KNC
	# For the reason why {sint8} (101b) is valid, see MVEX_Vaddps_zmm_k1_zmm_zmmmt
	ops: wvmm=reg r=vvvv r=rm | sae er swizz mem=1111_1111
END

# Code: MVEX_Vsubpd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F.W1 5C /r | VSUBPD zmm1 {k1}, zmm2, Sf64(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | sae er swizz mem=1110_0000
END

# Code: MVEX_Vpcmpgtd_kr_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F.W0 66 /r | VPCMPGTD k2 {k1}, zmm1, Si32(zmm2/mt) | KNC
	ops: w=reg r=vvvv r=rm | no-er-sae swizz mem=1110_1111
	flags: implied-z
END

# Code: MVEX_Vmovdqa32_zmm_k1_zmmmt
INSTRUCTION: MVEX.512.66.0F.W0 6F /r | VMOVDQA32 zmm1 {k1}, Si32(zmm2/mt) | KNC
	ops: wvmm=reg r=rm | no-er-sae swizz mem=1000_1111
END

# Code: MVEX_Vmovdqa64_zmm_k1_zmmmt
INSTRUCTION: MVEX.512.66.0F.W1 6F /r | VMOVDQA64 zmm1 {k1}, Si64(zmm2/mt) | KNC
	ops: wvmm=reg r=rm | no-er-sae swizz mem=1000_0000
END

# Code: MVEX_Vpshufd_zmm_k1_zmmmt_imm8
INSTRUCTION: MVEX.512.66.0F.W0 70 /r ib | VPSHUFD zmm1 {k1}, zmm2/mt, imm8 | KNC
	ops: wvmm=reg r=rm r=imm | no-er-sae swizz=1000_0000 mem=1000_0000 i32
END

# Code: MVEX_Vpsrld_zmm_k1_zmmmt_imm8
INSTRUCTION: MVEX.NDD.512.66.0F.W0 72 /2 ib | VPSRLD zmm1 {k1}, Si32(zmm2/mt), imm8 | KNC
	ops: wvmm=vvvv r=rm r=imm | no-er-sae swizz mem=1110_1111
END

# Code: MVEX_Vpsrad_zmm_k1_zmmmt_imm8
INSTRUCTION: MVEX.NDD.512.66.0F.W0 72 /4 ib | VPSRAD zmm1 {k1}, Si32(zmm2/mt), imm8 | KNC
	ops: wvmm=vvvv r=rm r=imm | no-er-sae swizz mem=1110_1111
END

# Code: MVEX_Vpslld_zmm_k1_zmmmt_imm8
INSTRUCTION: MVEX.NDD.512.66.0F.W0 72 /6 ib | VPSLLD zmm1 {k1}, Si32(zmm2/mt), imm8 | KNC
	ops: wvmm=vvvv r=rm r=imm | no-er-sae swizz mem=1110_1111
END

# Code: MVEX_Vpcmpeqd_kr_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F.W0 76 /r | VPCMPEQD k2 {k1}, zmm1, Si32(zmm2/mt) | KNC
	ops: w=reg r=vvvv r=rm | no-er-sae swizz mem=1110_1111
	flags: implied-z
END

# Code: MVEX_Vcvtudq2pd_zmm_k1_zmmmt
INSTRUCTION: MVEX.512.F3.0F.W0 7A /r | VCVTUDQ2PD zmm1 {k1}, Si32(zmm2/mt) | KNC
	ops: wvmm=reg r=rm | swizz mem=1110_0000 i32-half
END

# Code: MVEX_Vmovdqa32_mt_k1_zmm
INSTRUCTION: MVEX.512.66.0F.W0 7F /r | VMOVDQA32 mt {k1}, Di32(zmm1) | KNC
	ops: wvmm=rm r=reg | mem=1000_1111
END

# Code: MVEX_Vmovdqa64_mt_k1_zmm
INSTRUCTION: MVEX.512.66.0F.W1 7F /r | VMOVDQA64 mt {k1}, Di64(zmm1) | KNC
	ops: wvmm=rm r=reg | mem=1000_0000
END

# Code: MVEX_Clevict1_m
INSTRUCTION: MVEX.512.F3.0F.WIG AE /7 | CLEVICT1 m | KNC
	ops: nma=rm | mem=1000_0000 i32 ignore-opmask ignore-eh
END

# Code: MVEX_Clevict0_m
INSTRUCTION: MVEX.512.F2.0F.WIG AE /7 | CLEVICT0 m | KNC
	ops: nma=rm | mem=1000_0000 i32 ignore-opmask ignore-eh
END

# Code: MVEX_Vcmpps_kr_k1_zmm_zmmmt_imm8
INSTRUCTION: MVEX.NDS.512.0F.W0 C2 /r ib | VCMPPS k2 {k1}, zmm1, Sf32(zmm2/mt), imm8 | KNC
	# For the reason why {sint8} (101b) is valid, see MVEX_Vaddps_zmm_k1_zmm_zmmmt
	ops: w=reg r=vvvv r=rm r=imm | sae swizz mem=1111_1111
	flags: pseudo=vcmpps8 implied-z
END

# Code: MVEX_Vcmppd_kr_k1_zmm_zmmmt_imm8
INSTRUCTION: MVEX.NDS.512.66.0F.W1 C2 /r ib | VCMPPD k2 {k1}, zmm1, Sf64(zmm2/mt), imm8 | KNC
	ops: w=reg r=vvvv r=rm r=imm | sae swizz mem=1110_0000
	flags: pseudo=vcmppd8 implied-z
END

# Code: MVEX_Vpandd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F.W0 DB /r | VPANDD zmm1 {k1}, zmm2, Si32(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | swizz mem=1110_1111
END

# Code: MVEX_Vpandq_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F.W1 DB /r | VPANDQ zmm1 {k1}, zmm2, Si64(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | swizz mem=1110_0000
END

# Code: MVEX_Vpandnd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F.W0 DF /r | VPANDND zmm1 {k1}, zmm2, Si32(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | swizz mem=1110_1111
END

# Code: MVEX_Vpandnq_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F.W1 DF /r | VPANDNQ zmm1 {k1}, zmm2, Si64(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | swizz mem=1110_0000
END

# Code: MVEX_Vcvtdq2pd_zmm_k1_zmmmt
INSTRUCTION: MVEX.512.F3.0F.W0 E6 /r | VCVTDQ2PD zmm1 {k1}, Si32(zmm2/mt) | KNC
	ops: wvmm=reg r=rm | swizz mem=1110_0000 i32-half
END

# Code: MVEX_Vpord_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F.W0 EB /r | VPORD zmm1 {k1}, zmm2, Si32(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | swizz mem=1110_1111
END

# Code: MVEX_Vporq_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F.W1 EB /r | VPORQ zmm1 {k1}, zmm2, Si64(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | swizz mem=1110_0000
END

# Code: MVEX_Vpxord_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F.W0 EF /r | VPXORD zmm1 {k1}, zmm2, Si32(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | swizz mem=1110_1111
	implied: zero-reg-reg-regmem
END

# Code: MVEX_Vpxorq_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F.W1 EF /r | VPXORQ zmm1 {k1}, zmm2, Si64(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | swizz mem=1110_0000
	implied: zero-reg-reg-regmem
END

# Code: MVEX_Vpsubd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F.W0 FA /r | VPSUBD zmm1 {k1}, zmm2, Si32(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | swizz mem=1110_1111
	implied: zero-reg-reg-regmem
END

# Code: MVEX_Vpaddd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F.W0 FE /r | VPADDD zmm1 {k1}, zmm2, Si32(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | swizz mem=1110_1111
END

# Code: MVEX_Vbroadcastss_zmm_k1_mt
INSTRUCTION: MVEX.512.66.0F38.W0 18 /r | VBROADCASTSS zmm1 {k1}, Uf32(mt) | KNC
	ops: wvmm=reg r=rm | mem=1001_1111 f32-bcst1
END

# Code: MVEX_Vbroadcastsd_zmm_k1_mt
INSTRUCTION: MVEX.512.66.0F38.W1 19 /r | VBROADCASTSD zmm1 {k1}, Uf64(mt) | KNC
	ops: wvmm=reg r=rm | mem=1000_0000 f64-bcst1
END

# Code: MVEX_Vbroadcastf32x4_zmm_k1_mt
INSTRUCTION: MVEX.512.66.0F38.W0 1A /r | VBROADCASTF32X4 zmm1 {k1}, Uf32(mt) | KNC
	ops: wvmm=reg r=rm | mem=1001_1111 f32-bcst4
END

# Code: MVEX_Vbroadcastf64x4_zmm_k1_mt
INSTRUCTION: MVEX.512.66.0F38.W1 1B /r | VBROADCASTF64X4 zmm1 {k1}, Uf64(mt) | KNC
	ops: wvmm=reg r=rm | mem=1000_0000 f64-bcst4
END

# Code: MVEX_Vptestmd_kr_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 27 /r | VPTESTMD k2 {k1}, zmm1, Si32(zmm2/mt) | KNC
	ops: w=reg r=vvvv r=rm | no-er-sae swizz mem=1110_1111
	flags: implied-z
END

# Code: MVEX_Vpermd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 36 /r | VPERMD zmm1 {k1}, zmm2, zmm3/mt | KNC
	ops: wvmm=reg r=vvvv r=rm | no-er-sae swizz=1000_0000 mem=1000_0000 i32
END

# Code: MVEX_Vpminsd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 39 /r | VPMINSD zmm1 {k1}, zmm2, Si32(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | swizz mem=1110_1111
END

# Code: MVEX_Vpminud_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 3B /r | VPMINUD zmm1 {k1}, zmm2, Si32(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | swizz mem=1110_1111
END

# Code: MVEX_Vpmaxsd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 3D /r | VPMAXSD zmm1 {k1}, zmm2, Si32(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | swizz mem=1110_1111
END

# Code: MVEX_Vpmaxud_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 3F /r | VPMAXUD zmm1 {k1}, zmm2, Si32(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | swizz mem=1110_1111
END

# Code: MVEX_Vpmulld_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 40 /r | VPMULLD zmm1 {k1}, zmm2, Si32(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | swizz mem=1110_1111
END

# Code: MVEX_Vgetexpps_zmm_k1_zmmmt
INSTRUCTION: MVEX.512.66.0F38.W0 42 /r | VGETEXPPS zmm1 {k1}, Sf32(zmm2/mt) | KNC
	# For the reason why {sint8} (101b) is valid, see MVEX_Vaddps_zmm_k1_zmm_zmmmt
	ops: wvmm=reg r=rm | sae swizz mem=1111_1111
END

# Code: MVEX_Vgetexppd_zmm_k1_zmmmt
INSTRUCTION: MVEX.512.66.0F38.W1 42 /r | VGETEXPPD zmm1 {k1}, Sf64(zmm2/mt) | KNC
	ops: wvmm=reg r=rm | sae swizz mem=1110_0000
END

# Code: MVEX_Vpsrlvd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 45 /r | VPSRLVD zmm1 {k1}, zmm2, Si32(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | swizz mem=1110_1111
END

# Code: MVEX_Vpsravd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 46 /r | VPSRAVD zmm1 {k1}, zmm2, Si32(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | swizz mem=1110_1111
END

# Code: MVEX_Vpsllvd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 47 /r | VPSLLVD zmm1 {k1}, zmm2, Si32(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | swizz mem=1110_1111
END

# Code: MVEX_Undoc_zmm_k1_zmmmt_512_66_0F38_W0_48
INSTRUCTION: MVEX.512.66.0F38.W0 48 /r | UNDOC zmm1 {k1}, zmm2/mt | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_66_0F38_W0_48
	ops: n=reg n=rm | sae er swizz mem=1111_1111 f32
	flags: save-restore asm-ig
END

# Code: MVEX_Undoc_zmm_k1_zmmmt_512_66_0F38_W0_49
INSTRUCTION: MVEX.512.66.0F38.W0 49 /r | UNDOC zmm1 {k1}, zmm2/mt | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_66_0F38_W0_49
	ops: n=reg n=rm | sae er swizz mem=1111_1111 f32
	flags: save-restore asm-ig
END

# Code: MVEX_Undoc_zmm_k1_zmmmt_512_66_0F38_W0_4A
INSTRUCTION: MVEX.512.66.0F38.W0 4A /r | UNDOC zmm1 {k1}, zmm2/mt | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_66_0F38_W0_4A
	ops: n=reg n=rm | sae er swizz mem=1111_1111 f32
	flags: save-restore asm-ig
END

# Code: MVEX_Undoc_zmm_k1_zmmmt_512_66_0F38_W0_4B
INSTRUCTION: MVEX.512.66.0F38.W0 4B /r | UNDOC zmm1 {k1}, zmm2/mt | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_66_0F38_W0_4B
	ops: n=reg n=rm | sae er swizz mem=1111_1111 f32
	flags: save-restore asm-ig
END

# Code: MVEX_Vaddnps_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 50 /r | VADDNPS zmm1 {k1}, zmm2, Sf32(zmm3/mt) | KNC
	# For the reason why {sint8} (101b) is valid, see MVEX_Vaddps_zmm_k1_zmm_zmmmt
	ops: wvmm=reg r=vvvv r=rm | sae er swizz mem=1111_1111
END

# Code: MVEX_Vaddnpd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W1 50 /r | VADDNPD zmm1 {k1}, zmm2, Sf64(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | sae er swizz mem=1110_0000
END

# Code: MVEX_Vgmaxabsps_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 51 /r | VGMAXABSPS zmm1 {k1}, zmm2, Sf32(zmm3/mt) | KNC
	# For the reason why {sint8} (101b) is valid, see MVEX_Vaddps_zmm_k1_zmm_zmmmt
	ops: wvmm=reg r=vvvv r=rm | sae swizz mem=1111_1111
END

# Code: MVEX_Vgminps_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 52 /r | VGMINPS zmm1 {k1}, zmm2, Sf32(zmm3/mt) | KNC
	# For the reason why {sint8} (101b) is valid, see MVEX_Vaddps_zmm_k1_zmm_zmmmt
	ops: wvmm=reg r=vvvv r=rm | sae swizz mem=1111_1111
END

# Code: MVEX_Vgminpd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W1 52 /r | VGMINPD zmm1 {k1}, zmm2, Sf64(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | sae swizz mem=1110_0000
END

# Code: MVEX_Vgmaxps_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 53 /r | VGMAXPS zmm1 {k1}, zmm2, Sf32(zmm3/mt) | KNC
	# For the reason why {sint8} (101b) is valid, see MVEX_Vaddps_zmm_k1_zmm_zmmmt
	ops: wvmm=reg r=vvvv r=rm | sae swizz mem=1111_1111
END

# Code: MVEX_Vgmaxpd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W1 53 /r | VGMAXPD zmm1 {k1}, zmm2, Sf64(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | sae swizz mem=1110_0000
END

# Code: MVEX_Undoc_zmm_k1_zmm_zmmmt_512_66_0F38_W0_54
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 54 /r | UNDOC zmm1 {k1}, zmm2, zmm3/mt | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_66_0F38_W0_54
	ops: n=reg n=vvvv n=rm | sae er swizz mem=1111_1111 f32
	flags: save-restore asm-ig
END

# Code: MVEX_Vfixupnanps_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 55 /r | VFIXUPNANPS zmm1 {k1}, zmm2, Si32(zmm3/mt) | KNC
	ops: rwvmm=reg r=vvvv r=rm | sae swizz mem=1110_1111
END

# Code: MVEX_Vfixupnanpd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W1 55 /r | VFIXUPNANPD zmm1 {k1}, zmm2, Si64(zmm3/mt) | KNC
	ops: rwvmm=reg r=vvvv r=rm | sae swizz mem=1110_0000
END

# Code: MVEX_Undoc_zmm_k1_zmm_zmmmt_512_66_0F38_W0_56
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 56 /r | UNDOC zmm1 {k1}, zmm2, zmm3/mt | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_66_0F38_W0_56
	ops: n=reg n=vvvv n=rm | sae er swizz mem=1111_1111 f32
	flags: save-restore asm-ig
END

# Code: MVEX_Undoc_zmm_k1_zmm_zmmmt_512_66_0F38_W0_57
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 57 /r | UNDOC zmm1 {k1}, zmm2, zmm3/mt | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_66_0F38_W0_57
	ops: n=reg n=vvvv n=rm | sae er swizz mem=1111_1111 f32
	flags: save-restore asm-ig
END

# Code: MVEX_Vpbroadcastd_zmm_k1_mt
INSTRUCTION: MVEX.512.66.0F38.W0 58 /r | VPBROADCASTD zmm1 {k1}, Ui32(mt) | KNC
	ops: wvmm=reg r=rm | mem=1000_1111 i32-bcst1
END

# Code: MVEX_Vpbroadcastq_zmm_k1_mt
INSTRUCTION: MVEX.512.66.0F38.W1 59 /r | VPBROADCASTQ zmm1 {k1}, Ui64(mt) | KNC
	ops: wvmm=reg r=rm | mem=1000_0000 i64-bcst1
END

# Code: MVEX_Vbroadcasti32x4_zmm_k1_mt
INSTRUCTION: MVEX.512.66.0F38.W0 5A /r | VBROADCASTI32X4 zmm1 {k1}, Ui32(mt) | KNC
	ops: wvmm=reg r=rm | mem=1000_1111 i32-bcst4
END

# Code: MVEX_Vbroadcasti64x4_zmm_k1_mt
INSTRUCTION: MVEX.512.66.0F38.W1 5B /r | VBROADCASTI64X4 zmm1 {k1}, Ui64(mt) | KNC
	ops: wvmm=reg r=rm | mem=1000_0000 i64-bcst4
END

# Code: MVEX_Vpadcd_zmm_k1_kr_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 5C /r | VPADCD zmm1 {k1}, k2, Si32(zmm3/mt) | KNC
	ops: rwvmm=reg rw=vvvv r=rm | no-er-sae swizz mem=1110_1111
END

# Code: MVEX_Vpaddsetcd_zmm_k1_kr_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 5D /r | VPADDSETCD zmm1 {k1}, k2, Si32(zmm3/mt) | KNC
	ops: rwvmm=reg rw=vvvv r=rm | no-er-sae swizz mem=1110_1111
END

# Code: MVEX_Vpsbbd_zmm_k1_kr_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 5E /r | VPSBBD zmm1 {k1}, k2, Si32(zmm3/mt) | KNC
	ops: rwvmm=reg rw=vvvv r=rm | no-er-sae swizz mem=1110_1111
END

# Code: MVEX_Vpsubsetbd_zmm_k1_kr_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 5F /r | VPSUBSETBD zmm1 {k1}, k2, Si32(zmm3/mt) | KNC
	ops: rwvmm=reg rw=vvvv r=rm | no-er-sae swizz mem=1110_1111
END

# Code: MVEX_Vpblendmd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 64 /r | VPBLENDMD zmm1 {k1}, zmm2, Si32(zmm3/mt) | KNC
	ops: w=reg r=vvvv r=rm | swizz mem=1110_1111
	flags: k-elem-selector
END

# Code: MVEX_Vpblendmq_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W1 64 /r | VPBLENDMQ zmm1 {k1}, zmm2, Si64(zmm3/mt) | KNC
	ops: w=reg r=vvvv r=rm | swizz mem=1110_0000
	flags: k-elem-selector
END

# Code: MVEX_Vblendmps_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 65 /r | VBLENDMPS zmm1 {k1}, zmm2, Sf32(zmm3/mt) | KNC
	# For the reason why {sint8} (101b) is valid, see MVEX_Vaddps_zmm_k1_zmm_zmmmt
	ops: w=reg r=vvvv r=rm | swizz mem=1111_1111
	flags: k-elem-selector
END

# Code: MVEX_Vblendmpd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W1 65 /r | VBLENDMPD zmm1 {k1}, zmm2, Sf64(zmm3/mt) | KNC
	ops: w=reg r=vvvv r=rm | swizz mem=1110_0000
	flags: k-elem-selector
END

# Code: MVEX_Undoc_zmm_k1_zmm_zmmmt_512_66_0F38_W0_67
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 67 /r | UNDOC zmm1 {k1}, zmm2, zmm3/mt | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_66_0F38_W0_67
	ops: n=reg n=vvvv n=rm | sae er swizz mem=1111_1111 f32
	flags: save-restore asm-ig
END

# Code: MVEX_Undoc_zmm_k1_zmmmt_512_66_0F38_W0_68
INSTRUCTION: MVEX.512.66.0F38.W0 68 /r | UNDOC zmm1 {k1}, zmm2/mt | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_66_0F38_W0_68
	ops: n=reg n=rm | sae er swizz mem=1111_1111 f32
	flags: save-restore asm-ig
END

# Code: MVEX_Undoc_zmm_k1_zmmmt_512_66_0F38_W0_69
INSTRUCTION: MVEX.512.66.0F38.W0 69 /r | UNDOC zmm1 {k1}, zmm2/mt | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_66_0F38_W0_69
	ops: n=reg n=rm | sae er swizz mem=1111_1111 f32
	flags: save-restore asm-ig
END

# Code: MVEX_Undoc_zmm_k1_zmmmt_512_66_0F38_W0_6A
INSTRUCTION: MVEX.512.66.0F38.W0 6A /r | UNDOC zmm1 {k1}, zmm2/mt | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_66_0F38_W0_6A
	ops: n=reg n=rm | sae er swizz mem=1111_1111 f32
	flags: save-restore asm-ig
END

# Code: MVEX_Undoc_zmm_k1_zmmmt_512_66_0F38_W0_6B
INSTRUCTION: MVEX.512.66.0F38.W0 6B /r | UNDOC zmm1 {k1}, zmm2/mt | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_66_0F38_W0_6B
	ops: n=reg n=rm | sae er swizz mem=1111_1111 f32
	flags: save-restore asm-ig
END

# Code: MVEX_Vpsubrd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 6C /r | VPSUBRD zmm1 {k1}, zmm2, Si32(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | swizz mem=1110_1111
	implied: zero-reg-reg-regmem
END

# Code: MVEX_Vsubrps_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 6D /r | VSUBRPS zmm1 {k1}, zmm2, Sf32(zmm3/mt) | KNC
	# For the reason why {sint8} (101b) is valid, see MVEX_Vaddps_zmm_k1_zmm_zmmmt
	ops: wvmm=reg r=vvvv r=rm | sae er swizz mem=1111_1111
END

# Code: MVEX_Vsubrpd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W1 6D /r | VSUBRPD zmm1 {k1}, zmm2, Sf64(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | sae er swizz mem=1110_0000
END

# Code: MVEX_Vpsbbrd_zmm_k1_kr_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 6E /r | VPSBBRD zmm1 {k1}, k2, Si32(zmm3/mt) | KNC
	ops: rwvmm=reg rw=vvvv r=rm | no-er-sae swizz mem=1110_1111
END

# Code: MVEX_Vpsubrsetbd_zmm_k1_kr_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 6F /r | VPSUBRSETBD zmm1 {k1}, k2, Si32(zmm3/mt) | KNC
	ops: rwvmm=reg rw=vvvv r=rm | no-er-sae swizz mem=1110_1111
END

# Code: MVEX_Undoc_zmm_k1_zmm_zmmmt_512_66_0F38_W0_70
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 70 /r | UNDOC zmm1 {k1}, zmm2, zmm3/mt | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_66_0F38_W0_70
	ops: n=reg n=vvvv n=rm | sae er swizz mem=1111_1111 f32
	flags: save-restore asm-ig
END

# Code: MVEX_Undoc_zmm_k1_zmm_zmmmt_512_66_0F38_W0_71
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 71 /r | UNDOC zmm1 {k1}, zmm2, zmm3/mt | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_66_0F38_W0_71
	ops: n=reg n=vvvv n=rm | sae er swizz mem=1111_1111 f32
	flags: save-restore asm-ig
END

# Code: MVEX_Undoc_zmm_k1_zmm_zmmmt_512_66_0F38_W0_72
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 72 /r | UNDOC zmm1 {k1}, zmm2, zmm3/mt | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_66_0F38_W0_72
	ops: n=reg n=vvvv n=rm | sae er swizz mem=1111_1111 f32
	flags: save-restore asm-ig
END

# Code: MVEX_Undoc_zmm_k1_zmm_zmmmt_512_66_0F38_W0_73
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 73 /r | UNDOC zmm1 {k1}, zmm2, zmm3/mt | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_66_0F38_W0_73
	ops: n=reg n=vvvv n=rm | sae er swizz mem=1111_1111 f32
	flags: save-restore asm-ig
END

# Code: MVEX_Vpcmpltd_kr_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 74 /r | VPCMPLTD k2 {k1}, zmm1, Si32(zmm2/mt) | KNC
	ops: w=reg r=vvvv r=rm | no-er-sae swizz mem=1110_1111
	flags: implied-z
END

# Code: MVEX_Vscaleps_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 84 /r | VSCALEPS zmm1 {k1}, zmm2, Si32(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | sae er swizz mem=1110_1111
END

# Code: MVEX_Vpmulhud_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 86 /r | VPMULHUD zmm1 {k1}, zmm2, Si32(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | swizz mem=1110_1111
END

# Code: MVEX_Vpmulhd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 87 /r | VPMULHD zmm1 {k1}, zmm2, Si32(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | swizz mem=1110_1111
END

# Code: MVEX_Vpgatherdd_zmm_k1_mvt
INSTRUCTION: MVEX.512.66.0F38.W0 90 /vsib | VPGATHERDD zmm1 {k1}, Ui32(mvt) | KNC
	ops: rwvmm=reg r=rm | mem=1000_1111 i32-elem
	flags: krw knz unique-reg-num
END

# Code: MVEX_Vpgatherdq_zmm_k1_mvt
INSTRUCTION: MVEX.512.66.0F38.W1 90 /vsib | VPGATHERDQ zmm1 {k1}, Ui64(mvt) | KNC
	ops: rwvmm=reg r=rm | mem=1000_0000 i64-elem
	flags: krw knz unique-reg-num
END

# Code: MVEX_Vgatherdps_zmm_k1_mvt
INSTRUCTION: MVEX.512.66.0F38.W0 92 /vsib | VGATHERDPS zmm1 {k1}, Uf32(mvt) | KNC
	ops: rwvmm=reg r=rm | mem=1001_1111 f32-elem
	flags: krw knz unique-reg-num
END

# Code: MVEX_Vgatherdpd_zmm_k1_mvt
INSTRUCTION: MVEX.512.66.0F38.W1 92 /vsib | VGATHERDPD zmm1 {k1}, Uf64(mvt) | KNC
	ops: rwvmm=reg r=rm | mem=1000_0000 f64-elem
	flags: krw knz unique-reg-num
END

# Code: MVEX_Undoc_zmm_k1_zmm_zmmmt_512_66_0F38_W0_94
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 94 /r | UNDOC zmm1 {k1}, zmm2, zmm3/mt | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_66_0F38_W0_94
	ops: n=reg n=vvvv n=rm | sae er swizz mem=1111_1111 f32
	flags: save-restore asm-ig
END

# Code: MVEX_Undoc_zmm_k1_zmm_zmmmt_512_66_0F38_W1_94
INSTRUCTION: MVEX.NDS.512.66.0F38.W1 94 /r | UNDOC zmm1 {k1}, zmm2, zmm3/mt | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_66_0F38_W1_94
	ops: n=reg n=vvvv n=rm | sae er swizz mem=1111_1111 f32
	flags: save-restore asm-ig
END

# Code: MVEX_Vfmadd132ps_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 98 /r | VFMADD132PS zmm1 {k1}, zmm2, Sf32(zmm3/mt) | KNC
	# For the reason why {sint8} (101b) is valid, see MVEX_Vaddps_zmm_k1_zmm_zmmmt
	ops: rwvmm=reg r=vvvv r=rm | sae er swizz mem=1111_1111
END

# Code: MVEX_Vfmadd132pd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W1 98 /r | VFMADD132PD zmm1 {k1}, zmm2, Sf64(zmm3/mt) | KNC
	ops: rwvmm=reg r=vvvv r=rm | sae er swizz mem=1110_0000
END

# Code: MVEX_Vfmsub132ps_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 9A /r | VFMSUB132PS zmm1 {k1}, zmm2, Sf32(zmm3/mt) | KNC
	# For the reason why {sint8} (101b) is valid, see MVEX_Vaddps_zmm_k1_zmm_zmmmt
	ops: rwvmm=reg r=vvvv r=rm | sae er swizz mem=1111_1111
END

# Code: MVEX_Vfmsub132pd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W1 9A /r | VFMSUB132PD zmm1 {k1}, zmm2, Sf64(zmm3/mt) | KNC
	ops: rwvmm=reg r=vvvv r=rm | sae er swizz mem=1110_0000
END

# Code: MVEX_Vfnmadd132ps_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 9C /r | VFNMADD132PS zmm1 {k1}, zmm2, Sf32(zmm3/mt) | KNC
	# For the reason why {sint8} (101b) is valid, see MVEX_Vaddps_zmm_k1_zmm_zmmmt
	ops: rwvmm=reg r=vvvv r=rm | sae er swizz mem=1111_1111
END

# Code: MVEX_Vfnmadd132pd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W1 9C /r | VFNMADD132PD zmm1 {k1}, zmm2, Sf64(zmm3/mt) | KNC
	ops: rwvmm=reg r=vvvv r=rm | sae er swizz mem=1110_0000
END

# Code: MVEX_Vfnmsub132ps_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 9E /r | VFNMSUB132PS zmm1 {k1}, zmm2, Sf32(zmm3/mt) | KNC
	# For the reason why {sint8} (101b) is valid, see MVEX_Vaddps_zmm_k1_zmm_zmmmt
	ops: rwvmm=reg r=vvvv r=rm | sae er swizz mem=1111_1111
END

# Code: MVEX_Vfnmsub132pd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W1 9E /r | VFNMSUB132PD zmm1 {k1}, zmm2, Sf64(zmm3/mt) | KNC
	ops: rwvmm=reg r=vvvv r=rm | sae er swizz mem=1110_0000
END

# Code: MVEX_Vpscatterdd_mvt_k1_zmm
INSTRUCTION: MVEX.512.66.0F38.W0 A0 /vsib | VPSCATTERDD mvt {k1}, Di32(zmm1) | KNC
	ops: w=rm r=reg | mem=1000_1111 i32-elem
	flags: krw knz
END

# Code: MVEX_Vpscatterdq_mvt_k1_zmm
INSTRUCTION: MVEX.512.66.0F38.W1 A0 /vsib | VPSCATTERDQ mvt {k1}, Di64(zmm1) | KNC
	ops: w=rm r=reg | mem=1000_0000 i64-elem
	flags: krw knz
END

# Code: MVEX_Vscatterdps_mvt_k1_zmm
INSTRUCTION: MVEX.512.66.0F38.W0 A2 /vsib | VSCATTERDPS mvt {k1}, Df32(zmm1) | KNC
	ops: w=rm r=reg | mem=1001_1111 f32-elem
	flags: krw knz
END

# Code: MVEX_Vscatterdpd_mvt_k1_zmm
INSTRUCTION: MVEX.512.66.0F38.W1 A2 /vsib | VSCATTERDPD mvt {k1}, Df64(zmm1) | KNC
	ops: w=rm r=reg | mem=1000_0000 f64-elem
	flags: krw knz
END

# Code: MVEX_Vfmadd233ps_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 A4 /r | VFMADD233PS zmm1 {k1}, zmm2, Sf32(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | sae er swizz=1000_0000 mem=1010_0000
END

# Code: MVEX_Vfmadd213ps_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 A8 /r | VFMADD213PS zmm1 {k1}, zmm2, Sf32(zmm3/mt) | KNC
	# For the reason why {sint8} (101b) is valid, see MVEX_Vaddps_zmm_k1_zmm_zmmmt
	ops: rwvmm=reg r=vvvv r=rm | sae er swizz mem=1111_1111
END

# Code: MVEX_Vfmadd213pd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W1 A8 /r | VFMADD213PD zmm1 {k1}, zmm2, Sf64(zmm3/mt) | KNC
	ops: rwvmm=reg r=vvvv r=rm | sae er swizz mem=1110_0000
END

# Code: MVEX_Vfmsub213ps_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 AA /r | VFMSUB213PS zmm1 {k1}, zmm2, Sf32(zmm3/mt) | KNC
	# For the reason why {sint8} (101b) is valid, see MVEX_Vaddps_zmm_k1_zmm_zmmmt
	ops: rwvmm=reg r=vvvv r=rm | sae er swizz mem=1111_1111
END

# Code: MVEX_Vfmsub213pd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W1 AA /r | VFMSUB213PD zmm1 {k1}, zmm2, Sf64(zmm3/mt) | KNC
	ops: rwvmm=reg r=vvvv r=rm | sae er swizz mem=1110_0000
END

# Code: MVEX_Vfnmadd213ps_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 AC /r | VFNMADD213PS zmm1 {k1}, zmm2, Sf32(zmm3/mt) | KNC
	# For the reason why {sint8} (101b) is valid, see MVEX_Vaddps_zmm_k1_zmm_zmmmt
	ops: rwvmm=reg r=vvvv r=rm | sae er swizz mem=1111_1111
END

# Code: MVEX_Vfnmadd213pd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W1 AC /r | VFNMADD213PD zmm1 {k1}, zmm2, Sf64(zmm3/mt) | KNC
	ops: rwvmm=reg r=vvvv r=rm | sae er swizz mem=1110_0000
END

# Code: MVEX_Vfnmsub213ps_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 AE /r | VFNMSUB213PS zmm1 {k1}, zmm2, Sf32(zmm3/mt) | KNC
	# For the reason why {sint8} (101b) is valid, see MVEX_Vaddps_zmm_k1_zmm_zmmmt
	ops: rwvmm=reg r=vvvv r=rm | sae er swizz mem=1111_1111
END

# Code: MVEX_Vfnmsub213pd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W1 AE /r | VFNMSUB213PD zmm1 {k1}, zmm2, Sf64(zmm3/mt) | KNC
	ops: rwvmm=reg r=vvvv r=rm | sae er swizz mem=1110_0000
END

# Code: MVEX_Undoc_zmm_k1_mvt_512_66_0F38_W0_B0
INSTRUCTION: MVEX.512.66.0F38.W0 B0 /vsib | UNDOC zmm1 {k1}, mvt | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_66_0F38_W0_B0
	ops: n=reg n=rm | sae er mem=1111_1111 f32-elem
	flags: knz save-restore asm-ig
END

# Code: MVEX_Undoc_zmm_k1_mvt_512_66_0F38_W0_B2
INSTRUCTION: MVEX.512.66.0F38.W0 B2 /vsib | UNDOC zmm1 {k1}, mvt | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_66_0F38_W0_B2
	ops: n=reg n=rm | sae er mem=1111_1111 f32-elem
	flags: knz save-restore asm-ig
END

# Code: MVEX_Vpmadd233d_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 B4 /r | VPMADD233D zmm1 {k1}, zmm2, Si32(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | swizz=1000_0000 mem=1010_0000
END

# Code: MVEX_Vpmadd231d_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 B5 /r | VPMADD231D zmm1 {k1}, zmm2, Si32(zmm3/mt) | KNC
	ops: rwvmm=reg r=vvvv r=rm | swizz mem=1110_1111
END

# Code: MVEX_Vfmadd231ps_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 B8 /r | VFMADD231PS zmm1 {k1}, zmm2, Sf32(zmm3/mt) | KNC
	# For the reason why {sint8} (101b) is valid, see MVEX_Vaddps_zmm_k1_zmm_zmmmt
	ops: rwvmm=reg r=vvvv r=rm | sae er swizz mem=1111_1111
END

# Code: MVEX_Vfmadd231pd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W1 B8 /r | VFMADD231PD zmm1 {k1}, zmm2, Sf64(zmm3/mt) | KNC
	ops: rwvmm=reg r=vvvv r=rm | sae er swizz mem=1110_0000
END

# Code: MVEX_Vfmsub231ps_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 BA /r | VFMSUB231PS zmm1 {k1}, zmm2, Sf32(zmm3/mt) | KNC
	# For the reason why {sint8} (101b) is valid, see MVEX_Vaddps_zmm_k1_zmm_zmmmt
	ops: rwvmm=reg r=vvvv r=rm | sae er swizz mem=1111_1111
END

# Code: MVEX_Vfmsub231pd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W1 BA /r | VFMSUB231PD zmm1 {k1}, zmm2, Sf64(zmm3/mt) | KNC
	ops: rwvmm=reg r=vvvv r=rm | sae er swizz mem=1110_0000
END

# Code: MVEX_Vfnmadd231ps_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 BC /r | VFNMADD231PS zmm1 {k1}, zmm2, Sf32(zmm3/mt) | KNC
	# For the reason why {sint8} (101b) is valid, see MVEX_Vaddps_zmm_k1_zmm_zmmmt
	ops: rwvmm=reg r=vvvv r=rm | sae er swizz mem=1111_1111
END

# Code: MVEX_Vfnmadd231pd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W1 BC /r | VFNMADD231PD zmm1 {k1}, zmm2, Sf64(zmm3/mt) | KNC
	ops: rwvmm=reg r=vvvv r=rm | sae er swizz mem=1110_0000
END

# Code: MVEX_Vfnmsub231ps_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 BE /r | VFNMSUB231PS zmm1 {k1}, zmm2, Sf32(zmm3/mt) | KNC
	# For the reason why {sint8} (101b) is valid, see MVEX_Vaddps_zmm_k1_zmm_zmmmt
	ops: rwvmm=reg r=vvvv r=rm | sae er swizz mem=1111_1111
END

# Code: MVEX_Vfnmsub231pd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W1 BE /r | VFNMSUB231PD zmm1 {k1}, zmm2, Sf64(zmm3/mt) | KNC
	ops: rwvmm=reg r=vvvv r=rm | sae er swizz mem=1110_0000
END

# Code: MVEX_Undoc_zmm_k1_mvt_512_66_0F38_W0_C0
INSTRUCTION: MVEX.512.66.0F38.W0 C0 /vsib | UNDOC zmm1 {k1}, mvt | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_66_0F38_W0_C0
	ops: n=reg n=rm | sae er mem=1111_1111 f32-elem
	flags: knz save-restore asm-ig
END

# Code: MVEX_Vgatherpf0hintdps_mvt_k1
INSTRUCTION: MVEX.512.66.0F38.W0 C6 /0 /vsib | VGATHERPF0HINTDPS Uf32(mvt) {k1} | KNC
	ops: nma=rm | mem=1001_1111 f32-elem
	flags: knz prefetch
END

# Code: MVEX_Vgatherpf0hintdpd_mvt_k1
INSTRUCTION: MVEX.512.66.0F38.W1 C6 /0 /vsib | VGATHERPF0HINTDPD Uf64(mvt) {k1} | KNC
	ops: nma=rm | mem=1000_0000 f64-elem
	flags: knz prefetch
END

# Code: MVEX_Vgatherpf0dps_mvt_k1
INSTRUCTION: MVEX.512.66.0F38.W0 C6 /1 /vsib | VGATHERPF0DPS Uf32(mvt) {k1} | KNC
	ops: nma=rm | mem=1001_1111 f32-elem
	flags: krw knz prefetch
END

# Code: MVEX_Vgatherpf1dps_mvt_k1
INSTRUCTION: MVEX.512.66.0F38.W0 C6 /2 /vsib | VGATHERPF1DPS Uf32(mvt) {k1} | KNC
	ops: nma=rm | mem=1001_1111 f32-elem
	flags: krw knz prefetch
END

# Code: MVEX_Vscatterpf0hintdps_mvt_k1
INSTRUCTION: MVEX.512.66.0F38.W0 C6 /4 /vsib | VSCATTERPF0HINTDPS Uf32(mvt) {k1} | KNC
	ops: nma=rm | mem=1001_1111 f32-elem
	flags: knz prefetch
END

# Code: MVEX_Vscatterpf0hintdpd_mvt_k1
INSTRUCTION: MVEX.512.66.0F38.W1 C6 /4 /vsib | VSCATTERPF0HINTDPD Uf64(mvt) {k1} | KNC
	ops: nma=rm | mem=1000_0000 f64-elem
	flags: knz prefetch
END

# Code: MVEX_Vscatterpf0dps_mvt_k1
INSTRUCTION: MVEX.512.66.0F38.W0 C6 /5 /vsib | VSCATTERPF0DPS Uf32(mvt) {k1} | KNC
	ops: nma=rm | mem=1001_1111 f32-elem
	flags: krw knz prefetch
END

# Code: MVEX_Vscatterpf1dps_mvt_k1
INSTRUCTION: MVEX.512.66.0F38.W0 C6 /6 /vsib | VSCATTERPF1DPS Uf32(mvt) {k1} | KNC
	ops: nma=rm | mem=1001_1111 f32-elem
	flags: krw knz prefetch
END

# Code: MVEX_Vexp223ps_zmm_k1_zmmmt
INSTRUCTION: MVEX.512.66.0F38.W0 C8 /r | VEXP223PS zmm1 {k1}, zmm2/mt | KNC
	ops: wvmm=reg r=rm | sae swizz=1000_0000 mem=1000_0000 i32
END

# Code: MVEX_Vlog2ps_zmm_k1_zmmmt
INSTRUCTION: MVEX.512.66.0F38.W0 C9 /r | VLOG2PS zmm1 {k1}, zmm2/mt | KNC
	ops: wvmm=reg r=rm | sae swizz=1000_0000 mem=1000_0000 f32
END

# Code: MVEX_Vrcp23ps_zmm_k1_zmmmt
INSTRUCTION: MVEX.512.66.0F38.W0 CA /r | VRCP23PS zmm1 {k1}, zmm2/mt | KNC
	ops: wvmm=reg r=rm | sae swizz=1000_0000 mem=1000_0000 f32
END

# Code: MVEX_Vrsqrt23ps_zmm_k1_zmmmt
INSTRUCTION: MVEX.512.66.0F38.W0 CB /r | VRSQRT23PS zmm1 {k1}, zmm2/mt | KNC
	ops: wvmm=reg r=rm | sae swizz=1000_0000 mem=1000_0000 f32
END

# Code: MVEX_Vaddsetsps_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 CC /r | VADDSETSPS zmm1 {k1}, zmm2, Sf32(zmm3/mt) | KNC
	# For the reason why {sint8} (101b) is valid, see MVEX_Vaddps_zmm_k1_zmm_zmmmt
	ops: wvmm=reg r=vvvv r=rm | sae er swizz mem=1111_1111
	flags: krw knz
END

# Code: MVEX_Vpaddsetsd_zmm_k1_zmm_zmmmt
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 CD /r | VPADDSETSD zmm1 {k1}, zmm2, Si32(zmm3/mt) | KNC
	ops: wvmm=reg r=vvvv r=rm | swizz mem=1110_1111
	flags: krw knz
END

# Code: MVEX_Undoc_zmm_k1_zmm_zmmmt_512_66_0F38_W0_CE
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 CE /r | UNDOC zmm1 {k1}, zmm2, zmm3/mt | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_66_0F38_W0_CE
	ops: n=reg n=vvvv n=rm | sae er swizz mem=1111_1111 f32
	flags: save-restore asm-ig
END

# Code: MVEX_Undoc_zmm_k1_zmm_zmmmt_512_66_0F38_W1_CE
INSTRUCTION: MVEX.NDS.512.66.0F38.W1 CE /r | UNDOC zmm1 {k1}, zmm2, zmm3/mt | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_66_0F38_W1_CE
	ops: n=reg n=vvvv n=rm | sae er swizz mem=1111_1111 f32
	flags: save-restore asm-ig
END

# Code: MVEX_Undoc_zmm_k1_zmm_zmmmt_512_66_0F38_W0_CF
INSTRUCTION: MVEX.NDS.512.66.0F38.W0 CF /r | UNDOC zmm1 {k1}, zmm2, zmm3/mt | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_66_0F38_W0_CF
	ops: n=reg n=vvvv n=rm | sae er swizz mem=1111_1111 f32
	flags: save-restore asm-ig
END

# Code: MVEX_Vloadunpackld_zmm_k1_mt
INSTRUCTION: MVEX.512.0F38.W0 D0 /r | VLOADUNPACKLD zmm1 {k1}, Ui32(mt) | KNC
	ops: rwvmm=reg r=rm | mem=1000_1111 i32-elem
END

# Code: MVEX_Vloadunpacklq_zmm_k1_mt
INSTRUCTION: MVEX.512.0F38.W1 D0 /r | VLOADUNPACKLQ zmm1 {k1}, Ui64(mt) | KNC
	ops: rwvmm=reg r=rm | mem=1000_0000 i64-elem
END

# Code: MVEX_Vpackstoreld_mt_k1_zmm
INSTRUCTION: MVEX.512.66.0F38.W0 D0 /r | VPACKSTORELD mt {k1}, Di32(zmm1) | KNC
	ops: w=rm r=reg | mem=1000_1111 i32-elem
	flags: k-elem-selector
END

# Code: MVEX_Vpackstorelq_mt_k1_zmm
INSTRUCTION: MVEX.512.66.0F38.W1 D0 /r | VPACKSTORELQ mt {k1}, Di64(zmm1) | KNC
	ops: w=rm r=reg | mem=1000_0000 i64-elem
	flags: k-elem-selector
END

# Code: MVEX_Vloadunpacklps_zmm_k1_mt
INSTRUCTION: MVEX.512.0F38.W0 D1 /r | VLOADUNPACKLPS zmm1 {k1}, Uf32(mt) | KNC
	ops: rwvmm=reg r=rm | mem=1001_1111 f32-elem
END

# Code: MVEX_Vloadunpacklpd_zmm_k1_mt
INSTRUCTION: MVEX.512.0F38.W1 D1 /r | VLOADUNPACKLPD zmm1 {k1}, Uf64(mt) | KNC
	ops: rwvmm=reg r=rm | mem=1000_0000 f64-elem
END

# Code: MVEX_Vpackstorelps_mt_k1_zmm
INSTRUCTION: MVEX.512.66.0F38.W0 D1 /r | VPACKSTORELPS mt {k1}, Df32(zmm1) | KNC
	ops: w=rm r=reg | mem=1001_1111 f32-elem
	flags: k-elem-selector
END

# Code: MVEX_Vpackstorelpd_mt_k1_zmm
INSTRUCTION: MVEX.512.66.0F38.W1 D1 /r | VPACKSTORELPD mt {k1}, Df64(zmm1) | KNC
	ops: w=rm r=reg | mem=1000_0000 f64-elem
	flags: k-elem-selector
END

# Code: MVEX_Undoc_zmm_k1_zmmmt_512_0F38_W0_D2
INSTRUCTION: MVEX.512.0F38.W0 D2 /r | UNDOC zmm1 {k1}, zmm2/mt | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_0F38_W0_D2
	ops: n=reg n=rm | sae er swizz mem=1111_1111 f32
	flags: save-restore asm-ig
END

# Code: MVEX_Undoc_zmm_k1_zmmmt_512_66_0F38_W0_D2
INSTRUCTION: MVEX.512.66.0F38.W0 D2 /r | UNDOC zmm1 {k1}, zmm2/mt | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_66_0F38_W0_D2
	ops: n=reg n=rm | sae er swizz mem=1111_1111 f32
	flags: save-restore asm-ig
END

# Code: MVEX_Undoc_zmm_k1_zmmmt_512_0F38_W0_D3
INSTRUCTION: MVEX.512.0F38.W0 D3 /r | UNDOC zmm1 {k1}, zmm2/mt | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_0F38_W0_D3
	ops: n=reg n=rm | sae er swizz mem=1111_1111 f32
	flags: save-restore asm-ig
END

# Code: MVEX_Vloadunpackhd_zmm_k1_mt
INSTRUCTION: MVEX.512.0F38.W0 D4 /r | VLOADUNPACKHD zmm1 {k1}, Ui32(mt) | KNC
	implied: mem-displ=-64
	ops: rwvmm=reg r=rm | mem=1000_1111 i32-elem
END

# Code: MVEX_Vloadunpackhq_zmm_k1_mt
INSTRUCTION: MVEX.512.0F38.W1 D4 /r | VLOADUNPACKHQ zmm1 {k1}, Ui64(mt) | KNC
	implied: mem-displ=-64
	ops: rwvmm=reg r=rm | mem=1000_0000 i64-elem
END

# Code: MVEX_Vpackstorehd_mt_k1_zmm
INSTRUCTION: MVEX.512.66.0F38.W0 D4 /r | VPACKSTOREHD mt {k1}, Di32(zmm1) | KNC
	implied: mem-displ=-64
	ops: w=rm r=reg | mem=1000_1111 i32-elem
	flags: k-elem-selector
END

# Code: MVEX_Vpackstorehq_mt_k1_zmm
INSTRUCTION: MVEX.512.66.0F38.W1 D4 /r | VPACKSTOREHQ mt {k1}, Di64(zmm1) | KNC
	implied: mem-displ=-64
	ops: w=rm r=reg | mem=1000_0000 i64-elem
	flags: k-elem-selector
END

# Code: MVEX_Vloadunpackhps_zmm_k1_mt
INSTRUCTION: MVEX.512.0F38.W0 D5 /r | VLOADUNPACKHPS zmm1 {k1}, Uf32(mt) | KNC
	implied: mem-displ=-64
	ops: rwvmm=reg r=rm | mem=1001_1111 f32-elem
END

# Code: MVEX_Vloadunpackhpd_zmm_k1_mt
INSTRUCTION: MVEX.512.0F38.W1 D5 /r | VLOADUNPACKHPD zmm1 {k1}, Uf64(mt) | KNC
	implied: mem-displ=-64
	ops: rwvmm=reg r=rm | mem=1000_0000 f64-elem
END

# Code: MVEX_Vpackstorehps_mt_k1_zmm
INSTRUCTION: MVEX.512.66.0F38.W0 D5 /r | VPACKSTOREHPS mt {k1}, Df32(zmm1) | KNC
	implied: mem-displ=-64
	ops: w=rm r=reg | mem=1001_1111 f32-elem
	flags: k-elem-selector
END

# Code: MVEX_Vpackstorehpd_mt_k1_zmm
INSTRUCTION: MVEX.512.66.0F38.W1 D5 /r | VPACKSTOREHPD mt {k1}, Df64(zmm1) | KNC
	implied: mem-displ=-64
	ops: w=rm r=reg | mem=1000_0000 f64-elem
	flags: k-elem-selector
END

# Code: MVEX_Undoc_zmm_k1_zmmmt_512_0F38_W0_D6
INSTRUCTION: MVEX.512.0F38.W0 D6 /r | UNDOC zmm1 {k1}, zmm2/mt | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_0F38_W0_D6
	ops: n=reg n=rm | sae er swizz mem=1111_1111 f32
	flags: save-restore asm-ig
END

# Code: MVEX_Undoc_zmm_k1_zmmmt_512_66_0F38_W0_D6
INSTRUCTION: MVEX.512.66.0F38.W0 D6 /r | UNDOC zmm1 {k1}, zmm2/mt | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_66_0F38_W0_D6
	ops: n=reg n=rm | sae er swizz mem=1111_1111 f32
	flags: save-restore asm-ig
END

# Code: MVEX_Undoc_zmm_k1_zmmmt_512_0F38_W0_D7
INSTRUCTION: MVEX.512.0F38.W0 D7 /r | UNDOC zmm1 {k1}, zmm2/mt | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_0F38_W0_D7
	ops: n=reg n=rm | sae er swizz mem=1111_1111 f32
	flags: save-restore asm-ig
END

# Code: MVEX_Valignd_zmm_k1_zmm_zmmmt_imm8
INSTRUCTION: MVEX.NDS.512.66.0F3A.W0 03 /r ib | VALIGND zmm1 {k1}, zmm2, zmm3/mt, imm8 | KNC
	ops: wvmm=reg r=vvvv r=rm r=imm | no-er-sae swizz=1000_0000 mem=1000_0000 i32
END

# Code: MVEX_Vpermf32x4_zmm_k1_zmmmt_imm8
INSTRUCTION: MVEX.512.66.0F3A.W0 07 /r ib | VPERMF32X4 zmm1 {k1}, zmm2/mt, imm8 | KNC
	ops: wvmm=reg r=rm r=imm | no-er-sae swizz=1000_0000 mem=1000_0000 f32
END

# Code: MVEX_Vpcmpud_kr_k1_zmm_zmmmt_imm8
INSTRUCTION: MVEX.NDS.512.66.0F3A.W0 1E /r ib | VPCMPUD k2 {k1}, zmm1, Si32(zmm2/mt), imm8 | KNC
	ops: w=reg r=vvvv r=rm r=imm | no-er-sae swizz mem=1110_1111
	flags: pseudo=vpcmpud6 implied-z
END

# Code: MVEX_Vpcmpd_kr_k1_zmm_zmmmt_imm8
INSTRUCTION: MVEX.NDS.512.66.0F3A.W0 1F /r ib | VPCMPD k2 {k1}, zmm1, Si32(zmm2/mt), imm8 | KNC
	ops: w=reg r=vvvv r=rm r=imm | no-er-sae swizz mem=1110_1111
	flags: pseudo=vpcmpd6 implied-z
END

# Code: MVEX_Vgetmantps_zmm_k1_zmmmt_imm8
INSTRUCTION: MVEX.512.66.0F3A.W0 26 /r ib | VGETMANTPS zmm1 {k1}, Sf32(zmm2/mt), imm8 | KNC
	# For the reason why {sint8} (101b) is valid, see MVEX_Vaddps_zmm_k1_zmm_zmmmt
	ops: wvmm=reg r=rm r=imm | sae swizz mem=1111_1111
END

# Code: MVEX_Vgetmantpd_zmm_k1_zmmmt_imm8
INSTRUCTION: MVEX.512.66.0F3A.W1 26 /r ib | VGETMANTPD zmm1 {k1}, Sf64(zmm2/mt), imm8 | KNC
	ops: wvmm=reg r=rm r=imm | sae swizz mem=1110_0000
END

# Code: MVEX_Vrndfxpntps_zmm_k1_zmmmt_imm8
INSTRUCTION: MVEX.512.66.0F3A.W0 52 /r ib | VRNDFXPNTPS zmm1 {k1}, Sf32(zmm2/mt), imm8 | KNC
	# For the reason why {sint8} (101b) is valid, see MVEX_Vaddps_zmm_k1_zmm_zmmmt
	ops: wvmm=reg r=rm r=imm | sae er-imm swizz mem=1111_1111
END

# Code: MVEX_Vrndfxpntpd_zmm_k1_zmmmt_imm8
INSTRUCTION: MVEX.512.66.0F3A.W1 52 /r ib | VRNDFXPNTPD zmm1 {k1}, Sf64(zmm2/mt), imm8 | KNC
	ops: wvmm=reg r=rm r=imm | sae er-imm swizz mem=1110_0000
END

# Code: MVEX_Vcvtfxpntudq2ps_zmm_k1_zmmmt_imm8
INSTRUCTION: MVEX.512.0F3A.W0 CA /r ib | VCVTFXPNTUDQ2PS zmm1 {k1}, Si32(zmm2/mt), imm8 | KNC
	ops: wvmm=reg r=rm r=imm | sae er-imm swizz mem=1110_1111
END

# Code: MVEX_Vcvtfxpntps2udq_zmm_k1_zmmmt_imm8
INSTRUCTION: MVEX.512.66.0F3A.W0 CA /r ib | VCVTFXPNTPS2UDQ zmm1 {k1}, Sf32(zmm2/mt), imm8 | KNC
	# For the reason why {sint8} (101b) is valid, see MVEX_Vaddps_zmm_k1_zmm_zmmmt
	ops: wvmm=reg r=rm r=imm | sae er-imm swizz mem=1111_1111
END

# Code: MVEX_Vcvtfxpntpd2udq_zmm_k1_zmmmt_imm8
INSTRUCTION: MVEX.512.F2.0F3A.W1 CA /r ib | VCVTFXPNTPD2UDQ zmm1 {k1}, Sf64(zmm2/mt), imm8 | KNC
	ops: wvmm=reg r=rm r=imm | sae er-imm swizz mem=1110_0000
END

# Code: MVEX_Vcvtfxpntdq2ps_zmm_k1_zmmmt_imm8
INSTRUCTION: MVEX.512.0F3A.W0 CB /r ib | VCVTFXPNTDQ2PS zmm1 {k1}, Si32(zmm2/mt), imm8 | KNC
	ops: wvmm=reg r=rm r=imm | sae er-imm swizz mem=1110_1111
END

# Code: MVEX_Vcvtfxpntps2dq_zmm_k1_zmmmt_imm8
INSTRUCTION: MVEX.512.66.0F3A.W0 CB /r ib | VCVTFXPNTPS2DQ zmm1 {k1}, Sf32(zmm2/mt), imm8 | KNC
	# For the reason why {sint8} (101b) is valid, see MVEX_Vaddps_zmm_k1_zmm_zmmmt
	ops: wvmm=reg r=rm r=imm | sae er-imm swizz mem=1111_1111
END

# Code: MVEX_Undoc_zmm_k1_zmmmt_imm8_512_66_0F3A_W0_D0
INSTRUCTION: MVEX.512.66.0F3A.W0 D0 /r ib | UNDOC zmm1 {k1}, zmm2/mt, imm8 | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_66_0F3A_W0_D0
	ops: n=reg n=rm n=imm | sae er swizz mem=1111_1111 f32
	flags: save-restore asm-ig
END

# Code: MVEX_Undoc_zmm_k1_zmmmt_imm8_512_66_0F3A_W0_D1
INSTRUCTION: MVEX.512.66.0F3A.W0 D1 /r ib | UNDOC zmm1 {k1}, zmm2/mt, imm8 | KNC
	# Undocumented instruction. We need ops to decode/encode it so we chose these ops but they could be wrong!
	code-suffix: 512_66_0F3A_W0_D1
	ops: n=reg n=rm n=imm | sae er swizz mem=1111_1111 f32
	flags: save-restore asm-ig
END

# Code: MVEX_Vcvtfxpntpd2dq_zmm_k1_zmmmt_imm8
INSTRUCTION: MVEX.512.F2.0F3A.W1 E6 /r ib | VCVTFXPNTPD2DQ zmm1 {k1}, Sf64(zmm2/mt), imm8 | KNC
	ops: wvmm=reg r=rm r=imm | sae er-imm swizz mem=1110_0000
END

# Code: Wrmsrns
INSTRUCTION: NP 0F 01 C6 | WRMSRNS | WRMSRNS
	implied: r=eax;ecx;edx
	flags: cpl0 intel-may-vm-exit tdx-non-root-may-gen-ex amd-may-vm-exit tsx-impl-abort
END

# Code: Wrmsrlist
INSTRUCTION: F3 0F 01 C6 | WRMSRLIST | MSRLIST
	# Reads a u64 from [rsi+index*8] and a u64 from [rdi+index*8] where 0 <= index <= 63 (index = index of set bit in rcx)
	implied: r=rcx cr=rsi;rdi cw=rcx cr=[ds:rsi=Unknown] cr=[es:rdi=Unknown]
	# Not a serializing instruction, unlike WRMSR
	# rsi/rdi must be 8-byte aligned
	flags: 64 cpl0 intel-may-vm-exit tdx-non-root-may-gen-ex amd-may-vm-exit tsx-impl-abort aligned-mem
END

# Code: Rdmsrlist
INSTRUCTION: F2 0F 01 C6 | RDMSRLIST | MSRLIST
	# Reads a u64 from [rsi+index*8] and writes a u64 to [rdi+index*8] where 0 <= index <= 63 (index = index of set bit in rcx)
	implied: r=rcx cr=rsi;rdi cw=rcx cr=[ds:rsi=Unknown] cw=[es:rdi=Unknown]
	# rsi/rdi must be 8-byte aligned
	flags: 64 cpl0 intel-may-vm-exit tdx-non-root-may-gen-ex amd-may-vm-exit tsx-impl-abort aligned-mem
END

# Code: Rmpquery
INSTRUCTION: F3 0F 01 FD | RMPQUERY | RMPQUERY
	# Only writes rdx[63:8]
	implied: r=rax;dl w=eax;rcx;rdx
	rflags: w=oszap
	# #VMEXIT(NPF)
	flags: 64 cpl0 amd-may-vm-exit
END

# Code: Prefetchit1_m8
INSTRUCTION: 0F 18 /6 | PREFETCHIT1 m8 | PREFETCHITI
	# If not supported by the CPU or if not RIP relative memory operand, it's treated as a NOP
	ops: nma=rm | UInt8
	flags: prefetch
END

# Code: Prefetchit0_m8
INSTRUCTION: 0F 18 /7 | PREFETCHIT0 m8 | PREFETCHITI
	# If not supported by the CPU or if not RIP relative memory operand, it's treated as a NOP
	ops: nma=rm | UInt8
	flags: prefetch
END

# Code: Aadd_m32_r32
INSTRUCTION: NP 0F 38 FC !(11):rrr:bbb | AADD m32, r32 | RAO_INT
	ops: rw=rm r=reg | UInt32
	flags: tsx-abort atomic aligned-mem
END

# Code: Aadd_m64_r64
INSTRUCTION: NP o64 0F 38 FC !(11):rrr:bbb | AADD m64, r64 | RAO_INT
	ops: rw=rm r=reg | UInt64
	flags: 64 tsx-abort atomic aligned-mem
END

# Code: Aand_m32_r32
INSTRUCTION: 66 0F 38 FC !(11):rrr:bbb | AAND m32, r32 | RAO_INT
	ops: rw=rm r=reg | UInt32
	flags: tsx-abort atomic aligned-mem
END

# Code: Aand_m64_r64
INSTRUCTION: 66 o64 0F 38 FC !(11):rrr:bbb | AAND m64, r64 | RAO_INT
	ops: rw=rm r=reg | UInt64
	flags: 64 tsx-abort atomic aligned-mem
END

# Code: Axor_m32_r32
INSTRUCTION: F3 0F 38 FC !(11):rrr:bbb | AXOR m32, r32 | RAO_INT
	ops: rw=rm r=reg | UInt32
	flags: tsx-abort atomic aligned-mem
END

# Code: Axor_m64_r64
INSTRUCTION: F3 o64 0F 38 FC !(11):rrr:bbb | AXOR m64, r64 | RAO_INT
	ops: rw=rm r=reg | UInt64
	flags: 64 tsx-abort atomic aligned-mem
END

# Code: Aor_m32_r32
INSTRUCTION: F2 0F 38 FC !(11):rrr:bbb | AOR m32, r32 | RAO_INT
	ops: rw=rm r=reg | UInt32
	flags: tsx-abort atomic aligned-mem
END

# Code: Aor_m64_r64
INSTRUCTION: F2 o64 0F 38 FC !(11):rrr:bbb | AOR m64, r64 | RAO_INT
	ops: rw=rm r=reg | UInt64
	flags: 64 tsx-abort atomic aligned-mem
END

# Code: VEX_Vpdpbuud_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.0F38.W0 50 /r | VPDPBUUD xmm1, xmm2, xmm3/m128 | AVX_VNNI_INT8
	ops: rw=reg r=vvvv r=rm | Packed128_UInt8
END

# Code: VEX_Vpdpbuud_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.0F38.W0 50 /r | VPDPBUUD ymm1, ymm2, ymm3/m256 | AVX_VNNI_INT8
	ops: rw=reg r=vvvv r=rm | Packed256_UInt8
END

# Code: VEX_Vpdpbsud_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.F3.0F38.W0 50 /r | VPDPBSUD xmm1, xmm2, xmm3/m128 | AVX_VNNI_INT8
	ops: rw=reg r=vvvv r=rm | Packed128_Int8
END

# Code: VEX_Vpdpbsud_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.F3.0F38.W0 50 /r | VPDPBSUD ymm1, ymm2, ymm3/m256 | AVX_VNNI_INT8
	ops: rw=reg r=vvvv r=rm | Packed256_Int8
END

# Code: VEX_Vpdpbssd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.F2.0F38.W0 50 /r | VPDPBSSD xmm1, xmm2, xmm3/m128 | AVX_VNNI_INT8
	ops: rw=reg r=vvvv r=rm | Packed128_Int8
END

# Code: VEX_Vpdpbssd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.F2.0F38.W0 50 /r | VPDPBSSD ymm1, ymm2, ymm3/m256 | AVX_VNNI_INT8
	ops: rw=reg r=vvvv r=rm | Packed256_Int8
END

# Code: VEX_Vpdpbuuds_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.0F38.W0 51 /r | VPDPBUUDS xmm1, xmm2, xmm3/m128 | AVX_VNNI_INT8
	ops: rw=reg r=vvvv r=rm | Packed128_UInt8
END

# Code: VEX_Vpdpbuuds_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.0F38.W0 51 /r | VPDPBUUDS ymm1, ymm2, ymm3/m256 | AVX_VNNI_INT8
	ops: rw=reg r=vvvv r=rm | Packed256_UInt8
END

# Code: VEX_Vpdpbsuds_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.F3.0F38.W0 51 /r | VPDPBSUDS xmm1, xmm2, xmm3/m128 | AVX_VNNI_INT8
	ops: rw=reg r=vvvv r=rm | Packed128_Int8
END

# Code: VEX_Vpdpbsuds_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.F3.0F38.W0 51 /r | VPDPBSUDS ymm1, ymm2, ymm3/m256 | AVX_VNNI_INT8
	ops: rw=reg r=vvvv r=rm | Packed256_Int8
END

# Code: VEX_Vpdpbssds_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.F2.0F38.W0 51 /r | VPDPBSSDS xmm1, xmm2, xmm3/m128 | AVX_VNNI_INT8
	ops: rw=reg r=vvvv r=rm | Packed128_Int8
END

# Code: VEX_Vpdpbssds_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.F2.0F38.W0 51 /r | VPDPBSSDS ymm1, ymm2, ymm3/m256 | AVX_VNNI_INT8
	ops: rw=reg r=vvvv r=rm | Packed256_Int8
END

# Code: VEX_Tdpfp16ps_tmm_tmm_tmm
INSTRUCTION: VEX.128.F2.0F38.W0 5C 11:rrr:bbb | TDPFP16PS tmm1, tmm2, tmm3 | AMX_FP16
	ops: rw=reg r=rm r=vvvv
	flags: 64 unique-reg-num tsx-abort
END

# Code: VEX_Vcvtneps2bf16_xmm_xmmm128
INSTRUCTION: VEX.128.F3.0F38.W0 72 /r | VCVTNEPS2BF16 xmm1, xmm2/m128 | AVX_NE_CONVERT
	ops: w=reg r=rm | Packed128_Float32
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=x
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: VEX_Vcvtneps2bf16_xmm_ymmm256
INSTRUCTION: VEX.256.F3.0F38.W0 72 /r | VCVTNEPS2BF16 xmm1, ymm2/m256 | AVX_NE_CONVERT
	ops: w=reg r=rm | Packed256_Float32
	fast: flags=force-size=always
	gas: flags=force-mem-suffix suffix=y
	intel: flags=force-size=always
	masm: flags=force-size=always
	nasm: flags=force-size=always
END

# Code: VEX_Vcvtneoph2ps_xmm_m128
INSTRUCTION: VEX.128.0F38.W0 B0 !(11):rrr:bbb | VCVTNEOPH2PS xmm1, m128 | AVX_NE_CONVERT
	ops: w=reg r=rm | Packed128_Float16
END

# Code: VEX_Vcvtneoph2ps_ymm_m256
INSTRUCTION: VEX.256.0F38.W0 B0 !(11):rrr:bbb | VCVTNEOPH2PS ymm1, m256 | AVX_NE_CONVERT
	ops: w=reg r=rm | Packed256_Float16
END

# Code: VEX_Vcvtneeph2ps_xmm_m128
INSTRUCTION: VEX.128.66.0F38.W0 B0 !(11):rrr:bbb | VCVTNEEPH2PS xmm1, m128 | AVX_NE_CONVERT
	ops: w=reg r=rm | Packed128_Float16
END

# Code: VEX_Vcvtneeph2ps_ymm_m256
INSTRUCTION: VEX.256.66.0F38.W0 B0 !(11):rrr:bbb | VCVTNEEPH2PS ymm1, m256 | AVX_NE_CONVERT
	ops: w=reg r=rm | Packed256_Float16
END

# Code: VEX_Vcvtneebf162ps_xmm_m128
INSTRUCTION: VEX.128.F3.0F38.W0 B0 !(11):rrr:bbb | VCVTNEEBF162PS xmm1, m128 | AVX_NE_CONVERT
	ops: w=reg r=rm | Packed128_BFloat16
END

# Code: VEX_Vcvtneebf162ps_ymm_m256
INSTRUCTION: VEX.256.F3.0F38.W0 B0 !(11):rrr:bbb | VCVTNEEBF162PS ymm1, m256 | AVX_NE_CONVERT
	ops: w=reg r=rm | Packed256_BFloat16
END

# Code: VEX_Vcvtneobf162ps_xmm_m128
INSTRUCTION: VEX.128.F2.0F38.W0 B0 !(11):rrr:bbb | VCVTNEOBF162PS xmm1, m128 | AVX_NE_CONVERT
	ops: w=reg r=rm | Packed128_BFloat16
END

# Code: VEX_Vcvtneobf162ps_ymm_m256
INSTRUCTION: VEX.256.F2.0F38.W0 B0 !(11):rrr:bbb | VCVTNEOBF162PS ymm1, m256 | AVX_NE_CONVERT
	ops: w=reg r=rm | Packed256_BFloat16
END

# Code: VEX_Vbcstnesh2ps_xmm_m16
INSTRUCTION: VEX.128.66.0F38.W0 B1 !(11):rrr:bbb | VBCSTNESH2PS xmm1, m16 | AVX_NE_CONVERT
	ops: w=reg r=rm | Float16
END

# Code: VEX_Vbcstnesh2ps_ymm_m16
INSTRUCTION: VEX.256.66.0F38.W0 B1 !(11):rrr:bbb | VBCSTNESH2PS ymm1, m16 | AVX_NE_CONVERT
	ops: w=reg r=rm | Float16
END

# Code: VEX_Vbcstnebf162ps_xmm_m16
INSTRUCTION: VEX.128.F3.0F38.W0 B1 !(11):rrr:bbb | VBCSTNEBF162PS xmm1, m16 | AVX_NE_CONVERT
	ops: w=reg r=rm | BFloat16
END

# Code: VEX_Vbcstnebf162ps_ymm_m16
INSTRUCTION: VEX.256.F3.0F38.W0 B1 !(11):rrr:bbb | VBCSTNEBF162PS ymm1, m16 | AVX_NE_CONVERT
	ops: w=reg r=rm | BFloat16
END

# Code: VEX_Vpmadd52luq_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W1 B4 /r | VPMADD52LUQ xmm1, xmm2, xmm3/m128 | AVX_IFMA
	ops: rw=reg r=vvvv r=rm | Packed128_UInt52
END

# Code: VEX_Vpmadd52luq_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W1 B4 /r | VPMADD52LUQ ymm1, ymm2, ymm3/m256 | AVX_IFMA
	ops: rw=reg r=vvvv r=rm | Packed256_UInt52
END

# Code: VEX_Vpmadd52huq_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W1 B5 /r | VPMADD52HUQ xmm1, xmm2, xmm3/m128 | AVX_IFMA
	ops: rw=reg r=vvvv r=rm | Packed128_UInt52
END

# Code: VEX_Vpmadd52huq_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W1 B5 /r | VPMADD52HUQ ymm1, ymm2, ymm3/m256 | AVX_IFMA
	ops: rw=reg r=vvvv r=rm | Packed256_UInt52
END

# Code: VEX_Cmpoxadd_m32_r32_r32
INSTRUCTION: VEX.128.66.0F38.W0 E0 !(11):rrr:bbb | CMPOXADD m32, r32, r32 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt32
	rflags: w=oszacp
	flags: wig32 64 cc=cmp;o;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmpoxadd_m64_r64_r64
INSTRUCTION: VEX.128.66.0F38.W1 E0 !(11):rrr:bbb | CMPOXADD m64, r64, r64 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt64
	rflags: w=oszacp
	flags: 64 cc=cmp;o;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmpnoxadd_m32_r32_r32
INSTRUCTION: VEX.128.66.0F38.W0 E1 !(11):rrr:bbb | CMPNOXADD m32, r32, r32 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt32
	rflags: w=oszacp
	flags: wig32 64 cc=cmp;no;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmpnoxadd_m64_r64_r64
INSTRUCTION: VEX.128.66.0F38.W1 E1 !(11):rrr:bbb | CMPNOXADD m64, r64, r64 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt64
	rflags: w=oszacp
	flags: 64 cc=cmp;no;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmpbxadd_m32_r32_r32
INSTRUCTION: VEX.128.66.0F38.W0 E2 !(11):rrr:bbb | CMPBXADD m32, r32, r32 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt32
	rflags: w=oszacp
	flags: wig32 64 cc=cmp;b;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmpbxadd_m64_r64_r64
INSTRUCTION: VEX.128.66.0F38.W1 E2 !(11):rrr:bbb | CMPBXADD m64, r64, r64 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt64
	rflags: w=oszacp
	flags: 64 cc=cmp;b;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmpnbxadd_m32_r32_r32
INSTRUCTION: VEX.128.66.0F38.W0 E3 !(11):rrr:bbb | CMPNBXADD m32, r32, r32 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt32
	rflags: w=oszacp
	flags: wig32 64 cc=cmp;ae;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmpnbxadd_m64_r64_r64
INSTRUCTION: VEX.128.66.0F38.W1 E3 !(11):rrr:bbb | CMPNBXADD m64, r64, r64 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt64
	rflags: w=oszacp
	flags: 64 cc=cmp;ae;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmpzxadd_m32_r32_r32
INSTRUCTION: VEX.128.66.0F38.W0 E4 !(11):rrr:bbb | CMPZXADD m32, r32, r32 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt32
	rflags: w=oszacp
	flags: wig32 64 cc=cmp;e;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmpzxadd_m64_r64_r64
INSTRUCTION: VEX.128.66.0F38.W1 E4 !(11):rrr:bbb | CMPZXADD m64, r64, r64 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt64
	rflags: w=oszacp
	flags: 64 cc=cmp;e;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmpnzxadd_m32_r32_r32
INSTRUCTION: VEX.128.66.0F38.W0 E5 !(11):rrr:bbb | CMPNZXADD m32, r32, r32 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt32
	rflags: w=oszacp
	flags: wig32 64 cc=cmp;ne;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmpnzxadd_m64_r64_r64
INSTRUCTION: VEX.128.66.0F38.W1 E5 !(11):rrr:bbb | CMPNZXADD m64, r64, r64 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt64
	rflags: w=oszacp
	flags: 64 cc=cmp;ne;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmpbexadd_m32_r32_r32
INSTRUCTION: VEX.128.66.0F38.W0 E6 !(11):rrr:bbb | CMPBEXADD m32, r32, r32 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt32
	rflags: w=oszacp
	flags: wig32 64 cc=cmp;be;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmpbexadd_m64_r64_r64
INSTRUCTION: VEX.128.66.0F38.W1 E6 !(11):rrr:bbb | CMPBEXADD m64, r64, r64 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt64
	rflags: w=oszacp
	flags: 64 cc=cmp;be;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmpnbexadd_m32_r32_r32
INSTRUCTION: VEX.128.66.0F38.W0 E7 !(11):rrr:bbb | CMPNBEXADD m32, r32, r32 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt32
	rflags: w=oszacp
	flags: wig32 64 cc=cmp;a;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmpnbexadd_m64_r64_r64
INSTRUCTION: VEX.128.66.0F38.W1 E7 !(11):rrr:bbb | CMPNBEXADD m64, r64, r64 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt64
	rflags: w=oszacp
	flags: 64 cc=cmp;a;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmpsxadd_m32_r32_r32
INSTRUCTION: VEX.128.66.0F38.W0 E8 !(11):rrr:bbb | CMPSXADD m32, r32, r32 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt32
	rflags: w=oszacp
	flags: wig32 64 cc=cmp;s;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmpsxadd_m64_r64_r64
INSTRUCTION: VEX.128.66.0F38.W1 E8 !(11):rrr:bbb | CMPSXADD m64, r64, r64 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt64
	rflags: w=oszacp
	flags: 64 cc=cmp;s;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmpnsxadd_m32_r32_r32
INSTRUCTION: VEX.128.66.0F38.W0 E9 !(11):rrr:bbb | CMPNSXADD m32, r32, r32 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt32
	rflags: w=oszacp
	flags: wig32 64 cc=cmp;ns;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmpnsxadd_m64_r64_r64
INSTRUCTION: VEX.128.66.0F38.W1 E9 !(11):rrr:bbb | CMPNSXADD m64, r64, r64 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt64
	rflags: w=oszacp
	flags: 64 cc=cmp;ns;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmppxadd_m32_r32_r32
INSTRUCTION: VEX.128.66.0F38.W0 EA !(11):rrr:bbb | CMPPXADD m32, r32, r32 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt32
	rflags: w=oszacp
	flags: wig32 64 cc=cmp;p;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmppxadd_m64_r64_r64
INSTRUCTION: VEX.128.66.0F38.W1 EA !(11):rrr:bbb | CMPPXADD m64, r64, r64 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt64
	rflags: w=oszacp
	flags: 64 cc=cmp;p;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmpnpxadd_m32_r32_r32
INSTRUCTION: VEX.128.66.0F38.W0 EB !(11):rrr:bbb | CMPNPXADD m32, r32, r32 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt32
	rflags: w=oszacp
	flags: wig32 64 cc=cmp;np;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmpnpxadd_m64_r64_r64
INSTRUCTION: VEX.128.66.0F38.W1 EB !(11):rrr:bbb | CMPNPXADD m64, r64, r64 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt64
	rflags: w=oszacp
	flags: 64 cc=cmp;np;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmplxadd_m32_r32_r32
INSTRUCTION: VEX.128.66.0F38.W0 EC !(11):rrr:bbb | CMPLXADD m32, r32, r32 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt32
	rflags: w=oszacp
	flags: wig32 64 cc=cmp;l;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmplxadd_m64_r64_r64
INSTRUCTION: VEX.128.66.0F38.W1 EC !(11):rrr:bbb | CMPLXADD m64, r64, r64 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt64
	rflags: w=oszacp
	flags: 64 cc=cmp;l;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmpnlxadd_m32_r32_r32
INSTRUCTION: VEX.128.66.0F38.W0 ED !(11):rrr:bbb | CMPNLXADD m32, r32, r32 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt32
	rflags: w=oszacp
	flags: wig32 64 cc=cmp;ge;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmpnlxadd_m64_r64_r64
INSTRUCTION: VEX.128.66.0F38.W1 ED !(11):rrr:bbb | CMPNLXADD m64, r64, r64 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt64
	rflags: w=oszacp
	flags: 64 cc=cmp;ge;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmplexadd_m32_r32_r32
INSTRUCTION: VEX.128.66.0F38.W0 EE !(11):rrr:bbb | CMPLEXADD m32, r32, r32 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt32
	rflags: w=oszacp
	flags: wig32 64 cc=cmp;le;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmplexadd_m64_r64_r64
INSTRUCTION: VEX.128.66.0F38.W1 EE !(11):rrr:bbb | CMPLEXADD m64, r64, r64 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt64
	rflags: w=oszacp
	flags: 64 cc=cmp;le;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmpnlexadd_m32_r32_r32
INSTRUCTION: VEX.128.66.0F38.W0 EF !(11):rrr:bbb | CMPNLEXADD m32, r32, r32 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt32
	rflags: w=oszacp
	flags: wig32 64 cc=cmp;g;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Cmpnlexadd_m64_r64_r64
INSTRUCTION: VEX.128.66.0F38.W1 EF !(11):rrr:bbb | CMPNLEXADD m64, r64, r64 | CMPCCXADD
	# If condition is false, it will overwrite the memory operand with the original value.
	ops: rw=rm rw=reg r=vvvv | UInt64
	rflags: w=oszacp
	flags: 64 cc=cmp;g;xadd atomic aligned-mem
	gas: cc
	intel: cc
	masm: cc
	nasm: cc
END

# Code: VEX_Tcmmrlfp16ps_tmm_tmm_tmm
INSTRUCTION: VEX.128.0F38.W0 6C 11:rrr:bbb | TCMMRLFP16PS tmm1, tmm2, tmm3 | AMX_COMPLEX
	ops: rw=reg r=rm r=vvvv
	flags: 64 unique-reg-num tsx-abort
END

# Code: VEX_Tcmmimfp16ps_tmm_tmm_tmm
INSTRUCTION: VEX.128.66.0F38.W0 6C 11:rrr:bbb | TCMMIMFP16PS tmm1, tmm2, tmm3 | AMX_COMPLEX
	ops: rw=reg r=rm r=vvvv
	flags: 64 unique-reg-num tsx-abort
END

# Code: Pbndkb
INSTRUCTION: NP 0F 01 C7 | PBNDKB | TSE
	# Addresses stored in rbx/rcx must be 256-byte aligned and rbx must not equal rcx
	implied: r=rcx;rbx w=eax r=[ds:rbx=Unknown] w=[ds:rcx=Unknown]
	rflags: w=z 0=osacp
	flags: 64 cpl0
END

# Code: VEX_Vsha512rnds2_ymm_ymm_xmm
INSTRUCTION: VEX.256.F2.0F38.W0 CB 11:rrr:bbb | VSHA512RNDS2 ymm1, ymm2, xmm3 | AVX SHA512
	ops: rw=reg r=vvvv r=rm
END

# Code: VEX_Vsha512msg1_ymm_xmm
INSTRUCTION: VEX.256.F2.0F38.W0 CC 11:rrr:bbb | VSHA512MSG1 ymm1, xmm2 | AVX SHA512
	ops: rw=reg r=rm
END

# Code: VEX_Vsha512msg2_ymm_ymm
INSTRUCTION: VEX.256.F2.0F38.W0 CD 11:rrr:bbb | VSHA512MSG2 ymm1, ymm2 | AVX SHA512
	ops: rw=reg r=rm
END

# Code: VEX_Vpdpwuud_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.0F38.W0 D2 /r | VPDPWUUD xmm1, xmm2, xmm3/m128 | AVX_VNNI_INT16
	ops: rw=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: VEX_Vpdpwuud_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.0F38.W0 D2 /r | VPDPWUUD ymm1, ymm2, ymm3/m256 | AVX_VNNI_INT16
	ops: rw=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: VEX_Vpdpwusd_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 D2 /r | VPDPWUSD xmm1, xmm2, xmm3/m128 | AVX_VNNI_INT16
	ops: rw=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: VEX_Vpdpwusd_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 D2 /r | VPDPWUSD ymm1, ymm2, ymm3/m256 | AVX_VNNI_INT16
	ops: rw=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: VEX_Vpdpwsud_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.F3.0F38.W0 D2 /r | VPDPWSUD xmm1, xmm2, xmm3/m128 | AVX_VNNI_INT16
	ops: rw=reg r=vvvv r=rm | Packed128_Int16
END

# Code: VEX_Vpdpwsud_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.F3.0F38.W0 D2 /r | VPDPWSUD ymm1, ymm2, ymm3/m256 | AVX_VNNI_INT16
	ops: rw=reg r=vvvv r=rm | Packed256_Int16
END

# Code: VEX_Vpdpwuuds_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.0F38.W0 D3 /r | VPDPWUUDS xmm1, xmm2, xmm3/m128 | AVX_VNNI_INT16
	ops: rw=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: VEX_Vpdpwuuds_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.0F38.W0 D3 /r | VPDPWUUDS ymm1, ymm2, ymm3/m256 | AVX_VNNI_INT16
	ops: rw=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: VEX_Vpdpwusds_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 D3 /r | VPDPWUSDS xmm1, xmm2, xmm3/m128 | AVX_VNNI_INT16
	ops: rw=reg r=vvvv r=rm | Packed128_UInt16
END

# Code: VEX_Vpdpwusds_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.66.0F38.W0 D3 /r | VPDPWUSDS ymm1, ymm2, ymm3/m256 | AVX_VNNI_INT16
	ops: rw=reg r=vvvv r=rm | Packed256_UInt16
END

# Code: VEX_Vpdpwsuds_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.F3.0F38.W0 D3 /r | VPDPWSUDS xmm1, xmm2, xmm3/m128 | AVX_VNNI_INT16
	ops: rw=reg r=vvvv r=rm | Packed128_Int16
END

# Code: VEX_Vpdpwsuds_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.F3.0F38.W0 D3 /r | VPDPWSUDS ymm1, ymm2, ymm3/m256 | AVX_VNNI_INT16
	ops: rw=reg r=vvvv r=rm | Packed256_Int16
END

# Code: VEX_Vsm3msg1_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.0F38.W0 DA /r | VSM3MSG1 xmm1, xmm2, xmm3/m128 | AVX SM3
	ops: rw=reg r=vvvv r=rm | Packed128_UInt32
END

# Code: VEX_Vsm3msg2_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.66.0F38.W0 DA /r | VSM3MSG2 xmm1, xmm2, xmm3/m128 | AVX SM3
	ops: rw=reg r=vvvv r=rm | Packed128_UInt32
END

# Code: VEX_Vsm4key4_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.F3.0F38.W0 DA /r | VSM4KEY4 xmm1, xmm2, xmm3/m128 | AVX SM4
	ops: w=reg r=vvvv r=rm | Packed128_UInt32
END

# Code: VEX_Vsm4key4_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.F3.0F38.W0 DA /r | VSM4KEY4 ymm1, ymm2, ymm3/m256 | AVX SM4
	ops: w=reg r=vvvv r=rm | Packed256_UInt32
END

# Code: VEX_Vsm4rnds4_xmm_xmm_xmmm128
INSTRUCTION: VEX.128.F2.0F38.W0 DA /r | VSM4RNDS4 xmm1, xmm2, xmm3/m128 | AVX SM4
	ops: w=reg r=vvvv r=rm | Packed128_UInt32
END

# Code: VEX_Vsm4rnds4_ymm_ymm_ymmm256
INSTRUCTION: VEX.256.F2.0F38.W0 DA /r | VSM4RNDS4 ymm1, ymm2, ymm3/m256 | AVX SM4
	ops: w=reg r=vvvv r=rm | Packed256_UInt32
END

# Code: VEX_Vsm3rnds2_xmm_xmm_xmmm128_imm8
INSTRUCTION: VEX.128.66.0F3A.W0 DE /r ib | VSM3RNDS2 xmm1, xmm2, xmm3/m128, imm8 | AVX SM3
	ops: rw=reg r=vvvv r=rm r=imm | Packed128_UInt32
END
